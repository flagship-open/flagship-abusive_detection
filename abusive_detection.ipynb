{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word attention model with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttentionWordRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The embedding layer + CNN model that will be used to perform sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,  \n",
    "                 num_filters=128, kernel_sizes=[3, 4, 5], freeze_embeddings=True, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(AttentionWordRNN, self).__init__()\n",
    "\n",
    "        self.num_filters = num_filters\n",
    "        #self.embedding_dim = embedding_dim\n",
    "\n",
    "        KK=[]\n",
    "        for K in kernel_sizes:\n",
    "            KK.append( K + 1 if K % 2 == 0 else K)\n",
    "            \n",
    "        self.convs_1d = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (k, embedding_dim), padding=(k//2,0)) \n",
    "            for k in KK])\n",
    "        \n",
    "\n",
    "        self.lstm = nn.LSTM(num_filters,\n",
    "                           num_filters,num_layer,batch_first = True,bidirectional= True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def conv_and_pool(self, x, conv,x1):\n",
    "\n",
    "        x = conv(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.squeeze(3)\n",
    "     \n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"#x##:\", x.shape)\n",
    "        x = torch.transpose(x,1,0)\n",
    "        embeds = x.unsqueeze(1)\n",
    "        conv_results = [self.conv_and_pool(embeds, conv,x) for conv in self.convs_1d]\n",
    "        x = torch.cat(conv_results, 0)\n",
    "        x = torch.transpose(x, 1,2)\n",
    "        output,(final_hidden_state, final_cell_state) =self.lstm(x)\n",
    "        x = torch.transpose(output, 0,1)\n",
    "        x = torch.transpose(x, 1,2)\n",
    "        x = F.max_pool1d(x, x.size(2))\n",
    "        x = x.squeeze(2)\n",
    "    \n",
    "\n",
    "        return x.unsqueeze(0)\n",
    "      \n",
    "      \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttentionSentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The embedding layer + CNN model that will be used to perform sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 num_filters=128, kernel_sizes=[3, 4, 5], freeze_embeddings=True, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(AttentionSentRNN, self).__init__()\n",
    "\n",
    "        self.num_filters = num_filters\n",
    "        #self.embedding_dim = embedding_dim\n",
    "\n",
    "\n",
    "        KK=[]\n",
    "        for K in kernel_sizes:\n",
    "            KK.append( K + 1 if K % 2 == 0 else K)\n",
    "            \n",
    "        self.convs_1d = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (k, 2*num_filters), padding=(k//2,0)) \n",
    "            for k in KK])\n",
    "        \n",
    "\n",
    "        self.fc1= nn.Linear(384, 1000) \n",
    "        self.lstm = nn.LSTM(num_filters, num_filters,num_layer,batch_first = True,bidirectional= True)\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.sig = nn.Sigmoid()\n",
    "  \n",
    "    \n",
    "    def conv_and_pool(self, x, conv,x1):\n",
    "\n",
    "        x = conv(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.squeeze(3)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embeds = x.unsqueeze(1)\n",
    "        \n",
    "        \n",
    "        conv_results = [self.conv_and_pool(embeds, conv,x) for conv in self.convs_1d]\n",
    "        x = torch.cat(conv_results, 0)\n",
    "        x = torch.transpose(x, 1,2)\n",
    "        output,(final_hidden_state, final_cell_state) =self.lstm(x)\n",
    "        x = torch.transpose(output, 0,1)\n",
    "        x = torch.transpose(x, 1,2)\n",
    "        x = F.max_pool1d(x, x.size(2))\n",
    "\n",
    "        return x.squeeze(2)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Attention model with bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class entireContext(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):                \n",
    "        \n",
    "        super(entireContext, self).__init__()\n",
    "\n",
    "        self.wordCLSTM = AttentionWordRNN(\n",
    "                       num_filters, kernel_sizes)\n",
    "        self.senCLSTM = AttentionSentRNN(\n",
    "                       num_filters, kernel_sizes)\n",
    "        #self.CLSTM = CLSTM(output_size, \n",
    "        #               num_filters, kernel_sizes)\n",
    "        self.Lin1 = nn.Linear(200,2)\n",
    " \n",
    "    def forward(self, embed, source,max_sents):\n",
    "\n",
    "    \n",
    "        s = None\n",
    "        for i in range(max_sents):\n",
    "            _s = self.wordCLSTM(embed[i,:,:])\n",
    "            if(s is None):\n",
    "                s = _s\n",
    "            else:\n",
    "                s = torch.cat((s,_s),0)    \n",
    "\n",
    "        y_pred1 = self.senCLSTM(s)\n",
    "        #y_pred3 = self.CLSTM(source)\n",
    "        #final = torch.cat([y_pred1,y_pred3], -1)\n",
    "         \n",
    "        y_pred = self.Lin1(y_pred1)\n",
    " \n",
    "        return y_pred\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_grad_norm=5\n",
    "\n",
    "def train_data(mini_batch,source,  targets, sent_attn,  sent_optimizer, criterion):\n",
    "    \n",
    "    max_sents, batch_size, max_tokens, embed_size = mini_batch.size()\n",
    "    sent_optimizer.zero_grad()\n",
    "    y_pred = sent_attn(mini_batch,source,  max_sents)\n",
    "\n",
    "    loss = criterion(y_pred.squeeze(), targets)\n",
    "    loss.backward()\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(sent_attn.parameters(),max_grad_norm)\n",
    "    sent_optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions(val_tokens1, val_tokens2,  sent_attn):\n",
    "    max_sents, batch_size, max_tokens, embed_size = val_tokens1.size()\n",
    "    y_pred = sent_attn(val_tokens1.cuda(),val_tokens2.cuda(),  max_sents)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "embed_lookup = models.fasttext.load_facebook_model(\"kor_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "embed_lookup = gensim.models.KeyedVectors.load_word2vec_format(\"wiki.ko.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Supervised fastText models are not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-1ddc16b379d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membed_lookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_facebook_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cc.ko.300.vec\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv-python3.6/lib/python3.6/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36mload_facebook_model\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \"\"\"\n\u001b[0;32m-> 1142\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_load_fasttext_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv-python3.6/lib/python3.6/site-packages/gensim/models/fasttext.py\u001b[0m in \u001b[0;36m_load_fasttext_format\u001b[0;34m(model_file, encoding, full_model)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \"\"\"\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fasttext_bin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfull_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m     model = FastText(\n",
      "\u001b[0;32m~/venv-python3.6/lib/python3.6/site-packages/gensim/models/_fasttext_bin.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fin, encoding, full_model)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m     \u001b[0mraw_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv-python3.6/lib/python3.6/site-packages/gensim/models/_fasttext_bin.py\u001b[0m in \u001b[0;36m_load_vocab\u001b[0;34m(fin, new_format, encoding)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;31m# Vocab stored by [Dictionary::save](https://github.com/facebookresearch/fastText/blob/master/src/dictionary.cc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnlabels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Supervised fastText models are not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading %s words for fastText model from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Supervised fastText models are not supported"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "embed_lookup = models.fasttext.load_facebook_model(\"cc.ko.300.vec\", encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80797\n"
     ]
    }
   ],
   "source": [
    "print(len(embed_lookup.wv.index2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlwngud3028/venv-python3.6/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n",
      "/home/dlwngud3028/venv-python3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "word2index={}\n",
    "for i in range(0, len(embed_lookup.wv.index2word)):\n",
    "    try:\n",
    "        word2index[embed_lookup.wv.index2word[i]] = i\n",
    "    except KeyError:\n",
    "        word2index[embed_lookup.wv.index2word[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879129\n"
     ]
    }
   ],
   "source": [
    "print(len(word2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert reviews to tokens\n",
    "def tokenize_all_reviews(reviews_split):\n",
    "    reviews_words = reviews_split.split(' ')\n",
    "    tokenized_reviews = []\n",
    "    for review in reviews_words:\n",
    "        ints = []\n",
    "        for word in review.split(' '):\n",
    "            if(word==''):\n",
    "                continue\n",
    "            if(word=='.'):\n",
    "                continue\n",
    "            try:\n",
    "                idx = embed_lookup.vocab[word].index\n",
    "            except: \n",
    "                idx = 0\n",
    "            tokenized_reviews.append(idx)\n",
    "    return tokenized_reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20843\n",
      "3176\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "fr = open('trainset.tsv', 'r', encoding='utf-8')\n",
    "rdrr = csv.reader(fr,  delimiter='\\t')\n",
    "it =0\n",
    "for line in rdrr:\n",
    "    it+=1\n",
    "   # print(sen)\n",
    "    \n",
    "print(it)\n",
    "fr.close()\n",
    "\n",
    "\n",
    "fr = open('testset.tsv', 'r', encoding='utf-8')\n",
    "rdrr = csv.reader(fr,  delimiter='\\t')\n",
    "it =0\n",
    "for line in rdrr:\n",
    "    it+=1\n",
    "    \n",
    "print(it)\n",
    "fr.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12329\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "result=[]\n",
    "fr = open('trainset.tsv', 'r', encoding='utf-8')\n",
    "rdrr = csv.reader(fr,  delimiter='\\t')\n",
    "it =0\n",
    "X_train=list()\n",
    "y_train=list()\n",
    "for line in rdrr:\n",
    "    it+=1\n",
    "    #print(line)\n",
    "    a = line[0]\n",
    "    b = line[1]\n",
    "\n",
    "    if '1' in b:\n",
    "        b=int(b)\n",
    "        b = 0\n",
    "    elif '2' in b:\n",
    "        continue\n",
    "        b=int(b)\n",
    "        b = 1\n",
    "    elif '3' in b:\n",
    "        b=int(b)\n",
    "        b = 1\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    if(a==''):\n",
    "        continue\n",
    "    #print(a)\n",
    "  \n",
    "        \n",
    "    a_t=' '\n",
    "    j=[]\n",
    "\n",
    "\n",
    "    for e in a.split(' '):\n",
    "        a_t +=e+' '\n",
    "        \n",
    "        c_t = list(tokenize_all_reviews( a_t))\n",
    "        \n",
    "        if(len(c_t) <=3):\n",
    "            continue\n",
    "            \n",
    "        if('.' in e):\n",
    "            b_t = list(tokenize_all_reviews(a_t))\n",
    "            j.append(b_t)\n",
    "            a_t=' '\n",
    "        elif('?' in e):\n",
    "            b_t = list(tokenize_all_reviews(a_t))\n",
    "            j.append(b_t)\n",
    "            a_t=' '\n",
    "        elif('!' in e):\n",
    "            b_t = list(tokenize_all_reviews(a_t))\n",
    "            j.append(b_t)\n",
    "            a_t=' '\n",
    "\n",
    "        \n",
    "    if(len(j) == 0 ):\n",
    "        b_t = list(tokenize_all_reviews(a))\n",
    "        j.append(b_t)\n",
    "    elif(len(j) > 0 and len(a_t)>=3):\n",
    "        b_t = list(tokenize_all_reviews(a_t))\n",
    "        j.append(b_t)\n",
    "\n",
    "\n",
    "    if(len(j)==0):\n",
    "        continue\n",
    "\n",
    "\n",
    "   #print(\"############################################\")\n",
    "    X_train.append(j)\n",
    "    y_train.append(b)\n",
    "\n",
    "    \n",
    "\n",
    "fr.close()\n",
    "\n",
    "print(len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !!!! 남포동, 서면, 시청, 부산대에 가시면 우리 시민들 피 빨아먹는 거머리 같은 풍산의 특혜 비리 및 부산시가 무엇 하는 곳인지 잘 알 수가 있어요!! 꾹 들러 부산시민의 힘을 보여주세요\n",
      " ＂文 정부, 김기식 무너지면 참여연대 이어 청와대 무너질까 두렵나＂ 검찰 조사에 이어 관철할 것! 김기식 밑바닥 드러나면, 참여연대의 위선적 밑바닥도 드러나니 두려워하는 것. \n",
      " (contd 교육에서는 a 유형에게는 칭찬만 하는 편이 좋고, b 유형은 칭찬만 들으면 싱겁다고 느끼거나 위선, 가식, 무관심은 아닌지 의심하기 때문에 있는 그대로 말하는 편이 좋다고 한다.\n",
      " (미노스는 오지랖을 물리쳤다. \n",
      " (쌤통이다.\n",
      " .ㅌ 이게모람! 태양열받아 춤추는 인형인가!(상상하는 꼬락서니\n",
      " . 탐라에 합성 가능하신 분 계시나요 로고나 보석들.(개빡침 합성 따위 못하는 인간이라 그리고 있는데 사람 할 짓이 못 되는 것 같습니다 커미션이 있다면 추천 좀 해주세요.\n",
      " .팬레ㅌ 솔직히 병 크러들 키우는데 기획사가 한몫했다는 생각 든다. 플미충떠도 프로미 안 잡음. 잡는 거 힘들지 그럼 공지라도 한 번 해야지. 티켓은 책임질 수 없습니다.이런 식으로 위협이라도 줘야지ㅠ\n",
      " . 괴담. 오토디셉 군대 괴담 넘쳐나지만 그 누구도 과학부의 미스터리와 의료부의 알아선 안 되는 진실들<을 깬 괴담들을 없었다\n",
      "- .저기요. - .네? 윙의 목소리에 딥 고개 갸우뚱하다가 윙 아무것도 아니라며 손목 잡은 손 놓고는 일어나서 어디론가 가려고 하겠지 근데 이 남자, 잘 곳이 없는 건가. 그 생각이 들자마자 무슨 오지랖인지는 모르겠는데 딥 윙 손목 잡아버린다\n",
      " : (6 fta 전체가 국내법보다 우위에 있다? 생쇼를 해라. 세계화에 따라 국내법체계가 국제적 관행을 점진적으로 반영하게 되는 것은 당연하다. 이것은 케이스 바이 케이스다\n",
      " : 원맥소오 헤어스타일 반전(머리 내리고 단발로 자르고!입니.는 개뿔 자컾 만들 엇냐 김라 언니 : 너 내 거! 제일 좋아해! 사랑해!! : 웅 그래 (개에 크 \n",
      " : 최시중 환자복 입고 첫 재판…파이시티 비리 혐의 전면 부인 | 최시중의 휠체어 생쇼\n",
      " ? 오지랖 (손 넓어서 병이라고. \n",
      " ?오지랖 여고생 귀신 한 내 영 역의 전효성 배우님! 배우님 89년생. 맞아요.? 완전 애긔애긔한 전효성 배우님 \n",
      " [ 퍽 고집이 세기도 하지. 하지만 오지랖이 넓은 만큼, 다정하지. 그렇지 않니? 알리샤 마하 아비스, 그리핀도르! ] \n",
      " [2018/04/11 01:17 기준] 4월 21일(토 예매율= 77.5% 4월 22일(일 예매율= 89.7% 수수료 높아질수록 플미충들이 얼마나 떨어져 나가는지 보려고 기록합니다\n",
      " [2018/04/12 00:44 기준] 4월 21일(토 예매율= 76.26% 4월 22일(일 예매율= 89.52% 수수료 높아질수록 플미충들이 얼마나 떨어져 나가는지 보려고 기록합니다\n",
      " [2018/04/13 00:57 기준] 4월 21일(토 예매율= 76.44% 4월 22일(일 예매율= 89.21% 수수료 높아질수록 플미충들이 얼마나 떨어져 나가는지 보려고 기록합니다\n",
      " [2018/04/14 00:50 기준] 4월 21일(토 예매율= 75.95% 4월 22일(일 예매율= 89.13% 수수료 높아질수록 플미충들이 얼마나 떨어져 나가는지 보려고 기록합니다\n",
      " [2018/04/15 00:51 기준] 4월 21일(토 예매율= 76.44% 4월 22일(일 예매율= 89.46% 수수료 높아질수록 플미충들이 얼마나 떨어져 나가는지 보려고 기록합니다\n",
      " [6-1회] 세 걸음과 오지랖 [6-2회] 지금 당장 그렇게 살아야 하는 이유 (cr. 네이버 tv \n",
      " [962] “왜 그렇게 오지랖 넓게 굴어?” ‘쓸데없이 지나치게 아무 일에나 참견하는 면이 있다’를 뜻하는 표현은 ‘오지랖(이 넓다’입니다. “왜 그렇게 오지랖 넓게 굴어?”\n",
      " [daum 블로그] 겅 소농 농업비즈니스모델 개선 교육 모델 성 괴어에 대한 강의 잘 받았습니다: 진흥청에서 실시하는 강소농 농업비즈니스 모델 개선 교육 모델 및 성괴에 대하여 영광 기술센터 대강당에서 농업인 대표들이 100여 명의\n",
      " [] 엑스엘 여러분!! 티켓 양도 사기 조심하세요ㅠ 플미충보다 더한 사기 중!! 친구가 2장산 다고 입금한 뒤 연락 두절. 내일 경찰서 갑니다! 혹시 다른 피해자분들 보시면 디엠 주세요 #엑소 콘서트#원가 양도#엑소#사기\n",
      " [what remains of edith finch] 걷는 게임이라는 장르를 재정리하는 수작. 타파하거나 극복했다고 하기엔 부족하지만, 의미 있는 시도로 충분한 결과를 만들어 낸 것 같다. 이 하나의 게임에 쌓인 게임의 역사가 가히 대단하다.\n",
      " [공지] 양의 지 선수의 빠른 쾌유를 빕니다.//양 선수 부상과 베어즈 응원 행위 연관된 (쌤통 등 트윗 쓰지 마세요// 토. 일 경기 스윕 하면 이글스 6위 됩니다.이글스 파이팅. ://bit.ly/d9dmz4\n",
      " [노무현 위선 작태] 노무현 희망돼지 저금통은 거짓이군요. 80억 모금했다고 거짓 홍보했던 것은 친노종북 민주당이 평소에 잘하는 국민을 속인 거짓 허위 사실였고 고작 4억여 원 모금했군요. \n",
      " [사설] 지역구 예산 받고 테러방지법 내준 새정치연합 2015. 12. 3 민중의 소리. 아주 지대로 야당인 척 생쇼를 하는 중. 일다 테러방지법 통과 대면, 개 가꾸라 당 확실히 인증\n",
      " [소개] 가입인사드려요. 오지랖이 너무 넓다 보니 제 실속을 잘 못 차려서 집사람한테 맨날 혼나는 일인입니다. 부천 팝니다. \n",
      " [소개] 매일 구경만 하다 드디어 가입했네요. 오지랖장인인사드리옵니다!오지랖이여.영원하라.! \n",
      " [소개] 스타일적인 모든 부분에 오지랖이 넓어요. 웹디자인, 검색기획, 음악교육 등 많은 분야에서 일을 해오고 있습니다. 79파. \n",
      " [소개] 안녕하세요.저는 간호학 전공하는 대학생이고 22살입니다.오지랖 넓게 살아보고 싶어서 가입했습니다.!! \n",
      " [어쿠스틱 라이프] 142화의 화두는 오지랖입니다. 최근에 이렇게 많이 공감한 만화가 또 있었나 싶습니다.\n",
      " [외면/정의/위선자] 저쪽이 먼저 공격했으니까. 정당방위였어. 난 잘못한 게 없어. \n",
      " [트친 한정] 탐라의 쫄 바가 컴션받아여!!!(손덜덜심장뱉음 이렇게 해야 정리가 될 거라고 생각했는데 개뿔 일만 복잡해져서 우울해있다가 이미 일 벌인 거 어쩔 수 없지라고 생각하며(말이 많음 컴션받아여ㅕ(이어서 \n",
      " _양도 엠엑셈 양도 구합니다. 장사하려고 양도하는 플미충 안 받아요 . 제발 가게 해주세요 애들이 너무너무 보고싶어요ㅠㅠ. \n",
      " . 그 같은 사람은 다른 사람의 상처에는 극히 둔감하면서, 자신이 상처받으면 대단히 민감해 하죠. 또 잔인한 구석이 있으며 표정이 냉소적이죠. 때로는 남들을 배려하는 관대한 마음이 있는 것처럼 위선을 떨기도 하지만 배신을 쉽게 하며 카리스마가 없죠.\n",
      " . 지금 공가에 레고 회원카드 발급 신청자 100명도 안된다면서요? 명색이 팬들을 위한 미니콘서트라고 홍보 거창하게 낭랑하게 하셨는데 현실은.? 여기저기서 암표충 플미충들땜시 팬들 난리인데 이 사단 어찌하실. \n",
      " ‘드룰 킹’ 여론 조작 사건을 보면 사기와 배신을 일삼는 위선적 정치모리배들의 운명이 비극적입니다. 4.27 남북정상회담까지 거대한 사기극으로 드러나면 남북한 정권이 어떻게 될지 눈에 선합니다. 단테가 말한 지옥 중의 지옥은 사기 친 자들과 배신한 자들의 자리입니다. \n",
      " “ 정부가 2008년 사장을 쫓아낼 때 보인 막무가내 행태를 우리는 뚜렷이 기억한다\"라며 “‘임기 보장’을 내세우며 탄압받는 이미지를 연출하는 것은 위선” \n",
      " “그 사람은 쓸데없이 오지랖이 너무 넓어.” ‘오지랖’은 ‘웃옷이나 윗도리에 입는 겉옷의 앞자락.’을 뜻하는 ‘오지랖’을 잘못 쓴 것입니다.\n",
      " “내 돈이 네 돈이가?” 국민이 낸 세금도 정부에 위탁한 국민의 돈이다. 그 돈으로 기업체 직원 월급 주는 정부는 세상에 처음이다. 노동 및 규제 개혁 없이 자유시장경제체제를 죽이는 정책으로 온. \n",
      " 〈 gsdtv 〉 방송부 민아의 생쇼! 의 동영상에 좋아요 표시를 했습니다.\n",
      " <- 해시로 본인 하우스메이트를 찾아봅시다 장점 필요시 알람 대행 서비스 가능 너 님의 스케줄, 방 상태에 오지랖 x 비흡연자 절제된 소비생활과 공부하는 삶을 배울 수 있음 단점 요리존 못 가끔 집에서 노래 부름 잠버릇이 안 얌전함 쇼핑이나 장 보는 거 별로.\n",
      " <바람> 심사평 오롯이 담긴 한국적 정서 위에 역사와 판타지를 절묘하게 조합해낸 작품입니다. 수려한 작화와 능수능란한 감정 선의 표현으로 이견의 여지없이 대상으로 선정되었습니다. 많은 이들을 감동시킬 수작으로 기억될 것입니다. \n",
      " <오지랖 아짐의 끝없는 이재명 알리기> 최악의 정부 때문에 우연히 알게 된 이재명 시장은 바른 정치인의 표상이다! 이재명만이 답이기에 어딜 가나 이재명 시장 덕분에 혜안을 얻게 됐다고 말한다. 다행인 건 평판이 엄청 좋다는 것!\n",
      " <오지랖 아짐의 명분 있는 더 민주 홍보> 방금 장 보고 오다 새빨간 명함 한 장을 받았다. 묻는 척 그분을 잠깐 불러서 더 이상 새누리 뽑으면 안 된다고 역설했다. 위안부 사실까지 교과서에서 삭제한 朴 정권이라고!\n",
      " … <홍찬식 칼럼 - 젊은 세대의 위선> 민영화 반대 철도노조 파업 지지하는 젊은 세대들이 승자독식의 세계인 프로야구를 좋아하는 것은 이율배반이라고 하는 기가 막힌 글 \n",
      " ★윱사내 오늘의 명대사 2★ 최심덕 : (완벽한 결말에서 헌신짝처럼. 이 부분에서 거의 오열 윱 사내 : 넌 그냥 네가 해야 할 일만. 울지마!!(개빡침 울지 마. 울지 마. 넌 그냥 네가 해야 할 일만.(대사 다 치고 뽀뽀\n",
      " 04 아울러 자해 요러에요! 양성애자 (애인 x 사진은 안 올라가요 일상/우울 틧 많아요 병원 x 한 남 걸러요 친해지기 쉬워요ㅜㅜ 마구 다가와 조요 흔적 잡아요 \n",
      " 1. 사실 처음 공개되었을 때 아.음.스읍,,,베쯔니.,,,.,,;;이런 느낌이었으나. 왜냐면 나 같은 오지랖 넓은 아줌마에게는 당장 이발소 데려가고 싶어지는 타입이기 때문이다. 게다가 그 카우보이모자가 적잖이 충격이었는데 \n",
      " 1. 원칙을 세우고 2. 내 세금을 되찾고 3. 주진우를 살리기 위해 8000원 주고 이 영화를 봤고 아깝지 않다. 꼭 흥행해서 각하의 발목을 잡길 바란다. \n",
      " 1. 정산 - 카메라 켜진지 모른 상태에서 멤버들과 장난 식으로 이야기한 게 뭐가 잘못? 받을 건 받아야지 정산 얘기 안 하는 연예인 있나 2. 번호 - 팬 조롱은 개뿔 사생들이 자꾸 연락하고 찾아오니까 그거에 스트레스받아서 하는 말 그리고 일반인 번호가 아니라 자기 번호 아무 문제 없음\n",
      " 103> 문제는 진정성입니다. 나 후보의 피부 주치의 청담 피부클리닉 의사가 언론에다 이렇게 말했더군요. ‘피부는 화장을 벗겨봐야 안다.’ 그렇습니다. 거짓말은 말이 아닙니다. 위장과 위선은 결코 시민을 위한 정책이 될 수 없습니다.\n",
      " 11월까지 기다리기 싫어서 그냥 와버렸어요 . 슬로는 개뿔 지금 꾹 크릴 판매하고 이것저것 하는 갈피의 망친 구합니다 ?( ·`?´· ?? \n",
      " 16년 9월 함태호 오뚝이 명예회장이 작고하면서 주식 3500억 원을 남김. 상속세가 절반. 그들은 세금 1700억을 내기로 합니다. 이게 정상입니다. 진짜 애국이고요. \n",
      " 170218 윙즈콘 b03 구역 22열 n 번 원가 양도해요. 갑자기 첫 콘 못가게됬어요ㅜ플미충들 때문에 여기다 양도해요 양도 원하시는 분 알티 후 폴로 해주세요. 알티 추첨으로 하려고 해요!! 다음 주에 추첨할게요!\n",
      " 200가지 국민들의 세금으로 이런 특혜를 누리고 일도 제대로 안 하면서 제왕적 대통령. 세균아 그동안 너는 뭐 했냐??혼합형 정부 의원내각제 꿈도 꾸지 마 국민들의 바라는 개헌은 4년 중임제 국회의원 소환제 뿐 \n",
      " 2016.4.5 , 과태료도 정치자금으로 지출 2012.2015년 총 16건, 714,540원 중앙선거관리위원회, 이 같은 정치 자금 사용은 “명백한 위반에 해당한다” 범칙금을 우리가 준 세금으로 내다니!!! 김성태는 국회의원 직을 사퇴하라!!!\n",
      " 21살 nct에게 늘 을이고 싶은 사람 티켓팅 잘 하는데 허구한 날 구해놓은 표 중고로 양도하는 사람입니다 드림 가장 좋아하지만 배척 없어요 마음 정도만 남겨 주시면 제가 가겠습니다 제 키워드는 향도 충, 마음에 충, 관을 충, 구독 중 저와 트친 해 주세요 \n",
      " 22. 진중권, 조국처럼 대학교수나 되면서 왜 인정 못 받고 국민에게 지탄받는지 아시나요? 머리에 든 거 없으면서 상대방 존중치 않고, 깐족거리며 품위 떨어지는 망발 일삼기 때문입니다. 위선자들이기 때문입니다.\n",
      " 2가지 방법 (사진 참고 yes24 메일 ticket-cs@yes24.com로 신고 플미충들이 샤워들의 예매내역 도용해 억울한 피해자가 발생할 수 있으니 예매내역 꼭 가려서 올리기 \n",
      " 3/10 “위선: 언론사 임원과 전문가들은 일반적으로 공무원과 심지어 기업 임원들에게 하듯이 철저하게 행동 규범을 적용하지 못한다. 예를 들면 경제 지면 칼럼니스트에게도 재산 공개를 요구하지 않는다.” (톰 플레이트\n",
      " 4기 뽑고 티켓팅해줘 플미충없게 4기 뽑고 티켓팅해줘 플미충없게 4기 뽑고 티켓팅해줘 플미충없게\n",
      " 53. 2부 [에픽] 나의 어른, 너의 틀딱 : 기회로 가득 찬 폐허 편이 올라왔어요. 팟빵: 아이튠즈: \n",
      " 82쿡에서 성괴에 관한 글이 올라와서 댓글난 이 콜로세움이 됐는데 그중에서 인생 치트키 써서 살면 안 된다는 댓글 보고 개폭소\n",
      " cyphers [ jack the ripper ] - persona여 ㅡ 위선자, 오늘은 몸이 가볍군. 똑같이 돌려주지. 날만 상하겠군. photo by. 이무기 님, 백나일 님께서 고생해 주셨습니다! \n",
      " e11, e12시청률 13.8% 1위 선두 e.11 (12.1%, e.12 (13.8%의 시청률(전국기준을 기록했다. 앓이 다음 주가 더 기다려지는 t.t \n",
      " exon0509 ㅠㅠ.ㅌ트위터가 티스토리 이미지 링크를 막는군요.부순ㄷ다.(다섯ㅂ번시도.( 개빡침. \n",
      " h 수작 사전 차단 \n",
      " html에서 form submit을 할 때 따닥 두 번 누구면 같은 트랜잭션이 두 번 실행됩니다. 그걸 방지하려고 디비에 키값 넣고 받아오고 생쇼를 하죠, 하지만 aop로 세션으로 장난치면 전체 소스 수정 없이 가능하죠\n",
      " one ok rock - one by one one ok rock 최 새 곡 현재 밴드 꼬락서니를 봐선 절대 안 바뀔 듯 이곡 너무 서양 포하코스러워서 좋아함 \n",
      " qa 5편 민천도 세금공제가 되나요? 물론입니다. 법령에 따라 10만 원까지 공제로 되돌려 받으실 수 있습니다. 납부약정 : 계좌 : 농협 036-01-131970 \n",
      "  [개빡침주의] 전국여성연대 일촉즉발 전쟁 부르는 키 리졸브 중단하라. avi \n",
      "  강정에서 필요한 것들. 반팔 티,운동복 바지, 마스크, 양말, 칫솔치약,샴푸, 수건, 라면, 김치, 쌀, 파스, 소독약,붕대, 밴드, 보조배터리, 멀티탭 등. 697-370 서귀포시 강정동 4417 강정마을회관 064-739-2067\n",
      "  민주를 팔아 반역을 하고, 환경을 팔아 국책사업을 훼방하고, 평화를 팔아 적화통일을 기도하고, 인권을 팔아 반역자를 민주투사로 둔갑시키고, 민족을 팔아 김정일에 굴종하는 종북좌익세력의 위선은 이제 종식될 때가 되었습니다.\n",
      "  박원순 시장은 반값 등록금 실현하고 택시기사님들 카드 수수료 부담 줄여주고 우리 아이들 도시락도 챙겨주고, 대자본에 맞서 지하철 요금을 안 올리기 위해 끝까지 싸우고, 대 권력에 맞서 전두환에게 밀린 세금을 받기 위해 싸운다\n",
      "  오지랖 넓은 언니, 공주 같은 동생 음 적절한 중간제목이네요.  부산일보 기사 저와 제 동생 \n",
      "  음반 안 하고 떠난 당신에게 왈 쌤통  종로 3가 동대문 방향 고장차량으로 정체!!!\n",
      "  생쇼 하는 91라인?  둘이 생쇼.  에이프도 없어 동운아ㅠㅠ  뷰티가 없어 미르야ㅠㅠ  뷰티 찾는 동운이  \n",
      " to 교육부 나경원의 해명이 사실인가요? 법정부담금을 사학 법인이 내지 않으면 시도교육청이 대신 부담해야 한다는데, 국민의 세금으로 대납하는 것인가요? 정말로 불법이 아닌가요? 교육부의 입장이 궁금합니다.\n",
      " 가방 이야기 나오기 전에도 다른 아줌마가 고양이 어쩌고저쩌고 욕하더니. 내가 이동장에 안 넣은 것도 아니고 쯔는 버스 타고 한 번도 안 울었다. 꼭 들리게 오지랖 떨어야 하나? 여전히 고양이에 대한 인식이 바닥이라 씁쓸하다\n",
      " 가부장제는 권력구조다 여성 억압 뿌리뽑아야 한다 티젠 x 한남동 x 성림들 우리같이 랟펨합시다요.7 팔로해주심 맞팔 맞팔! 흔적 남겨주심 찾아갈게요\n",
      " 가온차트 원가 양도해요 34구역이고 다발은 가온 전날하고 현장에서드려요.(플미충방지 +follow 해주세요! 아이 하트 투표 알티하는 계정이니 보기 싫으시면 뮤트 하세요 뎀, 멘션은 블록 합니다! \n",
      " 간단히 적어보는 후기 아이카츠러쉬와 틀딱곡들로 스타트를 끊어서 꽤 만족스러웠던 초반 그리고 리믹스로 분위기를 띄우는 중반 소류님과 포로님의 따봉 날릴만한 세토리 리믹스 계도 굉장히 좋았음 오아타게 치기 애매한 것 빼곤 분위기도 괜찮았음 그리고 다시 리믹스로 스타트 끊고 후반\n",
      " 감추어진 것은 드러나게 마련이고 비밀은 알려지게 마련이다 지금 위선적으로 행동하여 감추어져 있는 행적이라도 마지막 심판 때에는 반드시 드러날 것이다 또한 이 말씀을 제자들의 복음 선포와 연결해 생각할 수도 있습니다\n",
      " 갑자기 껴서 오지랖 좀 펼쳐보면. 아마 2010년 때 라코스테 패션쇼 때인듯해요.; ㅎㅎ\n",
      " 같은 사이트 공모전 최우수작 화병 신공. 이건 무림맹 문관이 문서 정리하다가 발견한 화기를 다스리는 명상법(심공을 익혀, 상사한테 갈굼 당할 때마다 이걸 되네의 어느덧 내공 고수가 되어 있다는 이야기. 거기에 무협+추리로 유머러스하게 재밌다.\n",
      " 개빡침을 실트로 푸는 우리 팬덤 순하네\n",
      " 개뿔 휴덕 할 수 있긴 뭘 햌 그래. 이십 년이 넘었다. 이십삼 년 차인가. 데쿠의 마음은 갈대와도 같으니. 며칠 지나니까 보고 싶어 죽겠다.ㅠㅠㅠㅠㅠ 하지만 내 자리 없겠지. 보고 싶은 것만 보련다\n",
      " 게다가 오지랖 넓고 부지런하신 모아님 그들과 이야기하면 막혔던 하수구가 뚫리는 기분이다. [한국병 꽃] 미국으로 건너가 개량종이 로열티를 물고 심는다. 라일락이 미스킴이었다네요. \n",
      " 결국 거머리 같은 디멘샤 못ㅅ떼어내고 지쳐버린 사장ㅁ밈 ㅌ (대ㅊㅔ다 디멘시아는ㄴ마냥 좋아할ㄹ것 같다 \n",
      " 계정에는 유효기간 지난 영장 들이밀며 공권력으로 압박하고 미러링 유튜브는 부당하게 경고 먹여서 스트리밍, 업로드 못하게 만들고 여자들이 목소리 못 내게 하려고 들이 애쓰는 게 보이네 ㅎ 연대하고 같이 싸우고 싶어서 시작했는데 세상에 나 혼자인 것 같은 기분ㅜ.ㅜ\n",
      " 고생 많으셨습니다 오지랖 태평양 안승일 굴린 빵슈 입니다 . 무멘팔 멘션 마음 팔 모두 받지 않고요 따로 제가 찾아가겠습니다 . \n",
      " 고척 방탄 얼굴 볼 수 있는 데로 날짜 수능 이후로, 고3 팬들 무시 난 돈 담부턴 가입비를 비싸게 받아 플미충 없애게\n",
      " 골든디스크 10일 (수 티켓 원가 양도합니다 알티와 멘션만 달아주시고 디엠은 보내지 마세요 ㅠㅠ 디엠 보내면 뺍니다. - 친구 대신 양도하는 건데 오늘까지 입금이라 친구가 안돼서 양도합니다 ㅠㅠ 플미충 방지해 팬 인증 당연히 받아요 아미라 아미 우대합니다,, \n",
      " 공감합니다. 이중인격자의 특징이자 그분의 가장 장점 = 거짓과 위선!!!\n",
      " 공식이 유아 퇴행 조장함 우린 더 이상 빻지 않음 \n",
      " 공짜 인생, 불쌍타!  장물누님답구먼! “: [속보] 박근혜, 새누리당 비례대표 1번/ 참 가지가지도 한다. 동료 의원들은 희생 강요하며 다 잘라놓고 자기는 비례대표 1번???\n",
      " 관인이한테 하는 꼬락서니 보고 트롯 대부 채 사장이 싫어졌어. 태사자 싫다 싫어.\n",
      " 괜히 단체로 뭉쳐 다니니까 뭐라 하면 어쩔 건데?? 그런 심리로 저러는 거 같은데;; 나잇값 못하는 사람인 것 같네요. ㅠㅠ 액땜일 거예요 훠이\n",
      " 굥수 뒤태도 같이 앓아주 시 조 ⊙♡⊙ (오지랖 \n",
      " 구해요 구해요 스탠딩 원가 양도를 구해요 플미충 꺼지시고요 원가 양도해주실 천사님을 찾습니다. 직거래 원하고요 아니면 배송지 변경해주셔서 티켓이 오는 즉시 제가 입금해드릴게요. 사기 치려는 게 아니라 사기당할까 봐 그래요ㅠㅠ 대신 제 핸드폰 번호 드릴게요!!\n",
      " 국민 눈높이 볼 때 대승적 차원 아주 잘 된 일. 세금 절감에도 고무적 매우 환영.\n",
      " 국민 세금을 횡령해서 생활비로 사용한 사실을 스스로 자백했는데도, 처벌도 받지 않고 버젓이 정치를 하고 있는 사람이 있다. 유력 정치인이라고 해서 공금횡령을 저지르고도 처벌받지 않는다면 정의라는 단어는 설자리가 없으며, 공금횡령은 관행으로 치부될 일이 아니다\n",
      " 국민이 충격! 정치인 군대 빼려고 하는 수작은 많이 봤어도 아들 군대 받아달란 탄원서 처음 이낙연 후보자, 군대 보내달라 탄원서 공개. 평생 고통·부끄러움에서 못 벗어날 것 | daum 뉴스 \n",
      " 그 금주령은 누가 내리는 건가요? 어기면 어찌 되는데요? 오지랖 넓게도 참 궁금하네요\n",
      " 그날 약속이 잡혔는데 백퍼 플미충 있을 굿 같아서 원. 가. 양. 도해요 꼭 팬분들이 가셨으면 좋겠어요. 10일 날 자리 좋은 건 아니에요 ㅜ 댓글이 너무 많은데 누구한테 양도를 해야 될지 몰라서요 11시에 뎀드릴게요 \n",
      " 그동안 위선자들한테 열받았는데 오늘 내속이다 시원. 고맙다 얘들아? 이재명 “최성, 세월호 배지 뗐다 붙였다”···과도한 네거티브 논란 : 네이버 뉴스 (출처 : 서울경제 | 네이버 뉴스 \n",
      " 그래봤자 나중에 자기들을 어떻게 하겠냐는 식이겠죠. 포털 방치하면 문재인 낙선 후에 촛불폭동 시즌 2 필히 기획합니다. 486의 자기 기만적 위선이 섞인 패권주의는 엄청나게 고질적인 것 같습니다.\n",
      " 그보다 다른 이의 감성을 이성적으로 대하려고 하시니, 답답함이 느껴지네요. 필요 이상의 조언하는 분을 보고, 보통 오지랖이 넓다고 표현하죠? 다른 이의 입장을 좀 더 파악하는 능력이 필요하시겠[긴 글]\n",
      " 김한종 <역사 교과서 국정화, 왜 문제인가>, 선한 사람들의 악마적 본성 <쌤통의 심리학>, 지도에 바치는 오마주 <지도 위의 인문학>, 연속선 위 한 점 <외톨이 선언>을 주목도 서로 꼽습니다. \n",
      " 꼬락서니가 사투리라는 걸 방금 처음 알았다!\n",
      " 꼭 오늘 탐라 다!! 복습하셔야 해요!! (오지랖 견과류 (라 님 : 저리 가 \n",
      " 꼭 필요합니다! 결혼도 하고, 세금도 내고, 군대도 가고, 면허도 따고, 공무원 시험도 볼 수 있는데. 투표만 못합니다.는 국민의 지위를 인정하는 것입니다. 18세도 대한민국 국민입니다 \n",
      " 나 봉사활동 좋아해 . 내 홈피 오면 유니세프도 후원하고 그냥 못 지나쳐 =ㅁ= 성격이 오지랖이 넓을 건지 도와줘야 돼\n",
      " 나달링 성처뤼 캡 와 나보다 오지랖 넓은 애 첨 봐서 \n",
      " 나도 동감합니다. 여기 나온 엄마 부대 정말 무서운 종북세력인 듯 어떻게 이번 북한 수소폭탄 사전 징후 포착 못한 국정원장 물러나라는 시위는 안 하는지 그렇 국가 생각하는 사람이 완전 위선자 집단!\n",
      " 나도 이거?. 스펙터클하게!!!?((는 개뿔.\n",
      " 나라 꼴이 꼴이 아닙니다. 거머리 같은 친일세력이 사라져야 도움닫기라도 할 텐데 권세만 잡으면 국민의 안녕은 안중에도 없으니. 시국이 이러니 노통의 빈자리가 절실해집니다. \n",
      " 나의 피는 초록색이며, 두뇌는 무엇보다 강력하다. nvidia.는 개뿔이고 용단에서 아르바이트하는 다코야키입니다. 집 덕이에요. \n",
      " 난 느낄 수 있어. 너는 나, 나는 너. 우린 하나니까. 우리는 이미 미쳐있다. 너의 행동은 그저 위선일 뿐이야. 너 자신을 속여가면서 말이지. *허탈한 웃음을 짓는다.* 난 너와 천 년 동안 이곳에 처박혀 있을 생각은 없어!\n",
      " 난 보통 뇌구조 막 여러 개 틀 딱 나뉘어서 어떤 사람이 하든 형식이 다 똑같아ㅋㅋ 그게 더 정확한 거 같아 근데ㅋㅋㅋ\n",
      " 난 치킨 먹고 싶다 했더니 닭 뼈 주는데.? d 클래스가 먹다 남겼다는데 너냐.?(개빡침\n",
      " 날이 많이 차졌어요.아프지 마시길. 목감기 조심하시고 좀 마르신 거 같은데 오지랖 쩔게 새우젓은 걱정이 됩니다 큽;;;; 몸 건강 몸단장 19일까지 살 좀 찌세요! 4rang요.헿헿 \n",
      " 남구 한-그냥 평타.? 개 삐삐 시삐 이런 거.? 근데 얜 이렇게 말고 논리적으로 욕하는 거 잘 할 것 같다. 허가 표-생각보다 패드립 잘 침 대신 더-눈빛으로 모든 걸 말할 수 있음 레온-침묵으로 대답한다. 그래서 아무도 뭐라는지 모르는데 그냥 위압감만 느껴짐\n",
      " 남민우: 카드로 긁어서 만원 그대로 가져옴 진기: 쓰는 법 몰라서 지폐 보기만 하다가 눈 딩그래짐 용포를 입고 계신데 여기에 계시죠 그 아니 이분.((말잇못 강윤 옷: 얜 내 꼬락서니 보고 자기 돈도 내어줄듯싶다\n",
      " 내 오지랖을 기대한다니 네네. 알겠어요. 경선인단 모집 마지막까지 안심이란 없어요. 후회는 말아야 하는 것처럼. 내 오지랖을 몽땅 바치겠어요!! \n",
      " 내 통장을 받칠게요 흑흑하니까 진짜 팬들 통장이 너네 꺼라고 생각하는 거니? 그거야 너네가 내 새끼들한테 잘해줄 때고 이젠 아니야 너네 주머니에 내 돈 들어가는 꼴 못 본다. 얘들아 소속사랑 나눠가지는 꼬락서니 못 보겠으니까 계좌번호 디엠 줘\n",
      " 내가 이래서 팬싸를 못가 생명의 위협을 느껴서.는 개뿔 못 들어가게 하니까 못 간다 \n",
      " 내가. 내가 미안해ㅐ. 현생에 치여서 컴퓨터도 못 키고. 급하게 그린다고 채색은 개뿔 인피도 나고,. 그렇지만 츠카사 널 사랑한다 생일 축하하고 오늘 맛있는 거 맘껏 먹어ㅜㅠㅠㅠㅠ!!! \n",
      " 내일 6.4지방 선거 투표하시고 인증숏 보여주시면 내일 하루 모든 책 (국내외 서적 10% 할인합니다 (고작 10% 할인입니다.;;;. 사전투표하신 분들도 포함입니다. \n",
      " 너 우 오지랖이 넓은 게 아닌지 반성 중입니다.\n",
      " 너는 아무리 떠들어도 내가 보기에 위선자다. 곽노현 교육감에게 사과하기 전까지는. 사과하거라. 안 그러면 좋아하는 비행기 타다가 떨어진다.\n",
      " 넌 following 한 여자들 다 아는 여자들이야?? 뵨 태어냐?? 이상한 사람들도 잔뜩 follow 했어. 예전부터 오지랖이 넓긴했지만. \n",
      " 네 맞아요 근데 베토벤은 맘아픔<<<개빡침 이거라서 막 괴테하고 팔짱 끼고 산책하다가도 괴테가 지나가는 궁정 귀족들한테 예를 갖추면 거기 끼어들어 망나니 짓거리하고(그래도 귀족들은 베토벤한테 잘해줬습니다 그랬던 게 모에 합니다 (??\n",
      " 네. 개뿔 아무것도 없지만 오늘 계정 팠지만 정우 정선 파는 분들과 친해지고 싶어서 하는 트친소입니다 답멘션 빠릅니다 친화력 좋아요(? 흔적 남겨주시면 갈게요! 같이 정우 정선해요!!\n",
      " 네가 내 영양소 섭취에 오지랖을 꾀하길래 추가했다. \n",
      " 네가 뒤로 밀린 건 고객 업무에 대란 성과 처리가 비효율적이기 때문에 발생한 것이므로 성괴 측정에 대한 방법을 바꿔야 함\n",
      " 누락된 세금 등을 납부한 후 남는 돈을 회장이나 가족을 위해 쓰지는 않겠다고 하면서 유익한 일에 쓸 수 있는 방도를 찾아보자 하였습니다.” [한겨레 단독] 이건희 차명계좌 4조 4천억 싹 빼갔다 \n",
      " 늘 물러나는 걸로 책임을 지니 책임지고 잘못을 수습해본 경험이란 게 존재하지도 않고 책임회피나 복지부동에 능한 사람만 생존하는 게 체계로 굳어진 거겠죠. 책임감은 오지랖이고 동료에 대한 민폐로 여겨지니까요.\n",
      " 늦게 주무시러 갔던데 왜 그리 일찍 일어났는지. 형제님 그러다 일하는데 지장 갑니다? 아, 걱정돼서 그러는 건 아닙니다. 그냥 늙은이의 오지랖이라 생각하세요.\n",
      " 닌텐도 스위치용 프리 파라 올아이돌 퍼펙트 스테이지 발매 결정. 특전으로 시온, 히비키 한정 카드 세트(다운로드 코드 포함 등. 특전은 추후 추가 공개 예정. 3월 22일, 세금 제외 5980엔.\n",
      " 님들 플미충들 멜론 티켓에 신고하면 취소표 처리가 될 수 있다고하네요ㅠㅠ 근데 좌석표를 어찌 알아내느냐ㅎㅅㅎ.\n",
      " 님의 오로지 정의를 향한 신념으로 꽉 찬 당당한 트윗에 찬사를 아끼지 않고 있습니다만은 안철수 지지 호소만큼은 공감할 수 없군요 안철수 씨는 안철수를 있게 한 안철수 신화의 거짓 위선 의혹에 당당히 해명해야\n",
      " 다시. 빻은 저와 첸른을 해주세요,. 그림 그리고 글은 짧게 또 엄 그냥 여러 가지다 하고 취향이 정말 매우 대단히 빻았으니 유의하고 와주시고 저와 웹첸 온 체 띵딸 여ㅅ기나 캣플 도 그 풀 노나 먹으실 분 환영해요 \n",
      " 다정한 아저씨 세계 최고. 상냥한 연상 좋아해. 근데 뭘 가르치려고 드는 게 아니라 나잇값 못 하고 귀여우면 더 좋아해. 돈이랑 재력은 이미 있지? 나만 있으면 되겠네? \n",
      " 단 원고 세월호 유가족들은 서울시민이었습니까? 서울시민도 아닌데 박원순이 분향소 만들어주고, 광화문광장에 천막 치는데 들어간 돈 서울시민 세금입니다? 오 하나마 호로 가는 수학여행 세월 호로 가게 만든 경기도 교육감이 책임져야 하는데 국민 세금으로 보상까지 받았습니다.\n",
      " 담배 십 년 피우셨댔죠 네 ㅡ 그쪽이 십 년 동안 담배를 피우지 않았더라면 밖에 저 외제차를 살 수 있었을 텐데요 ㅡ 저는 얘 남자친구인데요 저 차 주인이고요 오지랖은 \n",
      " 담뱃값으로 삥 뜯은 돈 최순실과 같은 연놈들에게 세금을 퍼주었었다 담배는 즐기고 술은 즐기지 않지만 그 어떤 것이든 서민의 등 꼴을 빼먹는 것에 반대한다 최순실 같은 더러운 것들과 대기업에게 일감을 몰아주었던 모든 일들 우리는 잊으면 안 된다 \n",
      " 당신을 속인 위선자였던 나를 용서해주겠나요? \n",
      " 대기업에서 강의에 대거 등록하며 잘 보이려 애썼으니 삼성 불법을 눈감아주는 거지 그러니까 삼성 백혈병 참사에 도 죽어도 삼성 불매운동 안 하는 거지. 위선자들 촛불집회를 문화제로 몰고 가서 망쳐놓고 친삼성정권 세우고 친구 삼성도 국민 눈치 못 채게 몰래몰래 잘도 한다\n",
      " 대통령님 사랑해요 5년 동안 세금 잘 내고 바르게 살겠습니다(물론 그 뒤도. 예. 달님은 오늘도 레전드 갱신 반짝반짝-☆ 문재인 베스트 충성 충성.7 \n",
      " 더 건강하게 먹으려면? 1. 생 마늘을 통으로 먹는다. 2. 구워 먹는다. 3. 생 마늘을 빻아 먹는다. 정답은 뭘까요?? \n",
      " 더 나은 세상을 꿈꿉니다. 전에는 이거저거 많이 함. 오지랖짱. 닭강정 집 딸/사회운동/인권/사랑/연애/행복/패션 \n",
      " 더불어민주당 국민경선에 참여하세요! 국민 여러분에게 드리는 숙제 3 ( 준비물:  1 무조건 국민경선에 참여하기 2 가족 친구들과 함께 참여하기 3다섯 명의 지인과 공유하기 1811-1000 1811-1004 \n",
      " 도사님 이분(  소개 글이랑 트윗 봐주세요. 오지랖 넓게 이런 부탁드려서 죄송합니다.\n",
      " 동 감동 감 미야카게 생각할 때마다 같이 튀어나오는데 너무 좋아서 안 쓸 수가 없음 미야가 토비 오한테 수작 부릴 때, 어를 때, 그냥 귀여워할 때,,, 어디든 너무 찰떡인 명대사라 \n",
      " 동료의 원인 은수미 의원에게 삿대질과 남의 당 공천권까지 운운하며 오지랖을 떠신 김용남 의원은 지역구가 수원시병입니다 백남기 선생 참사 땐 언론 통제도 하고 싶었던 살이 인문 어때 허문도 재림임돠 \n",
      " 동영상 [질문 꼬락서니 좀 보소] 문재원 하수인 같은 시사자키 정관용의\n",
      " 둘은 오코노미야키 맛의 감자스낵과 초코맛의 야 이 하시(교토 명물 화과자를 골랐어요. 시우민의 초코 사랑은 여기서도 발휘되네요 래. 그냥. 혹시 궁금할까 봐 오지랖 \n",
      " 뒤에서 할 짓은 다하고 깨끗한 척 나는 아닌 척 3선을 노리는 뻔뻔함. 양심이 조금이라도 있으면 그만하자 그동안 허튼짓해서 서울시 세금 많이 날려 묵었다. \n",
      " 드디어 의사들께서 전문가로서 적극적으로 나서는군요. 분노의 거센 파도가 위선과 거짓투성이의 암흑 세력을 삼켜버리겠군요. 마치 바다가 갈라졌다가 합체되는 모세의 기적처럼. \n",
      " 드세요! 작년 9월 함태호 오뚝이 명예회장이 작고하면서 주식 3500억 원을 남겼습니다. 상속세가 절반입니다. 그들은 세금 1700억을 내기로 합니다. 이게 정상입니다. 진짜 애국이고요. \n",
      " 듣는 편이고 오지랖이 넓어서 참견이 많다, 나이에 맞지 않게 어리광 부릴 때도 있지만 그만큼 어른스러운 면도 있다.\n",
      " 등 비선 실세가 주도한 사업 관련 자료 정보공개 요구에는 비공개 방침을 통지했습니다. 국민 세금으로 운용되는 가장 기초 문서가 공개되면 국가의 중대한 이익을 해친다고? \n",
      " 딱 잘라 말하는 하얀이 보고 아무 말없이 볼 것 같아요. 자기가 나잇값 못한다고 생각했었는데 그렇게 안 보는 건가? 하구. ㅠㅜㅠㅜ ( 폰 주워드림  위에 올라타서 배부터 쓸면 손목 잡을 것 같아요. 내, 삐짝 말랐는데. 하면서 신경 쓰다가\n",
      " 또 누가 있지 \n",
      " 또 접니다 오지랖 아베다 비컬리 추천합니다.\n",
      " 라디오 퇴근 옹. 비가 와서 영상 포기ㅠ 이놈 오지랖 또ㅠㅠ 옹이 미안ㅠ 그러 공 고마워. \n",
      " 리얼미터 여론조사 3월 7일 내용입니다. 마지막에 문재인 단독 나옵니다. 리얼미터 대표와 파파이스 김어준이 대학 동기. 김어준은 문파. 김어준 연봉이 1억 3천. 진짜 알아갈수록 더러운 문재인 위선자. 청산 대상은 무능력 문재인.\n",
      " 릭 모 팝니다. 싫은 애 없이 다 아껴요 요즘 서머 특히 아낍니다 릭모의 빻은 sf 감성을 잘 숙지하고 즐기고 있습니다 마음이나 알티 해주시면 덕질계 위주로 찾아갈게요 멘션두 사랑해요.!!.! \n",
      " 만 통당은 한반도 비핵화와 핵에너지를 줄이라고 떠들면서 북한의 핵무기에 대해서는 말 한마디도 없다가 3월 서울에서 열리는 핵무기 없는 세상을 만들자는 회의에 대해서 대항행동을 선언하는 것을 보면 이들에겐 거짓과 선동과 위선만 있을 뿐이다.\n",
      " 만우절 따라간다고 꼬락서니 이런데 쿠페님이랑 맞팔함 \n",
      " 맞습니다, 마치 저번 슴티움에서 샤워 분들이 보여주셨던 어마어마한 플미충 잡기처럼요.\n",
      " 맞아요 여자에 대한 기대 시선의 기준치가 높죠. 비만해서 건강을 걱정하는 것도 오지랖일 판에 그걸 못생겼다고 비하하는 것도 심하고요. 그런 당연하게 일어나는 일을 하지 말아야 하는 걸로 인식하고 게다가 예쁘다고까지 하는 상냥함\n",
      " 맨 앞은 그림 시작은 개뿔 오너 구상한다고 그렸다가 그 뒤로 안 그렸다 한 2년 전 글, 앞쪽늗대는 그림 시작하고 나서 그린 거, 한 1년 전 \n",
      " 멍하니 네 침대에 걸터앉아 황망한 표정으로 창밖을 바라본 지 벌써 몇 시간. 마치 세상에 버려진 듯 허망하게 축 늘어져 앉아있는데 영 힘이 나질 않았다. 당연하지. 내 꼬락서니가 지금 이런데 어떻게 힘이 나겠어. 네가 집에 들여주지 않았다면 개꼴을 면치 못했을 텐데.\n",
      " 메가를 나온 이후로도 바뀐 게 없다고 좌절할 필요 없다. 세상은 점점 달라지고 있다. 생리컵을 이야기할 때 과거처럼 그런 걸 어떻게.라고 묻는 사람보다 뭐가 더 쓰기 좋아?라고 묻는 사람들이 많다. \n",
      " 메이 차 구로는 메이어가 솔직하지 못한 탓에 매일 맘과 다른 막말 뱉고 있으면 메이어 안에서 호랑이 같은 게 어슬렁 걸어 나와 차야 한 테 몸 비비고 있어서 에 이르 개빡침\n",
      " 메인 상단 오전 07:13 베대에 빻은 댓글 다수 일어나신 분들, 부탁드려요! 백악관 (출처 : 연합뉴스 | 네이버 뉴스 따봉 부탁! \n",
      " 메인 하단 오전 09:05 네댓 적으니 기쁨조, 접대 등 빻은 댓글로 부탁드려요!! 13년 만의 평양 공연…선발대 오늘 전세기편으로 방북 (출처 : 연합뉴스 | 네이버 뉴스 \n",
      " 며칠 전에 오랩충이 자기가 중학생 때 여자인 친구가 겨털잇는거보고 식겁했다고 나보고 자르라길래 너부터 자르라니까 난 남자잖냐. 이래서 난 여고생이라서 기를 거라 했다 내 체온 유지시켜주는 겨털사랑해 제에발겨털보고식겁하는한남이들내겨털보고걸러줘ㅠㅜ \n",
      " 모 대학 모 교수님의 글 펌 이글 제대로 전파가 되어야 현 경제 상태를 제대로 이해를 해야 합니다. 국민들이 모른다고 속이려는 허튼수작 황당 논리 속지 말자. 이병태 교수가 말하는 문재인 정부(장하성,. \n",
      " 무멘맞괄 함미다 전 호석 허구요 귀여워요 알티하세요 빻은 말 좀 패여 \n",
      " 무섭긴 개뿔이 이거 분명히 여혐 살인사건인데 지금 소리 소문 없이 묻어버리려고 안달이 나있다 지금 문제의 방송을 했던 비제이와 비제이의 광신도 남들은 삼가 고인의 명복을 빈다며 사건을 은폐하고 빨리 넘어가기만을 바라고 있다\n",
      " 무아경님! 제발 세금 빨아먹는 협혈귀 국제 의원 연놈들의 개혁 없인 이 땅의 부조리 부정부패 사라지지 않을 겁니다 우선 세비부터 70% 이상 삭감하고 수백 가지의 특권 또한 내놓아야 합니다 국민과 대통령 위에 군림하는 갑중에 갑 거머리 같은 국제 의원\n",
      " 무한  흔들리는 대한민국 바로 세우자 대한민국을 사랑하는 모임(대사 모임(대사로 박원순 시장의 환경 파리 위선 규탄 회견 10월 31일 오전 11시, 서울시청 정문 앞 멋져요\n",
      " 문대성 표절 문제가 있을 때에는 언론이 난리를 치더니 중권, 조국, 백지연, 표창원 등 몰지각한 위선자들의 표절에 대해서 방독마스크를 쓰고 관대한 것은 우리 언론에 종북좌파들이 그만큼 않다는 증거가 아닐까 언론을 정화해야 나라가 편하다\n",
      " 물건 가격이 올라간다= 상인들의 매출이 올라간다=세금을 더 많이 낸다=이득!이라고 생각하는 것 같습니다만, 상인들이 남아있지 않으면 세금은 누가 내지요? 법안 통과시키신 국회의원님들이 감당하실 것도 아닐 텐데요.\n",
      " 뮤비 공개 전까지 이거 무슨 큐피드 사랑의 빵이야 이딴 건 줄 알았는데 개뿔 사람 죽이려고 석궁 쏘는 거였음 \n",
      " 미국 남배우들 한국 와서 합장하는 거라지 봐라 \n",
      " 미도 치아 - ?赤 4편입니다 오니 치아와 부스러기 미도리 이야기. 오랜만에 목요일 전력했습니다ㅠㅠ이번에도 1시간 전력은 개뿔 날짜 넘겼지만. \n",
      " 미성년자 성추행 혐의로 검찰에 송치되고도 아무런 제재 없이 활동하는 백호의 얼굴을 보기가 역겹습니다 그리고 그 와중에도 그의 8300일을 축하하는 그의 팬들은 치졸하네요 \n",
      " 미스틱 과는. 말을 섞지. 않겠다.!!!!(동네체육관다미스틱이먹어서개빡침\n",
      " 미치겠다. 안철수 계파가 싹쓸이 했음. 이제 곡당과 민평련 간의 수작 부리는 건 끝났음. 절대 민주당과 합당 안 할 것 아냐 \n",
      " 미투를 이끄는 선봉장 같은 뉴스룸의 겉모습 뒤엔 제 식구에겐 열외인 이중적인 위선의 얼굴. 그런데도 어리석은 인간들은 잊고 지나간다.\n",
      " 민주 팔아 반역을 하고, 환경 팔아 국책사업 훼방하고, 평화 팔아 적 화통일 기도하고, 인권 팔아 반역자 민주투사로 둔갑시키고, 민족 팔아 김정일에 굴종하는 종북좌익세력의 반역과 위선은 이제 종식될 때가 되었습니다\n",
      " 민주당 의원들부터 건물 가지고 있는 정치인과 당원들도 임대료 반값으로 내리는 솔선수범 보이세요. 국회의원 세비도 지금 받는 금액에서 반으로 과감히 동결해서 국민들 세금도 줄여주고요. 하는 일도 없는 국회의원들 보좌관도 숫자 줄이고요.\n",
      " 밀감님.!.! 6k 너무너무 축하드립니다 헤헤(오지랖 항상 국부 떡밥 안 놓치게 착착착 정리해주셔서 넘넘 감사한 마음 하트 912억개예요ㅠㅠ 부디 국비 파시면서 좋은 일만 생기셨으면 좋겠습니다 :>사랑앵용 \n",
      " 박근혜 부역자에 세금 쓰며 피난처 제공 박근혜 미국 방문 때마다 앞장서서 부역하던 평통회장 황원 군, 촛불 정부 미주 부의장 승진이라니? 추운 겨울 워싱턴 링컨 광장에서 박근혜 탄핵을 외치던 재미동포 뿔났다!! 평통의 인사 헛짓 규탄한다! \n",
      " 박살님. 저번에 소개하신 수작 연어 맛나게 먹었답니다. 더 맛난 곳을 발견하여 알려드립니다. \n",
      " 박영선 지역구 유권자임. 지난 총선 땐 세입자분께 오지랖 넖게 박영선 찍어달라 부탁했는데 3월 말에 또 그분 만남. 정의당 부탁 예정임다.\n",
      " 박원순 시장은 뭔 이슈마다 오지랖 넓게 다관 여하는 지 하루가 멀다 하고 조용한 날이 없다. 서울시 운영이 생각보다 널널 한가 보다. 시장님 그리고 빨리 주니어 2세 군대 보냅시다 잉!\n",
      " 박원순의 참여연대는 2010년 아웅산 수지 여사 가택연금이 해제된 것을 환영한다면서 버마 군부의 정치범들까지 석방하라는 오지랖을 보였다. 그러면서 우리나라의 정치범(!도 석방하라고 은근(노골 물타기했는데, 북한 인권에 대행 입도 뻥긋 안 했다.\n",
      " 박원순이 말하는 비정규직에 대한 마음은 위선과 가식이죠. 실제로 약자들은 언론에서조차 안 나와요. 심지어 박원순이가 복귀시킨 비정규직은 알고 보니 악질 좌익 정치범들이 많았습니다. 전혀 박원순은 비정규직과 약자에 대한 배려 없었어요.\n",
      " 박지원, 北 김기남 김양건에 ˝개성공단 통 큰 결단 부탁˝ 개성공단을 철수한 것은 김정은이고 다시는 열지 않을 것이라 했다. 박지원의 오지랖. 국민들의 의견은 듣지도 않아. 네가 대통령이냐?\n",
      " 밤낮 새벽할 것 없이 유가족 옆에서 유가족과 함께한 거요 억수같이 쏟아지는 비속에 쫄딱 맞으며 경찰한테서 유가족 보호해준 거요 오지랖이 넓어 술 없이 크 잠도 못 잔다는 아버님들 술자리 만들고 위로한 거\n",
      " 방금 어떤 분이 프로미를 한 장에 8까지 붙이셔서 팔길래 화나서 플미충 신고하고 왔습니다. 여러분 보이시는 플미충들은 다 신고해버려요. 밑에 보이시는 주소로 신고해버리시면 됩니다!! 많은 분들이 보실 수 있게  부탁드려요!!! \n",
      " 방심하던 문재인 지지자들의 가슴에 불을 댕겼다. 정말 땡큐다. 더 강하고 더 무섭게 뭉칠 것이다. 더러운 정치 수작에 국민들은 안 넘어간다. 문재인으로의 정권교체가 더 강해졌다. 이번 경선 예상 65%로 상향 조정한다.\n",
      " 방탄 윙파콘 중곤 원가 양도합니다 좌석은 b02 2n 열입니다 b01 구역에 가까운데 돌출은 잘 보일 거예요 거라 안 하실 분만 받아요 ㅠ 취소표 돌리라는 말은 삼가 주세요 저도 취소표 돌리고 싶은데 플미충들이. 잡을 것 같아서 못 돌릴 것 같아요 ㅠㅠ 멘션에 아무거나 남겨 주세요. \n",
      " 방탄소년단 dvd/화보집 구해요. 2015화 온스 썸페 나우(나우 3 빼고 네 늦순이라 없습니다. 제에 충 플미충 꺼뎌버려. \n",
      " 방탄소년단 한남 더 힐 숙소의 허공을 떠도는 작은 먼지입니다 나랑 같이 숨 쉴래요? \n",
      " 법대에서 법 짜증은 오지랖 저는 덕후를 맡고 있습니다.\n",
      " 법원오지랖속죄설 탄생인가요?ㅎㅎ 황가가 날 간 보고 흔들려고 들이밀던 흥신소라는 자가 혹시 댁이요?? 대략 같은 부류요? 됐으니까 가서 일보세요. 작년 9월 9일 자 대화네요ㅎ \n",
      " 베라고 주인장 님은 아내가 일본 분이시고 음악을 전공하신 지인이랍니다. 트윗에서 그분 얘기 들으니 괜히 뿌듯하고 ㅎㅎㅎ 저 이렇게 괜한 아는 척 오지랖 한 번 부리고 갑니다.;\n",
      " 변희재 구석에 몰려 막장드라마를 쓰네요. 그 패악의 끝이 어딘지 보여줄 때가 됐죠! 이재명 시장을 종북몰이로 주저리는 그 거머리 같은 입에 진실의 회초리로 뭇매를 댈 때입니다. 종편서 궤변만 늘어놓던 변가의 말로가 궁금합니다.\n",
      " 별 짓 다하는 거머리 같은 김문기, 끝까지 투쟁해서 몰아내야 합니다. 예 열심히 싸워서 반드시 물러나게 하겠습니다 관심 가지고 응원해주십시오\n",
      "- 보고 싶었어. - 저는 아닌데요. - .미안해. - 미안하다고 생각하면 그대로 뒤돌아서 꺼지세요. 선배 얼굴 보고 있자니 좀 역겹다. 후회공 서동 재량 안 그런 척 미련 남은 도한 준 보고 싶다. 서로 티격태격하면서도 달달하게 잘 지내왔는데 오해 하나로 완전히 틀어졌으면.\n",
      " 보자마자 리뷰 ㅣ 위선으로 점철된 예비 정치인과 정체불명 소설가가 별장에서 보낸 24시간. 의뭉스러움 속에 비밀을 숨긴 지현우와 야망을 위해 광기를 드러낸 오만석의 시너지가 돋보인다. 꼬리에 꼬리를 무는 반전은 결말까지 서스펜스를 책임진다. 승선해 기자 \n",
      " 본명 대원이신 ( @ ddw0o 한테 입금하지 마세요. 플미충입니다 8ㅅ8 \n",
      " 부자아빠니까 그럴 수도 있지 근데 세금은 제대로 냈는지 난 그게 궁금함\n",
      " 부정하는 위선적 논리 / 침묵은 비겁함이다! \n",
      " 분위기는 개뿔 위기밖에 보이지 않는다 \n",
      " 비서실장이 실장 주제에 마이크 들고 대한민국 국회를 향해 호통칠 때부터 알아봤다. 오만과 위선이 가득 차라는 것을! 이 설치는 나라가 세계에서 몇이나 되는가? 그래서 은? 그래서, 은?\n",
      " 빅뱅 굿즈로 자기가 왜 돈 버는지 일도 모르겠음 자기 돈 없다고 돈 더 받는 거 너무 웃긴일 ㅌㅌㅌㅌㅌ 플미충이랑 머가 달라,,?(알 수 없다\n",
      " 빻은 말 듣기 싫어요. 그것도 선생님들한테. \n",
      " 빻은 사람 싫어함 레드벨벳 엔시티 이달 소 오마이걸 엔간한 그룹이면 다 받아요 트친 선생님들,, 인용해줘요,, 무멘맞괄\n",
      " 빻은 사람 알아서 거르고 박 전 최고 사랑에 다른 멤버들도 다 사랑해요 가끔 자료 올리니까 저랑 트친 좀 곡\n",
      " 사 대 강 보 철거하는데 3.4천억, 보 유지관리하는데 매년 2천억. 2년 치 비용만 들이면 보 철거하고 국민 세금도 절약\n",
      " 사기 나라 플미충 b 구역 연석 벌써 80만 원 제시받으셨답니다. \n",
      " 사랑 없는 율법은 위선 \n",
      " 사랑의 주님, 예배가 화려해지고 아름다워지는 것을 봅니다. 위선이 담긴 보이는 예배가 아니라 신령과 진정으로 드려지는 하나님이 기뻐하시는 예배를 드리는 예배자가 되게 하옵소서!\n",
      " 사불 등 빻은 짓을 안 하시는 분과 못생긴 사람 안 좋아하시는 분들만\n",
      " 사실 매진이 되는 건 예상했어요. 플미충도 당연히 예매할 테고 조이풀 분들 중에도 예매하시는 분은 계실 테니까요. 하지만 지금부터가 진짜 싸움이라고 생각합니다. 프로미 사지 않기! 콘서트 취소 기원하기! 우리 뜻 전하기!\n",
      " 사실 방금 받은 리케인데 플미잡는 캐럿이라는 흥미로운 주제인지라 바로 손 닿는 데로 그렸어요. 플미충 아웃. \n",
      " 사실 저 전공시험으로 위장하고 갔어서 후기 씁니다.는 개뿔 희망사항임 저도 만들어낸 후기 쓰고 싶은데요 엘 님이 참 예쁘셨다. ㅡㅡ트 로웰님이 참 차를 멋있게. 따르셨다. ㅎㅎ 즐거운 하루.! (뇌피셜 행복 회로\n",
      " 사실 저는 판 열리고 삼연이 어떤 꼬락서니인지 대강 감이 잡혀야 제대로 관극 스케줄 잡을 거긴 한데 거진 주말일 거예요!! 날짜만 맞는다면 함께 관극해요ㅠㅠㅠ\n",
      " 사실 현재도 싱글이 세금 더 내고 있음. 부양가족, 배우자 등의 감면 혜택이 없으므로;;\n",
      " 사장님 혹시 핀 마이크 많이 불편하시면 요록캐 테이프를 작게 잘라 고정해 보시는 게 어떨까요. 저렇게 하면 편하고 좋더라고요 재방 보는데 테이프 면적이 너무 크고 접착력이 좋아서 불편해하시는 것 같아서. 오지랖이면 죄송합니다! \n",
      " 산부인과 최악의 보호자 (옛날 글인데 읽다가 개빡침\n",
      " 살아남고 싶으면 날 만져라!, 내가 정의고 우린 항상 옳다! 벌레 소년 최신곡, 이번엔 랩이라기보다 헤비메탈 느낌. 고음 부분의 적나라한 가사와 욕설에서 왠지 웃음이 난다. 좌파의 위선은 이런 오버액션(?으로밖엔 표현할 길이 없음으로 인한 카타르시스 때문이랄까\n",
      " 삼 년 동안 하찮은 한남들과 같이 지내야 하는 고급식입니다 모르는 게 많으니 형님들이 많이 고쳐 주세요 흔적 남겨 주시면 맞팔 하겠습니다 충성 .7\n",
      " 삼성 뮤직 이벤트로 당첨된 무료 티켓을 유료로 양도하는 것은 프로미입니다 부득이하게 본인이 가지 못한다면 다른 포치에게 무료 양도해주세요. 유료로 양도해서 공돈 벌어보려는 당신, 너도 플미충 \n",
      " 새벽 반 제노 좋아하고 이태용 좋아하고 장르 상관ㅁ업으나 빻은@놈들 거릅니다 트친들 으리@인 알 해주시고 무민맞괄임\n",
      " 새줄랑이 : 아주 소견 없이 방정맞고 경솔한 사람. 강쇠네는 입이 재고 무슨 일에나 오지랖이 넓었지만 무작정 덤벙거리고만 다니는 새줄랑이는 아니었다. (송기숙, 녹두 장군\n",
      " 생각 없이 보다 갑자기 개빡침.대학때 무수히 뛰었던 알바. 진상 고객님에게 고개 숙일 수 있었던 이유는 지금 고개 숙이는 게 내 가치에 아무런 영향을 미치지 않았기 때문.\n",
      " 생긴 건 딱 보면 완전 a. 무관심 정도는 완전 ab 폭발력은 완전 b 오지랖은 완전 o 사람들의 한마디 넌 도대체 어디 소속이냐. 암튼 과학적으로는 a 소속. 방가 -_-/ \n",
      " 생일을 측하함니다 nichkhun-oppa! 옥체 만강 하사여 새로운 성괴를 거두시기를 바랍니다! 당신의 러시아어 팬의 사랑으로\n",
      " 서울시는 밀입국해서 김일성을 만나고, 5.18광주 폭동의 배후로 알려지고 김일성으로부터 조국 통일상을 받은 문익환 목사 생가가 있는 강북구 수유리에 세금으로 통일 문화관 건립할 예정이라면 철회해야 할 것입니다.\n",
      " 성도는 이기적인 목적으로 하나님의 뜻을 구하며 위선적으로 행해서는 안 됩니다. 하나님께 나아가는 자는 하나님의 살아 계심을 믿고 온전한 순종의 자세를 갖춰야 합니다. 우리의 구원은 하나님의 성품에 따른 은혜로 주어집니다.\n",
      " 성소수자 단체가 신상 보안 요구하는 게 권력이면 청소년이 세금 안내는 것도 권력이고 지하철 배려 석도 권력이게요? 좀 말 같은 소리를 해야 들어주죠. 사회대 학생들이 사회적 권력의 의미를 모르면 어떻게 하나요\n",
      " 성스럽게 우리 다나 어때요 금강불괴고 개뿔이고 전부다 때려치워ㅜ서 \n",
      " 세월호 법을 위해 정청래 의원께서 이렇게 힘들게 싸우고 있는데 당내에서 조경태는 민 집안을 만들어 계속 장외 투쟁하면 탈당한다며 생쇼만 하고 있으니 당 지지율이 18%로 추락했습니다. 그래도 의원님 힘내시고 파이팅!\n",
      " 세월호 유가족을 시체 팔이 장사하는 종북세력으로 매도하고 법에 보장된 파업을 벌이는 근로자들을 종북으로 몰아 비난하고 국민에게 바가지 씌우는 현기차나 삼성폰의 매출이 떨어지면 경제를 걱정하는 오지랖이 넘쳐나는 나라가 대한민국이죠.\n",
      " 소나타, 이브, 소파 : 월탱 터지는 표정과 함께 분노를 참지 않고 개빡침의 주먹 날림 김말희 : 볼 부여잡고? 이 상태로 눈 물둑 뚝뚝 이사라 : 웃으면서 짱돌 듦 아멜랴 : 일단 본인이 잘못한 게 아닐까 해서 울망울망상태로미안하다고함(?\n",
      " 소셜네트워크(sns에서 ‘위선자’라는 비난이 빗발치고 있다고 미국 매체들이 전했다. 이러한 내용은 ap 통신을 비롯한 주요 외신들에 보도됐고, 취재 기자 등 유력 오피니언 리더들도 트위터를 통해 “도저히 이해할 수가 없다”면서 그의 행동을 비난했다.\n",
      "- 소인국 사람들이 불쌍해서 - 불쌍해서 - 풀어 주려고 - .핸드폰을 던졌어? - 그냥 살짝. 8ㅁ8 - (개빡침 - 소인국 흡, 불쌍하잖아 아아 (뿌에에엥 \n",
      " 솔직히 돈을 벌고 싶어서 인 거라면 돈 많이 벌려는 플미충들에게 돈 퍼주는 거보다 jyp가 가져가시는 게 좋지 않습니까? 잘 생각해보세요 물들어올 때 노 저으려는 게 목적이라면 공식 먼저 만들고 정규 내고 콘서트해요\n",
      " 쇼케이스 절대 플미충에게 양도받지 마세요. 어차피 그 사람들 쇼크 안 가서 안 팔리면 취소표로 풉니다. 팬덤 분위기 지금부터 만들어가는 거예요 ㅠ\n",
      " 수많은 빻은 질문들 중에서 처음으로 유니세프 캠페인에 대해 질문해준 zach에게 감사 해시를 만든 아미들 핵소 스위트 물어봐 줘서 고맙다고 너무 기쁘게 대답하던 주노나, 그 기뻐하는 모습 보며 행복해진 아미들이나 너무 귀엽고 사랑이다 진짜 ㅠㅠㅠㅠㅠㅠ\n",
      "- 수선화 - 나이 들수록 느긋하게 생활하자. 나잇값 하자. <믿거나 말거나> \n",
      " 수작 부려줘 내건 가방 해줘 \n",
      " 슈퍼쇼 양도 디엠 왔는데 눌러보니깐 스캠 때 당당한 플미충이셧넴 ㄷ 진짜 웃긴다 애들 포사 달고. 왜 그렇게 사세요??? 혹시나 원가 양도받으실까 봐서 아이디 안 가렸어요 죄송해요 \n",
      " 스마트 트리오 랖랖랖(? 오디오 0 오지랖 ㅇ ㄷ. 도와 조! 석진아 난 로브스터 밖에 생각이 안 나 \n",
      " 스위치고 현재 섭 애인과 연 뒤 중인 해태로 시스 젠더 2n 살 여성입니다!(구인× 트위터도 bdsm도 초보에요 성별 성향 가리지 않고 친해지고 싶지만 빻은 계정 사양입니다 마음 주시면 모시러 갈게요 \n",
      " 스탠딩 구합니다.플미충들 제발 꺼지세요 진짜로 스탠딩 원가 양도해주실 천사 분 구합니다ㅠㅠ직거래면 좋겠어요. 아니면 티켓이 온 다음에 제가 입금해드릴게요! 사기 치려는 게 아니라 사기당할까 봐 그런 거예요ㅠㅠ 날짜는 상관없어요ㅠㅠ 후불인 대신 제 전화번호 드릴게요\n",
      " 스탠딩.원가양도.구해요.플미충. 꺼졌으면ㅠ 날짜 상관없어요ㅠㅠㅠㅠ 직거래 원하고요 직거래가 어려우시면 티켓이 온 다음에 돈 드릴게요ㅠㅠㅠㅠ 사기 치려는 게 아니고요 사기당할까 봐 그래요ㅠㅠㅠㅠ 대신 제 휴대폰 번호 드릴게요!!! 진짜 너무너무 간절해요 선생님들\n",
      " 슬기 레드벨벳 예쁜 여자 좋아하는 사람 한남 안 받아요 무멘맞괄♬♪?(●˙▽˙●?\n",
      " 시대에 따라 의미가 변해가는 현상과 잘못된 표현은 분명하게 구분해야 한다고 생각합니다. 그런데 그런 것을 알리려는 사람을 지나치게 깐깐하거나 오지랖이 넓다고 여기는 풍토도 문제고요. 국어교육, 특히 올바른 쓰기 교육이 참 절실합니다.\n",
      " 시즌이 시즌인지라 감히 트친소를 하러 왔습니다 24살 테라입니다 시스 젠더 남성, 정체화를 포기한 사람 빻은 사람만 아니면 됩니다 꺼몽꺼몽 \n",
      " 십일조 등록 신동만 60여만 명 된다는 한 대형교회. 내년 예산은 1248억 원, 그중 400억 원가량이 선교 명목. 2004년부터 2008년까지 조 모 담임목사 한 명에게 지급한 선교비는 월 10억 원가량, 5년 동안 500억 원. 모두 현금으로 세금은 물론 세무조사도 받지 않는 돈이다.\n",
      " 쌍꺼풀 짙은 사람은 개뿔 정국이가 다 부숴버림 \n",
      " 쌍용차 정리해고는 회계조작에 의한 불법이었음이 지상파 방송을 통해 국민들에게 확인 시켜준다는 것 자체로 큰 의미가 있습니다. 강희 중 책임 pd님 정말 감사합니다. 이명박근혜 새누리당은 국민대통합 생쇼 그만하고 지금 당장 쌍 차 문제 해결하라!\n",
      " 쌤통이다. 영어가 국제 공용어가 맞긴 하지만 미국식 영어가 공용어는 아니지. 국제 영어로 통용되는데 굳이 미국 발음만 고집할 필요는 없을 텐데.\n",
      " 아 맞아 너희들 공연장 앞에서 발로 뛰어서 암표상 플미충 잡아본 적 있어? 우리 팬들이 어떤 꼴까지 봤는지 알고는 있니?\n",
      " 아 좀 오지랖일 수도 있지만, 뭐. 트윗은 혼잣말이니까 보고 넘겨 주세요. 구이다의 회원 정리= 권력남용? 낮에 당트윗을 얼핏 봤는데. 회원 정리가 권력남용이 것 까. \n",
      " 아. 그렇군요. 언제 기회가 되면 재미난 에피소드도 들을 날이 있겠죠. 고민의 오지랖 끝을 맺어주셔서 감사해요--- ㅎㅎ\n",
      " 아개웃겨 누가 리케로 무영은 율<이랬는데 진짜 그리셧엇음 근데 그때도 좀 작가님 아 역겹;이런 반응도 아니셨어 공식인가 바(\n",
      " 아근디 이거 폭살 왕 미래라고 생각하니까 쩜 웃기고 행복해졌음ㅋㅋ 히어로 되고 고독한폭살방생겼는데 안티들이 멋대로 들어와 체육대회 1위 사진 올리면서 (폭살 왕 흑 역사+금지사진 임 응 폭살 왕 인성개빻음.히어로때려쳐라ㅠㅠ이런일꼭한번생길듯 \n",
      " 아까 트친소 타래 지우다가 트친소가 지워졌어요 개빡침 ㅎㅎ ,,,,, 죄송하지만 함만 더 해주세요 ,,,,, 트친들 으리 좀 ,, 잘할게 내가,,\n",
      " 아나미첬듬 왜 이렇게 이쁘냐 아 짜증ㄴ나 너무 이뻐 ㅠ ㅜㅡㅠ ㅜㅜ이걸 실물로 못 보고 있다ㄱ너 개빡침\n",
      " 아낰 아 세상엔 미칰 너무귀여워욬 ㄹㅇ 지금 제 꼬라짘 감사해요ㅠㅠ 졸귀탱ㅠㅠ \n",
      " 아뇨 원래 우수상이었는데 상장만 장려상으로 잘못 찍혀 나왔어요. 우수상 수상자로 되어있어요. 직업은 없고 오지랖만 쩔고 현금흐름은 아주 괴로운 사람입니다.\n",
      " 아니 그 당 싫다고 쪼개고 나온 사람이 왜 그렇게 남의 당 문제에 관심이 많대요?? 지금 자기 당도 창당한 지 얼마 되지도 않았는데 형사 제제 연루되신 분이 계셔서 풍전등화의 상황이더구먼 오지랖이 넓으신 분이시네요 \n",
      " 아르바이트생 엿 먹이려면 바쁠 때 그릴 치킨세트에 음료는 파인애플 에이드로 바꿔주시고 버거에는 토마토, 치즈 토핑 해주시고 포테이토는 고구마 치지 볼로 주세요 하면 됨용 기다리는 시간은 있지만 바쁠 때 진짜 개 빡침 버거도 새로 만들어야 하니까 맛있음\n",
      " 아빠가 얼마 전에 옷 사러 남양주까지 갔다고 해노쿠 정작 저한테 준 건 메모지에 제 이름 써서 붙여 조서요 나도 한남 더 힐 가서 살고 싶어요 연탄이 너 쩜 부럽네 \n",
      " 아침에 일어나서 자랑할래! 어제 열심히 음성 편집함 사나다 말수가 없어서 개빡침 큐ㅠ\n",
      " 아케 아낰 최대 피해자: 이혁재 신동희 피해자: 조규현 개빡침: 박정수 김종운 근데 원인 제공:이동해 \n",
      " 아하! 잠깐 들어가겠습니다 당시 연평해전을 지휘했던 2함대 사령관은 해전에서 승리한 죄로 좌천당하고 끝내 전역한 사실은 해군에서는 모르는 사람이 없을 정도입니다. 오지랖이 넓어서 미안합니다\n",
      " 안나 님.그래도 이 중환자 제품에 이렇게 안게 돼서 넘넘 가슴 벅차게 기쁜 내내 임도.그나 저도 이 꼬물이들 어떻게요ㅜㅜ또 이놈의 오지랖은 발동을 슬슬 하라라고 혀서 미치것시융\n",
      " 안녕하세요 숲록님! 지나가던 구독 러입니다: 혹시나 왕윤 선배님이 나오는 이 광고를 보셨을까 싶어 조심스럽게 링크 하나 올립니다. 뜬금없는 오지랖과 갑작스러운 멘션 죄송합니다ㅠㅠ \n",
      " 안녕하세요! 현재 대학생은 아니고 호주에 거주 중인 워홀러지만 각 학교 자매님들의 빻말 모음을 보고 저도 호주 워홀 한남 빻말 수집을 시작했습니다. 잘 부탁드립니다 \n",
      " 안녕하세요. 저는 섹시님이고 최애는 퍼거스 막 로이에요. 연성을 주로 하는 편이에요. 페이트의 빻은 부분을 자주 비판하고요. 페그오 나름 열심히 해보고는 있습니다. 반응 남겨주시면 찾아갑니다. \n",
      " 안철수 부인 다운 계약서 작성 시인 매입 실거래가 보다 4억 원 정도 낮춰서 신고 약 2000만 원 세금 탈루 ?탈세가 드러날 경우 일벌백계로 엄중하게 처벌해서 세금을 떼먹는 것은 엄두도 내지 못하도록 해야 한다? ( 안철수 본인 저서 中 \n",
      " 안철수 의원의 기자회견 발언은 당 회의에서 제안하면 될 일인데 굳이 기자회견까지 하는 오지랖을 떠는지 모르겠다는. 조경태나 안철수 의원이나, 본인들 존재감을 나타내려면 적어도 정권을 상대로 비난을 해야지 본인 들다에다 대고 디스질 하는 것은 뭔 경우인지.\n",
      " 안티팬도 팬이라고 믿는 건 아니겠죠? 차명진 의원?  그 유명한 안전한 미국 쇠고기 시식 생쇼 이거(미국 쇠고기 먹으려고 점심 안 먹었어요!\n",
      " 알자지라가 한국 대선 직전에는 한국 전문가 세 분을 원격으로 앉혀놓고 20분짜리 심층 분석도 하더군요. 드넓은 오지랖이긴 한데 그래도 나름 성의 있는 내용이었습니다.\n",
      " 알티 감사합니다! 은 원섭에서 앤가님이랑 행복하게 비누 하면서 지내는 천향입니다!! 섭 상관없이 트친소 하고 있고 성별, 나이도 빻은 발언만 안 하신다면 상관하지 않습니다! 알티는 찾아가지 않으며 마음이나 선팔 둘 중에 하나 남겨주시면 찾아갈게요 \n",
      " 알티 폴로 추첨 워너원 팬 콘 서울 s7 구역 200번대 원가 양도합니다! 제가 성공했는데 부탁한 친구도 성공해서 취소 표하면 플미충한테 갈 수도 있어셔 멘션 디엠 주지 마세요 당첨자 팬 인증 강하게 받아요\n",
      " 알티= 스친소 표 찾기 귀찮아서 그냥 쓸게요 저어는 레이는 하는 사람이고 언데드 오 시입니다,,, 요즘 학업/기숙사로 인해 접률이 낮아졌는데 이 점 감안해주시고 흔적 남겨주세요! 빻은 썰 풀고 그림도 가끔 올려요 \n",
      " 앗 괜한 오지랖인 것 같기도 하지만 알이 된 거 감상하다가 조심스레 답변드려 봅니다. 해리 포터와 죽음의 성물 중에 들어간 애니메이션 일부인데 여기서 보실 수 있으실 거예요. \n",
      " 애초에 이 녀석들 닮았으니까 오지랖 넓은 긴상이 무너져가는 귀신 부장을 가만히 보고 있을 수 없었던 거겠지. 쓰다 보니 선구자라는 거창한 단어를 써버렸는데, 바라가 키에서 그런 거창한 녀석들이 아니잖아?라고 말했던 히지카타가 생각난다.\n",
      " 양도 / 29일 3층 37구역 296,295두 자리 연석, 한혜린, 프리미엄은 범죄입니다. 신고했으니 구매하는 일 없길 바랍니다.\n",
      " 양도 가수랑 팬이 즐기는 콘서트를 플미충들 이 왜 껴서 돈 버는지 이해 안 됨ㅋㅋ 플미충 아웃.프로미 주고 티켓 사지 마세요 워너블 제발ㅠㅠ신고하라고요 오히려 가격 제시하지 마시고!!!!!!!!!!!!!!\n",
      " 양도 워너원 단독 콘서트 서울콘 플미충 잡는 법 신고 접수는 무조건 예스24 이메일로 보내주세요 예배자명, 예매번호, 휴대폰 번호 등 최대한 많은 정보를 모아서 접수해주시면 됩니다 제발 깨끗한 표 사셔서 우리 팬들 원가 양도 만 받고 한자리라도 더 갑시다 \n",
      " 양도 팬미팅 제발 플미로 사지 마요 저번에 쇼크도 브랜뉴가 플 미신고 다 받았었잖아요! 플미충이 파는 예매 좌석만 알아내도 신고 가능해요! 그때 저도 플 미신고 해서 플미충 취소 처리됐었어요 플루 미문화 초반에 싹 잡아야 되오 제발 ㅠ\n",
      " 어떤 경우에도 오지랖은 폭력입니다. 어떻게 남의 집 담을 넘어오듯 성큼성큼 타인의 심리적 경계선을 침범하는지 몰라요.\n",
      " 어제 이틀 동안 화성에서 갈매기 옷 입고 게임하던 약간 이상한 사람입니다 즐겜하느라 성괴는 많이 못 뽑았지만 그래도 오랜만에 트친소 돌려봐요 올 라운드라 모든 게임 가끔 하긴 하는데 유빗 사볼 디디 안 주로 해요. \n",
      " 어쩜 저렇게 사람 설레게 하는 재주를 타고났을까 다정다감한데 부담스럽지 않고 친근한데 오지랖은 1도 없는 느낌. 너무 형 아니 선배이 낭랑해서 개머시써.따흐흑.찌언.8ㅅ8 \n",
      " 얼굴에 챶 달라붙는 꼬리 물어봤더니 입에 털 잔뜩 들어가서 고생하는 녹턴 보고 싶네요(스콜:쌤통이군;\n",
      " 엇. 감독님. 제가 저번에 당직 서면서 제보 드린 물품이 두 개(삐삐, 턴테이블나 포함되어 있네요. 기분 좋은데요.\n",
      " 에서 전화로 세금을 내는 게 올해에만 무려 2만 1600건 이상! 이젠 주정차 위반 과태료도 전화됩니다! 전화 한 통으로 간편하게 세금을 낼 수 있는 성남시 ars 납부시스템 +__+ \n",
      " 에서 제일 말이 안 되는 건 어른들은 전부 위선적이거나 지질한데 2세들은 전부 쿨하고 건강, 건전하기까지 하다는 것. 자식들이 부모보다 좀 더 세련될 수는 있어도, 자신들의 물적, 계급적 사고방식까지 뛰어넘기는 쉽지 않은데, 좀 비현실적이다.\n",
      " 에이지 : 흐릿해함. 두 분 다 살아 계시지만 아들로서 해드린 게 1도 없음. 쩌는 불효자식 (  애쉬 : (개빡침 렌메이 : 응. 얘 반ㄴ응응 어렵네. 일단 멀쩡한 척하겠지만 동공이 팝핀을 출 것\n",
      " 엑소엘 개빡침 지금 11계단 올라감 \n",
      " 여기 베댓들 5개 좀 내려주세요 네댓이 틀 딱인데 쓰는 사람들도 문제지만 이거 추천하는 사람들은 뭡니까 네티즌들이 문파들 수준이라고 욕해요 트럼프의 종전 논의 축복. 예상보다 빠르고 깊은 북미대화 \n",
      " 여러분 다가오는 토요일인 12월 9일 경남교육청 앞 청소년 인권 보장을 위한 토요 집회가 열립니다! 투 클럭 삭발식, 손피켓 만들기, 빻은 말 파쇄하기 등 여러 이벤트가 열릴 예정이니 많은 참여 부탁드려요 \n",
      " 여러분 메리 크리스마스 ¡¡¡는 개뿔 이번 크리스마스도 집에서 소년단과 함께다 . 하는 사람은 저랑 트친을 맺어주세요（??ω?? つ━☆?았!!!!!! 제가 눅우냐구요 ¿¿ 윤기 하는 사람이요, 윤기 ¡¡¡ 하는 ¡¡¡ 사람이 ¡¡¡ 일류다 ¡¡¡\n",
      " 여러분 플미충들 보시면 높은 가격 불러서 돈 입금한다고 하시면 계좌 주면 신고 벗 계정으로 신고하던 인터파크에 신고합시다 많은 분들이 원가로 가기 위해선 저희의 힘이 필요해요 사진 아래에 표시되어 있는 계정으로 신고해주세요! \n",
      " 여러분 플미충들한테 넘어가서 50만 원 뜯기지 마시고 그 돈으로 그냥 얘들 컴백하면 앨범 판매수나 높여주게 앨범을 더 삽시다 그럼 얘들이 기뻐할 거에ㅕ그게 더 개 씹 이득.\n",
      " 여러분 플미표 절대 사지 마세요 쟤 내 어차피 안 팔리면 저거 취소표로 풀리는 거라고요 지금 양도하는 애들은 가고 싶은 애들 아니고 플미충입니다\n",
      " 여러분들을 위해 한번 찾아봤습니다! ￥2,900+세금+배송비 (최소 4만 원 이상: \n",
      " 여성민우회, 페미디아 같은 계정은 왜 폴로 했는가요? 한남이란 단어가 들어간 트윗을 리트윗한 이유는 무엇인가요? imc게임즈 김학규 대표가 자랑스럽게 공지로 올린 질문 내용입니다. \n",
      " 여자친구랑 랟팸 공부하다 못 참고 계정 판 고삼 삐리 랟팸입니다 혐오 발언 서로 정정해주면서 한남 패주실 분들 흔적 남기고 팔로 해주시면 바로 맞팔 드릴게요 여자만 안고 가는 페미니즘 합니다\n",
      " 여혐혐 아니고 남혐하늖 새롬 탐라에서 자당이 시비 털기 담당하고 있음다 코르셋 거의 벗음/ 여성 착취 반대 비혼 주의/ 한남혐애안함 도멘 안 하셔도 됨다 하트를 좋아함다 저가 하트를 달아도 놀라지 마세요\n",
      " 연속 신고 가능한가요ㅠㅠ? 이번 콘서트 따라 플미충들 너무 날뛰어서요 \n",
      " 열심히 열심히 열심히 방송 보며 응원하고, 의원님이 논리, 사실관계 제공해주시는 걸로다 주변 거머리 같은 보수들과 싸워서 이깁니다 열 일하십니다\n",
      " 열일 짱짱 플미충 다 비켜 ㅠㅠ 저 자리 불법인 거면 다 풀어주세요 \n",
      " 예결위원회 전체회의 “연소득 1400만 원에 불과해 세금을 내지 못하는 면세점 이하 소득자가 803만 명. 세금을 안 낸다고 비판할 것이 아니라 기꺼이 세금을 낼 수 있도록 지원해야 한다. 문재인 정부의 최저임금, 적정임금, 일자리 정책이 옳은 방향이다”\n",
      " 예결위원회 전체회의 “초 대기업과 초고소득층에 대한 과세를 찬성하는 국민이 86%다. 더 나은 복지를 위해 국민 72%가 세금 부담 의향이 있다고 답했다. 이것은 공평과세가 문재인 정부에서 시작됐다는 국민들의 신뢰이다”\n",
      " 오. 오지랖 같으면 죄송합니다. \n",
      " 오. 진중권은 정치, 경제, 사회, 문화, 국방… 이제는 의학까지… 도대체 안 끼는 데가 없이 오지랖이 태평양이구나. 아무 데나 여기저기 다 끼어드는 저 참을 수 없는 가벼움. 오지랖 퍼와 양대 산맥 진중권 vs 갑동 수!\n",
      " 오가다 정의 ‘욱’이 흥미로운 것은 그것이 정의를 앞세우거나 괜한 오지랖으로 누군가를 위한다는 대의가 아닌 자기 자신을 위한 선택이라는 점이다.\n",
      " 오늘 뜬 공지인데 오지랖 넓게 번역 정리. \n",
      " 오늘 저녁은 카라 아게 부제: 어디서 수작인가 \n",
      " 오늘도 귀여운 라몬이 덕분에 즐거웠습니다 둘이는 그냥 투다가 대는 게 귀여운 것 같아요. 다니엘이 나잇값 못하고 딸뻘인 라몬이랑 투다가 대는.\n",
      " 오늘도 재방송입니다. 삼일절을 며칠 앞두고 일본 시네마현 다케시마의 날이니 뭐니 생쇼를 하길래. <스피드 특집>스페셜 방송 추천했습니다.\n",
      " 오늘의 지수님 예쁜 슈 아들 도착했어요 정말 너무 예뻐요 사는 동안 많이 버시고 지금처럼 오랫동안 따뜻하게 슈아 담아주셨으면 하는 소망이 있어요(오지랖 곧 이사해서 걸기에는 애매하지만 매일 꺼내놓고 보려고요 정말 감사합니다 \n",
      " 오랜만에 직접 접하는 오지랖이라 순간 당황했습니다 이게 무슨 \n",
      " 오랜만에 트친소 돌려보는 슈코,{$!sp-sp!$}쇼코 p 뜌삠삠입니다!! 아무 말 하고 가아 가끔 그림 그려요!! 아이돌 성적 대상화, 빻은 별명 진짜 싫어합니다 저를 탐라에 심어보세요☆ 맘이나 알티 해주시면 찾아가요!! \n",
      " 오지랖 넓은 저는 체인점 빵집 사장님들에 대한 걱정도 살짝. 오래전부터 개인 빵집을 하다 어쩔 수 없이 돌아서신 분들도 계시고 회사와의 노예적 계약 때문에 고생하는 분들도 많으시죠. 체인점 빵집의 불공정한 계약 조건도 알려졌으면 좋을 텐데 말이죠\n",
      " 오지랖 만렙! 귀신 패는 여자 귀신 가지가 색 매력만점! 현지가 보고 싶다면 7월 11일 (월 밤 11시 tvn에서 만나 보실 수 있어요. \n",
      " 오지랖 칭찬해 내 호감 니꺼해 \n",
      " 오지랖 피디님 사진 바꾸시니 뭐랄까 상당히 더 영해 보이신다는!! 죄송합니다. 원래도 영 하셨다면요.;;\n",
      " 오지랖도 넓으십니다 이 바쁜 와중에 강서까지 응원하시고 이번에 꼭 국회 입성하세요 대구 부산 변화의 조짐이 많이 보이네요\n",
      " 오지랖은. (히죽 웃고 현관 밖으로 나간다. 잘 자요. 내 꿈꾸고요.\n",
      " 오지랖이 넓고 두루두루 관심이 있는 우리들은 탁월한 상담 능력이 내재되어있죠. 대신 중이 제 머리 못 깎는다고 엘프 피끼리 모이면 상담을 해주고 있는 진풍경을 볼 수 있음. \n",
      " 오지랖이 넓다 ??????/?????????????????\n",
      " 오지랖이 넘칠 때도 있고, 무신경이 넘칠 때도 있는 거 같아요. 좀 극단적이랄까?? 저만 이런 건가요? 아님 entp 분들이 이런 경향이 있는 건가요??\n",
      " 오지랖이 태평양 같던 디오네/ 신현우 오너 치리입니다.!.!!!.!(눈물 줄줄 \n",
      " 오지랖이지만 .; 연천 농장 제품보다는 캣츠 하트 제품 추천합니다. 연천 농장은 솔직히 질이 그냥 그래요. 캣츠 하트도 뼈 함량 조절해서 갈아주니 한번 이용해보셔요. 닭뿐 아니라 토끼나 메추리도 팝니다.\n",
      " 오지랖이지만 비트맵을 벡터 파일로 바꿔주는 사이트가 있어요! 인쇄하실 때 도움이 될까 싶어 적습니다. \n",
      " 오지랖이지만 한 번만 읽어달라 찌 유기 동물보호소에 찌 네 마리가 올라와 있는데 한 마리는 새끼도 낳았지.\n",
      " 오지랖일 수도 있겠지만 서명할 때 보니까 현이랑 씽이랑 면이 당첨자분들은 아직 안 찾으러 가셨더라고요ㅠㅠㅠㅠㅠㅠㅠ sum 마감시간 됐으니까 혹시 기다리시는 분들은 내일을 기다려보세요 (♡ v ♡\n",
      " 옥션 버려!!!!!!!!!!!!!!!!!!!!!!!! 선예매해줘!!!!!!!!!!!!!!!!!!!!!!!!! 플미충잡아줘!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      " 옳소!!! 어느 나라 대통령, 영부인을 만나도 전부 오징어를 만들게끔 코디 부탁합니다! 아니 진짜! 완벽한 외모, 뭘 입어도 완벽한 대통령과 영부인을 가졌으면 겁나 멋지게 꾸며보고 싶지 않습니까! 세금 더 내요? 네?!! 네 \n",
      " 와 부역 언론 1. 콘텐츠 융합 담당 상무 정 사장님 바쁘시게 잘 지내시겠지요? 총선 이후 식사 한번 할 수 있었으면 하는 희망인데 혹 틈을 내실 수 있을는지요? 동지인 mbc 김장겸 본부장과 같이 하려 합니다. 세금 ‘332억 원’ 지원받는 언론사 간부가 장충기와? \n",
      " 와라 ㅜ나를 밧음 알티해 른 낼부터 시험기간이라서 안 들어오긴 개뿔 정말 잘 들어와\n",
      " 왜 이렇겤 울분에 가득차신거애욬 ㅌㅌ 울지 말고 천천히 말해보세요,, 괜찮아요 여기 저도 트위터 한눈 꼬락서니를 보새요,,,ㅎㅎㅎ(토닥토닥 로 정님 보러 옆 나라 가고 싶은데 돈도 없고 시간도 없는 룬 놈입니다,, ㅠ(로 미곡\n",
      " 왜ㅐ잇는 걸까,,,,???? 되게 친해지렴!! 하고 둘을 붙여놓는 쓸데없이 오지랖 넓은 선생님 보는 기분임\n",
      " 왠지 모를 불안감이 있네요 미래를 보고 정책을 펼치는 것인지 자신들의 이익을 채우려 하는 것인지. 소위 부자 유치원들은 그럼 어떻게 되는 것일까?라는 오지랖 넓은 생각도 드네요\n",
      " 외전 1 이젠 이 동상이 외전을 연재해볼겡 ㅎ 대리가 왜 머릿수가 많은지 암? 그리고 상인동에 왜 플미충이 끊임없이 텨 나오는가는? 그건 바로 울 고생하는. 대리성님이=플미업자기 때문.일지도? ㅎㅎ\n",
      " 요새 하는 꼬락서니 보면 일은커녕 출근은 하는 걸까 싶다\n",
      " 요즘 ㅈ디에서 가장 많이 보이는 문장 벌크업 중입니다 아니야 너 그냥 밥 많이 먹는 중이야 벌크업은 개뿔.\n",
      " 용하가 제게 주었던 따뜻한 마음이었기 때문에 그걸 함께 나누고 싶었어요. 너무 오지랖 떠는 거 아닌가. 걱정스럽기도 했는데, 좋게 봐주셔서 제가 감사합니다. 바보 같은 놈이지만. 오래오래 기억해 주자고요 우리.\n",
      " 우울할 때 빵빵 터 지 게 해준다는 조작당 국가 수준 촬스스럽당 내 세금 아까비 \n",
      " 워너블 오늘 일례 실패했다고 플미붙인 티켓 사지 마요 프로미 신고해요 제발 15 이상 20 이상 붙여진 거 표 사서 사기당하지 말고요 원가로만 알아봐요ㅠㅠ 기프티콘 15번 이름 넣어준다고 이런 거에 속지말고ㅠㅠ원가로 가자고!! 신고해 프로미 붙이면 요 알겠죠? 잊지 마 원가 99000원이야!\n",
      " 원가 양도만 구하라고 난 말했다 나중에 티켓배 송 올 때쯤 사기당했다고 글 엄청 올라와 그 사람들 중에 포함될 거예요? 난 계속 말했어요 원가 양도만 구하라고 플미충한테 돈 줘서 사기당하지 말라고요 우리 팬들 원가 양도받고 한자리라도 앉아있었으면 좋겠다고요 플미충 신고해요\n",
      " 원래 계정에서 구독만 하며 살다가 화병 나서 만든 계정입니다 아직 배워가는 중이라 빻은 발언 있을 수 있습니다 지적해 주시면 달게 받아요: 함께하실 형님들 모셔요 흔적 주시면 무멘팔로드립니다 맞팔 부탁드려요\n",
      " 원하지 않는 임신과 ‘낙태’는 누구에게나 찾아올 수 있다. 그게 십 대라는 이유로 더욱 비난받아서 안 된다. 나이 먹은 여성에게는 ‘나이도 먹었는데 몸 간수도 제대로 못하냐’며 오지랖 떨어대는 세상에 뭘 바라겠냐만.\n",
      " 월화 밤 11시 합자 3 오지랖 만렙 김현지 \n",
      " 월화 밤 11시 합자 4 오지랖 만렙 김현지 \n",
      " 웨슬리 너무 깡패야 웨슬리+카인+레오 노르 개빡침조함 여기에 캐럴 넣어 바 ㅅ ㅍ\n",
      " 위선자는 배우처럼 사는 사람을 일컫습니다 바리사이들과 율법 학자들은 겉으로는 엄격하게 규율을 지켰지만 내면적으로는 하느님께 순종하지 않는 사람 들이었기 때문에 진실을 외면한 채 인생을 연극하는 것처럼 살아가는 위선자들이었습니다\n",
      " 위선적 행동 때문입니다. 세월호 유족들의 가슴에 대못을 박은 건 두고두고 기억날 겁니다 아마.\n",
      " 윈스로드입니다. 소셜 위선과 겉 멋으로 위장한 자칭 중도 보수는 가라!!! 오로지 팩트!!! 그게 대보련의 색깔입니다. 5월인데도 쌀쌀합니다. 진실의 공방에 참여해 주시는 회원님들 항상 건강하시고 행복하길 바라요.\n",
      " 유료화해달라고 백날 외쳐도 안 들어서 플미충이 판치고 코코 밥 앨범 잘 팔려도 언급하나 없고 코코 밥 챌린지 외국에서 흥해도 노도 못 저어, 종국엔 파워 챌린지로 뒷북 두드리질 않나 그동안 얼마나 맺힌 게 많았으면 아티움 의자가 제일 열 일한 다는 소리가 나오냐고\n",
      " 유시민에만 분노하는 게 아니라, 남의 아버지 친일에는 삿대질하고 자신의 아버지 친일에 대해선 존경을 표하는 친노종북세력의 위선과 기만에 대해 비판하는 겁니다.\n",
      " 으로 멘틀 털리고 등 단 거부하면서 글 쓰는 친구와 고민을 나누다 보니 문학은 개뿔을 만들게 됐다. 막막하고 답답한 맘에 약간 일기 쓰는 맘으로 시작한 거라 시즌제까지 할 거라는 기대는 적었는데 롱런하고 싶다. 등단 안 하고도, 더러운 꼴 감수 안 하고도 글 쓰면서 잘 살고 싶다.\n",
      " 으음. 아직 그 유기체의 모습을 하고 있군, 범블비.그럼 내가 굳이 나설 필요 없었군. 오지랖 부린 것은 사과하지. \n",
      " 은 당내 경선을 통해 정당하게 당선된 후보를 흔들지 마라!! 후보가 하겠다는데, 당내 의원들이 돕지는 못할망정 뭐 하는 수작인가!! 정신 차려라!! 이야말로 의 유일한 희망이다!! \n",
      " 은혼은 질답도 재미나  @나라님: 일본의 흔한 만화작가의 오지랖. jpg \n",
      " 의원님, 먼저 격하게 지지합니다. 다름 아니고 지금 02-6022-4688 번호로 1. 송기호 2. 배현진, 3. 박종진 .에 의원님을 기타 후보로 지칭한 여론조사가 진행 중입니다. 이건 분명 의원님의 여론조사 지지율을 극도로 왜곡하려는 수작임이 분명한 바 살펴 조치하시기 바랍니다. 급히 씁니다\n",
      " 의원은 지난 9년 동안 “경제는 성장해도 세금이 잘 걷히지 않는 현상을 분석하면서 인상하면 경제성장률을 상회하는 수준으로 세수가 늘어난다는 분석을 발표했었습니다. \n",
      " 이 금액 이상이면 플미충입니다 혹시 이미 수령받은 티켓을 재배송하는 경우 저 금액에 배송료 정도 다시 붙을 순 있으나 그 이상은 플미충입니다. 웬만하면 직거래 추천합니다. \n",
      " 이 자리 플미충 자리입니다 절대 사지 마세요!!!!!!!!!!!!!! 수요가 없어야 공급이 없는 법입니다 팬님 분들 \n",
      " 이 판피린 광고를 문제 삼았을 때 상당수 언론은 오지랖 넓게 하며 비아냥거렸지만 동아제약은 광고를 바꾸기로 했다. 소비자의 절대다수는 노동자이다. 신문 독자도 마찬가지. \n",
      " 이 해시태그를 적극적으로 지지하는 바입니다. 애초에 증거 불충분한 파쿠리 하나로 어른 여럿이 미성년자 마녀사냥하듯이 잡아놓으니 좋으신가요? 피해자 입장에서 생각해보신 적은 있나요? 가해자에게 기대하는 건 별로 없습니다만, 당신들이 운운해하는 나잇값에 맞게\n",
      " 이거 만든 사람 찾아갔다가 오지랖 같아서 돌아왔다가 해시태그에서도 많은 분들이 의도에 분노하길래 역시 뭐라도 말하자 싶어서 다시 찾아보니 삭제하셨네요.?\n",
      " 이거 보니까 일요일 생각난다 햄님이랑 만나서 밥 먹고 귀걸이 사고 있었는데 매장에 나오는 노래가 저 인간 들어간 노래였지 싶었음 물론 나는 전혀 몰랐지만 햄님이 그 이야기하는 순간 진짜 진심으로 질색하면서 육성으로 으 허 역겹네 이렇게 말했나 아마 그랬다 계산하다 쳐다보더라 \n",
      " 이건 공연계의 고질적 문제입니다. 가수들의 앨범이나 공굿, 스밍권 등에 써야 할 금액이 플미충들 주머니로 들어갑니다. \n",
      " 이것 좀 도와주실 수 있나요?? 플미충이라고 설명해 주세요 빅이/트랑 전혀 상관없다고요 얼른 빅이/트 알리라고 하는 게 나을까요?? \n",
      " 이것도 문의드립니다. 성괴라는 표현이 성형괴물의 약자 같은데. 아래 사진에 있는 내용들은 법적 조치가 불가한지요? 탐진강이란 자가 저런 식의 중상모략과 비방을 일삼고 있네요. \n",
      " 이게 그거다 천연 식물성 오지랖 스카이 하이한테 오지랖 넣는 판사 에피소드 \n",
      " 이게 뭐야 아미들 다들 진정해욬 는 개뿔 나도 올블랙 시스루. 나도 초밥 옷. 나도 레고 안무. 나도 하이파이브. 나도 돈ㅌ리미 무반주 즉석 노래. 나도 단체 흑발. 나도 오츠 카레 송 단체. 나도 호석 베이스라인 댄스. \n",
      " 이게 뭔 소립니까. 대표 시씩이나 돼가지고 문제를 해결하기는커녕 손학규 편만 들어주다가 당원들 폭발하니 앗 뜨거워하면서 나는 몰라요 하는거네요 정치 9단은 개뿔입니다\n",
      " 이달 소 팜 선팔 안 받 무멘맞팔 알괘스 신경 안 씀 빻은 남덕이랑 빻은 남들 파는 거 아니면 다 괜찮음 재미있는 사람은 아님 ㅠㅠㅠ흔적만 남겨 주세요.!!\n",
      " 이런 절절한 충언을 들을 대통령이 아니죠. 선사의 책임을 국가 책임으로 만든 건 유족의 능력이 아니라 대통령의 미숙한 리더십과 태평양 크기의 오지랖인 걸 알아야 합니다\n",
      " 이름: 강이 서낭 나이: 17살(1학년 성별: 여자 키/몸무게: 166cm/59.5kg 성격:활발하고 당차다. 자신만만하고 가끔 엉뚱한 생각과 행동을 할 때가 있다. 누구에게 나 붙임성있게 행동하고 오지랖은 없다. 귀차니즘이 심하다\n",
      " 이메레스로!! 경단 가족.!! 드워프님 리아님 시해랑 님 하얀 시계님 왔다 시 추석이니깐 떡 그림.!!((은 개뿔 \n",
      " 이번에는 프로미 절대 사지 않기!!!! 표 풀릴 때까지 기다리기!!!!! 플미충들 박살 내버려요!!!!\n",
      " 이쁘다 우리 융 ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ 촬영을 언제 했는지 모르지만, 추웠을 수도 있겠다는 오지랖이 ㅠㅠ \n",
      " 이상돈 동생, 이상기 씨가 이상돈 향해 부모 형제 속여서 재산 강탈한 탐욕스러운 위선 자라며 마포 국민의당 당사 앞에서 1인 사위를 벌였는데 국민의당 이상돈 의원은 동생이 1인 시위를 해 명예를 실추시켰다고 명예훼손으로 고소를 하겠다고 밝혔습니다, \n",
      " 이승호 경기도당 공동위원장은 1960년 전라북도 군산 출신으로 육군사관학교 38기로 임관하여, 육군본부 작전처장과 제205특공여단장, 제9공수특전여단장, 육군 리더십센터 단장을 역임하고 육군 준장으로 예편했다. 아울러 한남대학교 대학원 행정학과(박사 파이팅 .\n",
      " 이쑤시개 우리 엄마 개빡침 혼저옵서예 이렇게 데쓰노트에 휘갈겨놨음 \n",
      " 이연(과 홍란(의 생쇼. 쇼. 쇼 아니, 여러분! 이게 안 웃겨요? 네? 놔놔놔놔놔놔놔.♬\n",
      "- 이재명 (이어서 3. 의외로 디테일에서 약한 점이 있어 토론 내용이 오락가락하는 경우가 있음. - 전원책 1. 깽판 가보, 틀딱 그 자체 2. 말하다가 혼자 화나는 경우가 대부분이라 좋은 내용을 담아도 의사전달하는데 어려움을 만듦.\n",
      " 이재명 지지자들은 이재명 마타 도어에는 분기탱천이지만 지금 이 순간에도 안철수 마타 도어는 적극적으로 하고들 있네. 아.! 내로 남북의 대마왕 더불어민주당 지지자들이니 당연한 건가? 지 눈에 들보는 못 보고 안철수 마타 도어는 모두 진짜라며 남 마타도어 하는 꼬락서니 하고는!\n",
      " 이정현왈 대선 당일 일몰시간이 오후 5시 14분이니 투표시간 연장은 도서산간지역에서 위험할 수 있다. 참 오지랖도 넓네. 소수의 입장은 그렇게 생각해주면서 왜 투표하고 싶어도 못하는 다수는 생각 못 해 주니? 산간 지역에서 늦게 투표한다니?\n",
      " 이제 구미 와서 개봉했는데 9개 중에 7개가 중복 혹시 교환해주실 분 있으시면 저 말랑이2개 에브리 2개 삐삐 1개 메가 루카리오 1개 상대 분 피카츄, 님 피아, 데 그다, 뮤, 지 가르뎅 10% 폼 라티 오슬로 받아요 \n",
      " 이틀 전에 각성한 트랜스 웜련입니당.7 제가 탈쓰까한지 얼마 안 돼서 빻은 소리 많이 할 수도 있는데 많이 가르쳐주실 페리 분들 만나고 싶습니다 아무거나 흔적 남겨주심 맞괄합니당 갓 건배 팬이에요!!\n",
      " 인 스피릿 여러분, 이참에 플미충에 대한 싹을 뽑아버리게 관련 청원이 진행되고 있다고 하니 참여해주세요:- \n",
      " 일단 저런 얘기들은 저는 그러고 싶어요. 의 범주를 벗어나는 순간 망함. 남의 결혼관에 어느 방향으로든 가이드라인을 주려고 애쓰는 오지랖\n",
      " 일러스트레이터와 일러스트레이터 지망생분들께 많은 도움이 될만한 팟캐스트입니다. 일반적인 작가의 수입이나 계약서, 세금, 홍보방법 등등 유용한 이야기들을 많이 다루네요 : 강추강추. 매번 꼭 챙겨듣고 있어요 \n",
      " 일본 우경화는 걱정하면서 대한민국 헌정 파괴는 조용하고. 일본 국영방송국? 수신료도 일본에 달라 해라. : kbs 뉴스는 오지랖도 넓어 일본 우경화 걱정은 왜 하고 앉았냐\n",
      " 일본은 5명이 내는 세금으로 공무원 1명 연봉 부담하고 한국은 3명이 공무원 1명 연봉 부담한다. 근데 여기다가 80만 명을 더 늘리면??\n",
      " 임근준씨도 저도 트위터 이전부터 적이 많았어요. 이글루스 안 하셨나 봐요? : 더구나 노정태 씨야 말로 승리할 수 있는 필드의 영역은 더 넓죠. 제 말은 그의 존재가 공격의 대상이 되는 건 나머지가 지워지기 때문이라는 겁니다. 오지랖이 아니라\n",
      " 입문한지 얼마 안 된 아기렏펨이에요. 빡세게 공부 중이니 빻은 말하면 후 드려 패주세요. 흔적은 곧 선팔 갑니다 잘 부탁드려요 성림들.77\n",
      " 있는 만큼 풀어내림 (빻은 취향 주의\n",
      " 자 이루 . ! 입문한지 얼마 안 된 렏펨입니당 모르는 게 많아 열심히 공부하고 있어요 77 빻은 말 고쳐주십쇼 ㅠㅠ 선팔 또는 흔적 남겨주셔요 선맞팔 갑니다 잘 부탁드려요 성림들 .777\n",
      " 자 이루 형님들 ☆?（?。∂） 생물학적 여성분들 당근빠따 환영이에요 제가 혹시 빻은 말하면 지적해주세요 흔적 주시면 찾아갈게요\n",
      " 자 이제 심상치 않긴 개뿔. 올해 중학생의 이야기를 들려드리죠\n",
      " 자대가 아닌 훈련소에 보낼 경우 소포는 반입이 안될 가능성이 높습니다. 훈련소로는 손편지로, 자대 배치받았을 때 소포 보내는 게 어떨까 싶어요. (반송되면 너무 아깝잖아요. 이상 오지랖 넓은 팬이.\n",
      " 자신이 비겁함 뒤에서 느끼는 만족을 죄스럽게 하니까 대신 다른 사람이 오지랖 넓은 것으로, 이상한 것으로 말 들려 하는 하는 것입니다. \n",
      "- 자유당 8%, 정의당 7%, 국민당 6% 다음 총선 때 정의당이 원내 2당, 제1 야당, 지지율 2위 등극을 미리 축하한다 피 같은 국민 세금을 축내는 기생충 야당 국민당 몰살 운동이 들불처럼 일어난다 수없이 경고했었다 사느냐, 죽느냐, 드디어 내일!!\n",
      " 자존감과 오지랖이 쓸데없이 넓은 평범한 대학생 작곡가의 자기소개.\n",
      " 잘못한 거 알려드릴게요 1. 있는 장르 건드림 2. 심지어 담당 배우님들도 다 계시는 캐릭터들임 3. 저작권의 저 자도 모르심 4. 이미 논란 있었는데 계속함 5. 팬들이 잚 탰는데 왜 엑소 싫어하냐는 빻은 논리 이어서\n",
      " 재기한테는 니시무라가 어마어마한 사람인데 그런 사람이 아카시 좋아한다 했을 때 그래 다 끼리끼리 노는 거지하고 부글부글 끓어도 참았는데 아카시가 키게 좋아한대서 개빡침 자기 안의 신 같은 니시무라를 버리고 크세 따위를 좋아하나 이런 기분?\n",
      " 저 원래 이런 전공 오지랖 안 부리는데 민정님께는 얘기하고 싶어서 했거든요. 그만큼 투명하고 선하고 또 사람들로 하여금 경계를 풀고 돕고 싶게 하는 매력이 많으세요.\n",
      " 저 트위터랑 네이버 웹툰 멜론 다 앱 삭하고 인터넷으로 계속 들어와서 지금 사파리 기본 화면 애 자주 들어온 웹사이트 이 꼬락서니에요 전 뭘 해도 안될 인간인 듯 \n",
      " 저는 그때 즈음 태어나서 잘 모르지만. 현대의 나아가는 개인주의가 더 좋아요. 오지랖 부리는 문화도 좀 없어졌으면 좋겠고. 가족이란 이름 하에 폭력 행패 등등을 감싸 안고 살아가야 하는 것도 없어지는 게 좋아요 ㅎ\n",
      " 저도 기절 안 하고 잘 살아서 트윗 하고 있습니다.\n",
      " 저도 문 대표님의 생일을 축하드립니다. 그런데 우상이라는 표현은 좀 과하신듯 합니다. 반대자들에겐 어쩌면 공격의 빌미가 될 수 있다고 봅니다. 마음은 이해하나 되도록 평이한 용어를 쓰심이 어떠실 지요. 오지랖 죄송함ㄴ다.\n",
      " 저번에도 이렇게 번역 살짝 해드렸던 거 생각나서 섭씨님 보시라고 슬쩍 보내고 갈게요.! 혹시 너무 오지랖이었다면 죄송합니다ㅠ \n",
      " 적들은 현행법을 발에 떼만큼도 취급하지 않는데 자신은 민주주의의 마지막 보루 인양 법대로 하겠다는 국회의장, 위선자다. 아마 유관순, 안중근 아버지가 정세균이었다면 위대한 역사는 일어나지 않았을 것이다.\n",
      " 전력은 개뿔 고양이 귀엽다 \n",
      " 전세로 사시는 분들에게 희소식!! 가장 확실하고 간단하게 전세금을 지킬 수 있는 전세금 보장 보험이 드디어 집주인 동의 없이 가입할 수 있게 되었습니다!! 풍악을 울릴 일이네요. \n",
      " 전에도 말했지만 의대생들이 외과에 안 가는 이유는 근무환경과 여건이 너무 나쁘기 때문이라고, 거기에 돌 던지는 사람들은 위선자일 뿐이라는 트윗 한 적 있는데 오늘도 이런 트윗이. 이런 사람이 의사여야 한다 라.\n",
      " 정답인듯합니다. ㅠㅠ저 지금 꼬락서니 폐인 같아요. 완전드러븜ㅠ\n",
      " 정몽준, 박근혜, 새누리당 사당화. 위선이고 거짓 직격탄 정몽준-전여옥 요즘 옳은 말할 때가 많네, 오래 살고 볼 일이다!\n",
      " 정부나 지방자치단체가 언론사에 세금 지원하는 거 반대합니다. 있을 수 없는 일입니다. 언론사 세금 지원 반대합니다. \n",
      " 정의가 살아나고 상식이 통하는 나라를 만들려면 어떤 선거 결과가 나와야 하는지 국민들은 알고 있을 것이다. 이제 인지도 하나만 가지고 국회의원도 되고, 고위공직 자리도 차지하고 하면서 세금을 축내는 사람은 유권자들이 원하지 않을 것이다.\n",
      " 정철 카피_ 기권의 반대말은 기적입니다. \n",
      " 제 전 재산 꼬락서니를 보세요 낙자님이 하늘 잔 구석에 있는 집 동거인 설정해주셔서 거기서 같이 지내요 흑흑 \n",
      " 제가 개뿔이 할 줄도 모르는 영어를 들고 완곡을 했습니다 엉엉 오늘은 색다르게 실사 영상을 써봤어요! 앞으로 자주 이렇게 올릴 거 같네요 쀀힝인코딩 mandy moora - only hope 불러보았다!!! 전곡 유튜브: \n",
      " 제가 바로 69번 위선자입니다 리카{$!sp-sp!$}p고 잘 부탁드립니다.7.7\n",
      " 좌석 알려달라니깐 그냥 바로 입금하면 알려준대,, 여러분들 조심하세요 플미충을 업그레이드됐네요 \n",
      " 좌파 돈줄 충실히 해온 박원순 서울시장이나 이재명 성남시장이나 국민 세금으로 퍼주기를 하더니 결국 빚 잔치였다는 거네요.\n",
      " 주변 사정이 복잡하게 돌아가고 있네요. 개입할지， 지켜볼지는 당신의 선택이지만 모쪼록 자신으로 인해 상황이 악화되지 않도록 주의해서 신중하게 접근하길 바라요. 잘못하면 오지랖이 넓단 소릴 들을 테니까요.\n",
      " 주유 섭에서 오독 기르고 있습니다 .-. 9 섹트 욕트 많고 흉한 거 리트윗 많아서 미성년자의 팔로는 받고 있지 않아요. 취향 중 빻은 것이 많으니 조심해주세요. 스샷 찍는 거랑 자덕질 좋아합니다 흔적 남겨주시면 선팔 가요! \n",
      " 주제 연예인이었는데 그건 잘 모르겠고 60분은 개뿔이 34782489분 지난 것 같지만 정말 오랜만에 한 마감이니 박수나 쳐줍시다. \n",
      " 중국 여객선 침몰 지점이 앞을 전혀 볼 수 없는 흙탕물에 유속은 세월호 침몰 지점보다 빠른 상황 속에서도 선체 인양에 성공한 것은 아직도 세월호를 꺼내지 않고 특정 부위들이 녹슬기만을 기다리는 박근혜 일당의 위선적인 모습과 크게 대비가 된다.\n",
      " 쥐잡기 집회 여선웅 강남구 의원 발언 중 저는 죄지을 말이 아닌 죄지은 얘기를 하겠습니다. 국민의 세금으로 국민을 사찰한 죄인을 벌해야 합니다! \n",
      " 지금 삼성 언플 하듯이 민주당 언플 시작되었습니다. 오마이에서 시동 걸었고 포탈이 퍼나르고 이기명 오지랖 넘게 까이면서도 통합진보에 양보하라며 양비론에서 본심 나오는 중\n",
      " 지금 한나라당도 문제지만 더 문제집단은 통합이니 뭐니 무늬만 바꾸고 본질은 그대로인 진보의 탈을 쓴 좌파집단입니다. 살인마 김정일에게 조문하는 것은 도리고 수백만 아사자는 안중에도 없는 위선자들에게 대한민국을 맡길 수는 없습니다.\n",
      " 지난화를 보신 어떤 심리학과 학생분이 수업시간 프로젝트로 진행하신 오지랖 척도 연구 논문을 보내주셨다. ozr-scale인데 정말 재밌다 멋있어!!!!!!!!!!!!!\n",
      " 지지자들의 마타 도어를 그만두게 할 의지는 없나 보다. 선거는 이겨야 하는 것이지만 더럽게 이겨도 오물의 악취는 생각보다 오래간다. 게다가, 더러운 꼬락서니로 선거마저 진다면? 자중자애하시고 기다리는 인내를 배워서 더 큰 도량으로 떳떳이 자신의 뜻을 펼치시길.\n",
      " 진중권이 존경한다는 김신임. : 백토 나올 때마다 혼자 잘났다고 오지랖. 가만 보면 30초에 한 번꼴로 칠 푼이를 외치는 듯.“: 백토에서 김진이라는 분 도대체 무슨 얘기를 하고 있는 걸까?\n",
      " 진짜 라디오 챙겨듣는데 진짜 아오 어린애들이보낸거임?개빡침 오빠들 신인 된 줄\n",
      " 집값 떨어졌다고 아우성이라는데, 그걸 지원해 주려고 생쇼를 한다. 그 사람들이 집값 오른다고 봉사할 사람들도 아니고 자기들이 판단해서 투기. 투자한 건데 그걸 왜 남 탓을 하나. 집값 오르면 지가 투기. 투자를 잘한 거고,\n",
      " 찌게->찌개, 떡볶이->떡볶이 가 맞는 표기에용ㅠㅡㅠ 오지랖이 기분 상하게 해드렸다면 죄송합니다. 그렇지만 채팅의 아닌 기본 단어 정도는 옳은 표기로 쓰는 게 맞는 거 같아요\n",
      " 차에서 내려주고 나서 나누는 대화는, -장 당신은 내가 본 중에 제일 말썽쟁이 의사예요 -육 당신도 내가 본 중에 제일 오지랖 넓은 의사예요 \n",
      " 창비에서 펴내는 이만큼 가까운 시리즈, 우선 미국, 중국, 일본이 나왔습니다. 더불어 위선과 편견을 시니컬하게 드러내는 프랑스 코믹 메디컬 문학 <방귀의 예술>을 주목도 서로 꼽습니다. \n",
      " 채동욱 혼외자 밝혀지자 그의 부도덕보다는 정보 출처를 따지던 위선 좌파들이, 안경환의 부패상이 드러나자 또 정보 출처 운운하며 적반하장식 실드 질을 했죠. 정보 입수 경위를 당당히 밝혔습니다. 주광덕 의원, 싸울 줄 아네요\n",
      " 처음 탈북자 북송 반대 집회에 참여했을 때, 선거 얘기를 하는 것이 영 찜찜했다. 저쪽 사람들이 뜻을 같이하겠다 했을 때, 선거를 의식한 가식적이고 위선적인 행위라고 생각했다. 그러나 지금은 누가 뭐라 하든, 뭐가 됐든, 그들을 살리고 싶다\n",
      " 천류 월화님 트친 비 선입금 겸. (???으로 낙서했는데 괜한 오지랖인가 싶네요(쭈뼛 이런 거 좋아하시려나 ;;;;;;아니라면 죄송합니다(땀 땀 제가 과제 땜에 연성은 깊게 못 파고 낙서라도 8ㅅ8;;;; 좋은 연성 감사드리는겸에ㅠㅠㅠㅠ \n",
      " 첨언: 설명으로 김을 빼는 설명 중, 개입하지 않는 게 나을 것에 굳이 개입하는 오지랖, 애매함 수준의 앎에 당당한 선무당이이니라, 맨스 플레 네이션은 남성의 여성비하 방식에 대한 (유효한 문제 제기.\n",
      " 첫 콘 플로어 에이 구역 400번대 원가 양도합니다. 용병 뛰어주고 남은 자리입니다. 저도 누군가의 팬인지라 플미충한테 질려서 엘프 인증받고 배송지 변경으로 양도합니다! 원하시는 인증 다 해드려요. dm 주세요.\n",
      " 첫콘: b 구역 4nn 번대 막곤: b 구역 5nn 번대 두 장 각각 양도합니다 플미충 넘나 많아서 별 셋 인증 몇 가지 받을게요! 멘션 말고 디엠 주세요 원가 양도입니다♡??(●˙?˙●??♡  부탁해요\n",
      " 초면에 죄송합니다. 저도 저 트레이가 너무 탐이 나는 바람에 돌아다니다 우연히 찾아냈기에.! 오지랖이지만 링크 공유합니다. 이 예쁜 트레이를 소개해주셔서 감사합니다.\n",
      " 최 의원님 이거 하나만 약속해주세요. 당선되더라도 약속을 지키겠다고. 지금의 모든 게 당선되기 위한 위선이 아니란 걸 여.\n",
      " 최대마저 스포인 비운의 연치입니다ㅠㅠ(그런데 최애 연성 안 함 꼭 스포를 주의해주세요!!! 그리고 혐오스럽거나 트리거가 눌릴만한 그림 혹은 빻은 발언 등도 있으니 주의 부탁드립니다ㅅ 흔적 남기면 맞는 분 찾아가요 오 오 \n",
      " 최성 후보 이재명에 기본소득은 지원으로 저출산, 노령화 대책 어떻게 모두 지원하느냐. 가능한가? 기본소득은 년 3,000만 원 지원하겠다. 헐. 이재명이 막판에 이판 사판 막 지르고 있음. 세금 왕창 거두겠다는 뜻.\n",
      " 충 꾼 소년단  한 번씩 꼭 부탁드립니다 \n",
      " 취진 생이 되는 성인 미덕입니다.,. 그림 그리는 거 좋아하면서 전 잘 님들을 외치는 소비러랍니다☆ 어렵지 않고 오지랖 넓은 유쾌한(? 성격이니 맘 편히 알티마 마음 주시면 갑니다! \n",
      " 친구가 플미충이랑 친구 먹었데 ㅌ ㅌ ㅌ ㅌ ㅌ . \n",
      " 친일파도 청산 못해 온 나라가 병들어 있는데 오지랖도 넓습니다 친일파들 다 소탕한 후에 김구에 대해서 논합시다\n",
      " 친하기로 하면야 오지랖 문희상만 하겠습니까.ㅡ그리고 문재인은 노무현 대통령 서거 때 쥐새끼에게 백원우가 소리 지른 것에 대해 정중히 사과도 했었죠. 친구의 억울한 죽음 앞에서. 의리도 없는.\n",
      " 친한 척 잘하는 오지랖 넓은 페미니스트입니다 \n",
      " 카터는 불필요 오지랖이 넓어서 남의 나라 내정간섭이 비정상적이고 반대로 부시 재단은 우리나라와 유엔 북한 인권 개선에 올바른 행보입니다. 개선 노력은 좋으나 올바르게 현 상황을 볼 줄 모르는 카터는 가만히 계시는 게 북이 인권 개선에 도움이 됩니다.\n",
      " 코우메 위주로 올 캐러 사랑하는 위선자예요! 코우메 오시 캐인 분들 위주로 찾아갈게요 마음 남겨주세요. \n",
      " 콘 첫 콘 그라운드 f4 구역 안 열 쪽 원가 양도합니다 금요일 날 가고 싶었는데 지방이라 가기 힘들게 됐네요ㅠㅠ 취소표로 돌릴까 하다가 플미충들이 걱정에 되어서 그냥 제가 원가 양도합니다! 팬분들만 디엠 보내주세요. 콘서트 \n",
      " 콘서트 프로미 티켓 사지 마세요. 사주면 나중에 또 콘서트하면 플미충들 엄청 날뛰어요. 원가 양도하는 사람들도 많고 취소표도 풀릴 거니까 원가 양도 아니면 사지 마세요!\n",
      " 콜거래는 역시 원가 양도.! 제발 원가 양도 아닌 거래는 하지 마세요. 나중에 더 힘들어져요. 플미충들한테 먹이 주는 거니까 프로미 x 원가 o 콜거래 = 원가로 시원하고 멋있고 깨끗하게 자리 양도 외우세요. 원가 o 프로미 x\n",
      " 쿡. 제 글씨를 좋아해 주신다니 제가 떠 신나서 이렇게 오지랖을 한번 부려봤습니다. 사실 지금 켈리 허고 있던 중이라서 한번 적어봤어요. 프사가 약간 파랑 한 색감이라 파란색으로. \n",
      " 크레인님 최고 행복한 새 날이 밝았습니다. 숙면하셨나요? happy today.!! 크레인님 수작 \n",
      " 크아 이거 보고 진짜 웃겨섴 먹을겈 오지랖 그야 네가 잘 먹게 생겼잖앜 \n",
      " 크아 정말 웃겨 마케가 오란제 예약했는데 디엠 안 온다고 엄청 조마조마하고 있는데 다 같이 장난으로 디엠 한 번씩 보내서 마케 개빡침 \n",
      " 큼큼, 괜한 오지랖을 부린 건 아닌지 조금 걱정에 되는군. 하지만 그래도 역시, 자네들이 옳은 판단이 어떤 것인지 생각하는, 멋진 사람이 되었으면 좋겠다고 생각하네. 조금만 더, 주변에 관심을 가져주게.\n",
      " ㅌㅌㅌ ㅌㅌ ㅌ 생각하는 거라지 봐 힘들게 데뷔했더니 조회 수로 후려치는고봐ㅠㅠ \n",
      " 탐라대 환장이다 공식에서 먹여주는 내 쵱캐 이뻐죽겠는데 망겜이라 개빡침 이쁨과 화남을 공유하는 탐라\n",
      " 토모님 힘내시라고 밧짱을 좀 꺼내봐요ㅠㅠ 간 바로 뿅! 토모님 위 상큼한 모습이 보고 싶은 동이의 오지랖입니다 \n",
      " 톳토리 와규를 부위별로 담은 고기 벤토. 고기 양은 총 4kg, 세금 포함 292,929엔이라고 \n",
      " 투 유ㅣ터에 아 2콘 티켓 서치해보면 사촌 언니가 티켓을 그냥 줬다 부터 해서 플미충ㅈ들도 티켓 안 팔려서 원가이하양도하곸 4.5만 원에 원가 이하 양도하는 사람ㅇ매우 많고 슬로건이랑 티켓이랑 교환하는 사람도 있고요ㅎㅎ\n",
      " 트친 생기게 트친 분들  해주세요 : 오지랖 너무 당해서 봇전만 하고 있는 사람이에요 같이 봇전 해주는 분 정말 좋아합니다! 봇전 같이 하실 분은 멘션! 바로 팔로 해요! 3600레벨 찍고 부계로 빠대랑 경쟁 많이 할 예정입니다 남녀 혐오 발언은 질색합니다 \n",
      " 틀딱들 엑소 팬들 넘어서려면 애써야겠네요.\n",
      " 티브이 조선 가관이다. 자기들이 경찰이고, 자기들이 판사여. 여자 성괴 앵커. 맞장구치고. 왜 윤창중 입장에서 얘기하는 사람은 없을까? 여론몰이가 진실을 감출 순 없다. 이종훈 정신 차려라.\n",
      " 티켓 양도합니다 제가 가고 싶은데 돈이 없어서 양도해요 ㅠㅠ 플미충 엿 같은 새끼들 말고 꼭 팬이 갔음 좋겠거든요 간단한 팬 인증 같은 거 해 주시면 양도할게요\n",
      " 티켓 플미충들 양심 없으세요? 10 이상은 너무하시잖아요 . \n",
      " 티켓팅 실패하면 지금 당장 티켓을 구하지 못하면 나는 콘서트에 가지 못할 것 같다는 불안감 모두 이해하지만 계속 프로미 티켓을 사면 플미충들은 더 늘어나고 티켓팅은 더 어려워지고 악순환이에요 이번에 끊어내야 합니다 파샤\n",
      " 티켓팅 트라우마 란? 팬덤에 속한 사람 중 특히 에리들에게 자주 보이는 증상으로 반복되는 티켓팅 실패와 날뛰는 플미충, 알티 양도 충 때문에 정신적 외상을 입고 일상생활 중에도 문득 울분을 토하는 현상\n",
      " 파면하세요. 여자는 리트위트 때문에 잘리는데 이렇게 논란이 많은 남자를 파면 안 시키고 계속 세금 얻어먹으며 살게 내버려 둔다고요?\n",
      " 파투님 모세 이야기 끝나고 마지막에 나오는 그림이오! 그거 예수님 맞죠? 아 댓글에 모세가 이집트에서 성괴 들고 나온 이야기 그럴싸한데요!(모세 얘기 시작할 때 추측들이 억지스럽지만 재밌게 보고 있으니 태클 안 걸겠습니다.\n",
      " 파판 14 유저 디자인 콘테스트 원거리 마법 딜러, 힐러 입상작 발표. 각각 원거리 마법 딜러, 힐러 최우수작이 각각 게임에 실제로 구현될 장비 디자인 \n",
      " 패악 욕질. 오염 막장을 같이했고, 즈덜도 당했고 알면서, 한패가 되어 자덜은 아닌 척 아무나 모함하는 그런 위선과 거짓의 이중성이 더 역겹다는요. 첫 단추 원인 모르며 오지랖 하는 칠푼까지 암튼 오염시키는 자들 다 나빠요.\n",
      " 팬미팅 양도한다고 올라온 티켓들 절대 사지도 팔지도 마세요 예매자와 같은지 본인 확인합니다 구매해도 갈 수 없어요 플미충들 배불려주지 말고 취소표 되도록 해서 우리 취소표 잡아요!\n",
      " 페미하고,,, 방탄하고,,, 동성애하고,,, 남잡니다,,, 말을 최대한 아끼고 있지만 조금이라도 빻은 말을 한다면 말씀해주세요,,, 알티만 주시면 선팔 합니다!\n",
      " 페제페스나ubw연달아보고 치여버린 지 일주일도 안된 사람입니다 그린 게 없어서 걸어놓을 것도 없군요 키리츠구 사랑하고 궁절언절 사랑하는 취향 빻은사람<특히언절쪽에서 ;; 페그 오는. 한 그 오만 하구 하드는 아니고 노멀하게 달려요 흔적 주시면 맞는 분 찾아갑니다 \n",
      " 포인트 하이마트 세일 기간 바람 50% 빠진 행사 풍선. gif 허우적허우적 대지만 나름 가사에 충실한 안무 댕댕이 한 마리가 생쇼를 하는데 고퀄 화음 뽑으시는 형들 급 폼 잡고 래퍼 빙의 낑낑대며 의자에 발 올려보는 초꼬딩 \n",
      " 풋. 실질적인 도움(즉 양질의 남자을 제공하지 않은 사람은 오지랖 발휘한 걱정이나 훈수를 들이밀 자격이 없다는 강호의 도를 모르는 사람들이구먼요?\n",
      " 프로미 티켓은 거래하지 마세요! 내일 취켓팅 이후 양도 많이 나올 거예요 : 10원도 프리미엄으로 붙으니 절대 거래하지 말아주세요! 사는 사람이 없어져야 매크로?플미충들도 사라집니다 바른 문화 앞장서서 만들어가는 모범적인 팬덤이 되길 바라요 스민 놓치지 마세요.\n",
      " 프로미는 팔지도 말고 사지도 말자 어차피 그거 다 취소표 되는 거고 플미충은 지옥으로 떨어지세요 걸려라 서치 프로미 사지도 팔지도 마세요\n",
      " 플미충 신고합니다 \n",
      " 플미충 신고해요 돈 급하다고 25구역을 17만 원에 양도한다네요 \n",
      " 플미충 아웃.거기에 또 제시는 하지 말아요 제! 발! 요! 아 이 사람들아 정신좀차려요ㅠㅠ콘 10번 뛰고도 남을 가격 제시하는 분들 왜 이리 많아 신고하라고요 프로미\n",
      "----------- 플미충 접근 금지 ------------- 슈퍼루키 서울 양도받습니다 ----------- 플미충 접근 금지 -------------\n",
      " 플미충 좀 잡아주세요 1열 연석 찾아서 취소시켜주세요 일 하시길. \n",
      " 플미충들 보기 싫으니 매 티켓팅 취소표 티켓 얻으면 팬한테 인증받아서 원가 양도합시다 수고 비고 뭐고 그냥 깔끔하게 원가 양도\n",
      " 플미충들의 티켓을 구매하지 않으면 결국엔 전부 취소표로 풀리게 되어있습니다. 포뇨 친구들 모두 함께 플미충 근절하고 떳떳이 세운이 보러 가요 팬덤은 프로미를 소비하지 않습니다 \n",
      " 플미충들의 티켓을 구매하지 않으면 결국엔 전부 취소표로 풀리게 되어있습니다. 포뇨 친구들 모두 함께 플미충 근절하고 성숙한 팬덤 문화 만들어가요 \n",
      " 피디님:이긴 팀에겐 저희가 문화상품권 탄:오옥?!어?! 아미:얘들아. 너네 한남 더 힐 살앜 기여웤 피디님:총 금액 20만 원 아미:아. \n",
      " 하.그니꽌 그것 또한 무쟈게 보고 싶다ㅠ일요일 오전에만 했어도 이틀 딱 좋은데.\n",
      " 하다가 윤/27/남/171cm 61kg/교관 *친절함이 베이스. 모든 이에게 존칭을 사용. 오지랖이 꽤 넓은. 듯. *3남 1녀 중 장남. 무엇이든 돌보고 보살피는 일을 좋아함. \n",
      " 하루 됐으면. 그럼 우리 플미충도 사라지고 암표도 사라지고 무조건 원가 아님 처벌 \n",
      " 한미fta 미국이 웃겠다 6년간 말 바꾸며 살아온 달인들 중의 달인 정동영 씨는 위선자! 형편없는 인격 파탄자에게 우리는 국정을 맡길 수 없다(동영상 보기 \n",
      " 할 또 한 사람#세금 도둑! 특조위파견 공무원#mbc 스트레이트\n",
      " 할 일 없는 거 격하게 티 내는ㄴ 중은 개뿔 숙제해야 되는데 난 망했어 몰라 세븐아 사랑해 \n",
      " 항민연 뒤에서 밀고싶ㅇㅓ서 어떻게 참았지;;;;; 아기 감자 같은 뒤통수가 내 앞에서 저러고 있으면 왁!!!!!!! 한담에 놀랬다고 찡얼찡얼 꼬락서니 부리는 거 들으면서 키득키득 껴안아 조 버림 \n",
      " 해시태그 대란이 야간 좋은 이유가 플미충들 글 밀어낼 수 있음\n",
      " 해시태그 진짜 너무 충격적이다. 래디컬 페미니즘은 개뿔 진짜 전혀 과격하지 않으시고요. 진짜 여성 가짜 여성 나누는 게 기존 가부장제 이분법 너무 훌륭하게 수행하고 계셔서 교과서에 여성의 여성 혐오 예시로 실을 수도 있겠네요. \n",
      " 허셜: 설ㄷ은 개뿔 위협 오즈: 말재주 룬: 설득 말재주 아샤: 설득->위협 아카시아: 설득 코즈: 매혹(?\n",
      " 헐 오타라니. 성괴-->성과\n",
      " 헤이 캡. 이거 좀 볼래? ->[스티브 님에게 어울리는 향기는 바닐라 향 (오지랖이 바다 같음입니다] 혼자 보기 너무 아까워서 주워왔지. 잘 어울리는 것 같지 않아? 그렇다고? 그럴 줄 알았어.\n",
      " 헤헤 못난이 서래 오너에요 얘기 많이 해보겠다고 만든 캔데 너무 오지랖이 태평양이라 불편하셨을지 모르겠네요ㅠㅜㅠ,,. 서래랑 놀아주셔서 감사했어요.! \n",
      " 화유기. 복습할수록 너무 아깝다. 아사녀로 산만 안 탔어도 충분히 엔딩까지 시간 있었을 것 같은데. 진선미랑 꽁냥거린 게 거의 없다니. 절대낭만퇴마극은 개뿔. 그냥 퇴마 글이었어. \n",
      " 황사 심한 날 애 유모차에 태우고 유모차용 비닐 커버 씌워 나갔다가 동네 할머니한테 등짝 스매싱 당함. 애 숨 막힌다고. 오지랖이 자기 가족을 넘어 온누리에 차고 넘침.\n",
      " 흉사로 살다가 된통 당해서 몸도 정신도 망가진 후 각성한 래디컬 페미입니다. 페미니즘은 접한지 별로 안 되어 초보입니다. 친하게 지내며 페미니즘에 대해 배/우고 한남 박멸에 박차를 가하고 싶습니다. 리트윗 해주시면 바로 맞팔 하겠습니다._.\n",
      " 흔적 주시면 마음 맞는 분 찾아갈게요. 최애 윤지성 차애 강다니엘 박지훈 이대휘 제비제 서성혁 유선호 연생 언급 있음 오랜 팬 환영 빻은 소리 거절함 배척 거절함 트친밈들 자리할 티 믿습니다 (`?ω?´? \n",
      " 흨핰;ㅓㅎ 틈새라면 님이. 많이 조. 좋아해 주셔서. 생각해둔 몇 개 프로필만. 끄적끄적. (오지랖 o<ㅡ<. 그런데 프로필 보고 실망하셨을 거 같곸 ㅂㅂㅂㅂㅂ \n",
      " 힘드시겠지만 힘내세요 ㅠㅠ 견뎌내신 만큼 성괴가 있을 겁니다.\n",
      "! 프랑스 교민들의 촛불시위에 대해 대가를 치르게 할 것이라고 말해 논란을 빚은 새누리당 김진태 의원이 국회 윤리 위원회에 제소됐다. \n",
      "＂문재인 대통령·추미애 대표, ‘오만’보다 더 문제는 ‘위선’이다＂ - 위선에 열광하는 사회는 더욱 절망적이다 - [바른 정당 이종철 대변인] (출처 : 바른 정당 . | 블로그 \n",
      "＂세월호 국내 수입 때 세금 전혀 안내＂ 세월호 실소유주가 국정원이라는 것 전 세계가 알고 있다. 당장 국정원을 해체하라!!\n",
      "＂연봉 2000만 원 이상 근로자, 12만 원 세금 더 내는 개정안 준비 중＂ (출처 : 중앙일보 | 네이버 뉴스 부자증세는 배액!! 서민 증세 하자는 처바른다 클래스 메인에 올리고 알립시다\n",
      "## 4월 25일 sbs 8 뉴스 클로징 오늘 법의 날을 맞아 모두 12명이 훈장과 표창을 받았습니다. 수상자들은 범죄, 세금 체납, 임금체불, 어느 것도 하지 않은 클린 국민입니다. 원래 (cont \n",
      "#3. 앞으로 함께 걸어가자고 했어요. 동우의 진심 어린 그 말이 참 다정하고 자랑스워서 이것만은 편집 안되길 바랐는데 방송에 안 나와서 아쉬웠어요. 한낱 새우의 오지랖 같지만, 이 말은 인슾 전체에게 한 말이니 팬들에게 꼭 전해야 한다는 사명감에 글 남겨요\n",
      "(  (상상 ver. 녹화날 힘들어도 내 생각하고 힘내라고 막 생쇼를 하다가 넘어진 게 생각나 녹화를 의식하지 않고 힐링 웃음 지어주는 이기광 \n",
      "(  부탁드려요  하트 붙혀진 곳 (그라운드 양도받으면 t12 구역 d 열 원가 양도해드릴게요. 알티 부탁드려요 플미충 안 받아요 \n",
      "((chanmipark26님 호기심이 많아 오지랖이 넓고 열정이 넘쳐 몸을 가만두지 못 한다 집에 하루 종일 있지 못한다.있더라도 뭔가를 꼼지락.꼼지락하고 있다ㅎㅎ \n",
      "((s_rabbit_2님 오형은 오지랖이 넓어서 그런지 무슨 일만 생기면 막 신경 쓰고 궁금증도 많아서 막 물어보고 하다 보면 어느새 정보통이 되어있는 거 같아요. ☞☜\n",
      "((내가 봐도 나 하는 꼬락서니가 이상한 사람 같음 모르는 트친의 트친한테 가서 사진 찍고 그럼\n",
      "((이건. 그냥 참고지만 만우절 때문에 제 꼬락서니가 이 모양 이니 양해해주세요.\n",
      "((이재오는 매국노  손가락질 당할 생쇼를 하곤 왈 독도 문제는 개인의 인기영합이 끼어든다면 오히려 매국적인 행위. 국가적인 문제를 놓고 개인 장사는 정말 아니죠 이에 왈 나라가 어려울 때는 서로 간에 손가락질하는 일은 없어야\n",
      "((이재오의 광폭행보 특임장관이란 자가 연일 독도경비대 생쇼와 전국을 돌며 마치 대선 유세전을 방불케하는 일정을 소화하고 있다. 출근도 안 하는 모양이다. 이젠 재오가 대통되고 싶어 환장했다.쥐박이도 하니 대한민국 너무 만만한가 보다. 환장할 노릇이다\n",
      "(*와 크군 리케 완성되었습니다! 커플은 붙여놓고 싶은 오지랖에 쪼그만 시엔 군도같이 이렇게 이렇게. 신청해주셔서 감사해요! \n",
      "( 부탁드려요 여러분 무조건 11시 30분 전까지 플미충들에게 양도받지 마세요 플미충들 글에 취소표 돌리라고 하거나 양도 완료되었다고 빨리 다 돌려야 돼요 그래야 취켓팅으로 많이 풀리고ㅠㅠ진짜 제발 조금플미아닌이상 다 걸러요\n",
      "( 헉 저 트윗 좋다 난 위로나 응원을 섣불리 오지랖 쳐서 더 부담스럽게 하면 어쩌나 하는 것 때문에 우울 트는 마음도 못 찍는데 트친 분들 여기에 다 싹 털어놓고 다시 힘내면 되는 거예요 8ㅁ8.\n",
      "( 그러니까, 저기요, 섬 여러분 진정하세요. 우리라고 딱히 무슨 뾰족한 수가 있어서 그쪽을 지르밟고 잘 나가는 것처럼 생각을 하신다면 가혹한 오해세요 ㅉㅉ같이 망해가는 처지에, 이러지 말자고요 ㅜㅠ\n",
      "(클콘 막 콘 한 장 구해요ㅠㅠ 구역은 상관없고요 당일 직거래나 서울 경기 직거래 원합니다!!!!! 원가 양도만 받아요 플미충은 꺼지세요ㅠㅠㅠㅠㅠㅠㅠ\n",
      "(가 운동해서 몸이 좋아졌다는 말에 아야. 왜 때려요 근데 아 좋아서요 가슴이 정말 빻! 뙇! \n",
      "(가만있으라 시위 주도자 용혜인 대규모 연행은 일선 경찰이 결정할 일이 아니다. 위선의 지시가 있었을 것이다. 이것이 박근혜 대통령의 민낯이고 세월호 추모에 대한 박근혜의 대답이다. 경찰이 계속 연행한다고 해도 시민들은 멈추지 않아야 한다\n",
      "(개빡침주의 미국 시민권자에게도 기초 노령연금 지급 \n",
      "(개뿔\n",
      "(국민 개헌을 꼭 해야 하는 이유 대선·지방선거같이 하면, 20년간 1조 세금 절감 \n",
      "(김현은 열정이 넘치고 타인에 대한 배려가 깊다. 이런 오지랖은 정치의 세계에서 더 빛을 발한다. 어려움에 처한 사람을 돕는 것, 그래서 세상을 좀 더 살기 좋은 곳으로 만들고자 노력하는 게 정치의 본령 아니겠는가? -강원국\n",
      "(내 일이니까. 그 한 마디에 찬물을 끼얹은 듯 현실로 돌아왔다. 그래, 그렇겠지. 신경 쓰지 말라는데 더 이상 내가 할 일은 없지. 내 처지도 딱한데 오지랖도 넓어. 나는 최근 노인의 감성을 가졌다. 그. 렇게까지 말하니 자네가 어련히 알아서 잘할 테지. (눈을 굴리며 이빨을 보였다. 어색하다.\n",
      "(너희의 사랑을 이해하지 못 하겠다. 사랑에 목숨을 바친다는 것 또한 못 하겠다. 그러나 사랑하며 맞은 최후를 질시하며, 그래, 내 끝이 그렇기를 바란다. 역겹다. 속이 뒤틀린다. 지팡이를 넣어두었다. 코코아를 비운다. 혀를 데였다.\n",
      "(넷하오 기본 골조는 역전재판과 완전히 동일함. 상대의 트위터를 염탐해서 허점을 발견하고, 뒷조사를 해서 약점의 증거를 모으고, 1:1 배틀에서 상대의 위선과 가식을 깎아내리고 팔로워를 털어버리기까지가 하나의 스테이지임\n",
      "(뇌피셜 마법 세계 교제시 매너들 1 위치 추적 마법은 불법 2 부엉이 우편 대화 시 응답 없다고 부엉이 세 번 이상 보내지 않기 3 피임 주문 무언으로 하는 건 진심 빻은 매너 4 늦은 시간 양해 없이 보고 싶다는 이유로 플루 가루 타고 오는 건 이별 사유 됨\n",
      "(다녀오겠습니다ㅏ는 개뿔 글ㄹ 자퇴할 거야!!!! 엄마, 아빠 학교 다녀오겠습니다 \n",
      "(단독 mb 청와대 국정원 특활비로 총선 대비 여론조사. 박재완 억대 국정원 특활비로 조사비용 충당 2008년 4월 9일 출범 45일 만에 18대 총선 치러짐 박ㄹㅎ 정부도 내 세금으로 저 짓 하더니 명박ㄹㅎ 독대는 부정선거 맞는다고 강력하게 의심한다 선거 개입 여론 조작은 사형이다 \n",
      "(단독 국정원 군 댓글 공작 부대에 격려금까지 지급 /ytn 격려금 준 시기 대선 1년 앞둔 2011년 12월 국방부는 사이버사령부를 국방부 직속 부대로 승격 원세훈 김관진 내가 낸 세금으로 나를 욕하고 사찰했네 \n",
      "(단독 국회 특활비 논의에. 이 헌수가 최경환 공략 제안함. 국회 특활비 축소 논의 나오지 않게 하려고 최경환 영향력으로 막고 1억 전달 한 달 만에 국정원 특활비 인상. 최경환 할복자살 못하게 경찰은 신변 보호해라 국민 세금을 당연하듯 삥 뜯은 경환이는 무기징역이다 \n",
      "(돈까스먹기전깨빻기 (아하하고 소해 \n",
      "(동의를 얻고 올리는 팬 웨이보 내용입니다 공항에서 팬:(충칭 사투리 왜 인제야 오는 긴데! *왜 이렇게 늦게 왔어 야오 왕:(청두 사투리 내가 여 일찍 와가고 머 하니 *일찍 와서 뭐 해 진짜 화제 종결자임 팬:친구들이 나한테 수작 걸라고 시키던데 야오 왕:그럼 난 대답 안 할란다 출처: ??_ azcrew \n",
      "(드디어! 81개 사업 분석 외부 연구용역 발주 ㅡ국정 감사 민주당 의원 등ㅡ mb 공기업 43조 5000억 원 투자, 회수율 38.3% 불과(30조 어디? 천문학적 부채 나랏빚 현재진행 *더 이상 미래에 세금 빠져나가지 않도록 산업부, mb 정부 해외 자원개발사업 실태조사 착수 | 다음 뉴스 \n",
      "(리빙포인트 갓세븐 팬미팅 원가 양도 제시 등등의 단어를 이용해 트윗봇을 돌려서 프로미 붙은 양도 트윗을 묻히게 만들면 플미충들을 화나게 할 수 있다 \n",
      "(문재인 정권이 끊임없이 전쟁 가능성을 입에 담고 있는 트럼프한테는 한 마디도 못하고 있는 것이 저는 문제라고 생각합니다-정동영 정동영이 너무 핵심을 찔러서 위선적인 노문 버들은 또 온갖 게거품을 물겠구먼.\n",
      "(방금 리트윗 트럼프의 세제 개편 계획에 따르면 대학원생들이 면제받는 수업료를 소득으로 보고 여기에 세금을 물리고자 한다는군요. 미국의 대학원들에 유학 간 한국인 학생들이 초긴장 상태라고 합니다.\n",
      "(빻 이창준 흉부 부자인 거 치고 별로 민감한 부위 아니라서 의아해 하는 황사 목. 오히려 집착적으로 가슴에 자국 남기는 거 황새목이고 가끔 기막히단 듯 정수리 멀거니 내려다보는 창준. 본인 흉부도 만만찮은 거 생각 안 하는데 사실 시목은 가슴이 많이 민감했으면 좋겠다 유ㄷ 빙글 돌리면 앓아(\n",
      "(뽀뽀를 쪽 ㅉㅉ 쪽\n",
      "(생명의 무게에는 저울질할 수 없다, 선택 자체가 부당하다. 제 말에 떠나가신 당신은 힘이 없으면 오지랖일 뿐이라고 하셨죠\n",
      "(선플해주세요 안철수 딸 재산 공개, 말뿐인 해명. 여론은 ˙증빙자료˙ 원한다. (네이버 뉴스 (네댓 세금 신고도 입으로 할 기세\n",
      "(성림들 그 배꼽에서 물 나오는 동영상 혹시 가지고 계신 분 보여주실 수 있나요. 궁금해하시는 성림과 아직도 한남 유니콘 찾는 친구에게 보여주려고 합니다 \n",
      "(성북구청 문지 지자 비판 발언 논란에 안 지사는 오늘 강연에 한해서만 질문을 받겠다며 즉답을 피했다 이게 진짜 비열한 게 지 발언으로 조중동 종편이 부정적으로 이용해 찧고 빻고 하는데 그런 의미는 아니다란 말 한마디 안 한다는 거임\n",
      "(세금 ->세금 성추행을 저지르는 사람들을 보면 경비 유용, 남의 공 가로채기, 이력/학력 위조 등 회사에 해가 되는 행위를 저지르는 경우가 많은데, 이들은 타인의 아이디어, 돈, 공로 심지어 신체까지 맘대로 해도 된다는 생각을 가지고 있어서라고.\n",
      "(속보 최저임금 인상으로 소상공인 영세 중소기업 4조 이상 지원 대책 발표 이게 나라다 이명박ㄹㅎ 최저임금은 거의 제자리 재벌 지원은 국민 세금 올인 역대 어느 정부가 노동자 소상공인 영세 중소기업까지 부담 되지 않게 조율했나고 \n",
      "(손가락을 꼼지락거리다가 물끄러미 보았어. 이런 게임은 별로 환영하지 않아요. 사람이 죽는 걸 보는 것만큼. 끔찍한 건(입을 다물 고선 고개를 떨궜어. (끄덕끄덕 가증스럽고 역겹네요. 흑막으로 의심 가는 사람. 있으신가요?\n",
      "(시크릿 오브 코리아 안철수 안랩 미국법인 세금 체납으로 자산 압류 - 세금부터 내라 \n",
      "(시크릿 오브 코리아 최경환, 세금 팔아 뒷돈 챙겼나?-최경환이 나서 아진산업 78억 원 세금 면제 드러나- 국감서 국세청장 조지고, 소득세법까지 개정 - 최경환 최측근은 아진산업 신축공사 수주 ? 아진산업 인사팀. \n",
      "(쌤통이다! 하지만 불쌍하니까 초코맛 바나나를 뚝 때서 준다 이건 안 매울걸?\n",
      "(쓸 말이 업ㅅ네 너무 선뜩만 하는 거 같아서 정성 들여 그려봐야지 >는 개뿔 ㅎ. 뭔가를 그렸다는 데에 의의를 두자 . 안 그리는 애들도 넘치는데 (자기합리화 오짐 \n",
      "(아니 정정하자. 해탈한 것 같다. 방금 3인칭 썼냐, 역겹네. 똑바로 말해주지. 지금 당장 안 나가면, 네가 여기서 데리고 나갈 녀석들 같은 건 없을 거야. 그거 대신할 건 얼마든지 있거든.\n",
      "(아마도 재즈 오장. 오늘부터 장관님에서 후차 보시한테 수작질 당하면서 눈치 못 채는 오장님한테 한창 어인 차별이라고 잔소리 듣는 재 브라. 오장님을 좋아한다는 걸 자각하고 꿈꿨는데 이딴 꿈이나 꿨으면 좋겠다ㅋ 나 인어왕자님과 결혼할 거야! 하는 오장님. \n",
      "(아시는 분? ☞박근혜 씨가 사용 중인 대리인단(변호사들 공짜로 쓰는 건 아닐 텐데, 저 대리인단이란 자들에게 퍼주는 사용료는 박근혜 씨 개인 돈으로 지불하는 걸까요? 국민 세금으로 퍼주는 걸까요?\n",
      "(알려드립니다 오늘 추경 처리를 목표로 원내대표단이 막바지 협상 중에 있습니다. 늦은 밤이라도 꼭 본 회의가 열릴 수 있도록 예결위에서도 최선을 다하겠습니다. 일자리 추경은 국민 세금을 국민께 되돌려 드리는 것입니다. 야당은 모순된 태도를 버려야 합니다.\n",
      "(알티 관련 무례한 사람 많고 무례한지 모르니까 알려줘야 한다 나한테도 고양이 늠 많은 거 아니냐 하는 디엠 보내는 사람들 종종있음 작업실 친구들이랑 15년 같이 캐어하는 거 하나하나 말하기도 귀찮음/ 오지랖은 사료 한 포 사주고 하시던가 (대용량으로\n",
      "(알티 아니. 이래이래 살아서 본인들이 행복하다는데 왜 거기다가 너는 .한 거 모른다 .가 진짜 행복한 거 다라며 오지랖 질들 이여. 너 님들도 입장 바꿔놓고 보면 아이 없이 살 때의 행복감을 모르고 있는 거 아닙니까.\n",
      "(어이가 없음 어르신께 하는 말 꼬락서니 봐라. 네가 황태자면 난 3일 만에 세상을 창조하고 4일간 늘어지게 잠만 잤어, 인마.\n",
      "(언니가 꼬락서니 보고 옷 다시 골라주느라 늦게 나옴\n",
      "(엎어져있음.로 마니. 로마니. 쿼티님 로마니 그려주셔서 감사해요 행복해요 저. 아니 쿼티님이랑 오랜만에 대화하는데 제 상태 꼬락서니가ㅜㅜ (갑작스러운 종장 병 환자\n",
      "(여기 와선 많은 사람들을 걱정했다, 많은 사람들의 고통을 보고 많은 우울한 얘기들, 많은. 내가 해줄 수 있던 건 위로와 치료가 고작이었다, 이걸로 된 걸까? 나는, 괜한 오지랖으로 오히려 상처를 곪게 만든 게 아닐까.(눈을 꾹 감는다\n",
      "(오지랖 힝, 두 번째 사진을 쓰는 게 나은 거 같아요 -첫 번째 사진으로 홍보되고 있는데 두 번째 사진을 쓰는 게 나을 거 같아 느낌만 내어봄 (허접해 보여도 포샵은 잘 다룰지 몰라서 물어가며 나름 오래 걸린 거랍니다.;; \n",
      "(오지랖은 부리지 않기로ㅠ (포스터 디자이너 분들, 새삼 존경합니다\n",
      "(오지랖을 부리려면 이 정도 각오는 하고 합시다였고, 또 한 번은 오늘 친구 결혼식. 이번엔 아예 준비된 부케 친구가 남자였다. 오늘 결혼식 여러모로 마음에 들어서 기분이 아주 산뜻함.\n",
      "(이 시장은 지지율이 낮은 최 시장에게 질문을 해 9분의 토론 시간을 뺏기는 게 마뜩지 않았던 것으로 보인다. 최 시장이 항의했지만, 사회자는 “합의된 룰을 어기지는 않았다\"라며 일축했다. - 공정은 개뿔! \n",
      "(이어서 근데 나꼼수의 문제는 욕해서 경박한 게 아니다. 항간에 떠도는 소문들을 사실인양 얘기하면서 마치 자신들이 진실을 밝히는 유일한 매 체인처럼, 이득 없이 하는 마냥 위선을 떨며 대중들에게 빠돌이즘 광기를 일으킨다는 게 문제다. 거기 빨려 드는 대중도 문제고.\n",
      "(이어서 타임라인에서 진보신당의 어느 활동가께서 여러 가지 사정상 모 매체에서 기자로 일하시게 되었다는 것을 보았는데, 주제넘은 오지랖이지만 모쪼록 그분의 선배분들처럼 본인에게나 대중들에게 의미 있는 기회가 되고 또 본업으로도 어기차게 복귀하시길(끝\n",
      "(일 년에 싸울까 말까 한 늍민 싸우다 민호가 개빡침 민호 : 아, 진짜 너랑 안 맞는다. 네 거 다 가지고 나가. 뉴트 : (민호를 어깨에 들쳐맨다 민호 : 난 왜 들어!! 내려놔!! 뉴트 : 내 것 가지고 나가라며! 넌 내 것 아니야? 내 것 가지고 나가잖아!!!!\n",
      "(자꾸만 힘 빠지는 손으로 겨우겨우 펜을 쥔다 뭉개진 글씨가 범 꼬락서니 대변하고 있다. \n",
      "(자수합니다 광고천재 이제석 님을 문캠으로 오시게 하려고 수작 부린 적 있음. 1월 30일에 새싹( 님과 제가 이메일 보냄. 결국 정중히 사양하심.ㅜㅜ그러나 약속하신 게 하나 있음. 다음 총선에 더 민주 도와주겠다고 약속받아 냈음.\n",
      "(저 탑에는 더 이상 아무도 가지 않겠지. 갈 곳 없는 부랑자나, 좀도둑이 아니고서야. 조용히 시선을 아래로 거두고 선 자신의 발치에서 잠든 단테를 쓰다듬는다. 씁쓸하네. 괜한 오지랖일지도 모르겠지만, 이상하게도 한순간 네가 그렇게 밉지 않아서.\n",
      "(종이를 가만히 내려다본다. 차게 식은 무표정에 차차 웃음기가 돌아온다. 잠시 그렇게 서 있다가. 종이를 갈기갈기 찢는다. 갈색 편지지 조각은 역겹게도 공중에 잠시 머물러 있다가 바닥으로 가라앉는다.\n",
      "(중소 벤처기업부 장관 후보자 홍종학이 세금 낼 거 다 내고, 중학생 딸 8억 원 건물 넘겨준 걸 갖고, 연합뉴스가 딸한테 건물 물려준 게 문제라는데, 그럼 연합뉴스가(국민 세금으로 사역한 삼성 이재용과, 4조 다스 편법 상속 의혹.이시형 에겐 아무런 비판이 없냐?\n",
      "(짝짜가ㅉ가ㅉㄷ짝ㅉㅉ짝짝짜각짝 짯 짝(날개가 닳아 없어질 때까지 손뼉 침\n",
      "(최상위권 부자에 명문고 명문대 출신이며 엘리트주의자에 지독한 계급주의자지만 자리하나 내주면 하루아침에 서민 코스프레 하고 평등주의자나 사회주의자로 변신할 수 있는 위선자인 1%의 국민이 주인인 나라. \n",
      "(칭찬으로서 참 오지랖 넓게 비즈니스 한다. “: 구글, 모바일 결제 시장 진입 ”\n",
      "(트윗 번역 마 후 마우 : 있다가 같이 밥 먹으러 가는데 아마츠키상 블록 했습니다 하는 김에 소라로 상도 블록 했습니다 개빡침 (※농담입니다 금방 돌릴 거예요\n",
      "(파이크 술루 커크 위선 / 리케 박스에 올라왔던 건데 너무 구리게 쓰고 짧아서 더 다듬으면 포스 타입에 업데이트하겠습니다 read: \n",
      "(편 글 설마 ‘중국에서처럼’ 환대 받을 거라 생각한 건 아니겠지? 사람 먼저다’ 말만 했지, ‘사람 위한 시스템 구축’에는 관심 없이 오로지 정권 탈취 위한 선동만. 이대병원 신생아 죽음, 이번 화재사고 죽음 모두 다 책임져라! 단, 세금으로는 말고! \n",
      "(편 글■초호화 황제 공관 논란 일파만파■ 박원순 200평 28억짜리 월세 임대료만 208만 원 국민 혈세로 지급 물품구입비 등 서울시민 1인당 소득 9배 지출 아들 박주신 소환 불응 3년간 외국 잠적 세계 어느 시장도 이런 관사 사용 안 해 재벌 욕하고, 서민 위한다는 놈 위선자! \n",
      "(포토샵 또 안 켜져서 개빡침 (컴퓨터가 맛이 갔나 (쓰밍 때문에 계속 켜놔서 그런가. \n",
      "(하지만,.,, 준일님께 그림을 그려드리고 싶었던 두 줄,,, ,, ,,,,, 어젯밤에 잠깐 말했던 그.,. 오지랖 부리다가.휘말린<<< (  클리브 생각하면서 그렸어요(  \n",
      "(한국의 빻은 매체에 고통받는 대화를 나누고 있었음 제임스: 제가 제안을 하나 하죠. (여성이고 페미인 여러분들이 힘을 합쳐서 뭔가를 만드세요! 코린: 저는 글을 맡을게요! 돝솥, 츠루넬: (게임 바르: (애니메이션 포브: (프로그래밍 롭: (드로잉 리디아: 저는 음악!(발랄 (일동 웃음\n",
      " 왜./뭐가-?/어휴, 오지랖도 참 넓다.넌 누굴 닮아 서 그렇게 오지랖이냐?너네 엄마 아들 아니랄까 봐 그러냐-?/그 말 하려고 전화했어?( \n",
      " cbs 거짓말 장단에 정치권마저 동조하는 이유? - 20만 신천지 성도들도 똑같이 세금을 내는 국민임을 잊지 마시기를. \n",
      "* 국회의 주인은 국민입니다! 국회의원은 국민이 선출합니다! 국회의원이 매달 받는 세비도 국민의 세금에서 나옵니다. 국회의 주인은 국민입니다 그러나 왜 일도 안 하고 팽팽 노는 것들 나가라 할 수 있는 권리도 없습니까? 국회의원 국민소환제! 대한민국 국민의 국회 주권 찾기입니다! 파이팅!\n",
      "* 대한민국 기러기들에게 고함! 1. 중국에서와 같은 추태(맞을 짓는 보이지 말 것! 2. 기러기들 활동비는 삼성에서 받은 돈으로 해결! 세금 축내지 말 것! 3. 외국 기자들도 기사 쓰니 오보 내면 바로 언론사 문 닫는 걸로! 너희들만 가만있으면 남북 평화 이룩된다! 제발 사고만 치지 말자! \n",
      "* 망자방 없던 분들 뉴짤 받으세요. (뉴짤 뜯으려는 수작; \n",
      "* 스리랑카 대통령님 국빈 방한 기사 검색 조선 : 어제 하나 중앙 : 어제 둘 동아 : 못 찾음! 하하하 한결 : 어제 하나 경향 : 어제 포토까지 포함 둘 오마이 : 못 찾음! 허허허 경제, 지역, 인터넷 신문에서야 볼 수 있음. 이런 것들이 언론사 보조금 명목으로 내 세금 빨아먹는 세금 충들인가? \n",
      "* 오늘의 키워드 보험업법을 개정하는 것만으로도 삼성이 20조의 세금을 더 내야 한단다! 김기식 금감원 장님 파이팅!!!! \n",
      "* 오지랖이 넓다(?쓸데없이?지나치게?아무?일에나?참견하는 면이?있다. 머슴은 주인과 관계된 모든 것에 관심이 있어야 한다. 주인의 일상사에 아무리 관심을 가져도 지나칠 수가 없고, 아무 일이란 건 있을 수도 없다. 머슴 부하들은 피곤하겠지만, 머슴은 오지랖이 넓어야 한다. 그래서 이잼.\n",
      "* 이는 지저스에 대해서도 마찬가지로, 현생의 유다는 지저스를 기억하지 못합니다. 지저스에 대해서는 그저 복잡하게 얽히게 된 오지랖 넓은 이웃 정도로 생각하고 있습니다. 아마도? 그럼 이벤트 기간 동안 잘 부탁드립니다.\n",
      "* 이명박의 구세주 나땡땡? 공교롭게도. 이명박 한창 팡팡 터질 때 나경원이 ioc에 단일팀 반대 서한 보낸 일로 북한이 현송월 파견 갑자기 취소 연락. 평창과는 무관하게 이명박은 쭉. 가야 한다! 구세주는 개뿔! 주어없는 걸로 한 평생 잘 누린 너도 꼭 죗값 치렀으면! 친일파 x! \n",
      "* 정부는 곧 국민입니다! 당신들의 문제를 정부가 해결해주길 기대하지 마십시오! 정부는 곧 국민입니다! 정부가 쓰는 돈은 즉 우리의 피땀 흘린 세금입니다! 문제는 당신들이 만들어놓고 왜 그걸 사회적 문제로 보이게 해 정부가 나서게 합니까? 정부 해결은 결국 다른 국민 희생으로 이어집니다 \n",
      "* 주먹구구식! 오락가락 판결! 주먹구구식 국회! 저런 것들이 이 나라 선거와 입법을 책임지는 것들이라니. 국회의원들의 특권 의식! 우리가 홍준표처럼 (공금을 생활비로 김성태처럼 (국민 세금으로 벌금을? 아마 벌써 감옥 가지 않았을까? 기준도 없고 특권의식으로 가득 찬! 특권 박탈해야\n",
      "* 커뮤에 빻은 캐릭터를 낼 때 그 캐릭터가 하는 말이 뒷사람에게 트리거를 자극하는지 다시 한번 생각해보기. 인트로 시작하기 전 테스트 트윗 올릴 때 * 이 캐릭터는 빻았습니다. oo에 대해 트리거가 있으신 분은 마음을 주세요.라고 써두기. 어이 거 되게 조은 방법\n",
      "*** 여러분은 손톱보다 짧은 몽당연필을 보셨습니다!!!! 이 트윗을 알티 하면 돈이 들어오고 행운이 찾아오기는 개뿔 그냥 관심이 좀 필요한 정줄놓은 고3입니다(전 \n",
      "******* 해주세요(please******* 세븐틴 14일 콘서트 스탠딩 양도구합니다ㅠㅠ 너무 가고 싶어요 14일 스탠딩 어느 구역이든 상관없어요ㅠㅠ 플미충은 꺼지세요ㅠㅠ\n",
      "*otr* 백지영. 30살 여배우. 15살 때 드라마 조연으로 데뷔해 끼를 드러낸 후 예능, cf 등의 프로그램에도 종종 모습을 드러낸다. 보통 조용하고 상냥한 역을 많이 맡지만 사실 오지랖도 넓고 활발하다. 소문에 의하면 주량이 엄청나다고.\n",
      "*다니엘 이불 밖은 위험해 연구 예능 출연 많은 것을 사실 좀 걱정했었다. 이미지 소비가 빠를까 봐. 근데 개뿔. 다니엘은 대중 앞에 자신을 드러내면 드러낼수록 더 사랑받을 사람이다.\n",
      "*빻은 취향 전시 ○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○ \n",
      "*쇼크에 못 가시는 덕구 님들!!* 티켓팅인데 가격이 무료라니. 개헬 예상되시죠. 그래서 여러분이 필요합니다 티켓팅을 함께해주세요ㅠㅠ 함께해주셔서 플미충, 머글이 꿀꺽할 자리를 줄여주세요 잡은 자리는 주위 덕후분들께 양도해주세요ㅠㅠㅜ\n",
      "*장소에 혹시 혼돈이 있으실까 염려한 봇주의 오지랖으로 충무아트홀 컨벤션 센터의 전철 교통 편입니다. 안 보이시면 이쪽! 행사 준비하신 주최 및 스태프분들 고생하십니다ㅠㅠ \n",
      "*제일 중요한 플미충 신고방법 예매내역 캡처 본과 프로미 거래 정황이 필요함 그러니까 그 사람 예매내역(좌석번호 예매번호과 계좌 같은 거래 상황 캡처 본을 예스 1:1게시판이나 따로 문의하시면 해결 가능하다고. 아무래도 플미충확실한신고방법은 좌석번호 예매번호인 듯\n",
      ", 29조를 쓴 결과는 40조의 빚과 지금도 투입되고 있는 세금!. 참여연대가 자원외교에 대화를 발간했습니다. \n",
      ". ■■■☞ 시장님의 사퇴 여부 관련하여 이래라저래라 오지랖 떠는 인간들 있는데 시장님이 알아서 훌륭하게 잘 하실 거니깐 쓸데없이 이래라저래라 주점들 떨지 마라 분열의 언어 사용하는 것들은 국무당 박지원. 찰스 검증에나 집중해라.\n",
      ". 1번 문재인 대통령이 되어야 할 이유입니다!! 대선주자 1인당 선거비용 400억 .500억 원 소요 홍준표ㆍ안철수 유승민ㆍ심상정 득표율 10% 미만이면 국민 혈세 수천억 원을 절감할 수 있습니다 1번 문재인 찍어 국고의 세금 낭비를 줄입시다!!! . \n",
      ". 그는 대담집에서 “(세수가 부족하면 당연히 재벌과 부자에게서 세금을 더 걷을 생각을 해야 하는데 불쌍한 서민들을 쥐어짠 것”이라며 “담뱃값은 물론 서민들에게 부담 주는 간접세는 내리고 직접세는 올려야 한다\"라고 강조했다. \n",
      ". 김재련 변호사 누구? 위안부 화해치유재단 이사 ㅡ피해 할머니들껜 돈 받고 침묵하시라 더니 서지현 검사 변호? 자유당이 만든 여성신문 편집위원 새누리 정권 때 각종 감투 ytn 노조가 뽑은 3대 적폐 인물 중 하나인 류제웅이 김재련 남편 김재련 네 목적은 어떻게든 문재인 정부 흠집 내려는 수작\n",
      ". 짝 ㅉㅉ.멀리서 응원합니다. 귀국해서 전해철 지지하려는 1인.\n",
      ". 그리고 당내 적폐 세력, 댓글 부대, 혹시라도 국민의 세금으로 밥 처먹고 자당의 정치인을 음해했다면, 머리 박고 자숙한 뒤, 자수하여 광명 찾자.\n",
      ". 제가 그 탐라에서 부러워만 하던 라라 롱 마카롱을 먹었는데 말이죠 . 아껴먹으려고 하나씩 먹어야지 했는데 개뿔 정신 차려보니 6개 남은 거 있죠 어떡함 (쳐움 \n",
      ".(무거운 정적이 흘렀다. 이게 무슨 꼬락서니야. 눈을 질끈 감고 눈물을 참았다\n",
      ".근데 타입 문익 프혁에 난리 쳐놓은 꼬락서니를 보면 그거 될까.\n",
      ".아니. 안 괜찮아. 절대 안 괜찮다고. 멘틀 부스러기. 그래 딱 저 표현이 정답이라서 유레카라도 외치고 싶은 심정이었다. 제 멘틀은 부스러기가 되다 못해 베이비파우더급 고운 파우더가 되었다. 말이 되나. 이 꼬락서니가. 이 꼬락서니로는 어딜 갈 수도 없다고.시체가 되고 싶어.\n",
      ".? 내 콜로 마그 덱인데 이거 내가 이 무기 꼬락서니로 콜로 마그 잡고 다녔다고???? \n",
      ".근데 벌써 오늘 위키드 가기 귀찮아지고 양도 충동이;;;;;;;; 이놈의 병!!\n",
      ".따뱝ㄷ셔ㅑ 제가 원래 잔소리를 많이 합니다 오지랖이 넓어서 어푸푸푸ㅜ푸\n",
      ".갈 곳이 없다면 우리 집에 갈래? 히라 사변 카라카라. 불행 체질 오지랖 넘치는 히라와 상처에 무감각한 사변이 만나 담담하게 힐링하는 이야기를 보고 싶다 \n",
      ".계속, 좋, (틈. 좋아할 거예요. 조슈아도 날 좋아해 줄 건가요. 정말로? (눈매가 얕게 처졌다. 날 좋아해 주던 사람이 누가 있었지. 단 하나뿐이 기억나지 않는다. 그것도 이젠 없는. 그런 말은 전혀. 으. (스스로 역겹다는 표정.내가 그런 말을 들을 사람인 줄은 몰랐어요.\n",
      ".내가 지금 페미니즘과 관련해 매우 황당한 영상을 봤고. 반전이 있겠지라며 꾹꾹 참고 봤는데 반전은 개뿔.\n",
      ".는 개뿔. 진지해지려고 했더니 토마스 때문에 망했다. 왕 씨 눈알 봐.\n",
      ".사람을 미워하는 건 잘 못 해요. 목련 씨가 무슨 일을 했든 제가 역겹다고 생각하지는 않을 것이라는 의미예요. 다만 조금 슬플 뿐이지.\n",
      ".그래요? 내가 너무 오지랖을 떨었나? 아뇨. 흥미로운 의견이에요. 저는 사실 슬픔의 감정을 느끼지 못하거든요. 뭐? 요정은 무척이나 순수하고 아름다운 존재니까. 저희에게는 비(悲가 없어요. 희(喜만 남아있어요. 이곳에는.\n",
      ".하무열 형사. 허튼수작을 부리면 배는 폭파됩니다.장난으로 듣지 안아줬으면 하는군요.\n",
      "/ 170904 5화 민호 보정 캡처 1 누가 오지랖 부릴 거라고 경고하면서 이렇게나 다정하게 바라보면서 말하니 ㅠㅠㅠㅠㅠㅠ \n",
      ": [속보] 경찰, 정미홍 세월호 추모 청소년, 일당 6만 원 글 내사 착수 | 미디어다음 쌤통이다. 지켜보겠습니다. 그 지인도 함께 조사 바랍니다\n",
      ": 『안철수, 어머니가 투자한 집서 8년 살고선…“집 없는 설움 잘 안다”』 진짜 집 없는 사람들을 조롱하는 거 아니면 이따위로 위선을 떨지는 못할 것이다.\n",
      ": <박근혜, 단일화 비판하며 말춤을 추다> 박근혜가 말춤 추며 생쇼 하는 거야 그렇다 치고 옆에서 함께 춤추는 청년들 도대체 무슨 생각일까요? 이 나라의 미래가 걱정입니다 \n",
      ":  통진당 해산과 전교조 법외노조 처리를 두고 북한이? 오지랖도 넓다. 정은아!! 너네 선생이나 신경 써라. (cont \n",
      ": 민주를 팔아 반역을 하고, 환경을 팔아 국책사업을 훼방하고, 평화를 팔아 적 화통 일을 기도하고, 인권을 팔아 반역자를 민주투사로 둔갑시키고, 민족을 팔아 김정일에 굴종하는 종북좌익세력의 위선은 이제 종식될 때가 되었습니다.\n",
      ": 버스 2시간, 이제 지하철 . 크크크크 잘대따 쌤통.ㅎㅎ 얼른 와 보고 싶어ㅋ\n",
      ": 법원에서 감정 의뢰한 거니깐 회신했겠죠? 채택하던 말던. 의뢰도 안 한 걸 의협에서 오지랖? 중지하란 명령을 받고도 왜 꾸역꾸역 했을까나요?ㅎ \n",
      ": 아 엠블랙 수니들 웬 열폭이야 비스트한테 밀리고 인피니트한테까지 치이니까 다음 만만한 게 틴탑이냐 근데 어쩌냐 안 만만해서 막말터진닼;인피니트 비스트 드립? 제가 수는 제 가까요 웬 오지랖;아 그리고 저희는 해외 팬다 오십 당씩 사세요.\n",
      ": 유병언 잡는다고 생쇼를 하면서 정작 병력은 밀양과 청와대에 다 몰렸네 워.서초동 삼성본관에도 몰려있습니다 \n",
      ": 이재명 성남시장, 분위기가 심상치 않군요!! 이제 용서는 사치입니다 나라를 팔아먹고 수백 조를 날리며 처먹고 수백 명 아이들을 학살한 자들에게 용서는 위선입니다\n",
      ": 정신 나간 이중인격 위선자.   tv 토론에서 삼성 까댄 이정희 스마트폰이 갤노트인 것으로 밝혀졌군요. ㆍㆍ\n",
      ": 친일은 한국 보수의 정체성 중 하나입니다. 이 논리로 나도 수십 번 글을 썼다. 토 다른 오지랖들은 nl의 종북좌파즘으로 입진 보들이 나불거리더라.\n",
      "://bbs.game23.co.kr/humor-17859.html 개빡침.jpg - by 잉여 게시판\n",
      "://www.yagoogong.com/sp/mmm.168610 스타 2 캠페인 개화 남류 - by 나간 지\n",
      ":저 최근에 그거 들어가 봤어요 한번.! 카카. 카카오톡에. 그 방에 있잖아요. 움짤이라고 얘기하는 거 있잖아요. 들어가서 보기만 하고 나왔어요. :왜.? :안 넘겼어. 넘기면 약간 너무 쉬운 남자 같아서 시러쒀 ? 뱀이 도도한 남자 \n",
      "--;;  지난달 노짱님 계신 곳을 찾아 예를 갖추기 위해 신발을 벗었습니다. 지키고 있던 경찰 왈 벗지 않으셔도 됩니다 이런 오지랖은 없으면 좋겠습니다. 뵙는 것만으로도 가슴 아린데. 아직 내 눈물은 마르지도 않았는데.\n",
      "? _ 거머리 같은 나를 죽여 나를 묶어 나를 숙연! 하게 만들어 im so 슈퍼 ♭\n",
      "?  ◀? 솔리야<행복한 위선자들>선착순 통판(.1/15 이번 디 파스타에서 재판했던 영화 맨 프롬 엉클의 솔로 x 일리야 책 재고 선착순으로 통판합니다! 알티 감사합니다! \n",
      "? 개 삐삐 하나 했다\n",
      "? 우병우 쌤통이다 이우철 칭찬해 \n",
      "? ㅎ. 흐. 흑발이니.? (그때 내 머릿속을 스치는 한남 더 힐 헬스장 노란 머리 청년들 목격담. 남 오빠 흑발이면 뛰어내린다 \n",
      "???. 이. 이 몸께 무슨 짓을 한 거냐 잔챙이 놈들.!! 허튼수작 부리지 말라고! 제령 같은 거 당할 생각은 추호도 없단 말이다! \n",
      "??????????? 개빡침 코스트 하나도 안 남았는데 \n",
      "???????????????? 참견 ????????????????????????????????????????????????????????????????? 관용어 (???????? 오지랖이 넓다\n",
      "???탐라 너머에 수인 내는 분이 있다고 들었습니다 오지랖이지만 너무 반가운 나머지 그럼 20k\n",
      "??버프? 그 사람이잖아요 플미충들이 표를 가져가서 프로미 붙여서 팔아버릴까 걱정이 되셔서 자기가 가지도 않는 경기 티켓팅하고 트친들 주겠답시고 매경기마다 티켓으로 얼이 이 벵 하시던 분. \n",
      "?결제방법 무통장이 떠 빠르고 튕김 위험이 적습니다! 결제창에서 튕기면 최악이잖아요ㅠㅠ 1. 입금자명에는 입금하실 본인 이름을 적으시면 됩니다! 2. 세금계산서는 발급받고 싶으심 받으셔도 좋지만 시간이 걸립니다 3. 주소는 미리 저장해두는 센스 \n",
      "[ 12.19일 투표약속합니다] 곧 새누리당 박근혜 캠프에서 감성 전술로 눈물을 들고 나온다는 소식이 들립니다. 박정희의 죽음, 육영수의 죽음, 그리고 보좌관의 죽음에 대한 눈물 영상으로 감성을 자극할 전술인가 봅니다. 위선에 속지 마세요!!!\n",
      "[ 5화 예고 a korean odyssey preview ep.5] 계속되는 이승기의 수작질 위험에 빠진 ?? (출처 : 화유기 | 네이버 tv 5화 예고 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  event ] 이번 마스터가 출국 전 처음이자 마지막 오프라 너무 간절한데 플미충들 꼴보기 싫어서 티켓 구할 때 수고비로 붙이려고 모아둔 돈으로 >>갈릴레오 대형<< 망원경 알티 추첨 한 분 사드려요 만약 원가 양도(기왕이면 첫날 받게 되면 망원경 + 제 것 사면서 이 밤 2도 같이 보내드립니다 \n",
      "[ 개인적으로 과거사를 이야기하는 것을 좋아하지 않아. 이미 역겹고 수치스러운 기억이라고 정해버렸기 때문에.] \n",
      "[ 극과 극의 추천인거욬 조용하고 개인주의적인 애쉬랑 활발을 넘어 과도하고 오지랖 넓은 빈터랑 페어플레이햌 ???? ]\n",
      "[ 있지 바쿠고. ] [ 왜. ] [ 지금 기분 좋아? ] [ 뭔 짓 했냐. ] [ 미안해! 반지 잃어버렸어. ] [ ㅉㅉ이 칠칠맞은 새끼. ] [ 화 안 났어? ] [ ㅊ 새로 사러 가지 뭐. ] [ .바쿠 고도 사실 잃어버렸지. ] [ 많이 티 났냐? ]\n",
      "[ 필리버스터 ] 김경협 의원 발언 중 조원진 의원 항의 이석현 조원진에게 개빡침 <경고했어요, 퇴장시키기 전에 들어가세요> <내가 의장직을 걸고 얘기합니다. 의사진행 방해하지 마세요>\n",
      "[!트친소!] 이런 그림 그리는 새럼입니다 마음 남겨주시면 취향 맞는 분 찾아가요.! 3라인은 위주 리버스도 좋아하는 원더러 낼 루미입니다 탐라대 화랑 섹트, 빻은 취향 등등 유 위해서 흔적 남겨주세요.! \n",
      "[] 180309(금 안내 판매처 : 한남 동북 파크 (서울시 용산구 한남동 727-56, 블루스퀘어 3층 사인회 시간/장소 : pm 8:00 (tcc 아트센터 / 서울특별시 영등포구 당산동 4가 93-1 \n",
      "[★] 가식과 위선. a puppet with a pretending \n",
      "[10월의 퀴어 밥상] 명절날 고된 집안 일과 친척들 오지랖에 지치신 분들은 퀴어 밥상으로 오세요.영양 듬뿍 버섯밥과 주키니 팬케이크와 함께 수다 수다하면 몸도 마음도 힐링! 10월 7일 오후 1시까지 kscrc로 오시안 \n",
      "[13화 예고] , ＂나한테 시집올래?＂ 향한 수작질 \n",
      "[13화 예고] 나한테 시집올래? 오공이의 프러포즈 수작질 이번 주 사이다 원샷 드링킹 각! 이건 무조건 - 절대 낭만 퇴마극 <화유기> tvn 토 일 드라마 매주 [토 일] 밤 9시 tvn 방송\n",
      "[161030] 클로저 퇴근길 배우님 오늘따라 너무 반갑게 인사하길래 왜 친한 척(?? 하시냐고 농담 했더니 밖에서 그러면 오지랖이지만 여기서는 괜찮아!라고 하셨다. 무. 무슨 말이지. \n",
      "[180414 김포 팬싸] <4> (늦덕이라 뷰리풀콘 못 간 얘기 이번엔 와? 네! 오 성공해써? 저 이틀 다! 스탠딩! 오.잘 했어요, 너무 비싸게 팔더라고. ㅠㅠ.오빠 플미충들 때려줘요 손만 지작 만지작 하다 깍지 끼는데 머 이리 자연스럽냐고. 다시 한번 유다정.유스윗.오빠다해요, \n",
      "[1st look vol.60] 연기자는 유일하게 정직한 위선자라고 했던가. 예능에서 보여준 털털한 모습 안에 진지한 아름다움을 간직한 배우 송지효를 만났다. \n",
      "[1인 가구 토론회] 참석하시는 모든 분들께, 1인 가구 여성들의 이야기를 담은 소책자 <온갖 무례와 오지랖을 뒤로하고>를 드립니다. 백오십여섯 명의 이야기를 인포그래픽, 키워드, 웹툰 형식으로 충실히 담았습니다. 기대해주세요 : \n",
      "[1인 가구] 소책자 <온갖 무례와 오지랖을 뒤로하고> 소장하고 싶다면? 우편료 2,000원(1권을 입금 후 링크로 신청하시면 보내드립니다. 입금계좌 : 우리 064-121846-13-403 한국 여성민우회 \n",
      "[1차 수요 조사/] 체스는 신사적인 게임이지. 동시에 거짓과 위선도 없어져. 너희는 얼마나 아름답게 울부짖을까? 해리포터 위저드 체스 기반/시리어스/00/글 그림 복합/추리 조사/몰살 가능성/2주 단기 일정 말이 모이면 개장합니다. \n",
      "[1차 홍보] 태어난 생명에 귀천은 없습니다. 위선자. 그 자신도 결국 백성의 이름 위에 군림하고 있으면서. - 1월 1일 신청서 접수 예정 \n",
      "[2] 때로 이불을 뒤집어쓴 채 그 속에서 소리 내어 울기도 하거든. 나는 나를 둘러싼 가족, 친구들, 그 모든 것의 위선에 질식할 것만 같아. 남의 눈에 보이는 사랑과 행복이란 얼마나 위선에 가득 차 있는지 너는 모를 거야._『마이너리그』\n",
      "[2017 가요 결산] 올해 가장 사랑받았던 음악들2017년 올해의 주목할 만한 작품 태민 솔로 2집 앨범 < move > 케이팝(k-pop의 진화를 보여준 수작. 음악뿐 아니라 춤, 스타일 모든 면에서 완벽했다. - 오마이뉴스 부분 발췌 \n",
      "[2차 홍보지] = *야!!! 제대로 형님이라고 불러라!! *키도 작은 게 형님은 개뿔 *악마 주제에!!! 금사빠 주제에!!! *나는 모두를 사랑하는 거지 금사빠는 아니야.! *(뭐래 [투 커/03/bl/약 대립/부상/일상/3주 단기] \n",
      "[36.5°] 따뜻한 개천으로 내려오든가 진보적 지식인들의 위선을 신랄하게 비판한 글인데 좀 멋진 듯. 사실 보수든 진보든 그들이 대외적으로 말하는 청년에 자기 자식들은 포함되지 않는 것 같더라는. ㅎㅎ\n",
      "[4 대 강에 20조 이상 퍼부을 땐?] 언론이 최저임금 7530원으로 나라가 어떻게 될 듯 난리다. 자영업자. 중소상공인들 망한다 난리더니 관련 대책 내놓으니 세금 투입한다 또 난리다. 본래 세금으로 정책 실현하는 거 아닌가? 그럼 미르재단 2 만들어 꼼수 지원하란 건가?\n",
      "[6-1회] 세 걸음과 오지랖 \n",
      "[6-1회] 세 걸음과 오지랖 (출처 : 어쩌다 18 | 네이버 tv \n",
      "[76] 상냥함은 개개인이 손으로 만든 것과 같아서 때로는 오해받거나 위선이라고 생각되기 쉽단다 - 후르츠 바스켓 중 / 소녀감성봇\n",
      "[black label] 뜨거운 성원에 부응하여 팬텀 하이브 반지 리뉴얼 판이 2018년 1월 27일 발매 결정! 제조사:스퀘어 에닉스 판매 가격: 26,000엔 (세금 포함 호수 : 9호 / 11호 / 15호 소재: 925, 지르코니아(파랑, 스와로브스키(투명 ※ 전용 케이스 포함 \n",
      "[e-clean 선거] 사회에서 존경받는 이들은 품위와 품격이 있어 보입니다. 그러한 것은 남이 주는 것이 아닌 자신이 평소에 하는 말과 행동에서 비롯된다고 합니다. 가식과 위선이 아닌 진실된 말과 행동으로 자신의 품격을 만들어 갑시다.\n",
      "[hd 포토] 아이언맨 신세경-이동욱, ‘까칠남과 오지랖 여의 환상 케미 기대해주세요’ \n",
      "[heechul instagram] kimheenim: 여러분도 책 읽는 습관을 갖도록 하세요 . \n",
      "[hq] 180414 인천 페스타 진지하게 열 섹시하는 거 너무 좋아서 조금 죽고 싶다,,, 큐티 섹시에 이어 혼자 뷰티 섹시를 밀었는데 섹시함도 이 정도 되면 듀티 섹시 수식어도 부여해 줘야 한다 세금 내고 감상해야 한다는 뜻이고 면세 적용도 안 돼. まじ卍 \n",
      "[jd] 아웃도어 생쇼 헐.대박 -아웃도어 랭킹 9위 동방신기 (음성과 화면 버퍼가 약간 안 맞을 수 있습니다/ -에서\n",
      "[jtbc 뉴스룸] 국세청, 강남·세종 다주택자 세무조사 예보. 자금 마련 경로 및 세금 탈루 여부 등을 집중 조사. \n",
      "[jtbc 뉴스룸] 만찬을 하고 폭탄주를 마시며 금일봉이 오갔지만 의례적인 자리라며 문제없다는 입장인 검찰. 술자리서 오간 금일봉은 분명 세금이라는 생각에 오랜만에 자괴감을 느껴보는… \n",
      "[jtbc 뉴스룸] 안철수 후보 부인 김미경 교수, 세금으로 봉급 받는 국회의원 사무실 직원들에게 여러 사적인 일 지시했다는 의혹 제기돼. 김 교수로부터 이런 지시를 받았던 보좌관은 압박이 컸다고 밝혀. \n",
      "[jtbc 뉴스룸] 양지 축구단의 비극, 혹은 추억 양지 축구단의 최종 목표는 북괴를 꺾어라 였다는데…시민의 세금으로 전 직원들과 민간인까지 동원해가며 그들이 꺾고 싶었던 것은 무엇이었을까. \n",
      "[jtbc 뉴스룸] 예고 ● 날마다 달라지는 20대 표심 ● 재원 마련은 뒷전…헛된 공약들 ● 한·미 fta 개정 미국의 압박 ● 세월호 선내 수색작업 시작 ● 연봉보다 월등한 세금 인상률 ● 손학규 국민의당 선대위장 출연\n",
      "[jtbc 뉴스룸] 이시형 전세금 6억, 특활비 의혹으로 재조명. 당시 특검은 전세금의 절반을 청와대 직원들이 내준 정황을 확인했었는데, 그 직원들의 상급자가 김백준 전 기획관. \n",
      "[jtbc 뉴스룸] 장하성 정책실장 고소득자 세금 더 내야, 김동연 경제부총리 후보자 법인세 실효세율 높여야 이런 조치 뒤에도 정책 재원이 부족할 경우 증세 카드 꺼낼 방침 \n",
      "[jtbc 뉴스룸] 직장인, 지난 10년 동안 오른 연봉 비율보다 근로소득세 인상률이 세 배 이상 높아. 중산층 근로자 세금 부담만 늘며 정부가 기업보단 근로자 세금을 늘려 세수를 확보했단 비판 피하기 어려워. \n",
      "[jtbc 뉴스룸] 청년들 아르바이트비도 안 주면서. 임금체불 논란된 기업들, 고용 잘했다며 세금 감면받아온 것으로 확인. 민주당은 감면받은 세금을 환수하는 방안 추진하기로. \n",
      "[jtbc 뉴스룸] 최순실, 독일 도피 직전 머문 아파트 전세금 현금 다발 지불. 계약 당일 계좌 인출 내역이 없는 것 등, 검찰은 특수활동비 일부가 최 씨에게 건너갔을 가능성도 주목하고 수사 중. \n",
      "[kr] oregon scientific meep 간단 리뷰 [4k] 님이 공유 f717 님 개빡침 \n",
      "[mr removed] 141205 infinite f - 가슴이 뛴다 (heathr …: 엠알 제거 들고 옴 누가 못한대!!! 이거 듣고 이젠 괜한 오지랖 그만 좀;;;\n",
      "[newbc 광화문 뉴스] 안보 외치던 야당, 위기 상황에 ‘안보’이네. 김장겸 구하느라 대북결의안 표결도 불참. 안 보는 개뿔 \n",
      "[only ]부산팬콘원가양도 동생이 제 것 도와줬는데 둘 다 성공해서 하나 양도해요! 플미충 싫어서 원가로 양도합니다 자리는 1구역 600번대이고, 워너블 인증받습니다. 당첨자 발표는 제가 시간이 될 때 알티 추첨하겠습니다\n",
      "[proplica 변신 립 로드 세일러 유러너스 넵튠] 예약: 2월 2일 13시부터. 발매: 7월 발매 예정 유러너스+넵튠 (세트 세금 포함 16,200엔 유러너스 세금 포함 8100엔 넵튠 세금 포함 8100엔 \n",
      "[ plz] 윙즈 파이널 막 콘 t03 원가 양도해요. 월요일 제출인 과제가 생각보다 오래 걸리네요, 출국 때문에 팬미팅도 못 가는데 근처 살아서 티켓은 고척에서 직접 드리고 돈도 그때 받을게요. 혹시 모를 플미충 방지를 위해 4기 카드나 아미 밤 인증만 받겠습니다. \n",
      "[ 감사합니다]<산 자의 밤, 죽은 자의 아침> 이북 출간 기념 이 트윗을  하신 분 중 1분께 치킨 기프티콘을 선물 드립니다! 발표는 30일 7시! 짝사랑 수/짝사랑은 개뿔 내가 먼저라 공/포스트 아포칼립스/로드무비 \n",
      "[ 부탁드립니다] 내일 열리는 그럼 20000에 오시는 분들 중 제가 만든 파베 초콜릿을 ‘소량’나눔 하려고 합니다! 사실 지인분을 드리려고 시작하게 되었으나. 제 오지랖으로 과하게 되었네요; 원하시는 분 말씀 주세요♡ \n",
      "[ 추첨] 토끼즈 배지 선입금 “빻은 사람들이 세상에 너무 많아서 화가 난다.!” 토끼자와 함께 빻은 사람들을 다 빻아버려요! 선입금 하러 가기 ?> *선입금 후 제작이기 때문에 굿즈 수령까지 최대 두 달 소요됩니다! *선입금 특전으로 스티커 세트를 드려요(?˙??˙ ? \n",
      "[] mfu 온리전 솔리야 신간 <행복한 위선자들> 선입금 시작합니다. 포스 타입에 연재했던 거, 소설본, 60페이지 내외 예상. \n",
      "[] 로키는 파는 복숭아입니다 글은 어쩌다 쓰고 대부분 빻은 욕트섹트가 주를 이룹니다ㅠ 교류 좋아해요 되도록 성인분이면 좋겠고요! 마블(로키는 트윗을 주로 하셨음 좋겠습니다ㅠㅠ 리버시 브리, 잡덕, 구독러분들은 죄송합니다! 멘션 남겨주시면 성향 맞는 분께 찾아갈게요 \n",
      "[] 맨프엉 온리전에 나왔던 솔리야 신간 <행복한 위선자들>이랑 <아브락사스> 선착순 통판 시작합니다! \n",
      "[] 한 장르 계정 분리 결심 3년 만의 계정 분리로 알티 리벤 받습니다. 이런 거 그려드리고 트인 한정 아니욥. 수작업은 너무 오래 걸려서 컴퓨 작업으로 그립니다. 장르는 한 장르만 받을게욥 \n",
      "[]이 엑스 아이디 미니콘 원가 양도 구해요 300번대 안으로 주셨으면 좋겠습니다 플미충 안 받아요. 사람 하나 죽어가는데 살려주시오ㅜㅜㅜ\n",
      "[sbs][단독] 이건희, 차명계좌 더 있다. 상당한 수준_ ! 국세청 조사 결과 이건희 회장 차명계좌가 지금까지 알려진 4조 5천억 원 규모 외에 상당수 더 있는 것으로 파악됐다. 당국은 추가로 파악된 차명계좌에 대해서도 세금을 매긴다는 방침이다.\n",
      "[sc 초점] 불한당·남한산성 뒤늦게 빛 보는 비운의 수작 | 다음 연예 \n",
      "[talk] 청순한 얼굴의 여배우 a 양, 분장실에만 들어가면 돌변한다? 오지랖 대마왕부터 절대 앙숙까지 메이크업 아티스트가 고발하는 스타들의 분장실 진상 스토리.여기서 확인하세요! \n",
      "[tv 토론 실시간 팩트체크 ?] 홍준표 “(노무현 전 대통령 사저 그 집 주변에 들어간 세금이 1000억 원이 된다 대선 자문단 \n",
      "[wwyd: 한글자막] 뚱뚱한 여자가 뷔페에서 욕먹을 때, 당신이라면?: 내용 중에 뚱뚱한 여자에게 오지랖을 하는 사람(배우에게 하는 말이 내가 평소에 늘 하고 싶었던 말이라 심금에 울렸다.\n",
      "[강금실] “전범은 반성하는 법이 없다. 그런데 주은래는 참회를 요구했고, 참회할 때까지 반성문을 쓰게 했다. 첨엔 건성으로 위선으로 응하던 전범들도 반복되는 과정에서 외면했던 자신의 행위를 구체적으로 마주하게 됐고 결국은 참회했다”_\n",
      "[강철 온] 그리란 테마 목걸이 추가 사진입니다. 판매 가격은 아직 미정이나 1만 5천 원-1만 8천 원 정도 잡고 있습니다. 수작업이기에 색 분포도가 다 다릅니다. \n",
      "[개빡침] 서울 서대문 구청에서 김일성 찬양론자 한홍구 강연회 여는 거 알고 있냐? \n",
      "[개빡침] 조의연 판사 비겁한 판결이다!! -김어준 뉴스공장 0119 - 님이 공유\n",
      "[개빡침] 해수부가 세월호 절단하려는 비밀 -김어준- 님이 공유\n",
      "[개빡침주의] 2004년 밀양 여중생 집단 성폭행(41명 가해자 한 명 현직 여경 됨 \n",
      "[개인 홍보] 포르테님이 쓰신 전 신록의 천신의 현신 양요섭. 19살. 밝고 오지랖 넓음. 애교가 없음. ※현대 시대 사람.\n",
      "[경향신문] 선동과 권모술수로 얼룩진 위선의 화신 김대중을 벗긴다 \n",
      "[고발뉴스 브리핑] mb 국민 세금 탕진…에너지 공기업 빚 110조, 4대강 관리 비용 연 3조, 한식 세계화 931억 \n",
      "[공지] 을 다룬 문학은 개뿔 12회가 팟빵에서 비공개 처리됐습니다. 명예훼손, 허위사실 유포로 신고당했습니다. 앞으로 어떻게 해야 할지 논의 중입니다. 알려질 수 있게 알티 부탁드립니다!\n",
      "[국민당 비대위원 정진영 강경화에게 일침] 성실하게 세금 내고, 공정하게 교육에 임하는 수많은 여성들 워킹맘에게 강경화는 상대적 박탈감을 주는 인사, 유리천정 깨기에 앞서 정정당당히 일해온 여성 자존심이 먼저다 \n",
      "[굿즈] 앨범: 듀얼 기기 vol.2 2017.10.25 발매 2,800엔（세금 별도） 상세: \n",
      "[귀걸이 구매자분들] 침은 은침이며, 다른 부품들은 변색이 되기 쉽습니다. 착용하지 않을 때에는 지퍼 백 등에 밀봉하여 보관해주세요. 1자형 스틱은 원래 길이에서 잘라서 사용하였습니다. 때문에 끝부분이 조금 날카로울 수 있어요. 하나하나 잘라 야스히로 갈았지만, 수작업이기에 날카로울 수 있어요\n",
      "[기본 위선자] (gibon wiseonja dasar munafik\n",
      "[기사] [문화대상 최우수작]⑥ 콘서트 워너원 프리미어 쇼 콘 \n",
      "[김명진] 트럼프 우리가 북한 문제 해결할 것… 강력한 대북 조치와 전례 없는 중국 제재 가능성도 =>시진핑도, 문재인 귀태도 비켜 나란다. 강력 제재는 대외용이고, 참 시작 전 등 독자적 군사행동을 비밀리에 전개할 가능성이 보이는 듯. \n",
      "[나리] 21/여/156(저체중 밝고 사람들과 잘 어울리는 성격 대화를 좋아한다 여성스럽다 오지랖이 넓은 편 어두운 걸 싫어한다 직업은 피팅모델 \n",
      "[냴년] 영상 찍는 썰 안녕히 새오.?제가 오랜만에,,, 빻은 걸 하나 써봤는데요,,,, 그것만을 위한 글이 맞습니다,,, 성인 글이고요,,, 그럼,,, 이만,,,, \n",
      "[네이버] 블로그 : [tv조선 저녁 뉴스 7] 황장수, 위선에 대해 분노하다 (10.10 \n",
      "[네이버] 블로그 : 사회지도층 및 지식 상류층의 위선과 사회적 무책임 \n",
      "[녜롱] domesticate 9 점점 산으로 가는 나 잼 도메스.호옥시나 기다려주셨다면 감사함다. 결말만 정해두고 중간 과정은 의식의 흐름대로 쓰는 중. 구금/빻은 내용 주의 거지 같은 연재 텀 죄송합니다. \n",
      "[노마디스트 수유너머 n] 위선의 사회와 뻔뻔스러움의 사회 -이진경 선생님 칼럼!!! \n",
      "[논평] 김정화 부대변인, 민주당 당원의 댓글 ‘조작’, 민주당 현역 의원의 ‘개입’, 민주당의 대표는‘침묵’? 도무지 전 정권과 변한 게 무엇인가? 정말 대통령만 바뀐 것인가? 이중 정당, 위선 정당, 민주당의 참담한 민낯이 아닐 수 없다. \n",
      "[논평] 민주당은 오직(only 안철수,? 시민은 다시(again 안철수! 안철수 서울시장 출마 선언 직후 여당이 ‘철학은 없고, 조롱만 있는’ 맹폭적 비난에 혈안이다. 민주당은 안 전 대표와 싸울 것이 아니라 자신의 무능, 위선, 특권과 싸우시길 진심으로 당부드린다. -김정화 \n",
      "[논평] 비례성 강화 개헌한다며 뭐 하는 짓? - 기초의회 4인 선거구 좌절과 정부여당의 위선 기초의회는 2인 선거구를 없애고 모든 선거구를 3∼5인 선거구로 바꿔야 한다. 이런 수준의 개혁 없이는 지방의회는 도둑놈 정당, 위선 정당의 독무대로 남아 있을 것이다. \n",
      "[뉴비 씨 만평] 뉴비 씨 s 툰 2017-07-25 참여 정부 당시 종부세 추진할 때 대상자고 아닌 사람들이 세금폭탄이라며 광광 걸렸죠. 이번 슈퍼리치 증세에 대해서도 그럴 사람 분명히 있겠지만. \n",
      "[뉴스타파] 나경원 의원 딸, 대학 부정 입학 의혹 김상곤 후보자는 장관 임명받으면 이 사건 당장 조사해라 또 하나 국쌍에비학교 몇십억 세금 삥땅 친 것도 감사 들어가야 함 적폐 청산 확실히 해라\n",
      "[뉴시스 인터뷰] 박광온, 보유세 필요성 강조 “초과다 부동산 소유자 공적 규제 미약” “살 집이 아니면서 여러 채 가지고 있는 것은 임대 사업용으로 봐야 한다. 임대 소득이 발생하면 투명하게 등록을 하고 적정한 세금을 내는 것이 상식이다” \n",
      "[뉴욕 천기누설] 4월 15일 재산 공개 안설희 씨 누락 미국 안 랩 지사에서 발생한 천문학적 손실처리 폭탄 뇌관 안설희 씨 미국 시청 세금보고(irs 1040 공개할 수 없을 것 대학원생 수입 4만 불, 차량 소유, 아파트 렌트, 저축 1억 1천만 원, 현지에서 이 숫자 자체를 믿는 사람 없음! \n",
      "[다정다감] 싱어송라이터, 프로듀서, 작곡가 등등 음악만큼은 오지랖 넓은 선우정아 씨와 함께합니다.♪ 윌디도 엄청 기대하고 있는 라이브와 토크! 잠시 후 밤 10시 107.7mhz, 턴 온 더 고릴라\n",
      "[단독] “김무성 청년 일자리 걱정은 위선” 대학가 대자보 붙어살아있는 지성의 청초한 기운을 느낍니다\n",
      "[단독] “김정숙 여사, 국민 세금 아끼고 교민 소통 위해 현지 미용실 애용” 김정숙 여사님 정말 모든 게 사랑스럽고 멋지심.\n",
      "[단독] “김정숙 여사, 국민 세금 아끼고 교민 소통 위해 현지 미용실 애용” 문재인 대통령과 부인 김정숙 여사, 해외 순방 중에도 소탈한 서민 행보 현지 교민 사회 잔잔한 감동. 김 여사, 화장 도와주려 해도 직접 할 수 있다며 좀 쉬세요. 탈권위 행보 호평\n",
      "[단독] 10대 기업, 세금 32% 외국에 낸다 \n",
      "[단독] 19일 기부금 낸 안대희, 19.20일 총리 후보 통보받았다 <아 참혹하다. 참혹한 건 안대희가 아닌 국민이다. 총리하겠다고. 정말 하겠다고. 안대희는 위선의 큰 획을 그었다. 이럴 수 있는가. \n",
      "[단독] 20년 동안 법인 활동 거의 없었던 정강. 우병우 검찰 퇴임 직후 컨설팅 업무 추가 [03:02] 「특검, 정강에 급격한 자금 유입 확인. 수임료 세금 줄이기 위한 편법 의심」\n",
      "[단독] 27조 빚더미에도 명절 공짜 통행료. 세금으로 충당? | 이명박 집권 첫해 말에 21조 9,000억이었는데 한국도로공사 빚이 5조 원이 증가하는 지난 9년 동안 뭐하고 자빠졌다가 지금 왜 떠들까? \n",
      "[단독] mb 차명 의심 재산, 부동산만 전국 10여 곳 (출처 : 한국일보 | 네이버 뉴스 압수수색ㆍ소환 조사 과정에서 검찰, 자산 리스트 추가 확보 재산관리인 이병모ㆍ이영배 外 2, 3명 더 있는 정황도 포착 실소유주로 드러나면 세금 탈루 비자금 조성 땐 횡령 처벌도 가능 \n",
      "[단독] 검사장 특혜 폐지안, 이달 나온다 차관급 대우받는 검사장도 문제지만. 차관급 대우받는 부장판사가 무슨 100명이 넘어? 기계적인 3권 분립 그만하고 규모에 맞게 좀 적용해라. 국민 세금 가지고 너희들 의전 챙기기 바쁘다. \n",
      "[단독] 경찰 노무현 사찰 하드디스크 확보 | 다음 뉴스 제목 꼬락서니 봐라 평창올림픽 때 김보름 실드 치던 남성훈 기리기. 노무현 대통령이 네 친구냐?\n",
      "[단독] 공무원 개인 전화비까지 지급. 펑펑 새는 세금 | 다음 뉴스 10억 넘는 세금이 <강남구청> 공무원 1천2백여 명의 개인 휴대폰 요금으로 나갔는데, 민원인과 통화를 위해서라는 거짓말을.\n",
      "[단독] 공무원 개인 전화비까지 지급. 펑펑 새는 세금 강남구청의 휴대폰 통화요금 지원 내역 5급 이상 공무원에겐 5만 원, 6급 이하 엔 2만 원의 통화요금을 4년 넘게 지원해 와\n",
      "[단독] 구조조정 중 또 터진 대우조선 비리 검찰, 불량품 눈감아주고 수억 챙긴 직원 적발 그냥 청산해라. 국민 세금 가지고 뭐 하는 거냐. \n",
      "[단독] 김기춘 지시로 ‘자금 지원’ 받은 보수단체들, 탄핵반대 집회 주도 이직도 세금으로 이들에게 지원을 하고 있다는 것인가??? 이 정권을 끝장낸 뒤 반드시 진실규명을 하고 처단을 해야 할 것이다!!!\n",
      "[단독] 다스, 상속세 대납 의혹 mb 처남댁 유상감자로 손실 보전 | 안원구 전 대구지방국세청장은 “다스가 최대주주 배우자에게 상속세 일부를 보전해줬다는 것은 권 씨가 내지 않아도 될 세금을 냈다는 의미다. 결국 지분의 실소유주가 따로 있다는 방증”이라고 설명했다. \n",
      "[단독] 명성황후 윤호진 성추행 인정. 사과문 발표할 것 | 다음 뉴스 트친님들이 말씀하신 것처럼 한남 거의 전부. 성범죄와 너무 관련이 깊다. 그것이 어떤 업계의 기초라면. 그곳은 기이하게 뒤틀린 생태계라는 생각이 들었다.\n",
      "[단독] 명지전문대 연극영상학과 남자 교수진 전원이 성추행 | 다음 뉴스 참담하다. 한국 사회의 타락, 위선, 비겁함이 어디까지 갔을지 심히 걱정된다. 최근 몇 해 사건들을 겪으며 느꼈던 것보다 더 타락.\n",
      "[단독] 문재인 영입 김광두 세금 탈루 의혹 \n",
      "[단독] 문재인 정부에선 세금 폭탄이라고? 반대! 핵심은 부자·대기업 증세이며, 소득에 비하면 추가 세 부담은 미미하며 이에 해당하는 이도 극소수 \n",
      "[단독] 민주당 ”임금체불 땐 고용 감면 세금 환수” 추진 \n",
      "[단독] 박근혜-이재용 독대 말씀자료에 “임기 내 삼성 후계 해결 희망” 국민의 노후자금으로 세금 한 푼 안 내고 승계를 마무리해준 것이다! 이런 정경유착을 막을 방법은 재벌해체뿐이다! 서민이 살길이다!\n",
      "[단독] 방통위, 방통심의위 시간외수당 부정수령 실태 점검 조직적 세금 도둑 의혹이 짙네요. 반드시 발본색원해야\n",
      "[단독] 새누리, 대통령 친인척·측근 재산 공개 의무화 추진 대법관의 중립의무를 심각하게 훼손시킨 새누리 정치쇄신특위 위원장 안두희 씨! 정치쇄신 개혁 생쇼 하지 말고 지금 당장 박근혜 장물과 친인척 재산 공개하라!\n",
      "[단독] 세무사만 믿었는데. 프리랜서 3800명 세금폭탄 | 다음 뉴스 어머나.\n",
      "[단독] 세월호-반잠수선 더 위험한 해역에 옮겼다 | 다음 뉴스 수단과 방법을 가리지 않고 증거를 인멸하려는 수작 아니겠는가 선체 절단을 먼저 내세우는 것도. 감추고 숨기는 놈들이 범인이다 두 눈 부릅뜨고 지켜봐야 할 것이다\n",
      "[단독] 안철수 부인, 다운 계약서 썼다…세금 탈루 의혹 - \n",
      "[단독] 안철수 부인, 다운 계약서 썼다…세금 탈루 의혹 [2012-09-26]\n",
      "[단독] 안철수 부인, 세금 탈루 의혹 다운 계약서를 작성한 의혹이 있는 것으로 cbs 취재 결과 드러났다 김 교수가 다운 계약서를 작성한 의혹은 이 아파트 등기부등본을 통해서도 드러난다. \n",
      "[단독] 이건희 집 공사한 업자 “삼성 요구로 세금계산서 미발행” \n",
      "[단독] 이건희, 차명계좌 실명전환 않고 4조 4천억 싹 빼갔다 2008년 삼성 비자금 사과 유익한 일에 사용 약속했지만. 특검이 찾아낸 1천여 개 계좌서 전액 출금 금융위, 조 단위 과징금·세금 회피 길 터줘\n",
      "[단독] 작년 ˙동상이몽 2˙ 안희정 나올 뻔. 막판 대타로 이재명 출연 (뉴시스 <단독은 개뿔. 언론이 띄울 때는 이유가 있는 것. 뉴시스, 너 말이야!> \n",
      "[단독] 전통시장에 1조 세금 쏟아부었는데. 상인 대신 건물주만 이득 시장 매출 5% 늘 때 점포 임대료 18% 올라 국회 영세 상인 매출 확대 사업 목적과 괴리 비판\n",
      "[단독] 직무정지 이후에도. 현금봉투로 수당 나눠가져 ㅡ국정 농담, 부정부패의 똘마니 노릇이나 한 주제에 국가 세금까지 빼돌려 나누어 먹은 셈입니다. 박근혜처럼 구속 수사하고 부당환수해야 합니다.\n",
      "[단독] 최순득 지인 “사망 이유, 장소, 시기 모두 허위. 세금 등 금전적 이유” \n",
      "[단독] 최태민은 4월 18일 역삼동 집이 아닌 다른 곳에서 죽었다. 최순실이 세금 적게 내기 위해 시신을 역삼동 자택으로 옮겼고 재산정리를 마치고 5월 1일 사망한 것으로 입을 맞췄다” \n",
      "[단독] 탈세 혐의로 국세청으로부터 세금 추징을 통보받은 가수 인순이(60가 검찰에 고발된 사실이 뒤늦게 알려졌다 국세청으로부터 탈세 혐의로 검찰에 고발된 연예인은 인순이가 처음이다.\n",
      "[단독] 폭언·골프채 위협. 갑질 횡포 공군 소령 수사 이등병으로 강등해서 영창 보낸 후 파면하라 군에 아무 필요 없는 국민 세금 낭비하는 골프장 없애라. \n",
      "[단독] 한국당 신보라 의원의 아스팔트 우파단체 등 압수수색 북한 인권학생연대, 북한민주화 네트워크 .이름만 봐도 가식과 위선으로 포장돼있다. 민주와 인권을 들먹이고, 북한 팔아 종북몰이 하려는 의도가 .\n",
      "[단독] 홍종학, 자신도 압구정 아파트(시가 20억대 증여받았다. 4년 사이 재산 30억 불어나 (출처 : 서울신문 | 네이버 뉴스 뭐가 문젠데? 적법하게 증여받고 세금 냈으면 됐지. 어쩌라고?\n",
      "[단독][다스 ①] 전 청와대 행정관 la 총영사, 다스 관련 직접 요청 / sbs 사익을 위해 국민이 준 공적 권한, 권력을 이용해 국민 세금으로 운영되는 정부기관을 동원한 이거야말로 전직 대통령 예우도 박탈해야 될 중죄이고 빼 박 mb 이즈 뭔들 모든 게 사익추구 아니었겠냐마는 \n",
      "[단독]靑 비서실 어공 퇴직 후 주던 월급, 3분의 1로 삭감 박근혜 정부 때 임명 110명 6월 말 퇴직 靑 세금으로 특혜성 예우는 문제. 월급 지급기간 석 달 → 한 달로 단축\n",
      "[대선주자 검증 리포트] 안철수 싱크탱크 내일, 선거운동 위법 논란 안철수가 설립한 사단법인 ‘정책네트워크 내일’(내일은 지정기부금 단체로, 세금공제 혜택을 받는 대신 선거운동이 금지돼 있는데 이를 위반.\n",
      "[되/돼 구분 법] -하/-해를 붙여서 말이 되는 게 맞습니다 된다/됀다=한다/핸다, 됐어/됐어=핬어/했어, 됩니다/됍니다=합니다/햅니다, 돼요/돼요=하요/해요 어려워하시는 분들이 많은 거 같아서ㅠㅠ(오지랖발동\n",
      "[랜덤 체첸] n 년 전 엑소 첸 _141025 이 트윗 보시는 엑스엘 모두 포도알 보고 티켓팅 성공하소서 그리고 플미충 out \n",
      "[루시퍼 101] 대가를 치러야 해, 벌을 받아야 한다고, 고통을 느껴야지!(루시 개빡침 \n",
      "[리뷰] 오마이걸 ? windy day (2016 아이돌로 지가 꼽은 2016 주요 자기들에 대한 리뷰 시리즈. 해가 바뀌어 다시 들어보는 작년의 수작들이 새로운 감상을 더할 수 있길 기대하며. \n",
      "[리빙포인트] 와이지 티켓팅의 문제점 1. 회사가 아닌 팬들이 플미충을 일일이 잡아서 신고해야 하는 이유는 무엇인가? 2. 국내 팬들이 구하지 못하는 좋은 자리를 해외 팬에게 패키지로 판매하는 이유는 무엇인가? 3. 왜 옥션인가?\n",
      "[만화] 카터의 오지랖 님이 공유\n",
      "[무한 ] 비스트 봇에 라면 팔로 해주세요 기하급수적으로 늘어나는 봇에 비스트 봇에 비해 마땅히 충고해주는 분이 없으셔서 오지랖 넓지만 현직 봇 운영 중인 유저 몇 명이 나섰습니다 협조 부탁드립니다\n",
      "[문제 1]역겹다랑 같이 보낸 이유를 서술하시오.\n",
      "[문화대상 최우수작]⑥ 콘서트 워너원 프리미어 쇼 콘 (출처 : 이데일리 | 네이버 뉴스 \n",
      "[미디어워치] 김진태, 태블릿pc 특검 촉구 “침묵하면 평생 위선자” 그냥 넘어가면 우리들 중 누구도 이런 일을 겪을 수 있다 \n",
      "[민언련 신문 보도 비평] 정부의 건강보험 보장성 강화 대책을 세금폭탄 정책이라 비판해오던 조선일보가 느닷없이 탈모는 보장 대상에서 빠졌다며 탈모인들의 궐기를 운운하고 나섰습니다. 대체 왜. \n",
      "[민중의 소리] 오지랖 인권활동가의 인권 천리길 ⑩: 10월 18일 인권 순례 10일 차. 최전방에 위치한 을지 전망대, 제4땅굴에 서서\n",
      "[바른말 고운 말] 오지랖(o 오지랖(x / 무르팍(o 무르팍(x\n",
      "[바른말 고운 말] 힘깨나 쓰다(o 힘깨나 쓰다(x / 오지랖 넓다(o 오지랖 넓다(x \n",
      "[박영선 선대 위원장 서울 금천구 유세 영상] 일반 서민들은 유리지갑처럼 세금을 내는데 왜 재벌 2세 3세는 세금을 제대로 내지 않습니까? 이런 것들을 바로잡기 위해서 기호 1번 문재인을 압도적으로 당선시켜주셔야 합니다 \n",
      "[박주선 탈당] 친노 패권·수구…미래 없는 새정치/ 새정치號는 침몰하는 돛단배 후속 연쇄 탈당 시사/ 왜 따로 신당 만드나 문재인에 걱정 너무 많다 오지랖 꼬집어 \n",
      "[배움] 공자 왈 정직한 사람을 벗하고, 신의가 있는 사람을 벗하고, 견문이 많은 사람을 벗하면 유익하다. 위선적인 사람을 벗하고, 아첨 잘하는 사람을 벗하고, 말만 잘하는 사람을 벗하면 해롭다. -논어-\n",
      "[배움] 공자께서 말씀하셨다. 유익한 벗이 셋이 있고 해로운 벗이 셋이 있다. 정직한 사람을 벗하고, 신의가 있는 사람을 벗하고, 견문이 많은 사람을 벗하면 유익하다. 위선적인 사람을 벗하고, 아첨 잘하는 사. \n",
      "[백도] 장난 청계 백도 때 딸,, 수작 부리는 백과 알면서도 넘어가는 도 두 편 다 성인인증이 필요합니다.! 재미는 없지만 재밌게 읽어주세요(? 1편: 2편: \n",
      "[번외 편] 잠수: a형이 가장 잠수를 잘 타고 오래 탄다. ab형과는 달리 자신만의 세계에서 그냥 산다. 오지랖이 넓은 o형은 잠수를 거의 타지 않는다. b형도 잠수를 타지 않지만 연락이 없어서 다들 잠적한 줄 안다. ab형은 주기적으로 잡술 탄다.\n",
      "[분노] 김홍걸 뿔났다./안철수, 이희호 여사에 사기질 실체 폭로(지저분한 행태, 위선적 님이 공유\n",
      "[비밀의 숲의 아픈 손가락 모음] 강진서 우 : 갓 태어난 아이 걸고 살인에 대한 무죄 주장했으나 받아들여지지 않고 결국 자살로 사망. 황새목 : 본인이 아팠기 때문에 가족이 해체되었다고 생각하며, 앞으로 그 누구도 제 곁에 없을 거라 단언함. 한인 : 유달리 정이 많고 오지랖도 넘치나\n",
      "[빅뱅 라댄콘 플미충+선예매판매 신고 메일 작성법] 1. 프로미를 하고 있다는 증거 캡처 본 ex. 제시, 원가 아님 등 2. 예매번호 or 정확한 좌석번호 or 가상 계좌와 같은 티켓 관련 정보와 예매자 이름, 전화번호 캡처 본 보내는 곳은 타래로 계속- \n",
      "[사설] ˙공짜 지하철˙ 드는 세금 진짜 미세 먼지 저감에 써야 미세 먼지 예보는 변수가 너무 많아 가장 어렵다고 한다. 그 불확실한 예보를 전제로 공짜 교통을 실시했다. 공짜도 아니다. 시민 세금 50억 원을 쓴 것이다.\n",
      "[사설] 관변 단체의 탄핵반대 집회 동원, 헌정 유린이다 국민 세금을 받는 조직이 반헌법 집회에 참석한다면 즉각 해체해야 마땅하다. \n",
      "[사설] 朴 시장이 공짜로 증발시킨 서울 시민 세금 150억 원 수도권에서 인천시·경기도와 합의 없이 서울시 혼자 버스·지하철을 공짜로 한다고 효과가 있을 리도 없다. 이러니 6월 지방선거용 선심 정책이었다는 것이다.\n",
      "[사설] 이라크에서 드러난 미국의 위선과 쇠락\n",
      "[사설] 최저임금 뒷감당까지 국민 세금에 떠넘기다니 정부시책 시행하면 35명 정도 고용한 영업장은 6명 해고하고 정부 지원받겠죠. 정부가 개입주의 정책은 예상치 못한 부작용을 계속 만들 겁니다.\n",
      "[사설]260만 원짜리 평창 패딩 세트 공짜로 받은 의원들 (출처 : 동아일보 | 네이버 뉴스 .패딩 세트 받은 건 그렇다 치고. 근데. 뭔 놈의 패딩 세트가 260만 원씩이나 하는 걸까요? 이게 다 세금인데. 그만한 가치가 있는 건지. 투명하게 구매내역을 공개해주세요!\n",
      "[사이퍼즈/그랑 플라] 그랑프리람 학교 222 오지랖으로 마틴 걱정하는 하랑이랑 버림받지 않았다고 확신하는 부회장 마틴ㅠ.ㅠ 담배 피우는 마틴 주의해주세요! \n",
      "[사진] il_ma.re ig 이 사람 대원이 제작하고 김준수 대원이 내레이션을 맡은 테러 예방 홍보영상이 4/4분기 경찰청 대표 콘텐츠로?또! 선정되었습니다 각 부처별 콘텐츠 투표를 통해?우수작이 선정되니?많은 사랑 보내주세요 \n",
      "[사진]울먹이는 현영희 의원 부산의 졸부 현영희 씨! 일단 쌤통입니다. 3억 원 어쩌면 훨씬 더 많은 돈을 들여서 국회의원 직 산거 같은데 혼자 당하니 억울하죠? 혼자 당하지 말고 진실을 밝히길!\n",
      "[삶과 문화/5월 8일] 빈곤의 다문화화와 위선 (한국일보 많은 이들이 경고했던 객관적인 시각을 가진 칼럼이 나왔군요. 본질을 알아야죠. 다문화 현상을 반대하지 않지만 정책적으로 광풍이 되어서는 안됩니다.\n",
      "[생활의 지혜] 위험에 빠진 여성을 보거든 도망가라 후우 보기만 해도 아찔하다 오지랖질 하지 말아야지-_- 잘못하면 빨간 줄 획득. 인생 훅 가는 건 한순간. 남자들 필독\n",
      "[서울신문] 충북 옥천군 군민 320명이 박근혜 새누리당 비상 대책 위원장을 돕겠다며 발족한 단체가 제공하는 공짜 관광에 나섰다 1인당 70만.87만 원씩 모두 2억 원이 넘는 과태료를 부과 받았다 쌤통이다\n",
      "[선우정 칼럼] 이제 민정수석이 ´면죄부´까지 발급하나 청와대의 適法 발표는 대한민국에선 면죄부로 통한다 조국 수석의 오지랖이 입법권을 넘어 사법권까지 도달했다 \n",
      "[세금 아까비.정무직이 구속. 기소되면 자동 파면되는 법을 빨리 만들어야. 그전엔 최소한의 도리로 사퇴해야] 조윤선, 장관 첫 구속…장관직은 유지되고 차관이 직무대행 \n",
      "[셔냐의 부동산 투자 강의 3] 8. 네이버 카페 붇옹산에 가면 용산과 마포 등 요즘 뜨는 곳에 관한 생생한 정보가 있으니 모르면 질문하라. 많은 오지랖 쟁이들이 대답해준다. 9. 서울 사대문 안에 만 투자하라. (가수 방미의 법칙\n",
      "[속보] “유가족이 벼슬” 막말한 김호일 사표 제출. \n",
      "[속보] 박 대통령 11.14 불법 폭력 행위는 법치 부정·정부 무력화 의도 공권력 우롱 결코 묵과할 수 없어…배후 엄중 처리 복면 시위 금지해야… is도 얼굴 감추고 테러 국회, 맨날 앉아서 립 서비스만…위선·직무유기\n",
      "[속보] 박 대통령, 해외순방 후 첫 국무회의 주재 ⑤ - 국회가 무엇, 누구를 위해 일하고 있는지 묻고 싶어 - 책임 있는 사람들의 도리…립 서비스만 해선 안돼 - 경제 걱정만 하고 자기 할 일 안 하면 이것은 위선\n",
      "[속보] 정부, 소상공인·영세 중소기업 지원대책 발표 ① - 최저임금 인상은 소득 주도 성장에 기여 - 정부, 소상공인 영세 중소기업 지원대책 마련 - 영세 사업주 인건비 부담 완화, 고용 지원 - 영세사업체 각종 세금 금융비용 절감 방안 마련 \n",
      "[수작#] 오버워치.승리의 여신 메르시 \n",
      "[수작#] 오버히트 지스타도 끝났으니까-; 올해는 어째 이것저것 잡다하게 작업한 느낌. 최고 재미있었던 건 연희가 아닐까 함. \n",
      "[수작] 코스프레 소품 수주받습니다. 갑옷/무기/액세서리/기타 등등 dm으로 소품 사진과 구성, 필요 날짜 작성해서 문의하세요- 간단한 소품은 8월 말 수령 가능합니다. 급한 건은 협의 부탁드려요 \n",
      "[수학] 엘리오트는 50골드짜리 마법 시약과 20골드짜리 약병을 사고 거리로 나섰습니다. 마주치는 것은 세상의 위선자들뿐. 거리에 찬 기만과 악의에 엘리오트는 고뇌합니다. 정의란 무엇인가. 자신은 어떻게 살아가야 하는가. 엘리 오스카 살아가는 이유를 구하시오\n",
      "[신년사] 유승민 ＂기득권·수구보수 결별…개혁보수 지평 열겠다＂ (출처 : 연합뉴스 | 네이버 뉴스 유파들 많네 ;; 합리적 보수는 개뿔 여기 \n",
      "[신문고] “서울시 선관위의 총선 넷 고발은 위선의 지시” 총선 넷 “국면 전환을 의도한 정치적 수사” \n",
      "[심상정 경보] 심상정의 허구 ?내각제 개헌 주장:나눠먹기 ?부역 언론:갑자기 심상정 띄워 ?의석 6으로 뭘 해? 소신투표의 허구 ?아무래도 문재인이 될 테니 나는 소신투표나 ?자기 표는 소신투표에 ?정권교체는 남의 표로 소신이 아니다 위선이다 \n",
      "[아무오키] 39 피클님과 연성 교환으로 쓴 글이에요. 소재는 쓰기 민망하네요 성묘사 있어요. 키워드는 위선 \n",
      "[아주 깔끔하다] “홍종학, 이재용보다 세금 많이 냈다”_ ? 홍종학 후보자 37억 증여액 중 12억 세금 ? 이재용 삼성전자 부회장은 4조 중 16억 ? 안철수 대표 증여 논란도 다시 거론 \n",
      "[아침독서 10분] 우리는 하루에 타인에게 얼마나 상처 주는가? 관심이 아니라 오지랖이며 조언이 아니라 딴지이며 토론이 아니라 푸시를 하고 있진 않는가? 오늘 하루만큼은 말로 사람을 때리지 말자. \n",
      "[안철수 명언] 시간은 원칙을 가지고 올바르게 살아가는 사람들에게는 가장 친한 친구이자 든든한 지원자이다. 그와는 반대로 위선적인 사람들에게는 가장 큰 적이 된다.\n",
      "[알고 계십니까.] 한남오거리를 통과하는 한남 고가 역시 대표적 이륜차 통행금지 고가도로였습니다. 짧은 거리이지만 고가를 우회하기 위해서는 신호를 받아야 하는 만큼 많은 이륜차가 무시하고 타다가 단속 대상이 되었습니다. 이륜 문화 개선운동 본부 회원의 민원 제기로 2008년 통금이 해제되었습니다. \n",
      "[알림] 유엔사 북한군 jsa 군사분계선 너머로 총격으로 수정합니다 지라시 연합뉴스 당장 국고지원금 중단하라! 영어 오역질 보도부터 연합뉴스의 기리기 보도진 더 이상 내가 낸 세금으로 지원 눈뜨고 볼 수 없다!\n",
      "[알티 감사] 12/8 유미 크리 배포전에 나올 오지랖 탐정 크리스타+ 조수 유미르 개그 북 수량조사합니다. 간 글 부탁드려요. \n",
      "[애니플러스 11/13 23:00 방송『사쿠라코 씨의 발밑에는 시체가 묻혀있다』6화 아사히 브리지 이 레귤러 시] - 오지랖의 힘으로! 소년의 존재가치. \n",
      "[애니플러스 4/29 22:30 방송『그럼에도 세상은 아름답다』4화 ring of tales 1] - 요 오지랖만큼은 환상 빠개고 다니는 플래그 마스터에게도 지지 않을 듯 ㅠ 시련에 뛰어드는 니케. \n",
      "[야! 한국 사회] 위선의 ‘다문화주의’ / 김형완 \n",
      "[양정철 캠프]  혼란스러운 지금 머리 식힐 겸 꺼내든 노무현 자서전 운명이다 속 사진 한 장, 나이 들면 살아온 모습이 얼굴에 나타난다고. 물욕, 위선으로 가득 찬 사람과는 확연한 차이나는 따뜻함과 소탈함 \n",
      "[언론] 경남도청, 기자 밥값으로 1년에 5276만 원 왜 사기업 직원 밥값을 세금으로 주는 거죠?\n",
      "[엄마가 뭐길래] 병만은 오지랖이 넓네요. 사람이 좋아도 너.무 좋은 것 같아요. 대단한 거 같죠? 과연 병만은 새터민에게 가족을 찾아줄 수 있을까요? ㅇ_ㅇ 명수와 연석의 표정. 많은 걸 말하고 있죠? \n",
      "[영상] # 오지랖을 떠세요! # 2017 국민경선 참여하세요. \n",
      "[영상] lg g6, 얼려도, 끓여도, 세탁기에 돌려도 살아남는 극한의 내구성 lg 대신 홍보해주기. 네티즌들 오지랖 넓은듯하지만, 이럴 때 모두가 기분 좋네요. \n",
      "[영상] 강용석 박원순은 겉과 속이 다른 위선자이며 위법자 [1편] \n",
      "[영연] 사제지간 (쬐깐 이어져요. 빻은 부분 있고. 뒤에 사람 없을 때 봐주세요ㅜ 비번은 2000년도에 태어난 아이의 생일입니다(그냥 싀얂 생일임 \n",
      "[영화리뷰] 7호실, 웃픈 청춘들의 삶을 페이소스와 위트로 그려낸 세상 밖으로. 죄의식과 강박을 성찰한 끝까지 간다 코믹 버전. 은폐와 위선의 악순환을 끊지 못하고 계급 자본주의 수렁에 빠진 이들의 우화. 별점 ★★★☆ \n",
      "[예권] put it on your lips 포스 타입 비밀번호 기능이 사라져서 조금 무모한 도전이긴 한데 일단 열었습니다 다소 적나라한 묘사가 포함되어 있으니 주의해 주세요는 개뿔 여러분 야한 거 좋아하잖아 \n",
      "[오늘과 내일/정성희]‘사 거세’ 간부의 위선 사교육걱정하지 않으려면 학부모와 학생에게 학교, 교사에 대한 선택권을 주면 된다. 아무리 못 가르쳐도 교사, 학교가 살아남는 상황에서 사교육 근절은 없다\n",
      "[오늘의 영화] 5월 18일, 오늘을 품은 영화 best4 명품 열연, 명품 연출, 그리고 먹먹한 스토리. 이미 많은 영화제들이 인정한 수작 <화려한 휴가>(2007 이준기 \n",
      "[오마이 포토] 싸우자 귀신아 김소현, 오지랖 떨어볼까! 이정민 기자 \n",
      "[오소 카라] 변덕 - 천호 x 고구마 - 빻은 소재 주의 - 제업 제일 처음 썼던 글이에요. 보다 보니 뭔가 빠져있기에 올려둬요. 정말 한결같이 요괴 au가 너무 좋네요. \n",
      "[오스 하다 개 빡침류]삐짘! \n",
      "[오지랖] 태지 신 100억대 평창동 저택을 구혜선 누구와 사려고 했을까?\n",
      "[올림픽] 쇼트트랙 노 골드. 한국, 종합 4위 사실상 힘들어 | 다음 뉴스 정명의 기러기 금메달 맡겨놨냐? 노 골드는 개뿔 ㅡㅡ\n",
      "[올챔퀸연아] ★연아 편곡 모음★ ---빠진 거 有 오지랖 퍼라 고만하지 말아 줘 ㅠㅠ\n",
      "[우리 생애 최고의 날들.] 초토화된 집구석 꼬락서니에. 헌 짚신짝 버리듯. 엄마를 버리고. 지 살길 찾아 작은방 매트리스 위에서 며칠을 혼자 졸던 막돌이는 어젯밤, 스트레스 최고조 상태. \n",
      "[움짤 리뷰] ‘오 마이 비너스’ 6화 신민아, 정겨운에 “오지랖도 태평양이네. 너 요즘 한가하냐?”… ‘사이다 女’ ③ ‘오 마이 비너스’ 신민아가 정겨운에게 돌직구…\n",
      "[워즈 뉴스] (미리 보는 통합진보당 동평 (속마음 다 깨고 나갔으니 사필귀정. 쌤통이다. (겉으로는 통신비밀 보호법 유감이라고 하지 않을까 하는 빨대의 관측이 도착했군요. [15:14]\n",
      "[웹툰 리뷰] <릴리프> 백합· sm ·연애의 달달한 조화 무척이나 짜임새 있으면서도 장르 본연의 목적에 충실한 수작이라는 생각입니다. \n",
      "[웹툰 正 주행] <무장>, 복수와 오지랖의 이중주 by 김낙회 오지랖을 강조하는 작품들은 은퇴 고수의 이야기로 흐르고 원수를 강조하는 작품들은 복수의 처절함에 초점을 두기 쉬운데, <무장>은 둘 다 한다.\n",
      "[위기] 대한민국 국민도 줄리안 어샌지에게 많은 빚을 지고 있습니다. 한미fta를 비롯하여 많은 정부의 위선과 거짓말을 우리에게 알려준 그이지만 개인으로 모든 걸 희생했습니다. 그에게 조금이나마 도움 될 기부를 \n",
      "[육. 모든 관중 여러분, 어떤 다른 취향이 있든 간에 기본적인 예의, 우아함을 지켜야 합니다. 불손하고 상스러운 말은 어떤 시대에서도 영원히 받아들여지지 않습니다. 한 점의 아름다움을 마음속에 남겨둡시다.] 할 말 많지만 위선으로 보인다는 말 말고는 안 함\n",
      "[이 녀석 오지랖이 너무 넓어서 길가는 양아치나 깡패한테 당하는 애들을 못 지나치거든요, 이기지도 못할 거면서] 아이카와: [좋은 일이긴 한데. 너무 무모하지 않아?] 아카 아시: [그런 말 자주 들어요] 아이카와: [힘들게 사네.]\n",
      "[이명수의 사람그물] 판사의 오지랖 \n",
      "[이벤트] 아래의 영상을  하고 답글로 해시태그와 함께 제대군인에게 전하는 감사의 말을 남겨주세요! (영상은 제대군인 주간 영상 공모전 우수작입니다 이벤트 기간:10.16.10.27/당첨자 발표:11.03/경품:던킨도넛 6 pck(15명 \n",
      "[이벤트] 왜 타인의 불행은 곱씹을수록 통쾌할까? 평범한 사람들의 악마적 본성을 풍부한 사례를 들어 파헤친 책, <쌤통의 심리학>을 구매하시는 분들께 과자 고소미를 드립니다. (.소진 시 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[이슈플러스] 靑·국방부, 사드 환경영향평가 이견. 새 쟁점 부상 | 다음 뉴스 나라가 오염되고 망쳐진 후에 안 보는 무슨 개뿔? 안보만큼 소중한 게 환경이라고. 그런데 소규모 환경평가만으로도 만족하겠다고?\n",
      "[이재정 의원실] 2014년 이후 182억 원의 공무원연금이 과 오지급 되었음에도 불구하고 그 63%를 회수하는 데 그쳤습니다. 공무원연금이 국민의 세금으로 일부 보전되고 있는 만큼, 운영의 내실화에 힘써야 합니다. \n",
      "[이종택 칼럼] 김진태 지지 결집을 부추기는 인명진의 얄팍한 수작! 2선에 불과한 김진태의 대선 후보 부상은 반란 세력 그중에서도 비박으로 분류되는 역적들에게는 생각지도 못한 변수다 공포다. 그렇지. \n",
      "[이중 위선자! 단 하루도 못 참겠다, 박근혜는 즉시 내려와라!][단독] 특검 수사 받겠다던 박 대통령, 측근에겐 특검 막아라 지시 | 다음 뉴스 \n",
      "[인터뷰] 뉴스공장 김어준, 촌스럽고 위선적인 시대를 사는 국민에게 위로가 되길 \n",
      "[인터뷰] 박지원 탄핵 통과가 목표. 비박 계속 설득 비박은 이미 돌아선 상태다 그래서 추미애가 무성히 만난 거란다 무성히 가 말 바꾸기 도사였던 거 몰랐나 목적은 개헌을 통해서 나눠 먹는 거였지 핑계는. 오지랖\n",
      "[인터뷰] 선우정아 - 오지랖 예술의 혼을 불태우는 그녀, 음악적 원천은 열등감 장담하건대 이번 인터뷰는 선우정아라는 뮤지션과 그녀의 음악에 한 발 더 가까이 다가가는데 좋은 매개체가 될 것이다.\n",
      "[인터뷰] 이병태 kaist 교수 정부의 오락가락 행보. 가상화폐 가격 출렁 ① 이 교수 대단하다. 비트코인에 세금을 부과하면 가상화폐 기술을 원천 차단하는 비판을 받을 수 있대. 도대체 카이스트 교수들 여기에 얼마나 투자한 거냐.\n",
      "[일상] 스킨스쿠버 배우기_일산 수작 / 출처 : 륜이 여사_ li. | 블로그 \n",
      "[전문] 문재인, 병역 면탈·논문 표절 등 5대 비리 관련자 고위공직 원천 배제 병역 면탈, 부동산 투기, 세금 탈루, 위장전입, 논문 표절 등 5대 비리 관련자는 고위공직에서 원천적으로 배제해야 합니다. 녜녜\n",
      "[전체보기] 김현권 미국산 계란 30알에 세금만 1700원 \n",
      "[전희경 대변인 논평] 수면 위로 떠오른 ‘위선의 연대’, ‘악의 연대’. 문 정권은 할 말 있습니까? 님이 공유\n",
      "[정도원]親盧, 입당 통한 당권 장악으로 전략 변경? =>모바일 투표가 여의치 않자 문성근 귀태가 회원들 입당 독려. 그거나 저거 나네. 살인청부단은 친노 비노 다 똑같아 보인다. 행동 없는 빈집 모도 위선자들 아닌지. \n",
      "[정치] 박원순의 헤진 구두, 그리고 28억 공관 ▲ 진실(眞實과 위선(僞善의 차이. ▲ 서울시장의 전세 28억 어떻게 보십니까?!.\n",
      "[정치]<파투의 쿡 찍어 푹> - 12. 위선이라도 떨어라 정치에 대한 불신은 끝이 보이질 않습니다. 이젠 차라리 위선이라도 떨어줬음 싶기도 하죠. 이젠 정말 국민이 털끝만큼도 무섭지 않은 걸까요.\n",
      "[정치]<파투의 쿡 찍어 푹>-12. 위선이라도 떨어라 위선을 떨 거면 제대로 하든가, 거짓말을 할 거면 들키지를 말든가 뭐라도 좀 제대로 하란 말입니다. 정치 인드라. \n",
      "[정치분석] 문재인 정부 위선적, 이중적 사드 줄타기! 결국 파국으로 갈 수 있다 (2017.06.12 2부 \n",
      "[제1기 무한도전 대학생 크리에이티브 팀 모집] 대상은 . 그냥 오지랖 넓은 대학생 . 컥. 하고 싶다 ㅡㅠ !!! 원츄! \n",
      "[제보 ] 음악프로 만약 인피니트 back이1후보 올라 1위 선정할 때 실시간 집계가 문자투표도 있 만공방가시는분들응원소리도선정된다고합니다.그래서 성규가 응원소리 작다고 아쉬워한 거고요.실망하지 않게 1위 하게 응원소리라도 크게 합시다. \n",
      "[제천국제 음악영화제] 거리예술가 오지라퍼 모집! (.7/3 공연하는 모든 곳이 무대며, 모두가 관객이 된다! 오지랖 넓은 아티스트들은 짐 프로 모여라!\n",
      "[젠 더 표현 모욕/간섭] 낯선 이가 내 성별을 알아내려 몸을 훑어보거나 동의 없이 만진 적 있나요? 여성다운 남성다운 모습에 대한 획일적 틀과, 사람들의 집요한 오지랖이 짜증 나고 열받은 경험을 제보하세요 \n",
      "[조국 가족문제인데? 왜 조국을 까냐고?] 이거 봐라. 새끼들아 이게 체납 세금 말고 법정부담금 땡 까먹은 거고. 그중 조국이 이사 재직 중에 있던 일이니까 따질 테면 또 따져봐 \n",
      "[조국 수석 조대엽은요?] 내가 조국 글 적을 때마다 깜짝깜짝 놀랜다. 이쯤이면 위선자이거나 내로 남북의 최고 왕잣감 아닌가 싶다. 조대엽우짤낀데요? \n",
      "[조남준의 발 그림] 2월 2일 소박한 현실 쪼개서 낸 나의 세금은 어디로 갔을까 \n",
      "[조선] 박 대통령은 옆 테이블에 앉은 서울시 당 소속 의원들이 건배사로 서울 탈환을 외치자 웃음으로 답했다고 한다 어제 청와대에서 국민 혈세로 생쇼를 했군요!\n",
      "[조선닷컴 토론마당] 北 김정은, 살인마의 미소 역겹다?? \n",
      "[조선일보] 공립高 강사 공모기간 지났는데… 김상조 아내, 단독 지원해 합격 / 소위 진보진영의 위선은 김상조도 예외가 아니다.\n",
      "[조선일보] 탈인 전 외친 학자가 원자력 안전 수장됐다 ㅡ>국민 모두의 대통령이 되겠다더니 개뿔 자기편만 하나에서 열까지 챙기는 독재 파쇼 정권\n",
      "[조선일보]美 육군 특수부대, 휴전선 주변 北 지하 군사시설 유심히 관찰 중 > 땅굴에 대한 중대한 징후들을 청와대, 국방부에 그렇게 문제를 제기해도 무슨 수작들인지 번번이 무시하니 미군이 낌새 체고 나서는군\n",
      "[종북척결] 오지랖 시장, 이재명? 성남시정에도 바쁠 이재명이 참 오지랖도 넖은 것 같습니다. 오지랖 크기는 아마 저랑 엇비슷해 보입니다. 요즘은 젊은 아가씨를 만나서 격려도 했다더군요. 그 유명한. \n",
      "[주간보호 센터!! 하늘에서 내려온 천사입니다.] 친정엄마를 통해 노인장기요양보험을 직접 체험하고 작성한 2017 노인장기요양보험 체험수기 공모전 최우수작 작품입니다. \n",
      "[주장] 세금과 군대, 선거권의 조건이 아닙니다 김경빈 기자\n",
      "[중앙시평] 쌤통의 심리학 - 사설 칼럼( - 중앙일보 오피니언 \n",
      "[증세의 전제조건ㅡ 정부 신뢰!] 명예 증세는 불가피하다. 그러나 이 시기 보편증세는 반대한다. 나의 세금이 공동체 복원과 복지로 돌아온다는 확고한 믿음이 없으면 여론만 분열된다. 문재인 정부가 현명하게 증세 논의를 해가리라 믿는다.\n",
      "[지방선거 대구시장 여론조사] 민주당 김부겸 압도적 선두 거짓과 막말이 일상화된 위선자 홍준표의 자유한국당 초비상 \n",
      "[진실]에 바탕을 둔 실천과 위선에 따른 [거짓]의 비교. 박정희 전 대통령은 자신의 큰딸 박근혜 공대(서강대 전자과 진학시켰고 v s 모 대선후보는 과학발전 강조하며 자신의 딸 미국 귀족 유학 과학과는 거리가 먼 공부를\n",
      "[집회 홍보] 서울시민 여러분, 14일(火 오후 2시, 우리의 허파 북 아현 숲 학살 현장에 모이자! 자연 파괴의 관광명소로 만들어 박원순의 위선과 이화여대의 反 교육과 언론의 비굴함과 환경단체의 어용성을 폭로 \n",
      "[차 슬은 의 뉴스 잉글리시] 캐머런 해럴드 ? 아이들을 기업가로 키웁시다 악어의 눈물(crocodile tears 마음에도 없는 위선적인 눈물 1. the boy wasn’t hu, but he. \n",
      "[차기환] 태극기 집회로 네트워크가 되면 결국 종편은 물론이고 지상파까지 바꿀 수 있다. 이참에 kbs를 공영방송에서 퇴출하고 시청료 거부를 해야 하며 mbc를 공영방송으로 지정해 시청료를 mbc에게 줘야 한다 국민 세금으로 황제 노조 배 터지게 할 수 없다 \n",
      "[차범근의 따뜻한 축구] 나도 많이 비겁했다 세월호 가족의 아픔보다 국숫집 주인이 먼저 걱정이 되는 순간 내 몸에 밴 위선과 비굴함이 나를 부끄럽게 했다. 나는 오랫동안 그 부끄러움을 잊을 수가 없었다\n",
      "[착한 증세에 딴죽 걸지 말길] 자유한국당이 세금폭탄을 논하다니. 증세 없는 복지 운운하다 국민 들게 간접세 폭탄을 던진 게 박근혜와 자유당 아니던가. 문재인 정부는 5억 이상 초고소득자ㅡ법인 소득 연간 2천억 이상 초우량 기업만을 대상으로 나눔의 증세를 할 예정이다.\n",
      "[참 뻔뻔하다 야당계 무시해 놓고 간곡히는 개뿔] 국민의당은 논의 병 부세 공직자 5대 비리 배제 원칙에 맞지 않는데도 이낙연 통과 협조했고, 김상조도 실질적으로 인정했으며 더 나아가 강경화의 경우 당론은 비적격이지만 정동영, 박지원 등 개별 찬성 의사표시도 했다. 협치 누가 깬 거냐? \n",
      "[채널a 뉴스특극]너나 잘해 발언은 위선을 비꼬는 말(2014.04.05. 출처 : 네이버 블로그\n",
      "[청계재단 대해부] mb의 수상한 유산, 청계재단 ‘다스 상속 통로’ 정황 뚜렷 장학금 지급액 < 세금 감면액 수십억 대 양도세도 감면 혜택\n",
      "[청계재단 대해부] 찔끔 장학금 줘도 세금 혜택받아. 허울만 공익법인 청계재단 한 해 장학금 지출 총자산의 0.7% 수준이지만 세법상 공익법인 지위 유지 자산 팔아 써야 할 의무 없어 경영권 편법 승계 활용되기도 “선진국처럼 제도 개선” 목소리\n",
      "[추미애 의원실] 병역 면제를 포함해 11가지의 의혹이 있는 황교안 후보자. 여당은 크게 결격 사유 없다며 임명 동의 단독처리 가능성을 밝혔습니다. 위선적 행태를 보이며 검증마저 회피한 황 후보자 스스로 결단해야 합니다.\n",
      "[추천도서] 이동원 작가의 <조금 다른 지구마을 여행>를 강추합니다. 최고의 오지랖으로 세계의 ngo를 누빈 그의 감동적인 글과 사진! 이 책을 읽은 월비 소셜 운영자들의 조금은 사적인 리뷰를 들려 드릴게요.-> \n",
      "[취중진담] 김기식에 날 세운 안철수의 내로남불? 다시 보는 박경미 의원 공개 1+1 내역. 부부 동반 사적 출장 의혹은 괜찮나 모두 국민 세금으로 운영되는 카이스트로부터. 서울시장도. 너무도 엄중한 청렴성과 공정성이 요구되는 자리\n",
      "[카드 뉴스] 바꾸자! 서울. 혁신경영 안철수. 위선과 무능이 판치는 서울시부터 혁파하겠습니다. 일자리는 지키고 만드는 데는 바람처럼 빠를 것이고, 시민의 안전과 생명을 지키는 데는 산처럼 무거울 것입니다. 시민을 위한 일이라면 바람이 되고 산이 될 것입니다. - 서울시장 출마 선언식에서 \n",
      "[카미유] 위선자? - 내 감각으론 카미유 위선의 끝을 달리는 중인데 네오플은 나에게 떡밥을 안 준다. (808  카미유의 자비 안에서 살아가는 사람도 있지만 카미유의 무자비에 죽은 이들도 있을 텐데 어쩌다 그렇게 됐냐고!!! \n",
      "[칼럼] 5·18 광주 투쟁과 위선자 부산에서는 노무현과 문재인이 광주 비극의 비디오를 구해 가톨릭 회관에서 최초로 공개함으로써 부산에서도 광주의 비극을 알게 됐다.\n",
      "[캐러 애니] 1/7 주문은 토끼입니까?? - 치노 치어걸 ver. 2018년 6월 발매 예정, 12,960엔(세금 포함 \n",
      "[코믹 스토리/명대사] “사랑받고 싶어서 상냥하게 구는 것뿐이야. (중략 자신을 위해 상냥하게 구는 것뿐이야. 위선일지도 몰라.” \n",
      "[코인 세대 코인 시대] 한 끼로 0.003 비트코인 결제. 암호화폐 직접 써보니 경제지 기자면 진짜 중요한 걸 지적해야지. 비트코인으로 밥값 내면 매출도 안 잡힐 테고 그럼 세금도 안 낼 텐데 그게 정상적인 거래냐?\n",
      "[쿠로츠키] 모든 오지랖에는 이유가 있다. 괜히 부지런한 척 하루 텀으로 연성 올리기. \n",
      "[킬찰라/몽찰] redemption -불면에 시달리는 밤이면 너를 떠올렸다. 무늬( 님의 문장으로 쓴 글입니다. 사랑해요 무늬님! 조금 한남 문학 같습니다(현 타. \n",
      "[태민 콘서트 앙콘 원가 양도] 그냥 풀까 하다가 플미충들 너무 많아서 원가 양도하니까 멘션 주세요ㅜㅜ(디엠은 맞팔 아니면 잘 안보여요ㅠㅠ 첫 콘 29구역 14열 막 콘 29구역 5열 막 콘 33구역 11열 \n",
      "[통합 리뷰] 내 개처럼 살래? <개같이 살자> 흥미롭게 흘러가는 스토리와 그를 뒷받침해주는 탄탄하고 관능적인 작화, bl 물 마니아라면 추천하는 수작. \n",
      "[퇴근길 잡담] 하수의 지나친 열정은 언제나 오지랖이 되기 쉽다. 도를 넘지 않기 위해선 도를 쌓아야 한다. 무슨 일이든 목숨을 거는 건 자신에게도 독이 될 뿐만 아니라 주변의 원성을 사기 쉽다\n",
      "[투표하기] 여러분은 종교인 과세에 대해 어떻게 생각하십니까? \n",
      "[트윗 스타일]나의 트윗 스타일은 오지랖인지 마당발인지 (flier입니다.\n",
      "[티브이데일리] ‘살인 소설’ 오만석, 야망+위선으로 뭉친 부패 정치인 변신 - 오 배우님의 과감한 연기 변신 벌써부터 기대됩니다 영화 살인 소설 4월 18일 개봉 - -\n",
      "[팟빵] tbs 9595쇼-백 반 토론, 말 까기 백반 토론, 말 까기(0418-[사방에서 생쇼] \n",
      "[팟짱] 김현권 미국산 계란 30알에 세금만 1700원 조창훈 기자\n",
      "[팩트tv 이기명 논설위원 폭로] 김한길 밀약 김재원의 말을 빌리면 4자 회담에서 국정원 ‘특검’문제는 접기로 밀약이 됐단다. 사실이라면 애초 할 마음도 없는 특검 공수표 날린 위선에 경악을 금할 수 없다\n",
      "[팩트tv] 문재인 군대 가고 세금도 내는데…선거연령 18세로 낮추자“ \n",
      "[팩트체크] 대선 자료집 보니, 야 3 당 모두 소방·경찰 인력 확충 공약 더불어민주당 우원식, “홍준표·안철수·유승민 세 후보는 본인 돈으로 공무원을 채용하려 했느냐\"라며 야당의 추가 경정 예산안 처리 반대를 비판했다. 아니오, 그들은 세금이 자기 돈이라 생각할 거요!!!\n",
      "[페미니즘인(in 걸?] 왜 소수자들은, 여성/청소년들은, 오지랖이 넓은가 그걸 계속 지켜보고만 있어야 한다는 게, 그럴 수밖에 없다는 게 괴로웠다. 고민을 하다가, 그냥 거기에 그럴 만한 의미를 부여\n",
      "[플랜, 다스의 계] 다시 시작됩니다. \n",
      "[하승수의 틈]‘세금 도둑’ 홍준표를 고발한다 유력 정치인이 국민 세금을 횡령해서 생활비로 사용한 사실을 스스로 자백했는데도, 처벌도 받지 않고 버젓이 정치를 계속하고 있다. 바로 자유한국당의 홍준표 대표 얘기다.\n",
      "[하인 선의 선물 편지] ♡오지랖의 위대함에 대하여♡ 우리는 마더 테레사 수녀나 오드리 헵번의 생애는 아름답게 여기면서 내 가족 울타리 밖의 사람들을 진심으로 배려하고 베푸는 일에 대해서는 오지랖 넓다 실속 없다 등등 말들을 많이 하곤 합니다\n",
      "[한 남의 승리] 이 문서는 한남의 승리로 끝났습니다! \n",
      "[한겨레] 김기춘, 박 대통령에 블랙리스트 보고했다 특검, 대통령 관여 정황 확인. 직권남용 혐의 검토 박 대통령 비판한 인사 관리 적군 리스트도 확보 대통령, 2000억 세금을 사적 이익 위해 휘두른 셈 \n",
      "[한국 트위터 모임] 오지랖이 다 모임에 가입신청하였습니다. \n",
      "[한남/모던 그래놀라 컴퍼니] 세시 셀라의 세컨드 브랜드. 매장에서 직접 요구르트/그래놀라를 제조해요. 여기가 다른 곳과 차별화된 점이라면 요구르트/그래놀라/콤포트 종류가 세분화되어 있어 취향에 따라 선택할 수 있다는 것. 좀처럼 보기 힘든 핫/락토프리 요구르트도 만나볼 수 있었답니다. \n",
      "[한남/산수화] 조용한 한남동 골목, 유난히 단정한 외관을 뽐내던 티 하우스. 리모델링 후 첫 주말이라 조금은 손님들로 북적였지만, 차와 공간을 음미하기에 방해될 정도는 아니었어요. 전문대 예사 분이 우려내 주신 백호 오룡과 노총 수선. 큰 창으로 들던 늦은 오후 빛과 꼭 닮은 수색이 아름다웠어요. \n",
      "[한남/타르티니 베이커리] 드디어 손에 넣었습니다, 장발장 빵. 여긴 여전히 핫하네요. 먹으려던 샌드위치가 다 안 돼서 별 기대 없이 시켰던 에그 샌드위치가 생각보다 취향이어서 좀 놀랐답니다. 아메리칸 홈메이드스러운 심플한 맛인데 함께 나오는 매콤한 아이올리 소스를 곁들이면 맛이 복잡해져요. \n",
      "[한남/타르티니 베이커리] 여러분, 어서 저의 크고 멋진 빵을 봐 주세요. 웃기려고 산 빵이 아닌데 어째서인지 사진을 본 저의 친구들은 웃음을 멈추지 않고. \n",
      "[핵 안보정상 회의 공동기획] 내가 서울 핵 안보정상 회의를 반대하는 까닭. 지독하게 위선적이고 위험한 회의 세계에서 핵무기를 가장 많이 가진 나라들이 모여 핵 테러를 막겠다고? \n",
      "[현장 영상] 이유미, 마스크 쓴 채 법원 출석 묵묵부답 안철수의 새 청치의 본모습이다! 새정치는 개뿔! 경악할 만한 대선 공작 조작실! mb 아바타답다! 국물 당연 당장 해체하라!\n",
      "[홍보] 자기 전 홍보 좀. 꽃미남 당주( 와 꽃미녀 부당해주( 가있고 당원들 사람 좋.습니 당.오지랖 다이( 으로 오세용.당주니 마.나 이뻐.?ㅎㅎ \n",
      "[홍보팀] 떴다, 정의당 가계부 계산기! 간단한 설문만으로 정의당의 복지혜택을 계산해드립니다. 내 세금이 삶을 바꾸는 복지로 돌아온다는 확고한 믿음, 정의로운 복지국가의 출발입니다. 정의당 찍으면 살림살이 나아집니다. \n",
      "[황장 수의 금요칼럼] 가식과 위선의 정치가 미국 대선에서부터 깨진다 (2016.10.07 1부 \n",
      "[황장 수의 뉴스 브리핑] 야당 일본 안보법, 집단자위권, 사드 배치 등에 위선을 버려야 (2015.09.23 2부 (출처 : 황장 수의 . | 네이버 블로그 \n",
      "[황장 수의 뉴스 브리핑] 이 나라는 폭력 선동가, 오지랖 종교인, 사이비 법조인이 말아먹고 있다 (2015.11.30 1부 (출처 : 황장 수의 . | 네이버 블로그 \n",
      "[황장 수의 뉴스 브리핑] 정치인이라면 가식, 위선이 없는 트럼프, 샌더스 같아야 한다/ 트럼프 압승과 샌더스 끝까지 간다 (2016.04.27 3부 \n",
      "[황장 수의 쉬운 경제] 노조가 정치사회 투쟁을 내거는 건 위선! 실상은 내 밥벌이 지키기/ 박원순 청년수당을 청년이 비판한다 (2016.07.21 \n",
      "[황장 수의 정치분석] 박원순 시장의 위선과 내년 대선후보가 가져야 될 4가지 필수 조건 (2016.06.03 3부 \n",
      "[황장 수의 정치분석] 한일관계와 한중관계에서의 우리의 위선! (2017.01.09 1부 \n",
      ".p. 아 오랜만에 수작업하니까 재밌다 마마네 메 파주세요 이 둘이 개쩔지않나요 \n",
      "`돈은 받되, 감사는 안 받겠다`는 사립유치원장들의 표리부동. 세금 받을 때는 공공재라고 주장하고, 감사 받을 때는 사유재산이라니 이게 말이야? 방귀야? 이번 기회에 사립유치원의 추악한 비리를 바로잡아 부정의 뿌리를 뽑아야.\n",
      "{10번 박원순} 보증금 1억에 250만 원 월세를 사는 박원순이 서민시장을 표방하는 것은 위선이라는 나경원 자신은 평생 서민의 근처에도 가보지 못한 사학재단의 딸 수십억 대 자산가에 땅투기에 성매매 업소로부터 수백만 월세까지 받아먹는 파렴치 기득권 아닌가?\n",
      ".  국정원의 오지랖은 어디까지? 이번엔 반값 등록금! [단독] 국정원 ‘반값 등록금 운동 차단 공작’ 문건 입수 \n",
      ".근육질 공주가 납치된 왕자를 구한다. 동화를 뒤집은 스토리에 또 한 번의 반전이 담긴 수작 비주얼노벨이죠, 인디 모바일게임 <근육 공주>. 최신작 3편이 출시되어 기대를 안고해봤습니다. \n",
      ".대한민국 재벌들은.할 말 없냐? 빌 게이츠 나 같은 부자에게 세금 더 부과해야 | 다음 뉴스 \n",
      ".번외 편 2. 애인 어디 가 좋은가. 조현수: (질문 꼬락서니하고는 싶은 눈으로 훑어봄 강지원: 예뻐. 한재호: 음. 얼굴? 근데 꼭 얼굴이 아니더라도 현수는. 뭐. (말문 흐리며 빨개진 목덜미 쓸어내림 조병갑: 강 이사 잘 생겼잖아아. (애니팡 중\n",
      ".법대로 하자 세금 밀렸으면 내면 되는 거고 내자. 돈 없으면 담에 내도 돼 .냈냐?.돈 있어도 안내면 세무조사 들어가야지. 나경원 부친 학교, 6년간 감 사서 55회 적발 | 다음 뉴스 \n",
      ".수능 성적표 공개: 동현이 편. 동현: 나는 뭐 그냥 뭐 못하진 않지 너네가 성적이 이상한 거야 현우: 근데 수학 점수 꼬락서니가 왜 이러냐 동현: 조용히 해\n",
      ".안개숲에는 왜 린족 npc가 없을까. 군남 : 위선의 무리들! 일단은 주둔지부터 털어주지! 민녀 : 8ㅁ8 군남 : 역시 위선의 무리라서 파도가 한가득.! 민녀 : 8_8 우리 막사. 털 거예요.? 군남 : 민녀 : 오빠. 8_8 군남 :\n",
      ".장르 캐릭터로 욕해보기(?. 1. 당신 인성 한 세건 2. 패션 센스가 성현급(신광 3. 겁 없음이 or 간땡이가 서린 수준 4. 아르곤 같은 통장 상태 5. 오지랖이 팬텀 수준 6. 빌헬름급 스트레스 *죄송합니다*\n",
      ".팬싸 나 노후기. 우선 저는 6n 번을 뽑아서 마음의 준비를 할 시간이 넉넉했다고 생각했지만 마음의 준비는 개뿔 오빠한테 한걸음 한걸음 다가갈 때마다 천국의 거대한 문턱을 넘고 있는 기분이라서 자꾸 뒷걸음질쳤어욬 제 뒷문 달래주셔서 감사합니다. \n",
      ".피터(콜린스 짝사랑 중와 마주쳤다. 파: 하! 이제 이런 꼬맹이랑 눈높이가 맞아졌군 피: ? 원래 키도 저랑 차이가 없으셨습니다만 파: 도발하는 건가? 피: 제가 어린애를 상대로 도발하겠어요? 파: (개빡침 콜: (귀여움에 울면서 사진 찍는 중\n",
      ".현재. 아이카와 : 으악! 이와쨩 아이카와 씨 넘어졌어 이와 이즈미 : 뭐 어쩌라고. 아이카와 : 손바닥도 까졌어! 침발라줘ㅠㅁㅠ 이와이즈미 : 수작 부리지 마라. 소독약 여기 있으니까 이거나 발라. 아이카와 : (쳇 소독약을 가지고 다닐 줄이야.\n",
      "‘a4용지’ 시위에 박수 횟수까지 꼼꼼히 세고, 자유한국당의 유치한 백태 문재인 대통령 시정연설을 대하는 자유한국당의 자세 야! 이 미친 것들아! 얼빠진 것들! 저런 것들한테 내 세금이 들어가다니ㅠㅠ\n",
      "‘kbs · mbc 국민의 세금으로 운영되는 공영방송, 이대로 좋을까요? 참여연대는 지역 회원 모임에서 함께 외쳤습니다. 김장겸 물러나라! 더 나은 세상을 위해 참여연대는 힘을 모으겠습니다 회원가입 \n",
      "‘국정원 돈으로 진박 감별’ 김재원 비공개 소환…‘세월호 세금 도둑’이라더니 \n",
      "‘김치녀’, ‘한 난충’, ‘틀딱’ 이젠 함부로 못 쓴다 | 1boon \n",
      "‘노예 사병’ 논란 공관병 마침내 폐지한다 송영무 국방, “민간인으로 대체” 지시, 군 지휘관 사생활에 세금 지원 계속 \n",
      "‘놀이 운동가’ 편해요 문씨는 “너만 할 때 공부만 했다\"라는 부모 말은 위선이라고 했는데요 그는 지금을 “눈 깜짝할 사이에 아이 도둑맞기 딱 좋은 세상”이라고 했습니다. 부모나 아이나 당장 놀아야 된다는군요\n",
      "‘대나무 천장(bamboo ceiling’, 아시아 세금(asia tax’. 아시아계 학생은 타 인종보다 점수를 더 많이 얻어야 미국 명문 대학에 입학할 수 있다는 의미다.ㅣ워싱턴·정재민 편집위원 \n",
      "‘대선 불출마’ 반기문 “음해와 가짜 뉴스에 인격 살해당했다” 인격은 개뿔 국민을 70.80년대 무지렁이로 알고 있었던 거지 언론통제를 벗어난 1인 미디어 시대의 정직한 언론 이 한몫한 거야 \n",
      "‘동상이몽’ 홍진영, “성형 눈, 코 밖에 안 했는데 ‘성괴’소리 들어” \n",
      "‘리멤버’ 박민영, 매력 폭발하는 ‘인아 16종 표정 세트’ “정의의 이름으로 널 용서하지 않겠다!” sbs ‘리멤버-아들의 전쟁’ 박민영의 ‘사랑스러운 오지랖 년’ 매력이 빛나는 ‘인아 16종 표정 …\n",
      "‘문재인 테러’ 예고 50대 남성 검거 “탄핵반대 집회 매번 참여” 무엇이 옳고 그는 지 보다 개뿔도 없으 면서 알량한 떡고물에 영혼 팔아 방패막이 되어준 대가로 한 끼의 배를 채우기보다 차라리 복지를 위해 외쳐라\n",
      "‘벌금 미납 노역’ 전두환 처남, 세금 소송 2심서도 패소\n",
      "‘불쌍하고 얌전하고 부족하게’ 보여야 사는 사람들 어느 날, 센터로 항의 전화가 들어왔다. 애들이 지원을 받는 것은 좋다. 근데 굳이 좋은 돈가스집에 오는 건 이상하지 않나? 분식집이면 충분할 텐데. 내 세금이 쟤들이 좋은 것을 먹는 데 쓰이는 게 말이 되냐. \n",
      "‘빛나거나 미치거나’ 오연서, 강인한 ‘신율’ 역 완벽하게 소화… ‘눈길’ 매일 밤을 눈물로 지새우는 흔한 여인도 아니다. 무턱대고 넓은 오지랖으로 미간을 찌푸리어… \n",
      "‘사 대 강 살리기’와 ‘자원외교’를 빙자하여 천문학적 액수의 국민 세금을 빼돌린 중범죄에 대해선 아직 수사조차 시작하지 않았습니다. 아무리 시간이 걸려도 공범들을 전부 색출하고 사건의 전 모를 밝혀야, 더러운 권력 범죄의 재발을 막을 수 있습니다. 처벌이, 예방입니다.\n",
      "‘성형 괴물’의 등장 후 인공적인 외모는 본격적으로 추함, 사기, 무임승차 등 부도덕성을 표상하기 시작했다. 성괴가 된 여성들은 주류 미디어가 아닌 어디론가 가야 했다. 더 허구적이고 안전한 세계, 만화였다. \n",
      "‘세금 낼 돈까지 모두 옷 사 입는데 썼던’ 윤여정은 노년이 된 지금도 감각적인 패션을 선보인다. 방송에서 그가 직접 밝힌 옷 잘 입는 비결은 “김민희와 똑같은 옷을 산다는 것”이었다. \n",
      "‘소녀 괴담’ 감독의 스승도 못 알아본 각본 오지랖 \n",
      "‘안녕하세요’, 부하직원 ‘오지랖’ 때문에 스트레스받는 상사?등장 \n",
      "‘여자를 울려’ 인교진, 김정은·송창의 신경 쓰는 김지영에 “오지랖” \n",
      "‘오지랖’에 조사 ‘이’가 붙으면 [오지 라피]로 발음됩니다.  걘 참 오지랖이 넓어. 할 때, 오지랖이는 어떻게 발음하나요?[오지 라피]? [오지 라비]?\n",
      "‘오지랖’은 ‘웃옷이나 윗도리에 입는 겉옷의 앞자락’을 뜻하는 말이고, 관용구 ‘오지랖이 넓다’는 ‘쓸데없이 지나치게 아무 일에나 참견하는 면이 있다’를 뜻합니다.  오지랖은 무슨 뜻인가요?\n",
      "‘오지랖’은 겉옷의 앞자락을 뜻하는 말인데, ‘오지랖(이 넓다’는 ‘쓸데없이 지나치게 아무 일에나 참견하는 면이 있다’ 또는 ‘염치 없이 행동하는 면이 있다’를 뜻하는 관용구입니다.  오지랖 넓다고 할 때 오지랖의 정확한 뜻이 뭔가요\n",
      "‘의사들은 다른 일에 연대한 적 있냐?’로 ‘훗! 쌤통이라고 하시는 분들도 있는데 이렇게 ‘先 마일리지 적립 後 행동’을 서로에게 강요하면 사실 그 어떤 것도 이루어낼 수가 없음.\n",
      "‘이면합의’로 국민 속였던 박근혜 정부의 한미 방위비 협상 ‘추가 현금 지원’ 담은 이면합의 해놓고 국회 보고도 누락 503이 국민 세금을 마치 자기 돈이라도 되듯이 미국에 다 퍼줌!!!\n",
      "‘자백’에서 빵! 자유한국당은 다른 정권 탓을 하기 전에 자신들이 만든 정권에서 국민의 세금을 유용한 잘못을 인정하고 사죄를 구하는 것이 순서다. 일에는 순서가 있다 / 이정렬 \n",
      "‘종교인 과세’ 대비 ‘장부 2개’ 만들자는 대형교회 목사님 십일조 감사헌금 등등 기독교 신도들에게 꼬박꼬박 헌금 받으셔서 세금 내야 하면 내시면 되는데? 예수님이 이중장부 만들어서 세금 회피하라고 했나요?\n",
      "‘책임총리’ 국회가 뽑고 ‘의회 해산권’ 명시하자는 자유한국당 개헌안 개헌하지 말자는 말이다. 국회의원하는 꼬락서니 보면 국회에 총리 임명권 맡길 수 없다\n",
      "‘최저임금’ 때문에 떠난다는 ‘경방’의 실체 세 줄 요약. 1. 이미 2008년에 베트남에 자회사 설립 2. 최저임금 인상분은 공장 이전비용의 10% 3. 민족기업은 개뿔. 창업주부터 친일파\n",
      "‘치즈 인 더 트랩’ 서강준, 김고은 소개팅 자리 파투 내… ‘반가운 오지랖’ ‘치즈 인 더 트랩’ 서강준, 김고은 소개팅 자리 파투 내… ‘반가운 오지랖’ ‘치즈 인 더 트랩’…\n",
      "‘클라라 문학상’이라도 제정해야 할 듯. 연예인에 대한 오지랖을 주제로 심도 있는 문학적 성과를 이룬 작가(기자들에게 수여하면 되겠다. 수상자 섭외해서 연예인 캐릭터가 허구적 산물임을 모르는 중생에게 강연하도록 하자. 문학상 제정의 목적은 폐지.\n",
      "‘특조위 세금 도둑’ 이헌 전 위원 “朴 7시간 조사 靑 수석들이 막았다” \n",
      "‘팀’이 뭔지도 모르는 것들에게 ‘팀 추월’ 경기를 시켰으니 잘 될 리가 없겠죠. 국민 세금으로 지원 잘 해줬더니 자기들끼리의 알력 다툼 때문에 전 세계인이 지켜보는 경기 한 게임을 대놓고 날려버렸네요. 팀으로 나왔으면 조금 늦더라도 같이 가는 모습을 보여줬어야 했는데. 인성도 실력 중 하나입니다.\n",
      "‘프랑스판 9·11’ 충격파…기로에 선 톨레랑스 위선을 떠는 건 끝났다는 르펜의 말이 예사롭지 않게 들리네 유.\n",
      "“ ‘예쁘면 만지고 싶다.’, ‘짧은 치마 입으면 살이 많이 보이고, 보이면 만지고 싶다.’ 어떤 원인이 있기 때문에 결과가 있다? <쌤통의 심리학>이라는 책에 의하면, 타인의 상처 나 불행에는 그 사람에게 원인이 있다고 생각해버리는 것은\n",
      "“(친문 세력에 심지어는 ‘남자 최순실’이 보인다는 얘기도 나온다. 그만큼 패권적인 정치를 하는 문 전 대표가 새로운 시대를 열겠다고 호소하는 건 위선이자 적폐” \n",
      "“: : 정몽준 의원 아들, 너무 순수하고 영특해. 한국 사회 문제점 너무 잘 짚었어. 이제 고3 정도인데 칭찬받아 마땅하다. 우리 사회가 이를 겸허히 듣고 고쳐야 된다. 아이들의 순수한 생각, 위선으로 막지 말기를.”\n",
      "“:  : [속보] 검찰, 채동욱 의혹 국정원 개입 정황 포착 오지랖 한번 넓다! 손 안 댄 일이 없네! 이러다가 동네 반장선거에도 개입하겠네.\"\n",
      "“: 서영훈 배우님 연극배우로 전향하셔야겠어요 너무 재밌게 실컷 웃고 갑니다 용인대 짱 우리 사이짱!!! 오지랖 연기 ”\n",
      "“: 오빠오빠 여대생은 오빠를 어떻게 불러야 돼요? 계속 오빠라고 부르자니. 아이도 있으신데.이러생각이들어서욬 오지랖인가욬 ” 영원한 오빠.\n",
      "“: 웃기는 눈물!! 우려면 조문 시 눈물 흘렸어야지! 엉뚱한 가짜 유족 붙잡고 생쇼 할 땐 언제고 안 먹히니 눈물 생쇼???속 보이고 참으로 음흉한 인간이다!! 우는 모습에 이렇게 분노가 일게 하는 건 명박 이후 박 씨가 두 번째!!”\n",
      "“2010년 6월 5일부터 8월 27일까지 약 3개월에 걸쳐 전공도 학과도 다른 안철수 부부는 딸이 재학하고 있는 펜실베이니아대학으로 출장을 갔다 모두 국민 세금으로 운영되는 카이스트에서 지원받은 예산이 총 3000여만 원” 외유성 출장 인정? \n",
      "“20년간 약 1000억 가량 지방세 밀과 세? …용인시민이 삼성 세금 대납한 것” \n",
      "“82년 여름께엔 예비역 장성들이 모인 자리에 유치원 교사들이 한 명씩 옆에 앉아서 서빙을 하라는 지시를 받았다”/박근혜 이사장 때 육영재단 교사 “술 시중도…” : ‘여성 대통령’ 구호 위선적 생각해 폭로 \n",
      "“mb가 탕진한 국민 세금 최소 189조 원” 이 자를 구속시키고 전액 변상시켜라!\n",
      "“감성과 위선으로 포장된 거짓말이 기승하는 세상에서 용기 있게 진실을 말하는. \n",
      "“거장의 반열에 든 감독의 차기작입니다. 어떻게 평가하시나요?” “거장의 작품이라기엔 조잡하고 형편없네요.” “아, 잘못 봤네요. 이제 막 데뷔한 동명이인 감독의 작품입니다.” “신인치고 꽤나 노련한 수작이네요.” “평가를 휙휙 바꾸시네요?” \"고정돼서 바뀌지 않으면 그게 낙인이지 평가입니까?”\n",
      "“공영방송 사장 체포 유례없다\"라는 자유한국당 최교일 의원에게 팩트로 일침 날린 mbc 기자 거짓과 위선을 빼면 아무것도 없는 대한 당 \n",
      "“곽노현 교육감 20년 전에도 대가 없는 큰 도움” 알려져 변함없는 당신의 위선 없는 논리와 본성 일 것이다\n",
      "“국민 세금” 아끼려고 ㅠ ㅠ 우리 김정숙 여사님 보배로다!!!! 100점 드립니다. \n",
      "“글에 대한 오독”과 “편견”으로 시작된 것 같네요 “문재인 지지자들”끼리 오지랖 넓게, 그리고 “마녀사냥/조리돌림”이라니, 동의하지 않으면 그냥 넘어가면 될 일을, 같은 지지자들끼리 왜 그러는지 모르겠네요 힘내길,\n",
      "“기독교인들은 성소수자를 악마화하는 방식으로 내부의 문제를 숨기려 한다. 세금부터 내고, 목사 세습 문제, 교회 내 성범죄, 여성 목사 안수 문제 등부터 해결하라. 가부장제에 물든 교회부터 개혁하라. 그런 다음 양성평등을 얘기하라” \n",
      "“난 도운 적 없다. 도움이란, 남의 일을 할 때 쓰는 말이지. 난 내 몫의, 내 일을 한 거다. 내 일인데 자기 일 아닌 걸 남 위해 했다고 하면, 위선이 된다.” \n",
      "“네덜란드에 ‘페이퍼컴퍼니’ 2만 개 이상 존재 - 멀티 내셔널 기업들을 중점적으로 연구하는 연구센터인 somo 사의 조사 결과 2만 개가 네덜란드 국적으로 등록, 이 중 1165개사가 로열티 및 특허 관련 세금 혜택을 받기 위해 네덜란드를 이용”\n",
      "“댓글 1개당 5000원” 국정원 가격표에 네티즌 경악 “국민 세금으로 국민 우롱” \n",
      "“댓글 1개당 5000원” 국정원 가격표에 네티즌 경악 “국민 세금으로 국민 우롱” - 고발뉴스닷컴 @고발뉴스 님이 공유\n",
      "“라벨은 스트라빈스키의 음악과 발레가 역겹다고 느꼈고 드뷔시는 황홀해했다.”\n",
      "“류경·김숙 mb 정부와 비밀접촉 특종… 당시엔 부인하다 회고록이 서 시인” 위선적이라는 외국 기자의 지적.\n",
      "“를 딱”이라는 말이 위험한 이유 젊은 세대들은 교육과 변화한 문화적인 요인 덕에 추상적, 형식적 추론에 노인 세대보다 더 익숙하다. 사회 진보를 위해서는 다행스러운 일이지만 이 글에서 얘기하고자 하는 건, 그게 노인 세대를 혐오하는 이유가 될 수는 없다는 것이다. \n",
      "“를 딱”이라는 말이 위험한 이유 틀 딱이라는 멸칭이 위험한 것은 하나의 팀이어야 할 상대방을 2등 시민으로 간주하기 때문이고, 그게 결국엔 민주주의에 해가 되기 때문이다. 관련해서 글을 써보았다.\n",
      "“모두가 불가능하다 했다. 하지만 그들은 대한민국을 알지 못한 것!” 공무원 감축, 노동 유연성 강화, 법인세 인화. 홍준표가 옳습니다. 이게 국제정세고 한국이 살아남는 길입니다. 세금으로 공무원, 공공부분 일자리 80만 만든다는 문재인, 베네수엘라의 전철을 밟자는 것입니까?! \n",
      "“서울이 바뀌어야 대한민국이 바뀐다는 생각에 ‘매일 혁신하는 서울’의 모습을 여러분께 제시하고 함께 걸어가는 서울시장으로 시민의 선택을 받고자 한다” “위선과 무능이 판치는 세상을 서울시에서부터 혁파하겠다 \n",
      "“세월호 인양은 세금 낭비” “죽은 자식은 가슴에 묻어라” 이랬던 자 한 달이 “충격을 넘어 경악” 운운하는 거야말로, “충격을 넘어 경악”입니다. 유가족을 속인 공무원은 엄중 문책해야 합니다. 유가족을 괴롭힌 자 한 달은 훨씬 더 엄중하게 문책해야 합니다. \n",
      "“소공녀”: 집은 없어도 생각과 취향은 있어 월세, 담배, 위스키, 약 값, 세금. 지출을 줄이기 위해서 무엇을 포기할까? 담배와 위스키는 포기할 수 없다. 그녀는 결국 집을 포기하기로 했다. \n",
      "“스노든”은 왜 내부고발자가 되었나 <스노든>은 스톤 감독의 필모그래피로서는 범작이고 보편적인 정치 스릴러로 보기에는 수작이다. 스노든이라는 사람에 대해 알고자 한다면, 이보다 더 좋은 텍스트는 없다. \n",
      "“시종 긴장감을 유지하며 양심과 도덕, 위선을 그린 이 바로 데 마테오 감독의 연출이 묵직하게 다가온다” 언론 호평! <더 디너>7월 16일 개봉!\n",
      "“여론이 어떻다고 하면서 이야기한다면 국회 없이 여론만으로 대통령 혼자 국정을 수행해야지 국민 세금을 들여 뭐 때문에 국회를 두냐” \n",
      "“여유 좀 가져!”: ‘임신부 투쟁’의 핵심은 ‘무조건 스트레스 줄이기’였다. 나로 말할 것 같으면 빠른 눈치와 넓은 오지랖으로 점철된 피곤. \n",
      "“연금공단 이사장이 장관보다 좋다” 역시 국민연금 운용본부는 해체가 답. 남의 돈 수백조 원 나눠주며 금융권 슈퍼갑으로 사니까 이사장은 꿀을 빨지. 지금까지 연금 낸 거 다 환불해주고, 앞으로는 세금으로 복지해야.\n",
      "“위선자들아, 너희는 땅과 하늘의 징조는 풀이할 줄 알면서, 이 시대는 어찌하여 풀이할 줄 모르느냐”(루카 12:56\n",
      "“유럽 사람들은 ‘떠도는 삶의 애환이 담긴 집시음악’을 즐겨듣고, 사진전이나 tv 다큐멘터리를 통해 이들의 생활을 운치 있고 낭만적이라고 소비하지만, 막상 로마니들이 자기 동네에 정착하려고 하면 온갖 법규를 들이대며 불법으로 만든다. 세금을 내지 않고 복지혜택을 받는다고 매도한다.”\n",
      "“이 법안 통과시킨다고 뭐가 달라질 것 같아? 어차피 통과된다 해도 다른 주가 성 찍고 오면 그만이야. 이건 그저 주 세금만 축내는 안건이다” 등의 염세적인 의견 등을 듣게 됨. 하지만 내 마음은 저런 걸로라도 성병을 예방할 수 있다면 기꺼이 표를 던져주고 싶을 뿐이다.\n",
      "“이왕 이렇게 된 거 나 인생 즐길 거야”라고 해 놓고 오지랖 발동!(feat. 미운 정 \n",
      "“일본이 출연한 10억 엔을 우리의 세금으로 충당하기로 한 것은, 일본의 역할이 완성이 아니라 미완으로 남게 만든 상징적 조치” \n",
      "“저 자가 바로 정파의 우두머리라 칭해지는 남자이자 네 어미의 원수이다.” “예, 스승님.” “그리고 저 자가 사파의 흑막이라 소문난 여자이자 네 아비의 원수이다.” “. 죄다 원수면 전 어디서 무공을 연마해야 되죠?” “관원에 수석으로 들어가서 양쪽 다 세금 왕창 때려야지. 난 과외 스승이다.”\n",
      "“전부 손 올려! 허튼수작 부리면 전부 총살하겠다!” “이, 이게 무슨 짓이오! 우린 선량한 종교인 단체일 뿐이라고!” “선량한? 최근 들었던 얘기 중 가장 어이가 없군. 저 흉측한 그림에 절하고 기도하는 게 제정신이겠나? 너흰 전부 정신개조가 필요하겠군, 전부 끌어내!” “아, 안경이여 영원하라!!!”\n",
      "“전세금 인상이라는 얘기만 들어도 가슴이 내려앉고 무수한 아파트 불빛을 바라보며 눈물을 삼키던 시절이 있었다” - 김현미 국토교통부 장관 후보자 진심 공감되는 말입니다.\n",
      "“진심이든 위선이든 자선행위는 자본주의적 순환이 논리적으로 낳을 수밖에 없는 것이며, 이는 철저하게 경제적인 관점에서 봤을 때도 반드시 필요한 것이다. 그래야만 자본주의 체제의 위기를 연기할 수 있기 때문이다.” - 지젝,<폭력이란 무엇인가>중에서\n",
      "“집에서 뵈니까 새롭네요.” 아니야. 익숙해지긴 개뿔. 새롭다고 하면서 왜 시선을 위아래로 사람을 훑고 그러는지. 어제 밤샘을 하고 바로 집으로 들어와 자고 일어나서 바로 제임스를 맞았기에 얇은 파자마 차림이었는데 왠지 그게 신경이 쓰였다.\n",
      "“집을 나선 가족이 안전하게 귀가하도록. 사다리, 소방차, 튼튼한 소방복은 법이 정한 규정대로 구비되는 줄 알았다. 힘들게 번 돈으로 세금을 낼 땐” 단골 카페에 붙은 펼침막. 공유 및 불펌 환영. \n",
      "“초과 세수를 활용한다는 점에서 국민의 세금을 다시 국민에게 환원시키는 추경” - 더불어민주당 김태년 정책위의장 \n",
      "“한국의 야당은 ‘주저하는 자유주의자’ 혹은 ‘행태는 유사 운동권이면서 내용은 보수적 자유주의’였다고 할 수 있을지 모른다.” - 최장집 교수는 친노세력이 장악한 현재의 만 통당을 한마디로 위선으로 가득한 강남좌파 정당이라고 냉정하게 평가해놓은 것이다.\n",
      "“한글교실을 열고는 다문화 정책이란다. 결혼이주여성에게 세시 풍속을, 한복 입는 법을, 심지어는 장 담그는 법을 가르치며 다문화 정책이라고 호들갑을 떤다. 이러한 것들은 전형적인 동화정책이지, 다문화주의 정책이 아니다.”(김형완 칼럼 “위선의 다문화주의”\n",
      "“한남”의 검색 결과에 ‘한남동’과 ‘한남대교’ 등의 지명과 상호까지 다 포함된다는 것을 혹시 모르는 사람이 있습니까? \n",
      "“현대차 정몽구 회장 ‘1조 원’대 세금 내고 사회적 책임 다한다” \n",
      "“홍종학, 이재용보다 세금 많이 냈다” \n",
      "〈모노가타리 시리즈 남성 히로인 인기투표! 〉 - 결승전 알로하 아저씨를 무찌른 하렘의 주인공, 정의의 위선자 아라라트 기와 vs 최다 지지층을 가지고 있는 연전연승, 악의의 달변가 마이키의 대결입니다!\n",
      "《》의욕 넘치고 오지랖 넓은 사회부 기자 윤이래(! 지독한 근성도 갖췄다는데. 기자 운 유래의 맹활약, 기대할게요.\n",
      "《기업이 계속 한국을 떠나는 이유》 (1 높은 인건비와 낮은 생산성 (2 지나친 기업규제 (3 경직된 노동환경과 강성노조 (4 높은 법인세율. ※문재인 촛불 정부는 4개항 모두 반대로 가고 있으면서 기업을 살린다고 세금으로 종업원 인건비를 내주는 웃기는 정책을 경제정책이라고 쓰고 있음.\n",
      "《다스 주인 mb 》 반드시 사법처리해야 합니다 “mb가 탕진한 국민 세금 최소 189조 원” \n",
      "《메인 겸 트친소》 ♧초면부터 살갑게 대할 거라 생각하지 말 것. 당신도 처음 보는 사람에게 살갑게 대하며 뭐든 주지는 않잖아? ♧답답하거나 귀찮게 구는 건 못 참아. 조금 격해질지도. ♧오지랖이 의외로 넓어. 기분 나쁘다면 미리 사과할게. ♧나 장르, 자캐, 지휘관 봇은 사양이야. \n",
      "《문재인 정부는 국민 세금을 너무 허비한다》 얼마 전에는 원전 공사 중단한다고 일을 벌이다 1천억 원을 날리더니 오늘은 위안부 기금으로 일본 정부에서 준돈 1백억 원도 되돌려주고 국민 세금으로 충당하기로 결정. 비서실장이 중동에 별일도 아니 것으로 다니려 가는데 대통령 전용 여객기를 몰고 가기도 하고\n",
      "《소야》 민주를 팔아 반역을 하고, 환경을 팔아 국책사업을 훼방하고, 평화를 팔아 적 화통 일을 기도하고, 인권을 팔아 반역자를 민주투사로 둔갑시키고, 민족을 팔아 김정일에 굴종하는 종북좌익세력의 위선은. \n",
      "《수원 시장은 이제 수원시에 있는 평화의 (위안부 소녀상에 새겨진 고은 씨의 위선적인 시문을 당장 철거함이 마땅한데 어찌할 작정이오? 수원의 망신이다 대답하시지요》\n",
      "《아시아나 항공이 북한 선수단 싣고 온다》 한국의 좋은 스키장 놔두고 시설도 안 좋은 북한 마식령 스키장에 1박2일 코스로 한국 후보 선수들 12명을 위해 아시아나 대형 여객기를 대절했는데 알고 보니 북한 선수단 태우러 간 셈이 되었다. 국민 세금을 이렇게 낭비해도 되는 것인가?\n",
      "《이 돈은 국민 세금입니다》 중도 사직한 사무총장에 전별금 7300만 원 지급한 자유총연맹 \n",
      "《이것이 촛불 정권이다》 사 드문 제로 미국에겐 욕먹고 중국에겐 굴복하고 원전 폐기 문제 제기했다가 1천억 원 세금만 날리고 위안부 문제 건드렸다가 아베한테 본전도 못 찾고 평창올림픽에 북한 끌어들였다가 올림픽을 김정은 선전장으로 변모시켰다\n",
      "《이조사의 오차 범위는 ±3.1%이다》 국민의 당 지지율은 0%나 다름없다 국민 지지율 0%에 세금 읊어 붓는다는 게 말이 되냐? 文 대통령 잘한다 85.9%. 국민의 당 지지 3.8%로 역대 최저[ksoi] \n",
      "《일자리는 세금으로 만드는 것이 아니다》 예산은 얼마든지 줄 테니 청년 일자리 대책을 내달라 이것이 촛불 대통령이 각부 장관에서 내린 명령. 정부가 만드는 일자리는 세금으로 월급 주는 공무원/공공복지요원 늘리는 것. 그리스가 실업자 대책으로 공무원/공공인력 무한정 늘리다 국가부도났다\n",
      "《정상적 국가라면 총은 총으로 보복은 보복으로 맞서야》 어떤 경우라도 전쟁은 하지 않겠다는 문 대통령 발언이나 사드 보복을 거둬달라고 사정하는 촛불 정부의 꼬락서니를 보면 정상이 아니다. 중국이 한국 여행을 막으면 한국도 중국 여행을 막고 수입을 막으면 중국 수출도 막으면 중국이 함부로 못한다\n",
      "《찰스야, 감방 가고 시프냐? 국민 세금으로? 》 안철수 ＂민주당, 국민 세금으로 댓글 부대 동원＂ \n",
      "「영웅 살인 증후군」 의도적으로 사람을 죽음으로 몰고 가서 마지막에 도와주는 위선적인 증후군이야. 글쎄, 네 주위에도 있을지도. \n",
      "「이나즈마 일레븐 아레스의 천칭」 반짝반짝 깡통 배지 수집 8개들 입 1box 6월 발매 예정/현재 예약 중/세금 포함 4320엔이나 현재 하비 스톡에서 4104엔에 판매 중 (이나모리 아르토, 치우라 키티나, 하이 자키 료헤이, 기도 유우도, 노사카 에우마, 고에 지 쇼야, \n",
      "「촛불정신」, 「삶의 질 평범」은 개뿔 집값이나 잡아 박통 때보다 못한 「삶의 질」 높여라 [정치분석] (2018.01.10 5부 \n",
      "『 block b 』포토에세이북 b5판／하드커버／184페이지 발매일：11月29（수） 가격：3500円+세금 \n",
      "『위장전입 강경화, 외교부 장관 지명. 실화냐?』 문재인, 병역 면탈, 부동산 투기, 세금 탈루, 위장전입, 논문 표절의 5대 비리행위자는 고위공직 임명에서 철저히 배제하겠습니다. \n",
      "『파리대왕』의 후속작이자 골딩 자신이 가장 아낀 작품. 네안데르탈인과 호모 사피엔스의 비극적인 대면을 통해 인간을 규정하는 핵심 속성인 폭력과 이기심에 대해 탐구한 수작, 『상속자들』이 세계문학전집 347번으로 출간되었습니다. \n",
      "\\예매 성공 후 성공 인증 같은 거 올릴 때 티켓 번호, 몇 구역 몇열, 예매자 이런 거 꼭 가리세요 플미충들 그거 도용해서 돈만 먹고 튀는 경우 많아요.는 제 사촌 언니가 비꾸뱅 콘서트 예매 후 안 가리고 올렸다가 저 방식으로 표 취소됨. 조심하세요.\n",
      "+ 물론 과거의 사례로 인해서 직간접적으로 피해를 입으신 분들 입장에서는 진짜 꼴도 보기 싫고 위선적으로 느껴질 수 있다고 봅니다. 그 부분은 잘못한 사람이 평생 안고 가야 할 짐이라고 생각하고요. 다만 아예 나대지 말라는 뉘앙스는 지양해야 하지 않을까요.\n",
      "+ 여담 1 팬들의 개빡침을 이해하는 지훈 오빠 그리고 해명하는 지호 오빠 \n",
      "+에네 신타로는 계정 괜찮아? 아-아 물론 에네가 관리해주니깐 너는? 아. 난 뭐. 끝에 당했지. 풋- 쌤통이ㄷ. 주인! 지금 계폭됬어요!! 안되게 에에ㅔ!!!\n",
      "⊙정의나 의리, 오지랖이 과해서 가끔 모르는 척 안 들리는척하는 게 세상 편한 거 아는데 벌써 분노하고 울고 열 내는 날 본다. 귀 닫고 눈 감아도 아무도 비겁하다 겁쟁이다 욕할 사람 없는데 쓸데없이 내 뜨거운 심장… (cont\n",
      "< 2014년 12월 23일 오후 10:20 > 주사 날조부터. 티엔은 떡 되니 않을 만큼 취기 올랐을 땐 평소보다 상냥해진다. 쩌언에 썼던 것처럼 벽에 붙은 술 광고지 여자한테 밤에 야하게 입고 혼자 다니지 말라 주의 주는 모양새로 이상한 오지랖도 생기고.\n",
      "<<<<워너원 서울 팬 콘 중곤 2시 스탠딩 원가 양도해요>>> 취소표 푸려고 했는데 플미충들이 잡을까 봐서요 ㅠ3ㅠ 알티 하시면 추첨해서 오늘 열두시에 뽑을게요!\n",
      "<<<<인피니트 비긴 어게인 기억하자>>>> 플미충=취소표 취켓팅은 26일 새벽 2시부터 프로미 말고 원가로 가자 플미충한테 입금 금지 중요한 건 두 번 말합니다 플미충=취소표 플미충=취소표 플미충한테 입금 금지 플미충한테 입금 금지\n",
      "<> ♡ 독보적 사랑스러움 친근 훈훈 매력 허당 스튜어디스 오지랖 셰프로 변신! 새콤달콤 sns 러브스토리, ! .ㅇ./ \n",
      "<0세.29세까지 유아 아동 학생 청년도 대상인데 빠져있네요> 이재명 대기업, 고소득자에게 세금 더 걷어, 2800만 명에게 연 100만 원 주겠다 \n",
      "<18-35세 300만 명 중 0.3%인 중소기업 취업자 만 명에 세금 4천만 원 들여 1억 만들어주는 게 로또 사행성 포퓰리즘 정책 맞지 않나요?> 남경필, 이재명에 “대학 장학금도 로또입니까?”(경향신문 \n",
      "<1987년에 공부만 한 사람들 현재> 조국…임관과 동시 예편 특혜…노무현 문재인 백으로 서울대 교수 및 민정수석…세금 체납…기부 전무 진중권…석사과정 수료 동양대 교수…비방 전문…기부 전무 안철수…의학박사…공학 석사…와튼스쿨 mba …카이스트 교수…서울대 교수…v3 벤처…천5백억 기부 \n",
      "<29만 원 밖에 없다. 시대의 살인마 전두환 > 29만 원 밖에 없다던, 전두환이는 이런 거대한 집에서 살고 있고 있습니다. 더욱 놀라운 것은 왜 이런 살인마를 우리 국민들 세금으로 경찰이 경호를 해 주고 있는 것입니까? 이것은 어느 누구의 명령인가요? 진작에 단죄해야 할 악마가 살아 숨 쉬고 있습니다 \n",
      "<5.18 서울역 대투쟁>은 예정대로 진행됩니다. 진정 박근혜 퇴진을 원하는 분들만 오십시오. 우리의 적은 박근혜가 아니라 위선과 비겁입니다. 부정선거 응징을 위해 청와대로 향하는 시민 대오의 선봉에 선 횃불들은 적어도 스스로 발길을 돌리진 않을 것입니다.\n",
      "<강경화 증여세> 09년 남편이 딸과 공동명의 콘도 2억 6천만 원에 구입. 지분 1억 3천만 원 증여했다며 세금 탈루 주장. 2인 지분이 구매 조건이라 공동명의로 구입함. 실제 이용하지 않아 수개월 뒤 별 차액 없이 매도. 매도 금액 남편이 전량 회수(증여 아님\n",
      "<개발이익은 취하고 기반시설부담금은 안내면 국민 세금으로 기반 시설 만들어야 하는데. 왜 기반시설부담금을 면제해 줍니까?> 이재명 ＂文의 준조세 금지 공약은 대기업 특혜…철회해야＂ \n",
      "<개헌안 발의할 수밖에 없었던 4가지 이유> 1. 국회가 진척이 없었기에 대통령이 국민과의 약속을 지키기 위해서 2. 지방 투표 동시 개헌은 다시 찾아오기 힘든 기회이며 세금을 아끼는 길 3. 선거의 횟수를 줄여 국력 낭비를 막을 수 있는 절호의 기회 4. 대통령을 위한 개헌이 아니라 국민을 위한 개헌\n",
      "<경제 위기는 개뿔! 범죄자 아베 정권 유지와 체르노빌 보다 더 심한 방사능 재앙을 감추려는 짓거리 쥐!> 일본 우익단체가 경제 위기 극복하기 위해 생각해낸 방법 \n",
      "<고등학생 루시 데미> 데미안: 너 진로희망 뭐 썼냐 루시드: 아 정신과 의사가 꿈이라 의사요 데미안: 아; 난 딱히 없는데 뭘로 적지? 루시드: 정 없으면 간호사로 해요 데미안: 뜬금없이 왜 루시드: 아니 요즘 간호사 의사 커플이 많으니까. 데미안: 수작 부리지 마라\n",
      "<고영태 녹음 파일> 이현정이 고영태에게 지시하면서 대화 기록 없애라. 전화기를 한강 같은 데에 던져버리라고 그러더라고 말한 것(아래 사진은 위선 누군가로부터 지시받은 것을 전하는 말이다! 지시한 자가 누군가? 검찰은 수사하라! \n",
      "<고위공직자 인사 검증 기준 관련 청와대 브리핑> 7대 비리 12개 항목 추가, 음주운전·성범죄 관련 추가 불법 흠결 해당자는 원천 배제 병역기피·세금 탈루·부동산 투기 엄격히 적용 한-스리랑카 정상회담 오는 29일 개최 \n",
      "<공> 공갈 마! <수> 수작 부리지 마! <처> 처넣겠다 부정부패! 이석현 선수가 김병기 선수한테서 받은 공, 이정렬 판사 이학영 의원 최재성 위원장 받으세요! \n",
      "<공공 공사 원가 공개, 표준 시장 단가 적용으로 국가 재정 1조 6천억 원을 절약합니다> 이재명 표준품셈, 건설사에 세금 퍼주는 것 이재명 카카오톡 친구 추가 \n",
      "<공짜 아닙니다. 세금 낸 주권자들의 헌법 34조 2항에 의한 권리이고 국가의 의무입니다. 복지정책과 공짜 시혜 정도는 구분합시다> [조선일보 사설] 쏟아지는 無償 공약들, 또 선거철이 왔다 \n",
      "<국민의당 수석대변인 논평> 박성진 후보자에 대한 빠른 결단과 인사 관련자들에 대한 문책을 촉구한다 박성진 후보자에 대한 의혹이 일파만파다. 창조론, 뉴라이트, 세금 탈루, 자녀 이중국적까지 어느. \n",
      "<국세청 인사청문회> 세금 탈루 규모가 2011년 26조 8천억 원. 당시 근로소득 세로 거두어들인 액수가 18조 8천억 원. 세금 탈루 규모 가운데 상속증여세가 가장 크네요. 상속증여세 안 내고 탈루하시는 분들. 이런 분들이 바로 적폐입니다. \n",
      "<국정원의 선거 관련 전방위 댓글 오지랖>그동안 사적인 글로 취급됐던 요리·연예 글마저 야당 후보에게 유리한 글이 베스트 가는 것을 막기 위한 국정원과 댓글 알바들의 조직적인 선거 개입 글로 드러났습니다 \n",
      "<그래서, 문재인 공약> 문재인 더불어민주당 전 대표가 “병역 면탈·부동산 투기·세금 탈루·위장전입·논문 표절 등 5대 비리 관련자는 고위 공직에서 원천 배제해야 한다\"라고 주장했다. \n",
      "<그러니 위선자라고 느끼는 거야.!! 기회는 평등하다며 청년 일자리를 어설픈 최저임금제로 박탈했고, 평창 출전 선수들은 북한 출전으로 과정이 공정치 못해 문제가 생겨 그를 위선자로 보는 거야.> 문 대통령 축전 받은 정현 기회는 평등, 과정은 공정…깊이 공감 \n",
      "<급보>후원 시급! 더불어 민주당 19대 대선에 당비 모두 소진 재벌들의 후원 거부 여러분의 소액 후원으로 운영 1인당 10만 원 후원하면 연말에 전액 환불 소득공제가 아니라 세금공제로 “깨어있는 시민의 조직된 힘”은 문재인 정부 성공의 열쇠입니다 \n",
      "<김무성의 헛짓 민낯. 5.18 찍고, 친일 부친 동상 찾아> 세월호 유가족 능멸한 김무성, 팽목항 찾아 생쇼에 무례한 복장으로 5.18묘역 찾더니 친일 부친 김용주 동상 찾아! 너한텐 뭐가 중한 거야? \n",
      "<나의 그리스식 웨딩 2>가족애와 오지랖 사이 그 어딘가 김동민 기자\n",
      "<내일 mb 점심, 저녁 식단표 공개> 점심은 돼지고기 김치찌개, 저녁은 감자수제비 국이군요. 비록 우리 세금으로 먹이는 거지만…ㅋ\n",
      "<누가 내 국민연금을 죽였나?> 저자 김형모 씨가 말합니다. 세금 내는 국민보다 세금 받는 공무원 연금이 +α? \n",
      "<다정한 편견>의 손홍규 작가가 중편소설 꿈을 꾸었다고 말했다로 42회 이상문학상 대상을 수상했습니다. 우수작엔 구병모 한 아이에게 온 마을이, 박현희 내 마지막 공랭식 포르쉐, 정지아 존재의 증명, 정찬 새의 시선, 조해진 파종하는 밤 선정. 축하드립니다! \n",
      "<닥치고! 4년 중임 대통령 중심제> 개뿔 의원내각제 이원집정부제는 기득권들끼리 다 해 먹는 악의 구조다. 민주당 잘한다 기왕이면 연동형 비례대표 제도 힘껏 주장하라 \n",
      "<당신이 잠든 사이> 제작발표회. 이영은 씨 (극 중 오신 역 정 많고 고집 있고 의리 있고 오지랖 넓은 병원 영양사 \n",
      "<도가니>만큼 기독교의 위선을 통렬하게 비판한 영화도 드물 것이다. 자애학원 교장의 양복 깃에 꽂혀있는 금빛 십자가. 이제 십자가는 기의(記意를 상실하고 타락의 상징이 되고 말았다. 교회들은 첩탑에서 조용히 십자가들을 내려야 하리라!\n",
      "<딴지일보> 논객 아하스’는 거듭 “석패율제 도입해서 한나라당과 민주당이 윈윈하는 것이 지금 이 시점에 왜 필요한가? 민주당이 여유가 넘치다 못해 오지랖이 넓기도 넓은 것 아닌가?”라고 지적했다.\n",
      "<레이디 버드>는 여성의 영화다. 한남인 나의 추론은 곳곳에서 실패한다. 예상치 못한 곳에서 숏이 쪼개지거나, 상황이 급변하거나, 공기가 뒤바뀐다. 이 소소하지만 감당할 수 없는 리듬은, 전적으로 옳다. 소녀에 대한 내 안의 기만적 이미지, 그 무심한 규정이 무너지는 순간들이기 때문이다.\n",
      "<렛 더 선샤인인> 재미있겠다. 사랑에 목마른 중년 여성의 절실한 짝 찾기. 이자벨은 이혼 후 진실한 사랑을 찾고자 하지만 (. 쥘리에트 비노슈의 존재감과 감칠맛 나는 대사가 돋보이는 수작으로 칸영화제 감독주간 개막작이다. \n",
      "<멋진 하루> 마지막 장면에서 전도연이 유턴했다가 하정우를 보고 그냥 지나치는 장면은 영화 전체의 압축과 같다. 결혼을 생각하는 여성은 정 많고, 오지랖 넓은 남자를 보며 현실논리에서 벗어나 위안을 얻지만 함께 하기에는 대책이 없다는 사실을 잘 안다.\n",
      "<며느라기>나 <82년생 김지영> 같은 여성 현실 고발성 서사는 흔하디흔하다. 그 조차 입막음하려 드는 요즘 2030 한남들은 죽어 마땅하다.\n",
      "<무능 장관 열전> 경제 장관:세금 뿌리는 사람 교육부 장관:결정 장애 증후군 외교장관:투명인간 국방장관:시위대 허락받는 사람 환경장관:자기 업무도 모르는 사람 법무장관:가상화폐도 모르는 사람 고용장관:일자리 불황 책임도 모르는 사람 복지장관:자기도 모르는 문재인 케어 \n",
      "<문 대통령님, 떨리지 않으십니까?>세금 문제에 대해 말씀해 주십시오. 초고득자증세에 대해 발표했습니다. 더 큰 복지를 위한 추가적인 증세에 대해 국민적 공론을 모아주시면 검토하겠지만 정부 정책은 현재로도 가능하다. \n",
      "<문재인은 광화문 대통령이 되겠습니다> 청와대와 북악산은 국민께 돌려드리고 일하는 대통령이 되겠습니다. 고위공직자 비리수사처를 신설, 검찰을 개혁하는 권력분산하겠습니다. 병역, 부동산, 세금, 위장전입, 논문 문제없는 진짜 인사 다운 인사하겠습니다! \n",
      "<바나 분들 리트윗 해주세요!! >제가 바나는 아니고 븉벱인데여 그냥 트위터 검색에 달링 쳤는데 이분이 나오시더라고요. 음. 뭔가 그냥 넘어가기 찝찝해서. ㅠ .괜한 오지랖인가요.? \n",
      "<朴당선인 쪽방촌서 성탄절 봉사활동. 연일 민생행보> 박근혜 씨! 사진 찍기 위한 민생행보 생쇼는 그만! 국민 절반을 국가전복세력으로 낙인찍은 윤창중 수석대변인 인선이나 취소하고 쌍창 국정조사 등 노동문제 해결하라!\n",
      "<박용진 페이스북> 원문 : 청와대 밥은 부실해도 숙정문 : 청와대 밥은 소박해도 샥스핀 송로버섯 캐비아를 기대했을 모르지만, 문재인 대통령은 국민 세금으로 그런 말도 안 되는 짓 하실 분이 아닙니다. \n",
      "<朴정부가 세금 도둑 덧씌웠던 세월호 특조위.법원 구성 완비된 때 활동기간 시작 인정> 법원이 4·16 세월호 참사 특별 조사 위원회(특보 위의 활동기간을 2015년 1월 1일부터 시작한다고 보는 것은. \n",
      "<부패 새누리 일당이 먹으려던 5503억 원 중 1800억 사용법으로 임대 아파트 검토했지만, 건축비로 세금 수백억 더 들여 1200세대 임대 아파트 지어 1200명 혜택보다는 공평한 시민 배당이 낫다고 판단한 게 뭔 잘못?> 이재명의 1800억 배당, 그게 최선입니까? \n",
      "<사드 반대투쟁하는 분들을 모욕하지 말라> 사드 반대투쟁하는 분들이 홍준표를 찍지 않았다는 거 다 알면서, 그 주민들을 싸잡아서 모욕하는 건 의도가 빤히 보이는 수작이군요 문재인에게 부담스러운 건 다 지역주민들 탓으로 떠넘기자는 의도겠죠? \n",
      "<생각이 없어서 고마운 자유한국당> 공무원 수험생이 몰려 있는 노량진역 앞에 ‘공무원 증원 세금폭탄’ 현수막을 걸어 놀은 자유한국당 ( \n",
      "<서울의 달> <짝패> 김운경 작가 작가들은 시대의 부조리와 위선을 고발할 권리와 의무 있다. 드라마 작가들은 pd수첩을 집필했다는 이유만으로 억울하게 해고된 동료들의 피눈물 나는 현실을 더 이상 지켜볼 수 없다 김재철은 파렴치한 조치를 즉각 철회하라!\n",
      "<성추행 누명으로 죽음 내몰린 젊은 교수. 진상 밝혀져> 읽어보면 참 기가 막히다, 성범죄로 찔렸던 교수들이 엉뚱한 동료를 가해자로 몰려고 수작을 부린 것. 진짜 피해자의 고백으로 사건의 진상이 밝혀졌다. \n",
      "<세 모녀의 70만 원> 여러분! 서민들이 가난해서 자살을 합니다. 공과금도 못 내고 따뜻한 연탄도 못 사고 추위에 떨고 있습니다. 박근혜의 복지혜택은 거짓말이 됐습니다. 위선자입니다. [mbc 방송 9:30]☞ \n",
      "<세금 아껴 기본소득 준다는 게 황당한가?> 황당한 대선 공약 남발…“직장 있든 없든 100만 원” : 네이버 뉴스 (출처 : 채널a | 네이버 뉴스 \n",
      "<손석희 jtbc 뉴스 9> 군 사이버사령부 대선 개입 첫 공판에서 전 심리 단장은 정치개입, 위선 개입 검찰 기소 내용을 전면 부인하며 수사기록을 늦게 전달받았다며 재판 연기 요청이 받아들여져 6주 후 재판 재개. \n",
      "<쇼를 사랑한 남자> 잘 만든 영화인데 그 이유 중 하나는, 어설프게 이야기를 굴러가게 하기 위해 주인공 주변인들이 막 잘 짓 하거나 사고 치거나 오지랖 부리지 않아서. 두 사람의 감정과 관계가 변해가는 게 결국 그 두 사람 때문이라서 좋았다.\n",
      "<심야식당> 그 남자가 타인을 위로하는 방식 그 남자는 필요 없는 말을 하지 않는다. 어쭙잖은 위로도 없고, 쓸데없는 간섭과 연장자의 오지랖도 없다. \n",
      "<심야의 유감천만 사랑도 감>, 너무나 멋진 책입니다. 세금으로 출판해서, 이 나라의 모든 남자들에게 읽혀야 마땅한 책이 아닌가 싶은 생각이 드는군요. \n",
      "<쌤통이다! 왜곡 그리고 뻥 좀 그만 쳐라!> ‘이재명 종북몰이’ 악성 댓글 보수단체 간부, 재판 회부 트위터에“이재명이 북한 지령 받아 세월호 괴담 퍼트려” 허위사실 유포 \n",
      "<악마는 레이디를 키운다>가 카카오 페이지에 오픈되었어요!  해주신 분 중 두 분을 뽑아 기프티콘을 보내드려요 악마와 계약해 회귀한 여주가 복수하는 로판로맨스릴러에요! 덜 빻은 소설을 쓰려 노력합니다 \n",
      "<안철수 허위사실 유포> 민주당이 세금으로 저를 중상모략하는 댓글 부대 동원했다. 문재인은 저를 지지하는 국민들을 적폐라며 국민들을 공격한다. 최순실 게이트 변명하던 박근혜가 딱!\n",
      "<안티 페미는 지능의 문제> 안티 페미 이 친구들이 남초 커뮤 일제 포밍 하려고 올리는 자료를 가만히 보다 보면 남녀 역차별 레퍼토리 중 하나로 남성들이 더 많은 세금을 내고 여성들의 복지에 사용한다는 것이 있다. 그러나 평균적으로 남성의 소득이 더 많기 때문에 세금을 더 많이 내는 것은 당연.\n",
      "<어 멋날 재팬 dvd 출시> 1. 본편에서 편집된 미공개 영상 40분 2. 20페이지 사진집 3. 슬립 케이스 4. 캐럿 중 8명 추첨 사인 포스터 5. 가격은 세금 포함 8100엔 \n",
      "<어뮤즈먼트 이치방 쿠지 죠죠의 기묘한 모험 스타더스트 크루세이더스 super master stars piece 크죠 주타로>가 7월 29일 (토에 발매 예정. ■가격：1회 5,000엔 (세금 포함 ■구매 가능 지역：게임 센터 (일부 제외 \n",
      "<오버워치> ‘리퍼’ 액션 피겨가 출시됩니다. 제작과 채색이 전부 수작업으로 이루어져, 가면과 갑주의 스크래치까지 정교하게 표현돼 있습니다. 가격은 7,800엔(세금 및 관세 제외 금액으로, 한 사람당 세 개까지 구매할 수 있습니다. 자세한 정보는 링크를 참고하세요. \n",
      "<오소리 피부관리> 아아 마이크 테스트 흑설탕을 (1번 사진 곱게 빻으면 2가 됩니다. tip: 빻은 네이버 악플을 떠올리며 세차게 휘 둘러주세요. 더 곱게 갈아 집이니 닷. 3 여유가 되는 분들은 귀리가루를 섞어줍니다. 안 섞어도 효능은 별 차이 없음 \n",
      "<오자룡이 간다>, 오지랖이 간다? by 이가 온 부모 세대의 가장 큰 고민 중 하나인 자식 문제를 전면에 내세운 <오자룡이 간다>는 소재 선택에 있어서 신중하게 고민한 흔적이 묻어나는 작품이다.\n",
      "<온갖 무례와 오지랖을 뒤로하고 페미니스트로 살아가기> 화사 외 42인 지음, 한국 여성민우회 엮음, 궁리출판 펴냄 \n",
      "<위키리크스> 美, mb 취임 넉 달 만에 무능력 리더 낙인…그런데도 오지랖 mb 내가 후세인 잘 아는데 美에 이라크전 훈수도 - 이런 대통령과 4년 버틴 국민 참 대단 \n",
      "<유기 동물 보호 분양 훈련 교육 등을 담당하는 곳을 반려동물 문화센터라고 명명한 것입니다. 유기 동물보호소보다는 낫지요? 그리고 동물병원 수가 제와 의료보험은 세금이나 재정이 투입되는 것도 아니고 보험료 내는 사람이 공동으로 혜택 보기 위한 것입니다. \n",
      "<윤창중 칼럼세상> 극적 효과 완전히 소멸된 ‘문철수 단일화쇼’ * 거짓과 위선은 잠깐 국민을 속일 수 있으나 대선 일까지 계속 속일 수는 없다. 대선일 투표장 속의 유권자들을!* -- ☞서울뉴스 통신☜ 林 記者\n",
      "<읍.소리 나는 문재인 공약> 문재인 더불어민주당 전 대표가 “병역 면탈·부동산 투기·세금 탈루·위장전입·논문 표절 등 5대 비리 관련자는 고위 공직에서 원천 배제해야 한다\"라고 주장했다. \n",
      "<의원실> 정동영 국군 기무사 선거개입 진실 밝혀야 (전북일보 mb 정부가 국민 세금으로 국방의 의무를 수행하는 군대를 댓글 부대로 변질시키고, 이를 정적 제거에 활용한 것은 참으로 통탄할 일입니다. 국군 기무사의 선거개입의 진실을 규명하여 다시는 이런 일이 재발하지 않도록 해야 합니다. \n",
      "<이재명은 합니다!! 세금도 들지 않고 정부가 양심만 가지면 가능합니다> 이재명 ＂490만 명 신용 대사면으로 생계형 부채 탕감＂ (출처 : 연합뉴스 \n",
      "<이재명은 합니다!> 재벌은 세금을, 노동자는 최저임금 1만 원을. 국민은 기본소득을 19세기의 가장 큰 혁명은 노예 해방 20세기의 가장 큰 혁명은 보통선거 21세기의 가장 큰 혁명은 기본소득 \n",
      "<이재명은 합니다!> 재벌은 세금을, 노동자는 최저임금 1만 원을. 국민은 기본소득을 19세기의 가장 큰 혁명은 노예 해방 20세기의 가장 큰 혁명은 보통선거 21세기의 가장 큰 혁명은 기본소득 \n",
      "<이재명의 생각> 공무원은 1백만 원 선물 받기 위해, 1천만 원 수익 남는 1억 원짜리 사업을 준다. 그 모두가 국민의 세금. 차라리 1백만 원을 국고에서 빼가는 것이 낫지만 자금 세탁을 위한 프로세스. 부정부패 척결은 국민촛불 혁명의 명령! \n",
      "<작은 집> 남성의 전유물인 전쟁의 중심에서 하녀의 시선으로 본 주인 여성의 금지된 사랑. 시대의 요구 앞 여성이 겪는 억압, 기억의 방식, 여성이 여성을 이해하는 마음의 풍광에 주목하는 야마다 요지의 멜로. 크로키 하루에게 베를린 은곰상을 안긴 수작. \n",
      "<저수지 게임> 명박이 빼먹은 우리 세금은 저수지에 모여 있고, 닭 년이 빼먹은 우리 세금은 여기저기 나눠졌고, 전두환 빼먹은 우리 세금은 짐작들만 하고 있고, 우리 세금, 우리 돈을 찾습시다. \n",
      "<적패 청산은 개뿔!> 문재인 캠프는 채널a를 고소하라! 채널a가 흥정을 하자는 걸까? 아니면 버린 패라고 확신하는 걸까? \n",
      "<절세>란 내야 하는 세금을 덜 내는 게 아니라, 내야 하는 것보다 더 내는 것을 방지한다는 뜻이다. 절세를 마치 범죄처럼 말하는 자들이야말로 의심스럽기 짝이 없다.\n",
      "<조리사 이어 공무원 비하? 이언주 세금 먹는 사람. 필요 없는 인력 많다> 지금 늘린다는 게 행정공무원이 아니라 소방관 부사관 등 국민 안전 관련해서 늘린다는 건데. 민주당에서 나간 게 다행이네요. \n",
      "<조선일보>는 마치 <조선시대> 사대부의 위선적 공론(空論을 보는 듯하다. 이 신문은 교묘한 논리로 국회를 감싸고 있지만 이번에 적출(作出 된 「국회법 개정안」은 「식물국회」에 이어 「식물정부」를. \n",
      "<죽은 시인의 사회>는 위선이라며 도발하는 연극 <히스토리 보이즈>. <학교 2013>의 고남순, 박흥수 못지않은 8명의 훈남들이 출연하는 이 연극을 보고 싶으신 분은 이벤트 신청하세요. \n",
      "<참을 수 없는 오지랖의 가벼움에 보내는 아임 파인>: 어쿠스틱 라이프 142화 \n",
      "<청년들을 구차하게 만들지 맙시다 청년은 시혜 대상이 아니라 세금 내는 당당한 나라 주인입니다> [2030 잠금 해제] 청년심사 수당 / 박정훈 (한겨레 | 네이버 뉴스 \n",
      "<최소한의 팩트는 확인하고 씁시다. 개발이익 5503억이 회수된 건 판교가 아니고 대장동 지구입니다. 세금이 아니고 적폐 기득권 세력과 새누리당 시의회와 싸가며 만든 불로 소득 이나다> 선거 앞두고 또. 경제 덮친 포퓰리즘 (서울경제 성남도 판교 개발이익 1800억 배당.\n",
      "<친애하는 우리 아이> 고레에다의 근작이 닿지 않았던 가족의 초상.<그렇게 아버지가 된다> <행복 목욕탕>과 궤를 같이 하면서도, 영화가 다루는 의심과 연결은 안일한 가족주의의 봉합을 벗어나 개인 각각의 입장을 향한다. 감독의 전작이 떠오르지 않는 수작. \n",
      "<플미충 알레르기 워너블> 원가 \n",
      "<한겨레 후 재현의 이중잣대> 권재진 - 다운 계약서 써서 세금 탈루했으니 사과하고 사퇴하라 안철수 - 논문과 다운 계약서보다는 국정운영 능력을 검증하라. \n",
      "<한남 관광>버스에서 한남 우르르 내리는 거 보면서 볼 깨물어서 웃음 참 앗기\n",
      "<혁명하는 여자들>은 페미니즘 sf 단편집이에요. 다국적의 각기 다른 작가들이 모여서 만든 책이고 대부분 수작이라 읽으면 반드시 즐거울 거예요. 일본 작가 단편에서 모유 수유 이야기 나오는 거 보면서 아시아는 하나라는 걸 느꼈어요. 웨어울프 이야기도 좋았고요.\n",
      "<형의 몽정> 발기부전 40대 남성의 심리를 섬세하게 묘사한 수작이라네요. (<훈의 노래>로 유명한 김현 작가 자품ㅎ\n",
      "<화성인 바이러스> 리뷰. 신상 털기가 횡행하는 오지랖 넓은 현재 한국 사회에서, 관심을 꺼야 할 시점을 알고 있는 <화성인 바이러스>의 미덕-이근우\n",
      "<화차>에서 피 칠갑을 하고 바닥을 벌벌 기던, <아가씨>에서 새하얀 얼굴을 치뜨고 위선적인 신사들을 마주 보던, <지금은 맞고 그때는 틀리다>에서 눈길을 천천히 걷던 김민희. 그는 이미 왕관을 쓴지 오래다. 이번 수상이 그에 마땅한 대접을 받는 계기가 되길.\n",
      "<황교안> 공무원 시험을 주일에 치르는 건 부적절하다 교회 직원은 노동법상 근로자 아님 교역자에게 세금 부과하면 안 된다 재소자를 주님께 인도한다. -- 황교안 종교관이 훨 위험한데 언론이 박성진 자질 검증 무시하고 종교 프레임으로 덮어씌워 낙마시켰음. \n",
      ">> 계에 합니다 << 요즘 제가 예민 맨유라 실수하거나 틀어질 것 같은 분들이 좀 보여서 + 정리가 불가능한 트윗과 마음 한 + 아! 나도 계시해보고 싶어! 의 이유로 계에 합니다. 이 새끼의 빻은 면을 나는 참아줄 수 있다 or 빻앗다니 어 너도? 야 나도! 하시는 분만 팔로 해주셨음 좋겠어요.\n",
      ">>한남<< 대학 동기?\n",
      "■ cd + dvd (스마뿌라 대응 【첫 회 한정판】 <일본 오리지널 music video 오프 샷 영상 수록!> 가격 : ￥ 2,800 (세금 포함 디지팩 사양? 트레이딩 카드 (전 3 종류 중 1 종\n",
      "■ cd only (스마뿌라 대응 【 exo-l-japan 한정판 / 수량 한정】 <특대 (lp 사이즈 재킷 ver.> 가격 : ￥ 2,300 (세금 포함\n",
      "■ fc 선행 응모기간 2017년 4월 14일（금） 15:00～ 2017년 4월 24일（월） 12:00 ■티켓 가격 전석 지정 6,800엔（세금 포함 ※펜라이트는 포함되지 않습니다. - 태민이 보는데 이렇게 싸게 봐도되나요??ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ아진짜눈물난다ㅠㅠ\n",
      "■ 방송 공정성 논란의 마침표를 찍으려면? ■ 피감 기관 돈으로 외유가 국회 관행? 김기식 원장의 표리부동과 위선적 행태 수사해야 <발언 전문> \n",
      "▣ 양키 놈들 하는 꼬락서니 보면. 남북이 독자적으로 평화. 불가침조약을 맺고 주한미군과 그 식솔들 모조리 데리고 가라! 고 큰소리치고 싶다. 미국 한국, 미국산 사과-배 수입 허용하라 \n",
      "■『디지몬 테이머즈』 blu-ray box 너도, 블루레이로 테이머를 노려라…!! - tva 전 51화 완전 hd 화 - 초회 한정 신작 스페셜 드라마 cd 수록 - 스페셜 북클릿 동봉 2018.04.03 on sale / 53,800엔(세금 포함 \n",
      "■김기식 사임 역풍 부나, 국회의원 전수조사 청원 14만 명 돌파■ 현직 국회의원뿐 아니라 전직 국회의원도 조사하자고 했다. 형사 처분도 형사 처분이지만, 세금 환수란 네 글자가 주는 울림, 구린 구석이 있는 국회의원으로서는 뜨끔할 만하다. 17일 오전 5시 45분께 벌써 7만 7610명이 동참\n",
      "● 경찰에 끌려가고 철창에 갇히고 온갖 모욕을 당했지만 폭력으로 대항하기보다는 내가 상처받고 피 흘리고 박해받음으로써 그들의 거짓과 위선과 부당함을 드러나게 하는 방식으로 나는 불의와 싸웠습니다. - 도종환, 꽃은 젖어도 향기는 젖지 않는다中\n",
      "● 나무는 옷을 갈아입지 않는다. 가없이 혹독한 변화에도 안색만 철마다 바뀔 뿐 언제나 맨몸인 채 그대로 은근한 소박함이 눈부시다. 헐벗은 영혼은 방치한 채 매일 의복으로 치장하는 나는 얼마나 위선인가. - 공성진, 나무와 나 中\n",
      "● 시간이 없다는 말은 위선이다. 시간은 늘 충분하다. 단지 우리가 무언가를 포기하지 않기 때문에 새로운 것에 도전할 시간이 없는 것이다. - 박경철의 자기혁명 중\n",
      "● 인격은 그 사람이며 명성은 그의 그림자이다. 형체와 그림자가 언제나 같이 다닌다고는 하지만 그 그림자만을 크게 보이기 위해 자신과는 당치도 않은 위선자라는 허수아비를 지니고 다니는 사람이 있다. - 에머슨\n",
      "● 자신도 사랑하지 못하면서 남을 사랑한다는 것은 위선에 불과하고, 자신에 대한 믿음도 없으면서 성공을 다짐하는 것은 허세에 불과합니다. 사랑이 무언지도 모르면서 어찌 사랑을 말하고, 충실한 오늘 없이 어떻게 미래를 이야기할 수 있겠습니까 - 전용석\n",
      "●민주를 팔아 반역을 하고, ●환경을 팔아 국책사업을 훼방하고, ●평화를 팔아 적화통일을 기도하고, ●인권을 팔아 반역자를 민주투사로 둔갑시키고, ●민족을 팔아 김정일에 굴종하는 종북좌익세력의 위선은 이제 종식될 때가 되었습니다 -대한민국 국민 소망\n",
      "●이제 민평련 호남구 리디 구리 구태정치모리배들이 (박지원 천정배 정동영 조배숙 유성엽 김경진 이용주 박준영 등. 탈당하니 통합 찬성 90%겠구나 하고 마음 놓지 마세요 통만 파들이 또 무슨 수작을 부리려고 탈당 안 하고 있는 세작들이 있을 수 있으니 투표 독려해야 합니다\n",
      "←개빡침 / 게 기분 좋음→ \n",
      "…은 개뿔, 개 무섭잖아!!!!! ㅠㅠ\n",
      "☆빻☆은☆2☆d☆3☆d탈☆덕☆하☆고☆광☆명☆찾☆자☆\n",
      "☆이명박 수법☆ 1. 국민 세금이 들어가는 공기업을 노린다. 2. 공기업이 해외 합작 기업 형태로 투자하게 만든다. 3. 해외 합작 기업이 힘들다고 징징거린다. 4. 공기업 국민 세금으로 추가 투자한다. 5. 해외 합작 기업 망하고 투자금 날린다. 6. 해외에서 일어난 일이라 뭐라 못하며 국민 세금 날린다. \n",
      "☆콘서트 티켓 이 벵☆ 티켓 취소하려다 몹쓸플미충이 판을 쳐서 에리들한테 ☆원가☆로 드려요. 만 해주세요! 8충, 타 팬 절대ㄴㄴ.에리 인증 빡세요. 좌석은 3층 연석, 2자리입니다! dm 안 받아요. 다발은 내일 3시입니다. 내일 입금 바로 가능하신 분만!\n",
      "★ 센베이 (煎? : 멥쌀을 부수거나 치고 빻은 것을 구워 만든 쌀 과자에요. 설명 출처- 연세대학교 한국어 학당/네이버 한일사전 인용( 사진 출처-가공 상업적 이용 ok인 무료 사진 ac( \n",
      "★ 영화 귀향이 개봉합니다. 많이 봐 주세요. 일본의 위선에 대해 고민해 주세요. 저도 무언가를 하고 싶네요. 영화관을 통째로 빌려 당신을 초대할까요? 알아보겠습니다. 영화 홍보 알티 부탁드려요. \n",
      "★ 컴백 중비 :: 1탄 음악프로별 1위 선정 방식/2탄 앨범 구매 권장 구매처/3탄 스트리밍 정복기 [출처-비스티움 매일 윤두준 님] \n",
      "★5.18유공자 선정은 광주가 하고 혜택은 국가가 주고 세금은 국민이 내고 혜택은 광주가 먹고 이걸 해결할 사람 오직 남재준!!!\n",
      "★여성의 기쁨★=남편, 출산, 아이! 여성이 이 땅에 온 의무 : 가정과 자녀 양육! 남편의 사랑과 아이가 없으면 무엇이 남지요? 동성애는 가정을 파괴합니다! 여성 단체는 진정한 여성의 삶을 위해 동성애를 반대해야! 저는 이런 빻은 카톡을 읽는 사람 \n",
      "♡문재인 정부의 독선과 위선♡ 민정부는 겉으론 적폐 청산을 내세우고 뒤로는 더 더러운 적폐를 만들고 있다! 취임 직후 2달간 100만 명의 개인 통신정보를 수집한 것은 헌법위반이며 탄핵 사유가 된다 그러고는. \n",
      "※ 본 공연은 예매 완료 후 취소가 불가합니다??????????? 플미충들에게 프로미를 하라고 아주 판을 펼쳐주는구나? \n",
      "※수요 조사. 여러분에게는 밝은 앞날이 기다리고 있습니다! 앞날은 개뿔. [10월 연휴 후, 개장 예정] [1.5차 지인제/복합/04/판타지/현대/시리 (사망, 부상 o/창작 세계관] [당신의 자캐의 몸에서, 무기를 꺼낼 수 있습니다.] \n",
      "010 4783 7996 신한 110303449781 이재훈 플미충이에요 아무나 신고 좀!!! \n",
      "010-8840-1936 플미충 전화번호 \n",
      "01이면. 아까 주워들은 얘기로는 최소한 06이 있단 얘긴데. 이건 뭐 완전 티브이에 워너원 나오는 판에 함중아와 양키스 lp 판들고 있는 꼬라니 구마.\n",
      "03:25 해결했다. 간호사실 연락이 계속 안돼 119에 전화해 물어봤더니 바늘 꽂은 상태로 두면 혈관 막힌다고 약을 갈든 바늘을 뽑아야 한단다. 극적으로 간호사 실과 연락. 간밤의 119생쇼를 모르는 간호사는 바늘을 뽑아주고 나감서 한마디 쉬세요.\n",
      "03년생인가부터 문이과 통합인데 내가 하필 03년생이라서 개빡침 10개월만 일찍 태어날걸((((((임신 기간이 10개월인데?\n",
      "04 김 냄비 이마니 더. 할 말 좀 할게요  흠흠 김영산 사랑해(배액 워낙 트찐이라 이것저것 오지랖이 많고 꼽사리 끼다 보니 탈장르가 만흘수도잇어오. \n",
      "08__hkkim 계정은 이미 이재멍 아내 계정. 늘 붙어 다닌 이재멍 계정과 수작 부린 것은 결과적으로 차명 계정으로 1인 2역 한 것으로 보이는데, win인 겨? \n",
      "1 이재용 자산이 합당한 증여세 아래 이뤄졌다면 이건희는 칭송받았을거다. 갓뚜기란 말은 상속하지 않아서가 아니라 정당한 세금을 냈기 때문이었다. 부의 대물림 비판은 상속 증여를 하지 말라는 게 아니라 편법 탈법 세습 비판 아닌가.\n",
      "1. 가끔 이렇게 부족한 제가. 매일 넘어지는 위선자 같은 제가. 이렇게 공개적으로 신앙을 이야기 한다는 게 두려울 때가 참 많습니다. 주위 여러 연예 관계자분들도 이제 막 일을 시작한 저 같은 신인에겐 얻는 것보다 잃는 게 많을 거라는 충고와.\n",
      "1. 개식 용의 일차적인 원인이 아니라 육견/구를 좀 더 안전하고 위생적으로 기르는 걸 동물보호운동가가 막았다는 거. 2. 육식의 총량을 전반적으로 줄이는 게 아니라 특정 종의 식용을 줄인다는 발상은 심각한 위선.\n",
      "1. 공무원/공공부문 근로자를 81만 명을 채용해서 지금 9급 공무원 수준의 월급/연금을 제공하면 대략 4인 가정이 300만 원 정도의 세금을 매년 더 부담한다. 절반 정도의 근로자만 소득세를 내는 것을 고려하면 그보다 훨씬 부담액은 늘어날 것이다.\n",
      "1. 나는 개인주의자라서, 각자 할 일을 열심히 하는 것으로 세상은 나름 좋아진다고 생각한다. 오지랖 떨지 말고, 피해 주지 말고, 사기 치지 말고. 하지만 세상은 나의 일만으로 굴러가지 않는다. 아무리 중요한 일을 하는 것 같아도,\n",
      "1. 누구 오는지 아직 모름. 근데 올 수도 있다면서 인기투표 진행함.->인기투표에서 표 많이 받은 사람들이 8월에 스케줄 있음. 2.1인10매->플미충들 날뛸 것 같은데.? 그리고 본인확인 필요해서 신분증 지참해야 한다는데 1인 10매.?\n",
      "1. 닭 다리 칼집 내서 차가운 물에 소금 한 움큼 빻은 마늘 풀어 염 지하기 2. 고구마전분 튀김가루 1:1봉투에 넣고 염지한 닭다리 넣어 골고루 가루 옷 입히기 3. 팬에 닭다리 반쯤 잠길 만큼만 기름 붓고 두 번 바삭 튀기기 4. 마늘간장 강정소스와 허니버터 시즈닝 입히기 \n",
      "1. 딸이 외할머니에게 8억 정도 건물상 속 2. 상속세 낼 돈이 당연 없음 부모로부터 빌려서 상속세 납부 3. 그냥 부모 돈으로 세금 내면 증여세나 상속세 발생 4. 빌린 후 상속받은 건물 임대료로 부채를 갚는 방식 선택 5. 법적 문제없고 국세청에서도 권하는 절세방법\n",
      "1. 바른 정당도 용납 못하면서 무슨 중도는 개뿔;; 503호 탄핵에 동참했고, 그리고 솔까 바른 정당과 대한 당 복당이(쿨럭;가 안도 왔음 탄핵도 안됐음. 여당 의원 기득권 버리고 탈당했고, 복당이가 헛짓 할 때도 남은 게 바당인데 여기에 무슨 영패는 또\n",
      "1. 수작 연어 500g에 22,800(택배비 별도 내가 사 먹어본 곳 중 제일 비싸지만 비싼 값을 한다 기름이 많지 않다 살도 무르지 않고 탱탱해서 씹는 맛이 있다 어울리는 술은 청하 \n",
      "1. 스타패스 티켓 수량 모름 2. 표일 인당 최대 10매? 플미충들 날뛰는 게 보인다 3. 인기투표 탑 4에 있는 사람 중 8월에 스케줄 있는 사람도 있다고 예매해도 못해도 답답한 코믹콘\n",
      "1. 약속이 생겨서 양도합니다 알티 팔로워 충 2. 여행 가서 양도합니다 충 3. 플미충 4. 알티팔로우제시충\n",
      "1. 월세 세액공제 여부. 여러 조건이 있지만 연말에 세금을 돌려받을 수 있는 법률 조항이 있다. 지금 사는 집은 집주인이 원치 않았기 때문에 시세보다 저렴한 대신 세액공제는 안된다는 계약 조항이 있음. 참고 링크 \n",
      "1. 전세금 1억을 예금해 두었는데 금리가 5%에서 2.5%가 되어 이자는 500만 원에서 250만 원이 되었다. 같은 이자를 받으려면 전세금을 두 배로 올려야 하는데 전세 인상은 5%로 제한되어 있고 의무 한 세계 약은 4년이다. 당신이라면 무엇을 하겠는가?\n",
      "1. 참 사소한 것에 울고 웃고 삐지고 화나고 슬프고 짜증 나고 즐겁고. 그런다. 2. reset. 다시 맞추다. 다시 제자리에 넣다. 늘 며칠 새 초기화가 되어버린 느낌. 3. 잠이 안 오는 뮤비 증후군. 4. 모르고 싶은 모닝콜 알람 기능. 5. 멍의 늪=오지랖\n",
      "1. 제 걱정이 오지랖이 될까 가끔 무섭네요. 8ㅂ8. 트친 분들 중에 혹시 그렇게 느끼신 분들 죄송해요. ㅠ 2. 앓는 것도 몸이 아프면 힘들다는 생각. 흠. 짝사랑은 힘든 거죠 8ㅂ8 \n",
      "1.8일 온라인 패러디 최우수작 \n",
      "1.mb 정권의 범죄사실이 낱낱이 알려지는 것도 처음이자 마지막 2. 티끌도 없는 문재인이란 정치인이 대통령이 된 것도 처음이자 마지막과 정권이 결탁해 국민 세금을 갈취한 증거를 확실하게 잡아낸 것도 처음이자 마지막 대한민국의 현재는 하늘이 준 처음이자 마지막 기회다\n",
      "100억짜리 페미니즘 케이블 채널<이렇게 쓰니 진짜 대단한 것 같네. 이렇게 쓰면서 막 옛날에는 그랬는데 지금은 그런 거 없잖아 엉엉하며 한을 키우는 게 뭔 득이 되지요?\n",
      "106. 오지랖(o, 오지랖(x.\n",
      "1073일! 세월호특조위 구성에 공안검사 출신 추천해 방해하고,특조위 활동을 세금 도둑이라고 비난하고, 특조 위각 국회에 요청한 특검 안도 x 무시하는. 이 모든 것이 박통이 서릿발 같을 때 벌어진 일. 그의 7시간과 함께 진상을 규명하여 책임을 더해야 한다.\n",
      "10년간 옷 만들면서 보니까 저 사이즈가 평균으로 나와요. 신장은 158.163. 등길이는 34.37. 팔 둘레는 25.27. 가슴 엉덩이 팔은 제일 두꺼운 부분, 허리는 제일 얇은 부분 잽시다. 허리 사이즈라고 골반 청바지 사이즈 주면 개빡침\n",
      "10시쯤 양도 글 올릴게요. 원가 양도 고요 취소표 돌리네 마네 하지 마요 짜리 내가 취소표 돌려도 플미충넘쳐 10시에 글 올리면 선착순 1명 쿨하게 넘길게요 4층이고요 디엠 하지 마요! \n",
      "1-1. 작중 등장하는 인물들은-계속 어리다, 어리다 불리는 모모 쪽은 넘어간다 쳐도- 이와야 쪽 사람들은 이미 아이가 있거나 결혼을 생각하고 있을 정도로 상당히 나이가 있는데도 불구하고 여주의 친구인 유리를 제외하면 하나같이 나잇값을 하는 사람들이 없다. 자기가 하면 로맨스, 남이 하면 불륜 ㅡ.ㅡ\n",
      "11/24 화 아트 나인 상영 시간표 <0관> 부에나 비스타 소셜 클럽 9:20 프리덤 11:30 이터널 선샤인 13:30 15:40 17:50 [시네프랑스] 위선적 영웅 20:00 에이미 22:10[late show]\n",
      "11만 개의 일자리를 만드는 추경! 우리 가족을 지키고, 세금을 더 걷지 않는 추경! 생색내기 대규모 soc 사업 없는 추경! 나랏빚 안내는 추경! 내 삶을 바꾸는 일자리 추경, 국민과 함께하겠습니다. \n",
      "11시 50분 청와대입니다 출근하면서 보는데 고민정 부대변인 책상 보고 울컥ㅠ 뜯겨지고 때묻은 벽지에, 의자엔 농락 박스테이프ㅠ 청와대 대변인실이 평범한 내 삼실보다 한참 못해ㅠ 청와대 돈 더 써도 돼요, 그러라고 세금 내는 건데 전혀 개의치 않는 고민정 부대 멋짐 \n",
      "11호는 아재 트럭은 할배 온 작전은 틀딱 미드웨이는 조선시대 사람 색 적기는 원시인 부강 아는 오스트랄로피테쿠스 ibs는 공룡 남방해역 강습 정찰은 스트로마톨라이트\n",
      "120123 김포 지디 gd . 하아. 이거 하느라 버벅대는 컴퓨터를 붙들고 생쇼! 그래도 원하는 분위기가 나와서 다해유ㅠㅠ \n",
      "120년 시차로 맞은 갑오년, 나라꼴과 주변 정세가 예사롭지 않지만 결국은 타락?위선의 위정자가 아니라 참됨?진정의 민초들이 혼돈과 위기에 맞서 싸우며 헤쳐나갈 것이다. \n",
      "125 급에서는 울프나 cg로 가시는 게 가장 안전합니다 ㅎㅎ 이건 오지랖이지만. 타이어 바꾸시는 과정에서 혹여나 앞뒤 휀더를 떼는 결정은 되도록 않으시는 게 좋습니다- 휀더가 없으면 예쁘긴 하지만 굉장히 괴로워지더라고요\n",
      "12월 24일 크리스마스이브에 서울시청 광장에 모인 4,900만 애국보수들의 탄핵무효, 헌법수호, 종북척결 집회 영상입니다. 촛불들은 거짓과 위선 가득한 종편들이 아무리 허위로 감싸주어도 진실을 속이거나 감출 수 없습니다. 진실은 승리합니다. 애국보수 파이팅! \n",
      "12월 30일 경향신문 1면입니다 - 헌법 수호자 촛불시민들 - 내년 경기부양 위해 21조 원 더 푼다. 결혼 땐 최고 100만 원 세금 돌려받아 \n",
      "12월 31일 지양하시는 분들과 한남 부대찌개에서 정모 드레스코드는 해후에 코트/베이징 니트 건배사는 어디야? 88! or 좋으냐? 나도 좋다!\n",
      "12일 경기 15층 오른쪽 구역 연석 두 장을 좋은 스친 분께 양도해드려서 뿌듯한 날. 친구분이랑 재밌게 보고 오세요!! 다음에 또 플미충들 보이면 아예 티켓 무료 나눔 할게요. 뭐 그런다고 없어질 것 같진 않다만. 내 계정 티켓 두 장의 권리는 이행하겠음\n",
      "1-3. 이는 살인을 조정하기에 유해하듯이 프레임이 씌워질 것이다. 한국 사회가 어떤 사회인가, 이유 없이 오지랖이 넓고 참견이 심해 법적 성년이 아닌 존재들에게 조금이라도 유해하다고 판단이 되면 강압적으로 막아버리고 존재 자체를 없애버리려는 굉장히\n",
      "130620 아웃도어 생쇼 - 유노윤호 편 \n",
      "13월의 보너스 챙기자…연말정산 서비스 오늘 시작 \n",
      "13일 마스터 4층 양도해요 원가 양도 고요 티켓은 재배송할 예정입니다. 대신 티켓 다시 돌려주시고 아미 부스 포커 주실 수 있으신 분이었으면 좋겠어요 티켓값 62500원이고요 플미충들이 가져가는 거 싫어서 최소한의 아미 인증만 받을게요 공식 인증은 꼭 해주세요 \n",
      "14 김이 그는 자신이 이런 오지랖이 넓었다고 함. 윰댕은 김이 그가 오지랖 넓어서 했던 말들이 상처가 되었던 것이고 그게 아까 말했듯이 아직도 응어리였던 것인 듯. 그래서 둘이 그냥 서운했던 거 얘기하고 연락을 안 하고 있는데 1과 같은 어 그로 들 이 생겨서 이 사달이 난 듯.\n",
      "145일째, 검사 87명 매달린 적폐 수사… mb 조사가 관건 mb ·朴 정부 때 사건 19건… 논란이 나올 수밖에 없는 진행 과정 이 19건에 검사가 87명이 매달렸는데 나온 것은 개뿔도 없다 이명박 조사한다더니 이명박이 노무현 적패를 까발린다니 도망갔다 아무리 표적조사해도 나오는 건 없다 문재인 떨고 있니 \n",
      "14년을 함께 지낸 늙은 개, 삐삐. 이제는 보내주어야 할 때가 온 듯하다. 친구이며 가족이었던 녀석인데. 가슴이 아프다.\n",
      "14차로 토르 3 라그나로크 막차 완료 ?(?????. ?????? 슬슬 내리는 것 같아 아쉽다 솔직히 10번 넘게 보니 조금 질리긴 개뿔 매일 새로워 오늘도 뽕차서 앞 좌석 뽑고 옴 \n",
      "15. 이런 식이면 누가 앞으로 미디어스에 제보하겠냐는 소리는 접어두자. 왜 미디어스가 걱정할 일을 오지랖 넓게 제3자가 걱정해. 장사 전망 걱정은 언론사 내부인들의 몫으로 둬도 된다. 독자의 몫은 보도에 윤리적 문제가 있는지를 따지는 것이다.\n",
      "15. 자기가 좋아하는 걸 일방적으로 상대에게 주고선 왜 기뻐하지 않냐며 서운해하는 타입(전 남자친구가 이런 인간이었는데 두 번 다시 만나고 싶지 않음 16. 생활방식이나 직업에 대한 오지랖(예: 왜 그렇게 돈 안되는 일을 해요? 17. 여성성의 강요\n",
      "150222 0시 퍼로 비디오 10시 티저 1시 하메리 2시 태양의 후예 3시.9시 멤버들 출근 퇴근 멤버들 인스타 쫑트 찡 스타 카스타 태민 쇼메 플미충들 제거 10시.2시 각종 떡밥 보라 쫑탬 음원 뮤비 공개 사월 들 오늘 하루 수고 많으셨습니다 \n",
      "150327 정글의 법칙 형식쓰 프롤로그 ts 오지랖 넓은 수니의 자근 기차입니다. 프롤로그는 사랑이니까 여. 퍼플님 받아주에 떼.-. \n",
      "150626 종로 파고다 쌤통 특강 프리뷰\n",
      "150626 종로 파고다 쌤통 특강 프리뷰 나쁜 댓글은 다 무시해버리고 오빠 응원하는 마음들만 봐요 장 오빠 많이 응원해 주세요!!! 인스타에 나쁜 댓글 다는 사람들 꿈에서 코털 다 뽑아버릴 거야 \n",
      "151230 가요대축제 ( 오빠가 내년에 제복 입으면 법에 걸리는 거 알고 내년 이틀 전에 제복을 입어줬는ㄷㅔ 조명이 오지랖 쩔면 어쩌자는 건지 나는 우울해 돌아가실 것 \n",
      "15억 짜리 로또가 당첨돼 어 세금 떼면 10억 받음. 이걸 20년 동안 매주 당첨되면 1조가 됩니다.\n",
      "15일에 취소표 왕창 풀리고, 티켓 배송 후 원가 양도 티켓 쏟아져서 플미충들 다 쪽박 차길\n",
      "15표 플미충 신고 이 제 제왑에 메일 보내야겠네. \n",
      "16 marzan이라고 연남동 낙랑파라 근처에 있어요. 깨끗하고 음식 맛도 좋고 서비스가 정형화되어 있고, 계산하면서 우리끼리 커피 어디서 마시지? 했는데 주인 되시는 분이 친절하지만 오지랖은 제거된 톤으로 알려주셨어요\n",
      "16.06.28 잘생긴 오지랖 | blue \n",
      "160617 에드거 앨런 포 윤형렬 그리스월드 / 와. 소문 장면에서 미간 찌푸리며 한없이 안타까운척하다가도 눈썹 한쪽 치켜뜨며 야비한 표정으로 입을 다 무는데 그 전환이 너무 좋았음. 위선과 야비함. \n",
      "160617 에드거 앨런 포/ 윤형렬 위선과 야비함을 동시에 지닌 곰이 그리. 아까 걸 말했더니 그게 보이는군요! 하고 좋아하시는데 (맞나? 네 그거 보려 전진합니다. 오늘도 티켓 찾는 하이에나 극한 직업 무덕. \n",
      "16-1 그래 시대가 시대려니 하고 빻은 부분들이 불편해도 넘기는 편인데 그때마다 웬디가 나타나서 다 박살을 냄. 최고 됐던 장면 중 하나는 새 요원 후보 면접 때 후보자가 너무 자연스럽게 예스 맴 하니까 닥터 카라고 정정하라는 장면이다. \n",
      "161015 mc 분 안 부럽다 안 부럽다 안 부럽다는 개뿔 부러워 으앙 \n",
      "16년 5월, 올해 봄의 개밥 남 문득 그때의 흑발 더기가 보고 싶어져서 찾아봤던 영상에서 반려 견+토니 덕기의 케미에 치여 급 필받아서 완성. 늘 의욕만 앞선다ㅠㅠ 염창동 멍멍이들 안부까지 궁금해하는 오지랖 부리는 중. 흥해라 티엔. \n",
      "16세면 합의하에 성관계도 되는데 애 낳는 것만 안 된다는 식으로, 19살에 군대?결혼도 가고, 세금도 내고, 할 건 다하면서, (지가 세금 낸 걸 쓰는 공직자 선거권만 없다는 게 말이 되냐? 어떻게 개헌에, 임기 단축에 별 아기 다 나오면서, 선거연령 낮추는 아기는 없냐?\n",
      "170114 골든디스크 찬열이가 황제님이라면 내 세금을 가져가도 돼 t.t \n",
      "170526 여의도팬싸 최승철한테 세금 낼래 \n",
      "170618 유리병 편지 후기 아내분께 바라는 점 없냐니까 남편분이 우리 이제 애 가지자 하셔 가지고 종현 눈 뚱그렇게돼서 허허 참.! 제 노래 많이 들으시면서. 무드 잘 잡으시길. 제 노래 그런 분위기의 노래 많으니까요. 수작송.ㅎㅅㅎ \n",
      "170714 리를 잭 ㅌ 그리고 이건. 경재에게 줬던 내 선물. - 설렘. 진짜 오랜만에 만나는 경재에 대한 맘을 대신했달까??? (.는 개뿔.!! 그냥 이뻐서 산거.!  - 사진 제공해주신 ㅁㅈ언니 감사. \n",
      "170722 lw 루나님 방송 중 새 별비님 야누스님 마이크에 별비님 목소리가 들림 루: 야 종렬아 좀 조용히 해봐 네 목소리 게 커 새: 미안해 경호야 (루-로 시 사망 새: 쌤통이다 \n",
      "170905 퍼펙트 부르는 퍼펙트 한 윤형이 (ft. 빻은 조명,, \n",
      "170915 <여배우는 오늘도> gv 00:31 (빻진행자가 훈수 두니까 전도연 님이 왜 저한테 이래라저래라 하세요?(쨕쨕쨕 자기가 뭔데 크자. 전도연 배우님 멋져 \n",
      "170930 kmf 생각보다 여의도가 안 밀립니다 내 세금이 터지기 전에 지나간다 ㅠ \n",
      "171021 사이퍼즈 - 카미유 데샹 (cyphers - camille deschamps code : hypocrisy (위선자 cos. pb. 유충이다. \n",
      "171111 몽타주 한남팬싸 진짜 이쁘다 우리 오빠 \n",
      "171118 분당 팬사인회 - 오빠 이번에 우리 티켓팅 선예매 아예 없어요? t : 아직 얘기를 못 들었어요. (대리 티켓팅, 플미충이 벌써 노리고 있더라.%*$ t : 아. 진짜여? - 네 그런 거 올라왔다는 얘기가 있더라고요. t : 그럼 안되는데. 알아볼게요! - 감사합니다! t : 잘 가요.\n",
      "171230 kbs 무대 <50분> 2017 kbs 라디오 극본 최우수작 \n",
      "17년 상반기 주간 슈지 《막차 갔어》로 참여합니다. 절대 수작 부리는 거 아님-上 \n",
      "17세 남학생의 전 여자친구 살해에 상사병이라는 핑계를 대는 것은 정말 역겹다: 상사병이 아니다. 위험한 살인범이다. 우리는 남성의 분노와 여성의 죽음이 관련 있다는 것을 다 같이, 어쩌면 의도적으로 모른 척한다. \n",
      "17세기 프랑스의 귀족 문인이었던 프랑수아 드 라 로쉬 푸코는 위선은 악덕이 미덕에 바치는 경의다 lhypocrisie est un hommage que le vice rend a la veu.라는 잠언을 남겼다. 참 울림 있는 말이다.\n",
      "180112 리몽타주 한남 북파크 팬사인회 아고 눈아팟! >.< 아아. 오빠는 눈 아파서 깜! 빡! 하는 건데 그것마저 이렇게 귀여우면 어떡하면 좋지 ㅠㅠㅠㅠ 오빠 이 사진이랑 예감 사라는 별명이랑 너무 잘어울려요ㅠㅠㅠㅠ \n",
      "180112 리몽타주 한남팬싸 \n",
      "180112 리몽타주 한남팬싸 아. 배고파.(먹으면서  오빠도 벌들이도 맛있는 거 먹자\n",
      "180112 한남 북파크 보고 싶고 보고 싶고 보고 싶다. \n",
      "180112 한남팬싸 뽀또랑 투숏 찍고 싶던 태이리 귀여워 \n",
      "180123 콘서트 부분 최우수작 수상 축하해♡ 멋져멋져♡ \n",
      "180211 세븐틴 gv 지금 널 찾아가고 있어(가이드 ver. 호시 focus 따라 부르다가 마지막에 빻!하는 거 너무 귀엽지ㅠㅠ 가이드 버전 엄청 좋아하는 순영이ㅠㅠㅠㅠ 풀 버전( 1:46 은 유튜브에서 봐주세요! 유튜브 full: \n",
      "180218 플미충 제에 충 사연 중 알티충 모두 가만두지 않겟닷!! \n",
      "180309 한남대학교 우원재 올린 원재가 많지만 일단 예쁜 거부터 올리고 본다 . \n",
      "180309 한남대학교 프리뷰 \n",
      "180309한남대 목젖 ㅎ ㅏ,,,, 진짜 대박이다 머리 많이 길렀다 \n",
      "180311 nodaehun ig 슈퍼주니어 이특 님과. 그란투리스모. 마세라티 한남 전시장. 예의도 바르시고 실물도 더 멋짐. \n",
      "180321 johnny’s live collection 2017 발매 발표 발매일: 2018년 4월 6일 (금 가격: 3200엔(세금 포함 사양: a4 사이즈/ 본문 160페이지/ 상제본上製本 “쟈니즈 올스타 첫 라이브 사진집” arashi live tour 2017-2018 untitled 포함 \n",
      "180331 미니 팬미팅 천천히 쉬어가긴 개뿔이!!!!!!!! 쉬지않는예뿜 ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ \n",
      "180413 역시 이불 박은 힐링 흑머녤 못 봐서 슬펐던 것도 기억 안 나(긴 개뿔. 잊지 않을 거다 ㅠㅠ 너는 참 단단한 말만 하는 아이 말하는 대로 모두 이루어졌으면 좋겠다 오늘도 난 너의 팬이라 참 좋았다!! \n",
      "1880년대 개항장 객주 중에는, 세금 내기 싫어 기독교에 입교한 사람이 꽤 있었습니다. 기독교인이 되면 외국인처럼 치외법권의 대상이 될 줄로 안 거죠. 21세기인데, 지금도 19세기 개항장 객주와 같은 생각을 가진 사람이 많은 듯합니다.\n",
      "18대 대선에 박근혜 후보를 찍지 않았지만 추악한 사생활, 外道, 위선, 거짓말, 광신적 성역화, 뇌물, 패거리 정치와 가장 거리가 먼 전직 대통령은 박근혜 같다.\n",
      "18세 선거권 논의가 뜨거운 가운데, 어떤 사람들은 의무를 이행해야만 선거할 권리를 가질 수 있다고 말합니다. 과연 그럴까요? 세금과 군대, 선거권의 조건이 아닙니다 >> \n",
      "18세 선거권 적극 찬성합니다. 결혼도 할 수 있고 세금도 낼 수 있고 사업도 할 수 있고 군대도 갈 수 있는데 왜 투표만? 요즘 젊은이들은 더 영민합니다 또 영민하지 않다고 해도 그들의 권리입니다 다 떠나서 이젠 청년들에게 그 참정권을 보장할 때가 되었습니다 \n",
      "18일부터 취소표 수수료 붙으니까 입금해놓고 거래 못한 플미충들 17일쯤에 대거 취소할 거 같기도 하고요\n",
      "18학년도 수시 1차, 이미지 보드 전형만 실시된 것에 당황하셨던 분들 많으시죠?! 실기 우수작과 교수님들의 심사평을 공개합니다! 19학년도 수시 실기도 동일하게 진행될 예정이며, 입시생 여러분들에게 좋은 정보가 되기를 바랍니다 아래 링크에서 확인해보실 수 있어요! \n",
      "191. 환생 : 기억상실증에 걸린 여자에게 최면을 걸자 40년 전의 살인사건을 기억해내고 전생과 현생이 교차합니다. 케네스 브레너가 실제 아내였던 에마 톰슨과 열연, 연출한 미스터리 멜로극으로 히치콕 터치가 매력적인 수작. \n",
      "1948년 오늘-도쿄재판, 일본 전범 7인에게 사형을 선고하다 “이 재판은 역사상 최악의 위선이다.” \n",
      "고맙습니다? 국부는 개뿔 매국노!\n",
      "1967년 몬트리올 만국박람회 한국관. 김수근 설계. 면적은 132평으로 이후의 한국관과 비교해 보면 작은 규모이나 전통 건축의 특징을 잘 살린 수작이다. 현존하나 관리 부실로 오랜 기간 폐허나 다름없었다. 다행히도 올해 5월을 목표로 복원 예정. \n",
      "1980.5.18일자 경향신문도 이날 선동?권모술수로 얼룩진 위선의 화신 김대중을 벗긴다는 제목과 공판 과정에서 드러난 출생시 친북 괴 활동까지란 제목을 단 특집기사로 김대중 신상을 털었다\n",
      "1987년 경찰에 의해 불법 연행되어 수사 과정에 물고문으로 세상 떠난 대학생 보라, 박종철의 처참한 시신을.! 위선자 박상옥이 대법관 임명되면 정권도 스스로 독재정 부임을 고백한 것이나 다름없다. \n",
      "1987년 벌써 30여 년이 흐른 6.10 민주화 항쟁 당시 87년 6월 10일 당일에만 3831명이 연행됐고 이후 17일간 2145회 시위, 경찰이 쏜 최루탄은 무려 35만 발, 전두환의 악랄함은 끝이 없었습니다. 행동하지 않는 양심은 위선이다. 행동하지 않는 양심은 불의이다. -고 이한열 열사의 유작시 중에서- \n",
      "1991년 10월 총선을 코앞에 두고 주간조선 우종창 기자는 노무현 호화 요트 기사로 대박을 쳤다. 노무현은 위선자로 몰렸고 낙선했다. 나중에 알고 보니 호화 요트라는 건 두 사람이 겨우 앉을 구명보트 같은 것에 돛 하나 꼽아놓은 거였다.\n",
      "19세기 러시아의 대문호 레프 톨스토이의 『안 나 카레니나』는 위선, 질투, 신념, 욕망, 사랑 등 인간의 감정과 결혼, 계급, 종교 등 인간이 만들어 낸 사회 구조에 대한 톨스토이의 모든 고민이 집약된 소설입니다.\n",
      "19세기 미국 저널리즘의 시작은 말 그대로 내가 보고 느낀 것에 대한 저널. 20세기 팩트 절대주의도 백 년을 구가하지 못한다. 21세기 우린 다양한 나의 수많은 관점으로 사실을 넘어 진실에 다가서는 디지털저널의 시대에 섰다. 위선적 팩트 주의자의 기댄 거했다\n",
      "1년 71억의 세금이 청계천에 들어간다 \n",
      "1년에 320억 원에 이르는 국회의원 관련 예산은 모두 국민의 세금에서 나옵니다. 하지만 국회는 납득할만한 설명 없이, 예산 사용 내역을 공개하지 않고 있습니다. 뉴스타파와 함께 국회를 상대로 정보공개 소송을 진행하고 있는 하승수 변호사의 기고문입니다. \n",
      "1년에 3억, 모두 합쳐 10억 넘는 세금이 구청 공무원 1천2백여 명의 개인 휴대폰 요금으로 나가 강남구청 측은 안전, 청소, 교통민원 등을 언제 어디서나 처리하고 있어 개인 핸드폰 요금을 지원했다고 설명 \n",
      "1년에 생활비로만 5억 원씩 쓰는 사람이, 급여와 업무추진비 외에, 매달 국민 세금에서 불법으로 빼돌린 돈 500만 원씩을 더 받았답니다. 이런 인간이 있는 걸 보면, 삶아 죽이는 형벌인 팽형을 고안해 낸 옛사람들의 마음을 이해할 수 있습니다.\n",
      "1만 유로 만 들어와도 수사; 한국에서 독일로는 위장 무역거래로 돈을 보냄. 그리고 독일에 돈 세탁이 가능한 게 회사 설립시 입금하는 자본금은 출처를 조사하지 않아요. 회사가 많이 설립될수록 기본적으로 세금을 더 거두니까. 그래서 독일에서 돈 세탁이 횡행.\n",
      "1살 아기에게 50억을 증여하고 증여세 20억을 낸 후, 30억을 굴려줘서, 25살이 될 때, 3000억을 만들어 줘도 추가적인 증여 상속세가 없습니다. 증여받은 사람이 돈을 불린 실력이 아님으로, 이런 경우 1200억을 세금 물리도록 법 개정해야 합니다.\n",
      "1시간에 7명. 40억짜리 썰렁한 mb 마을 10억 또 투자하겠다고? 포항시, 전시관 콘텐츠 설치 계획 발표. 사업 타당성 논란 세금으로 쓸데없는 짓 하네 에라 포항시야\n",
      "1억 논두렁 시계 심리학자까지 동원해 1억 시계 이란 단어로 친서민을 박살 내고 논 두렁이란 단어는 천박한 이미지로 만들어 국정원이 개입해 검찰 발인 것처럼 신뢰를 올려 언론을 통해 대대적으로 홍보했음. 모두가 공범이었고 역겨운 일에 내 세금이. 또 당하지 맙시다\n",
      "1월 23일 뉴스타파 중국 프로젝트 이틀째 보도, 시진핑의 개혁은 위선? 언론부터 막았다 1. 석유 방도 무더기 유령회사 중국, icij ·뉴스타파 웹사이트 차단 \n",
      "1위 쌤통이닼  올레 랭킹 관련 공지드립니다. 매월 1위에게 아이폰을 드리려고 했으나 여러 사정으로 인해 쇼옴니아폰으로 교체가 될 예정입니다. 양해 부탁드립니다.\n",
      "1인 가구가 세금은 가장 많이 내고 혜택은 가장 적은 것으로 나타났다. \n",
      "1인 예매시 제한되는 자리 생기는 것도 개빡침\n",
      "1인칭처럼 전개되던 며느라기는 가부장제 안의 또 다른 여자들의 시점을 제공한다. 오지랖을 사전 차단하는 형님(이 명칭 진짜 이상한 듯, 시아버지를 챙기기만 해야 하는 시어머니, 본인의 시댁에 가고 싶어 하지 않는 시동생. 민가린에게는 가해자가 되지만 동시에 피해자가 되는 여자들.\n",
      "1조 세금 내겠다. 현대차 정몽구 부자의 정공법 (출처 : 오마이뉴스 | 네이버 뉴스 [분석] 현대차그룹 지배 구조 개편안을 뜯어보니. 김상조 공정위원장 긍정적으로 평가\n",
      "1조 세금 내겠다. 현대차 정의선 승계 정공법 김종철 기자\n",
      "1조 손실 mb 자원외교. 2조 원대 묻지 마 증자 추진 세금 2조 투자. 2000억 원 회수 “중단 땐 투자금 회수 불능” 실토 2조 자본 광물公, 4조 채권 발행\n",
      "1조. 솔직히 삼성 싫어하는 나에겐 쌤통브라보콘이긴 한데, 1조 날렸다고 여기저기서 패악질 부리고 애국 드립치고 국민들 힘들게 할 걸 생각하니 그것도 매우 피곤할 것 같은 걱정이 든다…\n",
      "1화부터 화끈하게 동인 저격한 꼬락서니 보니 참 기가 막히죠 단순하게 인기 있었다는 걸 어필하고 싶었다면 평균적인 사람들을 그렸겠지 왜 마츠 후드 입은 여자들을 그렸을까욥\n",
      "1회부터 전 작품 섭렵해 온 eidf(ebs 국제다큐영화제가 18일부터 25일까지 열린다. 이번 10회에는 어떤 작품들로 세상 곳곳을 비출지 기대만발. 다큐 광인사 세상사에 오지랖 넓은 분들은 놓치지 마시라. \n",
      "2 토론 관전평: 선거 유불리로만 보자면 오늘 이정희 역할은 박근혜의 거짓말과 위선 드러내 야권 및 중도층에게 어필했을 수. 하지만 박근혜 지나치게 공박하는 느낌 줘 보수 결집 요인 됐을 수도. 일단은 전자 효과가 컸을 것으로 기대\n",
      "2. 랩 슈 (빻은 것들끼리 가지가지 한대요 \n",
      "2. 수석도 22일째 (기자들에게 브리핑을 하고 질의응답을 하는 춘추관에 나타나지 않고 있다. 소통은 개뿔ㅎㅎㅎ 웨스트윙 코스프레하며 이벤트 할 때는 좋았쥬? 임종석과 조현옥 찾아유. 끝.\n",
      "2. 이곳저곳을 바라보며 한 곳에 시선을 두지 않는다 관찰력이 상당히 뛰어난 타입. 주변 상황을 살펴보기 좋아한다. 어떻게 보면 오지랖 또한 넓은 편. 하지만 은근 조심스러운 부분도 많아서 일을 하기 전엔 계획을 세우는 경우도 많다.\n",
      "2. 장병들의 몸과 영혼을 위한 최소한의 배려. 보상임 이는 의학 심리학 군사학적으로 접근해여할. 집단 증후군의 가능성이 있음 나머지는 할 일 없이 궤변 하는 군에서 세금으로 전문가 위촉해서 tf 구성해서 해야 할 일. 돕는 것도 힘들구나! 오지랖!\n",
      "2. 재정적자에 대해서 예민하지만 재정적자 증가를 막기는 거의 불가능하다. 빨리 현실을 직시하고 재정지출을 효율적으로 늘려서 궁극적으로 재정적자를 줄이겠다는 발상을 해야 한다. 세금 인상은 정치적 경제적으로 할 구석이 별로 없고 돈 쓸 곳은 많다.\n",
      "2. 허브 숙성 연어 500g에 17,200(택배비 별도 가격은 세 개중에 가장 싸다 돈은 조금 휘달리는데 연어가 먹고 싶을 때 추천 살이 무르지 않고 탱탱하다 수작 연어보다는 기름이 많고 약간 비렸다 어울리는 술은 매화수 \n",
      "2.0은 오지랖을 넓히는 것(engagment입니다. 기존에 관여 안 하던 일까지 관여하면서, 의견도 내고 논평도 하다 보면 상호학습도 강화되고, 그 안에서 제품/협력자/고객/직원/회원 등에 대하 이해/니즈 파악이 쉬워지죠.\n",
      "2.5d 파면서 어느 정도 각오해야 하는 게 온전히 캐릭터만 판다면 그게 최고 좋겠지만 만일 본체까지 파게 되었다면 그 인간이 입 밖으로 내뱉은 빻은 말과 빻은 행동 때문에 멘틀 작살나기 전에 서둘러 본체와 캐릭터를 분리할 수 있는 능력을 키워야 덜 고통스러움 백인 남자 시스 헤테로 면 더 주의해야 함\n",
      "20%를 늘릴 수도 줄일 수도 있다면, 여러분은 무엇을 늘리고, 무엇을 줄이고 싶으세요? 뱃살과 오지랖은 줄이고, 하루의 시간과 머리카락은 늘리고? 세브란스병원 보험 심사팀의 스트레스 해소법\n",
      "20, 30대는 들으세요. 문재인의 경제정책은 당신들이 앞으로 낼 세금을 담보로 하는 겁니다. 반면 안철수 정책은 당신들이 부자 될 수 있는 가능성을 최대한 키워주는 정책입니다. 문재인 뽑는 것보다 안철수 뽑는 게 당신에게 10배는 이익이라는 것만 알아요.\n",
      "20. 프로오지랖퍼에요 막 어 다도 와주고 싶어 합니다 아! 고 나리는 안 해요\n",
      "2000억 이상 버는 재벌과 5억 이상 버는 사람들만이 더 내는 세금을 마치 국민 모두에게 부과하는 증세로 오해한다. 언론의 증세 강조는 무슨 저의인가.\n",
      "2003년 4월 김근태, 실명제가 욕설을 줄일 수는 있을 것이다. 그러나 금방 안티사이트 주민번호 추출기 유동 ip로 피해 갈 것. 규제는 규제의 틈을 막는 강력한 규제를 요구한다. 규제는 위선을 만들고 인터넷의 활력을 빼앗을 것이다.\n",
      "2003년 대구 유니버시아드 때 김정일이가 남한으로 내려보냈던 미녀 응원단 기억하죠. 김대중, 김정일이 가 나온 길거리 플래카드 보고 미녀 응원단이 울고불고 생쇼 했죠. 그리고 미녀 응원단은 북한으로 간 다음에 정치범 수용소로 끌려갔습니다. 정대세는 북괴의 선전도 구입니다.\n",
      "2003년 안티 오마이뉴스를 다 검색해볼 계획. 아직도 어설프게 현실에서 진보 보수라는 거짓 프레임에 놀아나시는 잠잖은 지지자들을 위해서. 진보의 노통 때리기는 십수 년이 지나도 같은 수작으로, 한경 오가 하고 있다. 조중동 버린 지는 오래다\n",
      "2005년도에 농민이 과잉진압으로 사망했군요! 위선자 문재인은 이 사실을 기억할까요?  과잉진압 농민 사망. 무한  부탁해요 ”\n",
      "2005년부터 수입을 현금이나 차명계좌로 받아 세금 탈루한 혐의로 검찰 고발된 인순이의 지금까지 알려진 탈루액은 60억 홍 후보가 30억 증여받고 10억 증여세 낸 건 국세청 공식 책자 절차를 따른 절세 야당이 주장하는 탈세는 인순이 같은 사람을 말하는 거 절세와 탈세 차이를 모르면 글자 공부를 해 \n",
      "2007년 노무현이 김대중 때와 같은 정상회담 성사를 대가로 우리 세금으로 북한 군사기지를 지어줄 것을 약속했다고 한다. 그리고 지금 그 정부의 민정수석이 대한민국의 대통령 자리를 넘보고 있다. 그 민정수석이 누군지 몰라도 북한이 조국이라 했다 \n",
      "2007년 이수만과 polex development limited. a hong kong corp. 가 40:60공동 소유 구매. 당시 융자 기록이 없는 걸로 봐선 $4,800,000현금으로 산 거 같고, 2011년에 s.m.innoviate amusement llc로 소유권이 넘어가고. 2017년에 5백만 불 융자 받은 거 같은데. 이수만 세금 제대로 냈나요?\n",
      "2008?삼성家의 증여세 탈루 적발.?삼성에버랜드 전환사채 저가 발행 사건으로?이건희 회장으로부터?이재용 상무이사로 지분 변경 중 편법 증여 발생.?목적은 세금 내기 싫어서. 수사 중 명의신탁계좌 수두룩 발견. 이재용의 불법재산증식. 1조 사재 출연 약속 거부 중.\n",
      "2008년 삼성특검 당시 밝혀지지 않은 비자금 4,000억 원 밝건- 세금 82억 원 포탈 경찰 이건희 회장과 사장급 임원 a 씨를 입건. 삼성의 불법 상속에 면죄부만 준 엉터리 삼성특검은 재수사해야 한다. 삼성장학생? 어떻게 삼성공화국을 만드는지 삼성 내부고발자 어디 없습니까? \n",
      "200만당원 10%만 서명해도 20만입니다. 현재 2만 육박합니다. 20만 넘어 쭉 갑시다. 국민 세금만 축내고 국익에 도움 되는 기사 안 쓰고 사고나 쳐서 나라 망신 시키고 특히 박근혜 국정 농단에 1급 부역했던 청와대 기자단과 해외순방 기자단 제도 폐지를 청원합시다. 국익에 도움 안 되는 것들은 필요 없습니다. \n",
      "2012년 뉴이스트 데뷔 초 시절 황민현이 나갔던 예능 ‘안아줘’의 민현이에 대한 만행 모음 (개빡침주의 타래로 계속 추가 \n",
      "2012년, 도둑맞은 대통령을 되찾기 위해 트워터 가입이 봇물을 이루었다. 안철수, 김한길, 박지원 같은 밥그릇들이 분열과 위선으로 민주당을 흔들 때 문재인은 당 대표가 되어 지금의 40프로 지지율로 끌어올렸다. 이젠 대선까지 트위터리안의 힘을 보여줄 차례다\n",
      "2014년 맨 부커상 수상작 『먼 북으로 가는 좁은 길』. 리처드 플래너건의 작품입니다. 맨 부커상 심사위원장에게 몇 해간 받은 작품 중 가장 걸작이라는 평을 받은 수작. 얼마나 매력적인지 마케터 분이 열변을 하셔서, 저도 얼른 읽고 싶은 마음에 책을 받자마자 올립니다. \n",
      "2015 멜론 뮤직어워드 투표 참여를 위하여 이렇게 하면 해외에 계신 분들이 조금이나마 공지를 쉽게 이해하시지 않을까 싶어. 오지랖을 조금 부려봤습니다 (melon music awards : mma \n",
      "2016 bts live 〈화양연화 on stage：epilogue 〉 이번 콘 플미충 정말 판치네요 ㄷㄷㄷ. 방탄 콘서트 첫 콘 스탠딩 b 구역 1000번대 원가 양도합니다. 알티 해주시면 내일 저녁 남준 시엠 한 분 뽑겠습니다 : 팔로× 가미한 정○\n",
      "20160908 호원대 수작 공연 지금 음악에 대한 순수한 열정도 팬들과 국민 프로듀서들까지 다들 알 거라고 생각해요. 좋겠네요 ㅠㅠ \n",
      "2016년 . 12월 . 21일. 팬미팅. 티켓팅 . 성공. 제발 . 소취 . 플미충 . 제발 오지 마. \n",
      "2016년의 재환 신의 목소리 설 파일럿 출연 호원대 실음과 입학 신의 목소리 정규 1회 출연 운전면허 취득 수작에서 skyfall 공연 퍼듀 참가신청 미팅(feat. 붐붐춤 2017 김광석 노래 부르기 신청(2017년 1월에 참가 수상 \n",
      "2017 청강대 애니메이션 스쿨 실기 우수작들을 공개합니다.0. 세상에나. 우수작인 이유가 있군요(끄덕 더 많은 우수작과 심사평까지 보고 싶으시다면 \n",
      "2017-04-01 세계선수권 남자 fs ㅣ은퇴 이야기가 들리는 미샤 지가 하얗게 불사른다. 점프에 한계가 있는 아티스트 유형의 선수가 어떻게든 3a 두개로 클린이 가능한 컨 시를 만들어내고 많은 수작을 남겼다. 만약 은퇴한다면 명예로운 은퇴 무대가 될 거다.\n",
      "2017년 2월 21일 현재 오후 여섯시 차트 상위 7곡 중에서 아이돌 곡이 총 몇 곡이냐 탁상공론만 처하지 말고 일이란 걸 해봐 \n",
      "2017년 올 한해 같이 지위, 위주, 외니, 청송이 앓던 많은 분들 내년에도 같이 덕진 해요! 내년에는 꼭 상은이 들 한국에서 볼 수 있길 내년에도 함께 빻아보아요 모두 계타는 한 해 보내시길 우리 함께 덕을 쌓아요 내년에도 건강하게 오래오래 상은이 들 덕 질하시길! 새해 복 많이 받으세요 \n",
      "2017년 정말 얼마 안 남았네요 제가 대입 직후 여태까지, 특히 최근 1년간은 힘들다 죽겠다 하는 소리만 한 오조오억 번 하고 있는 것 같은데 꿋꿋하게 남아주신 분들 다 감사드리고 제가 빻은 소리 하면 제 기분 생각 말고 꼭 지적 좀 해주시고요 더 나은 사람 되도록 노력하겠습니다\n",
      "2017년도 <온갖 무례와 오지랖을 뒤로하고 페미니스트로 살아가기> 힘드셨죠? 정말 고생하셨습니다. 연말을 맞이해 올해 여러분의 고군분투를 모아 모아 보려고 합니다. \n",
      "2017년의 어느 순간부터 그 배려가 오히려 서럽게 느껴지기 시작했다 이제 나는 아무리 빻은 질문이라도 좋으니 다 물어봐달라고 그렇게 안 다가오는 게 더 싫다고 솔직하게 말하고 다니기 시작했다\n",
      "2018 st ★ rlight fan meeting - 요코하마 공연 2018년 5월 2일(수 19:00 파시피코 요코하마 국립대홀 - 고베 공연 2018년 5월 4일(금 낮 공 15:30 / 밤 공 19:00 고베 국제회관 국제홀 좌석 지정 8,500엔 (세금 별도 fc 선행 3월 1일 12:00～3월 7일 23:59 모바일 선행 3월 15일 12:00～3월 21일 23:59\n",
      "2018. 01. 15 dear. alex 되는 대로 많은 편지를 지니고 다니고 싶어. 물론 내가 배급받을 군복 주머니가 널찍하다면 말이야. 프런트 라인에선 전투가 진행 중이라고 얼핏 들었어. 아버지한테 오지랖 넓게 네가 있는 하이랜더 소속 부대들은 어떻게 되는 거냐고 물었더니 괜히 의심만 하더라.\n",
      "2018/2/26 -오늘의 자적 자 판결 무당 남위 신내림 받기로 한 20대 남 때려죽여서 징역 8년 받음 -10대 한남 60대 할머니 숨소리 거슬리단 이유로 때려 사망케 함 징역 2년 6개월 선고(가벼운 정신장애가 있고 이를 반성하기 때문에 -11개월 아들을 때려죽인 30대 남 징역 12년 확정\n",
      "2018년 04월 15일에 삼성 특집이라고 제목을 단 이이제이 시즌 2가 팟캐에 올라옴. 하지만 앞의 한 시간은 권순욱 tmi 특집. 투친들 이랑 약속 지키려고 해내ㄸ r. 잘난 척과 문로남불 냄새가 넘나 짙게 나는 걸 어떻게 제대로 옮길까 싶지만 해본들 아.\n",
      "201n 년 1월 1일. 아는 사람도 없고, 또 누군가를 알아가기도 두려웠던- 그때의 제가 생각이 나서 그려보기로 한 연말맞이 오지랖 프로젝트랍니다. 어쩌면 저보다 더 잘 하고 있을 새싹들에게, 그래도 조금 덜 새싹이 해주고 싶은 이야기들을 해보려 해요. \n",
      "203구역  + 폴로 해서 ㅠㅠ 낼 뽑아요ㅠㅠㅜ 괜히 취소표 풀었다가 플미충이 가져갈까 봐 그런 거니 이해 부탁드려요ㅜㅠ\n",
      "20살 차이에 오빠라고 불러달라는 빻은 연예인 누구와는 다르게 11살 차이라고 삼촌이라고 하는 우리 섭이가 너무 자랑스러워 \n",
      "20세에서 45세 유권자들은 저 도표를 잘 보아야 한다. 당신들이 중장년이 되었을 때 각종 사회 보장 기금은 모두 고갈되고 사회안전망이 파탄 위기로 몰린다. 세금 올리자고? 그러면 경제가 급격히 추락할 것. 지금부터 정책적 대비해야 한다. 선거를 잘해야 \n",
      "21. 모르는 인간들이 너무 많아서 계속 강조 22. 은메달은 세계 2위 23. 아시아 최초 24. 빻은 소리 하는 인간들 경기장에 서면 기절 25. 선수들 그 부담감 이제는 내려놓길. 26. 팀 킴 정말 자랑스럽다 27. 팀 킴은 컬링 신 28. 이제 꽃길만 걸으세요 29. 길은 만들어드리겠습니다 30. 팀 킴 사랑해\n",
      "210. 새로운 살림 팁 떠오르거나 배우면 어서어서 트친님들께 전파하고 싶다. 오지랖 병. ㄲ ㅏ르르. 살림 익히는 시간은 최대한 단축하셔야 해요. 살림 말고 세상 신나는 일 정말 많으니까. \n",
      "21세기 형 오지랖 비밀번호는 3개월마다 한 번씩 변경해야 하고 숫자와 알파벳 대문자와 특수문자가 포함되어야 합니다\n",
      "21억 원 우리 세금 들여 만들었다 하는데 수년째 방치되어 있던 한옥마을을 전현희 의원이 활용방안 모색하고 lh에 수차례 요청한 끝에 주민 의견 듣고 어린이 도서관으로 최종 결정되었다고 오늘 축사에서 전현희 의원이 상세히 설명해줘서 축사 끝나고 주민들이 감사하다고 전현희 전현희 외쳤습니다\n",
      "222 : 식물이라면 아주 잘 돌본다. 275 : 없어서 삶의 꼬락서니가. 287 : 딱히 책에서 재미를 느끼진 않았을 듯\n",
      "28일 양도 구해요!!! 자리 상관없고요 플미충 안 받아요.! 멘션이나 디엠 주세요 ㅠㅠㅠㅠㅠ 제발 부탁드립니다 저희 딸내미 넘나 가고 싶다고 하네요. 3 \n",
      "2년 만에 불거진 검은 예산 특수활동비. 수술대 오를까 그렇게 쓰라고 낸 혈세가 아니다. 국민들이 낸 세금을 쌈지 돈 쓰듯이 써도 사용의 적정성을 감시하고 따질 수 없다는 것은 큰 문제가 아닐 수 없다.\n",
      "2박 3일간의 죽네 사네 장정 끝에 드디어 스케줄 정상화가 보입니다 오늘 저녁 외출 때는 옷을 다소간 신경 써서 입고 나갈 수 있으면 좋겠습니다 그럼 뭐가 되냐면 피로 토핑 광명 찾음 맨. 오늘 나갔다 와서 그나마 좀 일찍 자구 니얄부텀 사람 꼬락서니로 돌아가기로 합니다 슬슬 휴가 디데이 센다 힣히\n",
      "2번 유형들은 친밀한 관계를 위해 남들에게 무언가를 자꾸 베 푸려고 합니다. 합니다. 다소 부담스러울 정도의 오지랖을 자랑합니다. 호의가 거절당했을 때는 정색을 하고 모욕감을 느끼니 그냥 감사하게 받아주세요. 친근한 눈웃음이 트레이드 마크.\n",
      "2부 문제없다? 위선 김기식 문 정권의 「늪」이 되다 [사회 이슈] (2018.04.10 \n",
      "2부 문제없다? 위선 김기식 문 정권의 「늪」이 되다 [사회 이슈] (2018.04.10 님이 공유\n",
      "2억 줬더니 흡족해해 최순실 게이트 터져도 돈 챙겨 | 다음 뉴스 국정원에서 우리를 챙겨주는 거냐 이 워딩이 모든 걸 내포하고 있죠. 첫째, 국민들의 세금은 곧 짐의 돈이다.라는 의식수준과 둘째, 챙겨주는 것 즉 뇌물이란 인식을 하고도 받았다는 것.\n",
      "2일 콘인데 3층 30구역이라도 가실 분 있으시면 원가 양도해드릴게요ㅜㅜ! 플미충한테 티켓 가는 거 보기 싫어서 티켓팅했습니다. 혹시 필요하시면 멘션 주세요. 양도 \n",
      "3 당의 대선 공약에는 분명히 문재인 정부가 추경으로 증원하고자 하는 인력의 증원 공약이 담겨있습니다. 한데 증원하려니까 국민 세금으로는 안 된답니다. 3 당은 공무원 증원 공약, 세금 아닌 무슨 돈으로 하려고 하신 겁니까? 문재인 대통령이라서 반대입니까? \n",
      "③ 삼성 경영권 승계 때마다 에버랜드 땅값 요동. 2015년에도? / sbs 시간이 지나면서 서울랜드의 땅값은 급격히 올랐고, 한국민속촌도 꾸준하게 우상향 곡선을 그린 반면, 에버랜드 땅값은 이례적으로 폭락한 이후에 오름폭이 비정상적으로 낮게 유지…낮은 공시지가는 세금 혜택으로 이어져 \n",
      "3% 면 청소노동자 원내 진출 가능합니다. 그런데 사표 걱정하는 이들의 오지랖은 역할을 과대평가함으로써 실존을 과소평가하고 있지요. 정당투표는 16번 진보신당 모르면 한 밤중에 목이 말라 냉장고를 열었더니 등 뒤에 \n",
      "그러다 보니 내가 정신적으로 상태가 안 좋을 때 연예인도 아닌 가진 것이 없는 나를 욕하는 사람들이 있으면 흥분이 되는 경우도 종종 있었다. 정말 씹어 먹을 것들이야…\n",
      "3. 각 변의 저 울분에 찬 글에 희정이가 답하면 되지 정재호 네가 왜 끼여 각 변을 비난해? 희정이 캠프에 있으면 이런 일에도 나서는 거야? 오지랖은 정재호 그냥 곽변한테 사과하고 찌끄러져 있어라 재호야 똥오줌 가려라 각 변이 이유 없이 그런 글 올렸겠어 반성해라\n",
      "3. 남 페리에 대해서 어떻게 생각하나? 관심 없는데 본인이 남파 미라고 생각한다면 페미니즘에 대해 조신히 입다물고 있을 것!(청춘들 박수 남페미라고 표방한다면 어느 빻은 발언이든지 응원받고 그런 그들이 여성의 마이크를 뺐어 가는 것을 보았다. 페미니즘 판에서 이는 잘 못 되었다.\n",
      "3. 미개한 고대인들(풋이 갑자기 두려움에 떨고 대혼란에 빠지기는 개뿔;;이고 메디 아군과 리디아군은 아 이게 그리스와(철 학자 탈레스가 얼마 전 계산(! 해서 곧 있을 것이라 했던 개기일식이군, 탈레스 예측이 맞았네(털썩라면서 개기일식 감상 \n",
      "3. 박광온 후보는 한 달 전 만에 해도 김명수 부총리 후보의 논문 표절 문제 제기하며 사퇴하라고 논평 내기도 했습니다. 아무래도 위선 시비도 피할 길이 없겠네요. \n",
      "3. 플미충이 가격을 제시하거나 원가보다 높게 부르는 등의 행위를 캡처하셔야 합니다. 이 3가지 질문은 이렇게 트윗을 올리오니, 확인해주시고 설명드린 것은 따로 답을 드리지 않겠습니다 ㅠㅠ\n",
      "3.1절 행사 국민이 뽑은 최우수작 \n",
      "3.4.5번째 댓글 제외하고 다 빻은 메인 안전진단 오늘부터 강화 … 목동 재건축 어려워진다 (출처 : 중앙일보 | 네이버 뉴스 \n",
      "300+a 연차 돌린 꼬락서니가 이거다. 그 오 가챠 진짜 조망인데 \n",
      "30대의 니노가 너무 귀여워서 자끄 빻은 말이 나오려고 할 때마다. 아기 니노를 찾아요. 으아아아 아악 아기야 진짜ㅠㅠㅠ 왜 이렇게 귀엽니 ㅠㅠㅠ \n",
      "30분 뒤에 앤가랑 200일!!!!\n",
      "30억짜리 받으면서 10억 세금 낸 사람을 불법은 아니지만 비도덕적이라고 조지면. 대체 도덕적 상속은 어떻게 해야 하는 건가요?\n",
      "36은 개뿔 26 같음 \n",
      "3만 5천 남았습니다. 조건부 승인은 개뿔 개나 주라고 하고 꽤 시민들의 힘으로 문 닫게 합시다. 방통위는 원칙대로 하세요. \n",
      "3억 이상 소득만 돼도 세금 내기 싫어서 리스로 수입차 3대 끌고 다니다 1.2년도 안되어서 막 바꾸고 그래 비용처리해버리고. 세금 내기 싫은 몸부림은 각양각색이긴 한데 손석희는 뉴스에서 거짓말을 해서 선동하니 더 죄질이 나쁨\n",
      "3월 13일 안철수 연세대 강연 어마어마하네요. 빈 의자기 뭐 개뿔 딱 지나 배울게 있어야 강연을 듣지 . 참 안타까운 철수 안.!! \n",
      "3월보다 4월이 더 힘들 줄 몰랐는데. 현생 미친 듯 힘드네. 진심 나잇값 못하는 사회성 떨어지는 사람 만나 오래간만에 인간에 대해 또 한걸음 배웠던 요즘. 갑자기 터져 나오는 분노. 동호야 네 생각으로 버티고 컨트롤하였다.\n",
      "3집 때 타 그룹이랑 번지 점프하러 간 잭 스키. 그땐 운동 잘하고 막 묘기하면서 점프하고 이러면 엄청 화제 될 때였음. 타 그룹이 전원 그런 점프를 한 반면. 겁 없는 재진만 등 떠밀려 도전하고 나머지는 무섭다며 도망감. 화제성 따윈 개뿔 관심 없었던 마이웨이 젝스키스\n",
      "3층 31구역 10열 18번 좌석 3층 31구역 15열 17번 좌석 플미충이에요 신고했으니 사지 마세요 \n",
      "3층이랑 시제 열고 추가 티켓팅하자 그리고 플미충 못 잡게 보안코드라도 좀 걸어줘 ㅠㅠㅠㅠㅠㅠㅠㅠ 차라리 그거 치는 게 낫지ㅠㅠㅠㅠㅠ\n",
      "4 대 강에 국민 세금 몇 십 조를 쏟아부었던 자유한국당이 일자리 추경은 불법이고 낭비라며 반대합니다. 아동수당 공약을 10년은 지킬 수 있는 세금을 콘크리트 바닥에 버린 정당이 할 말인가요? 심장이 콘크리트처럼 굳어 있으니 민심을 전혀 느끼지 못하는 것 같습니다\n",
      "4 대 강의 폐해를 이제야 말하는 감사원. 그 폐해가 새로운 것인 양 대서특필하는 조선. 그런 사실을 이명박 정부가 득세할 땐 몰랐던가? 총선 전후엔 몰랐던가? 대선 땐 몰랐던가? 기자들아. 팩트, 팩트 위선 떨지 마라. 맥락 없는 팩트는 거짓이다. 아이에 난 승냥이다.\n",
      "4 자방만 생각하면 열받는다. 한 대 때리고 끝낼 일이 아니다. 반드시 조사해서 이명박과 관련자들 모두 처벌해야 한다 다시는 세금으로 장난질 못하게 법을 개정하고 소급 적용해야 한다 이것이 바로 적폐 청산이며 촛불민심의 명령을 지키는 일이다. \n",
      "4%의 박근혜를 탄핵했는데, 3.4%의 정당도 해체돼야 합니다. 자신들의 범죄행위를 발목 잡는 정치행위로 적당히 덮으려는 수작 절대 용납할 수 없습니다. 대선 조작 국민의당 해체를 걸고, 호남을 시작으로 뜨거운 여름 촛불투쟁을 해야 할 것 같습니다.\n",
      "4. 글은 사람의 뒷모습 옆모습 보이지 않는 그늘을 드러낸다. 글과 사람이 서로 틀린 것이 아니라, 서로 다르다. 글로 사람을 꾸밀 수는 있으나, 글이 사람을 망칠 때는 안타깝다. 위악(僞惡이든 위선(僞善이든 하나의 몸에서 나온다\n",
      "4. 부동산 보유세 인상도 꼭 필요하다. 담뱃세 인상으로 서민들에게 8조 원을 걷는데 9억 원이 넘는 주택에 사는 사람들에게는 세금 1조 원을 걷는다. 이것은 정의로운 사회가 아니다. 부동산 안정화는 하나의 정책만으로 해결 돼지 않는다. 관련 정책들이 유기적으로 잘 연결돼야 정책 효과를 볼 수 있다.\n",
      "4. 스카티 커크 생파에서 술에 꼴아서 에어비앤비 돌아가는 바람에 칸 개빡침\n",
      "4. 일본도 인쇄소 영업자는 (좋은 의미로 오지랖이 넓다. 5. 전 실수가 나올까 봐 겁나서 제가 교열한 책을 못 봐요 6. 이 일을 하면서 한 번도 실수 안 한 사람은 없죠 ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ\n",
      "4. 집에 와서 보니까 요정은 개뿔. 수달인지 쥐인지 사람인지 알 수 없을 정도로 고양이의 모습은 아니었다. 고양이를 처음 키워봐서 정말 그땐 입양 사기당한 줄 \n",
      "4.05 패치 때 추가되는 만물 장비 탱커 디자인은 유저 콘테스트 최우수작 디자인을 가져다 썼는데, 이 디자인을 기반으로 힐러/딜러 장비 디자인을 했다고. 힐러/마딜 콘테스트 디자인은 다른 장비 시리즈의 베이스로 적용하려나 보네 \n",
      "4.1 패치에 힐러 장비 디자인 콘테스트 최우수작의 디자인을 활용한 장비들이 추가되는데. 힐러 장비 디자인 하나 가지고 전 직업 장비 디자인으로 활용하는 건 좀 많이 아닌 거 같다. \n",
      "4/6 johnnys live collection 2017 발매 세금 포함 3200엔 / a4 사이즈 / 160페이지 쟈니즈 올스타 라이브 사진을 1권에 응축 한 사진집 완성! 각 투어 세트리스트와 콘서트 굿즈 라인업도 소개. 또한 여기서 밖에 읽을 수 없는 당시의 콘서트를 회상하는 멤버 코멘트도 게재! \n",
      "41평 아파트서 4년 전세 살고선…“집 없는 설움 잘 안다” 안철수가 보여준 모습 중 거짓과 위선이 아닌 것이 거의 없다\n",
      "428조 8천억 원의 소중한 세금, 국민의 안전·일자리·살림살이를 위해 소중히 쓰겠습니다. \n",
      "43만 원짜리 하나 팔린 거 보세요. 1열 가셔서 참 좋으시겠어요 차액 30만 원으로 앨범 샀으면 우리 오빠들 시상식에서 상 받았을 텐데 플미충들 집사에게 도와주셔서 정말 감사하네요 프로미 사지 마세요 ㅠㅠ \n",
      "44만 원 진짜 돌았나 저딴 플미충이 프롬찌 보는 거 소름 돋아서라도 신고 간다,,, 제 발로 강퇴해 달라 하네\n",
      "48945612464년 만에 그리는 그림은 오차 코로 시작하고 턴을 마치지 (안 닮아서 개빡침 \n",
      "48억 세금 낭비 막은 직원. 일자리 잃고 홀로 법정 싸움 기상청이 성능 미달 장비 입찰하려 하자 내부고발한 사람을 해당 장비업체가 고발. 검찰은 1,2심 무죄에도 불구하고 상고심까지 끌고 가 5년 넘게 소송.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48억 세금 낭비 막은 직원. 일자리 잃고 홀로 법정 싸움 | 다음 뉴스 \n",
      "4구 대회가 없어진 이유 내가 하면 기분 좋은데 당하면 개빡침 ㅇㅈ? \n",
      "4년 전, 지푸라기라도 잡는 심정으로. 그곳만은 가지 말아야지 했던. 위선의 대명사(그때의 편견 교회라는 곳을 처음 가게 됐을 때. 4년 뒤 제가 기독교 대표 방송의 강의 프로에 나가게 될 줄은 꿈에도 몰랐죠. 이런 제가 어떻게 하나님을 부정하겠습니까.\n",
      "4부 미국 싱크탱크 지원 중단과 김기식-홍일표 라인의 놀라운 이중성과 위선 [사회 이슈] (2018.04.09 님이 공유\n",
      "4월에 눈이 오는 꼬락서니를 보면. 8월에도 겨울이 오는 날이 머지않은 거 같아 주나.\n",
      "4조 원이 넘는 불법 차명계좌를 세금 한 푼 안 내고 이건희에게 돌려준 금융위는 삼성의 심부름센터인가요?. 전면 재조사해서 최소 2조 원 이상 세금 확정하고 즉각 추징하라! \n",
      "4차 산업은 잘 모리겠는데, 5차 산업으로 종교 산업을 육성하면 어떨까 싶다만. 전 세계에서 우리나라 만치 종교 사업(?이 발달한 나라가 없는데. 벤처 종교 회사를 설립해서 투자도 받고 능력 있는 종교인은 연봉도 많이 받고, 또 세금도 많이 내고.\n",
      "5,18 유공자는 가산점 10% 그러면 공부 열심히 해도 공무원 될 수 없다 모든 세금 전부 공짜다 이것이 공정한 사회가 되겠습니까 국가를 위해 희생된 분들도 이렇게 안됩니다 이제 국민 여러분 자녀들 아무리 고생해도 공무원 임용 어렵습니다\n",
      "5,18특별 법과 세월호 특별법 모두 폐기해야 한다 국고 축내는 하마다 왜 세금으로 이들을 보호해야 하나 새 정부는 바로 폐기 바란다 \n",
      "5. 사생 대처 안 함 6. 황제님한테 염분 알레르기가 있음에도 불구하고 바다 가서 촬영 7. 오히려 이니스프리가 일 더 잘함 8. 샤콘 티켓 플미충들 단속한다고 입으로만 함 행동으로 실천 안 함\n",
      "5.18 유공자 명단 즉시 공개해야 한다 그 명단을 공개하고 안 하고는 보훈처나 국가기관이 권리가 있는 게 아니라 세금을 내는 국민들이 그 세금이 어떻게 수용되고 있는가를 철저히 제대로 알아야 할 권리가 있다\n",
      "5.18유공자는 국가 아닌 광주시가 독자 인정한다. 이 얼마나 엉터리인가? 돈은 국민의 세금으로 나가는데 왜 국가가 아니고 광주시가 제멋대로? 광주시가 인정하면 그에 따른 보상금도 광주시가 해야지 왜 우리가?\n",
      "503 716 정부는 사자방 비리에 100조 원 세금을 꼬라박았는데. 문재인 정부는 일자리와 국민의 지갑을 위해 세금을 쓴다. \n",
      "503호 국민 건강 위해 담뱃값 올리고 최경환은 국민 건강 중진이 타면서 서민들 등쳐 서민들 세금 뜯어 503호 순 우리 배불려 놓고 인제 담뱃값 내린다고 인제 국민 건강 모르쇠 하나 양아치 새끼들 됐고 담뱃값 안 내려도 된다. \n",
      "50년간 미뤄진 종교인 과세 또 유예? 김진표 의원처럼 표심을 의식한 정치인들이 종교인에 대한 특혜를 거두지 않으면서, 현재 한국은 oecd 국가 중 종교인이 세금을 내지 않는 유일한 국가로 남아있다.\n",
      "5k님. 제발 플미충들을 물리쳐주세요. \n",
      "5부 언론의 이상한 「삼성 이지메」와 문 정권의 본심. 52시간 근로 줄어든 수입도 세금으로? [사회 이슈] (2018.04.11 \n",
      "5월 17일에 개봉한 이후로 불한당이 가진 각종 혐오적 태도에 대해서 이야기하지 않은 적이 없는데 이제 와서 너도 빻은 거 파고 있잖아 하면 예 알고 있습니다 그걸 공격 지점으로 삼지 마세요 내가 파는 것이 나의 전부가 아닙니다\n",
      "5월까지 세금 11조 2천억 더 걷혔다. 추경 충당하고도 남을 수준 국민들 고통 주는 야당은 당장 국회의원 사퇴하라! 우체부의 자살! 소방 공무원의 처우개선 청년 일자리 아무것도 못하게 발목 잡는 야당 해체하라\n",
      "5월까지 세금 11조 2천억 더 걷혔다. 추경 충당하고도 남을 수준 이런데도 미친 야당들 때문에 추경은 꽉 막혀 있지.\n",
      "5월까지 세금 11조 원 더 걷혀. 일자리 추경 실탄 확보 / sbs 정부가 제출한 추경 규모와 맞먹는 수준까지 걷혀 빚내지 않고도 추경할 수 있는 실탄 마련. but 내수 회복세는 여전히 부진, 특히 도소매업이 부진. 추경이 절실하다는 뜻ㅇㅅㅇ \n",
      "5월까지 세수 초과분이 11조 원을 넘었다.?정부는 올해 추경을 편성하면서 초과 세수를 8조 8천억 원 수준으로 봤는데 이보다 2조 원 이상이 많다. 5월까지 세금 11조 2천억 더 걷혔다. 추경 충당하고도 남을 수준 \n",
      "5인 지지 사상검증하고 싶으면 그분 생일날 하시길 엄한데 와서 깽판 놓지 말고. 종현이 솔 콘에 종현이 영상회까지 와서 분위기 뭐같이 만들어놓고 종현이 생일날까지 빻은 소리 하지 말자\n",
      "5천억 원으로 추산되는 회사를 사실상 아들에게 넘기면서 낸 세금은 50만 원 정도입니다. 14년간 물밑에서 치밀하게 진행된 편법 증여는 새우가 고래를 잡아먹는 양상이었습니다. \n",
      "6 를 딱 얘기에서 벗어나서. hl은 아니고 그냥 여캐 얘기인데 엘리랑 기둥이 나왔을 때 취조 엄청 심했음. 엘리 때는 바이오에 엘리 욕 잔뜩 써놓고 보이면 블록 한다고 써놓은 사람도 있었고. 리둥이떄도 욕만 안 써놨지 비슷한 맥락으로 써놓은 사람 있었다. 싫어할 수야 있는데 여캐만 유독 격하게 싫어하는 게 .\n",
      "6 사람들은 너나 할 것 없이 흥에 겨워졌다. 그리고 말뚝이를 떠올렸다. 해학과 재치로 위선의 양반 사회를 풍자하던 탈놀이 판에 말뚝이. 헐벗고 짓눌린 슬픔으로 눈물조차 나오지 않던 이들의 대변자, 말뚝이. 그 말뚝이가 추던 곱사춤.\n",
      "6. 그런데 해피빈 후원자들은 배지가 안 와서 더 기다리라고 함. 여기서 화나서 본인이 입장대기줄 부스마다 서는 거 맞냐고 다시 물어보니 아니라고 함 개빡침. 개싸움 그냥 죄송하다는 말이 끝. 그러면서 하는 말이 품절 안될 거라고 초반부라고.\n",
      "6. 드 발은 속(본질은 이기주의자, 겉에만 도덕(적 위선의 도금을 둘렀다는 식의 인간에 대한 설명을 판뚜껑 이론으로 부르며 최근의 과학적 성과를 동원해 융단 폭격을 가합니다. 인간의 도덕적 능력은 진화한 본성에 뿌리박고 있다는 것입니다.\n",
      "6. 서민주거안정을 볼모로 한 분양사업에 불과하다. 시민들에게 강제로 얻은 땅과 세금으로 조성한 기금을 건설사의 수익사업에, 재벌 건설사의 먹잇감으로 제공한 것은 특혜다. 정부는 땅장사를 즉시 중단하고 lh와 sh 등 공기업이 주택을 직접 공급하여 서민 주거안정에 기여하도록 만들어야 한다.\n",
      "6. 서울로 다시 이사 가고 싶다 다들 멀리 있어서 외롭고 쓸쓸하다 온리 전도 다 서울이고 모임도 다 서울이고 흑 흐흑 흑흑 짜증 난다 서울 망해라 cgv 토르 2 서울 개봉 안 하는 거 쌤통이다 하하하ㅏ하하흐극흐흑 흐극 흑흑 7. 농담입니다 죄송합니다\n",
      "6.25기념식에 참석도 않고 북한 체육인 만났고, 연평해전 행사엔 보훈처장마저 참석 않는 국가관을 가진// 문정권이 미국으로 날아가 (자기들이 기념비 제작 반대하고 제작한 넘을 적폐 1호로 자른 장진호 전투 기념비 앞에서 생쇼를 하는데/ 믿겠나?\n",
      "6/4 막 콘에 나서 알밤 무대 중 기광이와 함께 노래하신 분을 찾습니다 ㅅ 팬분들 얼굴이 너무 많이 나와서 올리지 않을 예정이라. 추억 삼아 갖고 계심 좋을 것 같은 오지랖이 본인이시면 보내드릴게요.! (+프리즈 때 기광이와 셀카 찍은 분도.!\n",
      "60대 의인이 참다못해 김한길이 생쇼 하는 천막에 오셔서 하는 말. 혈세로 세비 축내지 말고. 국회로 기어 들어가라 거센 항의에 김한길 개구리눈처럼 휘둥그레. 통쾌. 상쾌. 유쾌.\n",
      "61. 그 후로 한 달, 즴인과 윥기는 누구보다 달달한 연애를 하면서 막 달달하게 삶. 근데 문제는 즴인의 정체가 정부에 발각되면서 윥기 귀에도 들어갔고 윥기는 극악무도한 살인마가 즴인이었다는 사실에 역겹다며 헤어짐. 즴인은 이제서야 후회하며 죽음으로도 용서가 안되겠지만 이젠 알겠지.\n",
      "625 희생자들 그 가족들의 슬픔 거슬러 한일강제합방의 나라 잃은 슬픔 그 이전에는 종북세력과 친일파, 위정자들의 위선과 무능이 있었다 3대가 병역 면피한 박원순의 아들 박주신이 대한민국 법정에서 진실의 심판을 받아야 잘못된 역사를 바로잡을 수 있다\n",
      "625, 보릿고개, 산업화, 민주화, imf, 금융위기 정도가 내가 아는 대한민국의 역사네. 내 아버지가 이 모든 걸 견디셨네. 흔히 말하는 를 딱 들. 하지만 그분들도 인정하고 설득하면 어떨까? 하지만 잘 안 된다. 그래도 노력해야겠지. \n",
      "6년 넘게 만났지. 함께 아는 지인 오만 명이다. 주변인들이 너네 결혼할 때 되지 않았냐? 내년 안에 하면 세탁기 사줄게 고따위 오지랖 떨 때마다 애매하게 웃는 슈주.\n",
      "6년이 아이라 60년이 지나도 내는 주야장천 공부하고 있어야 될 끼다, 네 하는 꼬락서니 보면.걱정은 네미. 안 묵었으면 나가서 밥이나 사 무라!\n",
      "6시에 와퍼를 받으러 가면서 모바일로 폰 케팅을 해보고 안되면 난 양지도 충이 되거나 가지 말거나.\n",
      "6월 13일 자 <낢이 사는 이야기>, 아기는 언제? 평소 보살에 가까운 느낌의 느긋한 낙천주의자인 서나래 작가조차도 화나게 하는 오지랖 공화 국민들의 단골 멘트. \n",
      "6일 치 덕질 안 하던 거 지금 받고 정리하고 하는 중이었는데 스 엠 일하는 꼬락서니 때문에 안티들 붙은 거 보고 화가 나서 손 놓고 있었는데 스트레스 내릴 겸 다시 받으러 가야겠군요\n",
      "6주택 이상 소유자 명단, 구입가격, 임대 소득과 세금은 공개하자. 5년 전 상장회사 임원 연봉 공개 법, 저항 있었지만 지금 누구도 이의 없다. 상위 1% 보유한 주택은 총 90만 채. 한 명 평균 6.5채. 6주택 이상은 상장사로 보고 소득ㆍ세금 공개. 이 오비 도 공개 \n",
      "6한남 소추 9는 42언스 \n",
      "7. 그러니 깨 시들게서도 그녀의 과거를 들추는 점잖지 못하고 여태 별로 재미 못 본 일들을 계속하시는 것보다 그녀가 결혼해서 결혼 전 약속이나 이런 신혼 초 다짐대로 잘 하는지(처녀왕이 롤모델ㅠㅠ나 꼼꼼히 따져 볼 일 아니겠는가 하고 오지랖 떨어본다(끝\n",
      "7. 아님 뭐가 냉전임? 냉전에서 한미 동맹을 두텁게 해 북한 핵위협에 그럼 맞서야지 여기에 물러터지게 대응하고 빻은 낡아 빠진 햇볕정책(풋이나 계속 물고 빨고 그래야 하겠음? 안철수 대표 입장 중에 제일 흥미로웠던 것은 탈원전 부분. 기본 방향에서는\n",
      "7. 오지랖 좁은데 자기한테 도움 청하는 사람 절대 그냥 못 지나침 8. 직장에선 한없이 깔끔하고 좀 정리정돈에 예민한데 집에선 겁나 후련함(나갈 일 없으면 수염도 안 깎을 거 같음. 9. 안주 없이 술 처먹는 거 좋아할 듯 10.의 산데 지 몸 잘 안 챙김\n",
      "7. 저것들 하는 짓거리를 보면 안철수가 고민하고, 숙고할 필요, 가치, 조차도 없었다고 하는 생각이 들게 합니다. 안철수가 출마 선언 안 했으면 국민의당은 구태적인 인위적 정계개편 수작질로 완전히 공중분해될 뻔했을 것이라는 생각이 듭니다.\n",
      "7.9시 30분경 본인은 예매 발권 받음 입장 줄 봤더니 내 앞에 300명은 있어 보임 개빡침 새벽 6시에 도착해서 일등으로 세 시간 기다렸는데. 참을 수 없었음. 같이 새뱍부터 기다린 사람들과 함께 항의.\n",
      "7/21 발매 소라로× yasuhiro 2nd album 동화를 테마로 한 리버스인 원더랜드 13곡 수록 1500엔 + 세금 별도 구입은 아니며이 트, 빌리 지방 가드에서 가능합니다.\n",
      "70대 울 어머니. 안철수는 진심이 느껴지는데 문재인은 위선이 느껴진대요. 우리 식구들은 모두 안철수!!\n",
      "74세 반지름 장어 정신 줄 놓은 생쇼 일주일 총정리. 호주머니 손 질러 넣고 토그 하는 꼬락서니 봐라. 스브스 쥔 자 잘 만든다는ㅋㅋㅋㅋㅋ \n",
      "76. 자는 줄 알았더니? 아, 깬 건가. 뭐어 느 꼬락서니 봤을께 됐다 일. 뭐 하나 싶어서 왔는데 팔자가 아주 상팔자구먼.웜마 느 귀에 점도 있었니 야아.물어뜯고 싶게에.\n",
      "7년 만에 돌아오는 쏘우의 신작, 쏘우: 레거시는 비록 공포영화는 아니지만 꽤 수작으로 유명했던 타임 패러독스의 두 감독이 맡게 됐다고 합니다. 각본은 피하냐 작가(. 또한 전작의 차 트랩과 비슷하게 오토바이를 이용한 트랩이 등장한다고 하네요.\n",
      "7대 고위공직 임용 원천 배제 기준(병역기피, 세금 탈루, 불법적 재산증식, 위장전입, 연구 부정행위, 음주운전, 성 관련 범죄를 마련하고 예정 직무 비리 관련해서 엄격한 기준을 적용합니다. 靑, 7대 비리 관련 고위공직 임용 원천 배재 기준 발표\n",
      "7분 만에 끝난 총리 이임식. 이완구 눈물 글썽 목숨을 내놓겠다던 이완구의 생쇼… 검찰이 정상이라면 비리 백화점 이완구 구속영장 청구하고 압수수색해야! \n",
      "7월이 되면서 새롭게 바뀐 정책 중에서 생활과 관련된 것들만 쏙쏙 뽑아봤습니다. 버스 요금 할인부터 세금 납부까지! 꼭! 읽어보시기 바랍니다☆ \n",
      "7집 가사가 죄다 (덕후들에게 눈물 버튼인 것은 박효신이 n 연간 늘 언제나 해오던 말과 마음이 녹아있기 때문임 그래서 가끔은 이런 이야기 저런 이야기를 다 모르면 내가 느끼는 것만큼 마음에 와닿지는 않을 수 있겠구나 생각하면 안타까움 모두가 이 개쩌는 걸 느꼈으면 좋겠어,,(오지랖\n",
      "7호실 특유의 날 것의 느낌이 너무 좋았던 영화였던 7호실 처음 보고 정말 수작이라고 느꼈던 기억이 나네요 \n",
      "8. 다리 역할 해드리기 위해 노력해 볼게요. 물론 상대 분이 단호하게 거절하시면 강요할 수 없지만 시도는 해볼게요. 저를 많이 애용해주세요. 기쁜 맘으로 돕겠어요! 이런 것들이 두꺼운 철판과 오지랖을 소유한 제가 할 수 있는 일인 것 같아요.\n",
      "8. 육성 초등학교 졸업 이후로 자기보다 손이 큰 사람은 처음이었다. 손이 크다는 이유만으로 호감이 가다니 쥐성은 자신이 이렇게 단순한 인간이라는 걸 인정하기가 싫었다. 하지만 욱키의 얼굴을 10cm 앞에서 마주 보는 순간 결국 인정했다. 손은 개뿔. 난 이 형 얼굴 보고 좋아하는 거였지.\n",
      "8/16(일-qa: “he deserved it. / it serves him right! (고것 참 쌤통이다!”\n",
      "81만 명 생산직에 풀어바라. 외국 노동자들 수입해 쓰겠냐. 개뿔 가족들 이름도 한자로 못쓰는 새끼들이 4년제 대학 나왔다고. 펜대만 굴리려는 골빈 새끼들이 나라를 망치는 기다. 나한테 40명만 보내도고 일 빡세게 시켜줄게. 난 일할 사람이 없다.\n",
      "82. 윤숙 표정 점점 험악해지고.즴인 아차 싶어서 화제 돌림 ㅡ테 형이는? ㅡ모르겠다 ㅡ응? ㅡ아니 그보다도, 너 돈 있냐 ㅡ웅! ㅡ나 컵라면 하나만 사줘라. 그날 불려간 건 네 탓도 있으니까 네 탓은 개뿔, 그냥 배고파서 다\n",
      "82억 세금포탈 혐의 이건희 회장, 기소 의견 송치 경찰이 세금포탈 혐의로 이건희 회장을 기소 의견으로 검찰에 송치한다. 차명계좌 관리를 도운 삼성그룹 사장급 임원도 함께 기소 의견으로 검찰에 넘긴다. 이들은 차명계좌 260개를 관리하고 세금 82억 원을 포탈한 혐의다.\n",
      "83번째 발언-미투 운동을 보면서 과연 성폭력에서 자유로운 사람이 있을까 하는 생각이 듭니다. 저도 어린 시절 지워버렸던 거머리 같은 손들 이 떠올랐습니다. 그리고 그때 대응하지 못했던 나 자신이 싫어서 열병이 날 정도였습니다. \n",
      "85% 부자증세 잘했다. 72% 복지 위해 세금 더 낼 수도 | 다음 뉴스 \n",
      "85% 부자증세 잘했다. 72% 복지 위해 세금 더 낼 수도 | 문재인 정부 100일 여론조사 대기업·자산가·고소득층 증세 경제적 상층 빼곤 지지 압도적 60대도 73%가 긍정 평가 \n",
      "8년간 45억 세금들인 역사지도에 독도가 없다. 황당. 동북아역사재단의 지도 실질적으로 중국 측과 일본 측의 자료를 아무 검증 없이 사용으로 중국의 동북공정-탐원공정 그리고 일본 식민사관을 도와주는 지도 \n",
      "9. 그리고 sns 안 하고 기사 접하지 못한 더 많은 저자들에게 자음과 모음의 악마 같은 행태가 더 널리 강력하게 알려질 수 있도록 저자 여러분의 적극적인 오지랖도 함께 기대합니다\n",
      "9. 여자 혼자 여행하면 위험하지 않냐는 악의 없는 오지랖 필요 없어 그래서 페미니즘 해\n",
      "9. 익명님 진짜 너무 귀여우세요. 아 진짜 너무 귀여우세요. 사실 연성하시는 것도 집에서 혼자 보면서 생쇼 한 적이 한두 번이 아니에요애 흐흑. 게다가 제가 이 계정을 파기 이전에 연성 서치하면서 익명님 그림 보면서 얼마나 행복해졌는지 모릅니다.ㅜㅡㅠ 천사님이랑 두 너무 행복하게 지내시는 것\n",
      "9. 자신의 젖은 상태는 희생정신을 뜻합니다. 좋게 말하면 희생이지만, 나쁘게 말하면 오지랖입니다. 머리부터 발끝까지는 남을 위해 무엇이든 바칠 수 있는 희생정신이 아주 강한 사람입니다. 열정과 힘이 넘치며, 자신보다 남을 소중히 하는 경우도 있습니다. 다리나 배를 이용한 사람들은\n",
      "9. 처음 관람한 건 개봉날, 첫 상영 타임이었음. 다들 처음으로 관람하는 거고, 티켓팅도 엄청 치열했고, 배포 특전도 플미충이 들러붙지 않는 거라 정말 라겐을 기다리던 사람들로 꽉 찬 상영 회차였다. 그래서인지 다들 관람 태도도 좋았고 가장 몰입해서 본 듯\n",
      "9. 컨트리 맘 + 자석 600엔(세금 포함 \n",
      "98일간의 위선 박정은 기자\n",
      "a korean odyssey 삼장인 너를 내가 지켜줘야겠다(는 개뿔. 171224 ep.2 \n",
      "a 교회 담임목사 설교 : 직원의 세금 문제로 한국 교회에 노조가 깊이 들어올 위험성도 있습니다. 교회는 사탄과의 영적인 전투를 하는 영적인 공동체이기 때문에 이런 노조는 어마어마한 위험성을 교회에 (줄 수 있습니다.? 한국교회 망해야 할 또 하나의 이유\n",
      "a 씨는 분명 정봉주가 말한 대로 정치적 의도가 있었고 나는 정의 주장과 달리 이런 의도야말로 순수한 의도라고 생각한다. 정치적 이념을 떠나서 위선적인 사람이 공직자가 돼서는 안된다는 순수한 의도. 이를 위해 a 씨는 고통스러운 기억을 끄집어냈다. \n",
      "ab형 여성의 절친 중에 o형이 많았다. o형 여성은 일단 활달하고 오지랖이 넓은 편. o형은 ab형 친구에게 자주 연락하는데다 늘 생기 넘치고 마음은 open 돼 있다. ab형이 가끔 외로울 때마다 o형은 든든한 버팀목이 돼 준다.\n",
      "인간은 모두 위선자인데 그중 가장 큰 위선자는 위선을 혐오한다고 말하는 자\n",
      "apl 파이널 보러 kbs 아레나 가시는 여러분들 근처 발산역, 가양역에 내려서 버스 타고 가세요.! 걸어서는 가기 힘들어요 도보 10 분은 개뿔,,, 생각보다 거리 있어요 발산역에서 웬만한 버스는 다 kbs 정류장 가니까 꼭 타고 가시고. 근처에 먹을 거 없. 8ㅅ8 발산역 가서 밥 드세요.\n",
      "b1a4는 솔직히 내가 데뷔 팬인데. 2011년 5월? 그쯤부터 관심 갖고. 오케이 때부터 뭣도 모르고 앨범 사고했는데. 8년 차면서 여혐 가사 없고 빻은 말 안 하고 팬이랑 조목 안 하고 과거 논란 없는 거 보면 진짜 대단한 것 같다 뿌듯하고 그래 ㅠ ㅠ\n",
      "bbk 덮으려고 생쇼를 했구먼. 미국산 일본 서식 쥐야. 盧 ‘美 기지 이전비용’ 버텼지만 mb ‘통 큰 합의’ 안치용, “mb, 미국 요구 수용…′09년 국회 비준 없이 통과”\n",
      "bbk 주가조작 사기 의혹 바른말 정봉주는 감옥행 bbk 내가 세웠다고 언론 방송에서 개나발 불고 다닌 사기꾼 이명박은 대통령? 범죄조직집단 자해공갈단 이명박 일당 99% 뭉쳐 범죄자 위선자 쥐때을 가디 이처럼 처단해야 한다\n",
      "bbq 윤홍근 회장, 수천억 원 편법 증여. 문제는 미성년자 아들에게 지분을 넘겨, 이들 자회사를 포함해 회사 전체를 장악할 수 있도록 정지 작업을 하면서 낸 세금은 50만 원에 불과하다는 점이다. \n",
      "bbq 윤홍근 회장, 수천억 원 편법 증여. 세금은 50만 원 14년간 치밀한 준비. 소스 만들던 가족회사가 지주회사로 둔갑 \n",
      "bbq 윤홍근 회장, 수천억 원 편법 증여. 세금은 50만 원 이런 부도덕한 악덕기업 수는 철퇴를 내려야 한다. 난 비비큐 불매한지 이미 오래됐음.\n",
      "besuccess와 오지랖 넓은 5명의 남자가 만났다!: besuccess와 오지랖 넓은 5명의 남자가 만났다! 신선한 참견을 기다리고 있는 스타트업 여러분들의 많은 참여 바랍니다. \n",
      "bighit 5기 마스터 때엔 아미 5기분들이 마스터에 참여할 수 있도록 플미충 편코 팔로워 충돌을 재끼고 새로운 방안을 제시해주셨으며 좋겠다. 3기가 제일 좋았어 . 2기는 배가 너무 고팠어서 패스\n",
      "bts 컴백쇼 dna 무대 리액션 영상 우수작을 발표합니다. 선정되신 7팀 축하드려요! 우수작으로 선정되신 분들께는 개별 연락드리겠습니다. 참여해주신 전 세계 여러분 감사합니다!\n",
      "b-가장 중요하게 생각하는 인생의 가치는 바로 진실이다. 아무리 불쾌, 불행하고 고통스럽고 참담한 일을 당해도 그 일이 진실되고 진실을 위한 일이라면 기꺼이 받아들인다. 거짓과 위선을 용납할 수 없으며 진실을 알아가는 것이 최고의 가치라고 믿는다.\n",
      "c 로그까지 하면 챔피언 등극  싸이 네이트온 트위터 미투데이 페이스북 다하는 사람 등장  싸이월드, 네이트온, 미투데이까지 오지랖만 200만 평  여기 . \n",
      "cgv 에이틴 무대인사 플루 미사는 분 계시나요? 죄송한데 . 저는 플미충 못 보겠어요ㅠ 안녕히 가세요\n",
      "changed 베드 엔딩, 진 엔딩 3개 전부 다 올 클 했습니다. 난이도 제법 있고 상당한 수작인 듯! 진엔딩 보면 모든 일러스트랑 데드 신이 열리는데 직접 못 본 데드 신이 5개나 되네요 지금은 중국어만 있지만 월 말에 영어 패치 나온답니다 tf 좋아하시는 분은 지금 해도 가이드만 보면 할만합니다 \n",
      "cu 칼칼한 깻잎 라면(1500원 sns에서 꽤나 화제가 되었던 라면인데 깻잎 맛은 개뿔 깻잎이 스쳐 지나간 흔적만 남았다. 그냥 슈퍼에서 깻잎 사서 신라면에 널어먹는 게 정신건강에 좋다. \n",
      "d-2 벌써 내일모레입니다 오늘 약 400석이 풀린 첫 콘이 마감되어 모두 현장 판매일 것 같습니다ㅠㅠㅠㅠ 400석 아쉽지만 플미충에게 안 갔으니. 신고와 제보해주신 많은 분들께 감사드립니다 ㅎㅂㅎ\n",
      "dec.27.2017 - suomi finland 100 with moomin 핀란드가 독립 100주년이라고 해서 오지랖 넓은 축전! 사실 무민을 그려보고 싶다고 말해! :0 바빠서 무민 원화전을 못 가봤네요. \n",
      "df-1023.실험명 소피아. 군인들의 말로는 오지랖 넓은 여자였다고 한다. 시설 앞에 진을 치고 있는 군인들의 장교가 한밤중에 소피아의 시체를 들고 들이닥치더니 이걸로 실험을 해보란다. 뭐, 거절할 이유는 없다.\n",
      "disgust [동] 역겹게 하다 [명] 혐오감, 메스꺼움 // disgusting [형] 메스꺼운, 역겨운\n",
      "drop the q 곧 시작! 8시. 오늘 드롭 더 큐 참여하고 상금 타서 마늘 빻기 춤 세리머니 가즈에.! 찧고. 빻고. 갈고. 돌리고!! 앱 커 kr app \n",
      "end - 정해진 길과 위선-\n",
      "exo planet #4 - the e ℓ yxion 티켓 원가 양도 <일시> 17.11.25일 중곤 1층 103구역 l 열 플미충들때문에 너무 스트레스라 팬 인증 빡세게 받을 생각입니다. 인증 내역은 타래로 알려드릴게요 \n",
      "exo-l-japan presents exo channel exo cup 자세한 발표 티켓 요금】 전석 지정 ￥ 5,800 (세금 포함 : 수수료 모두 포함 ※ 입장 특전 : 트레이딩 카드 (여러 종에서 랜덤으로 1 매\n",
      "fixed by youngblood_kanto 오지랖칸토! 언제 왔다 갔어?!기운 빠지는 목요일 오후 소소한 미소를 주네 \n",
      "fta 발효 전의 관심 없던 분들 발호되고 나서 이득 많이 보셨나요? 체리는 많이 쳐드셨는지? 그러나 어쩌나. 체리 값에 변동 없다던데. 그렇게 애타게 기다리셨던 분들.줒됐네요 쌤통입니다 더 슬픈 건. 앞으로 우리가 당할 일이 쓰나미 이상이라는 겁니다!\n",
      "ft아일랜드 콘 플미충은 상습범이에요 개펜시 아무것도 안 할 것 같으니 우리가 막습시다 >프로미 티켓 안사면 취소표로 풀려요< >절대 프로미 티켓 사지 마세요!!< _x \n",
      "gm 문제가 어떻게 흘러갈지 예상하는 건 어렵지 않다. gm대우도 결국 세금으로 떠안게 될 것이다. 구조조정은 없거나 미약할 것이다. 비슷한 일이 일어나겠지만 gm대우만큼의 상징성이 없는 기업은 버려질 것이다. 역시 공무원이 최고야 사람들은 말하겠지. 9급 공무원이 젊은이들의 꿈인 나라.\n",
      "gm은 더 이상 자동차 제조업체가 아니다. ma를 통해 덩치를 불리고 기업을 쪼개서도 팔고 붙여서도 파는 기업사냥꾼이다. 그런 기업에 세금을 쓰게 할 수는 없다. 어차피 액션일 뿐이다. \n",
      "gm은 상습범이다. 그 리스크를 세금으로 질 이유가 없다. 매각도 아니고 공장을 폐쇄한다는 것은 정부 지원을 위해 시위하는 것이다. 어차피 깎아진 십자가 붙은 차를 탈 사람은 많지 않을 것. 판매가 안되니 적자가 날 수밖에. 시장논리로 풀면 된다. \n",
      "gm이 정부에 유상증자에 참여하라고 요구하는 것은 국민 세금 4조 원을 몇 년간 일자리 유지시켜주는 대가로 자기들에게 달라는 30년간 한국에서 장사를 해본? 한국 정치 상황을 이용한? gm은 다른 나라에서 하나 짓처럼 우리에게서도 돈을 갈취한 후 먹튀하려는 듯 gm 한국인 낙하산 인사들 비리도 조사해야 \n",
      "harman kardon soundstick 사용의 바른 예. 첫 번째가 배송받을 당시의 모습이고, 두 번째 사진처럼 받침을 뒤로 돌려줘야 합니다. 이거 모르고 사용하시는 분을 너무 많이 봐서 오지랖 좀 떨게요. \n",
      "he also know the slang 플미충 haha\n",
      "independent sky [grv] 생쇼 \n",
      "isis는 큰 문제가 있어! 하지만 이슬람의 문제를 바깥사람들이 참견하는 건 위선이야! 그러니까. is에 들어가겠어! 들어가서, 내부로부터 is를 바꿔주겠어!\n",
      "james ensor(1860.1949 벨기에 인간의 위선과 어리석음을 적나라하고 그로 테스 하게 그린 표현주의의 선구자. 무수한 가면의 얼굴 정중앙에서 관객을 돌아보는 앙소라의 자화상은 사뭇 도전적이다. \n",
      "jbj 쇼케이스 양도해요!! 친구랑 같이했는데 저도 되고 친구도 돼서 그냥 제거는 원가 양도할게요 취소표 돌리고 싶은데 플미충이 잡으면 안 돼서 취소표는 안돌리겠습니다ㅠㅜㅠ 알티마 마음 해주시면 오늘 12시에 추첨기 돌려서 양도해드릴게요! s 4 구역 8열입니다\n",
      "jk 김동욱의 그녈 위해나, 왁스의 부탁해요 같은 노래가 예전엔 참 멋졌는데 한 살 씩 먹을수록 참 쓸데없는 오지랖처럼 느껴진다. 어쩌면 그 사람 너랑 만날 때, 그거 별로였는데 좋은 척했을 수도 있고 너와 헤어져서 더는 안 하고 싶을 수도 있는데.\n",
      "jm이라는 이니셜과 함께 자잘한 선물들을 잔뜩 받은 레예스. 아직 미련이라도 남은 것인지 잭 모리슨이 같잖은 수작을 부리고 있나 보다고 생각하여 솟아오르는 짜증을 못 참고 맥크리한테 버려버리라고 던져주는데. 사실 그거 제시 맥크리가 보냈다.\n",
      "jtbc ‘싱글세’ 소동 팩트체크(2014-11-13 방송 캡처. 가족 단위의 소득공제 시스템으로 인해, 결과적으로 소득활동을 하는 싱글이 세금을 더 많이 내고 있다. <가난은 여성의 얼굴을 하지 않았다> \n",
      "jtbc 뉴스룸, 유승민 풋! ㅋㅋ 싸늘은 개뿔 100% 文 대통령 지지. 부쩍 끈끈해진 한미 정상 | 다음 뉴스 \n",
      "jtbc 팩트체크는 김미경 서울대 교수 임용 특혜 안철수 kaist 교수 임명 의혹 변변한 논문도 없는 세계적 석학 bw 통한 안랩 지분 급증, 매년 수억 대 배당 다운 계약서 부동산 투기 세금 탈루 무르팍 도사 사기행각\n",
      "jyj 뚜껑콘 소재랍니다 (뚜껑 가지고 이말 저말 오지랖 쩌는 잉여세력들 특히 보십쇼 ** 바리솔의 특성 ** 1. 단열성 : 천정에 공기층을 형성하여 단열효과가 있다. 2. 내구성 : 환경 변화(습기, 직. \n",
      "jyj, 강남에 전용 녹음 스튜디오 매입 ._. (근데 기사가 너무 자세한 거 아닌가.;는 오지랖이길; \n",
      "k 프리미엄 양도를 하지 않았는데도 애꿎은 샤워 분이 갑자기 자기 티켓이 취소되는 사례가 일어납니다ㅠㅠ 티켓 구하신 분은 인증 사진 올리지 마시고 신고할 때는 플미충이 맞는지 확인 부탁드려요!! 저희도 어찌할 방법이.ㅠㅠㅠㅠ\n",
      "kbs 공식 트위터 담당자님, 국민 세금이 들어간 공공재이자 공영방송의 공식 트위터에 악의적 비아냥 비방성 편파 왜곡 해시태그를 걸어 트윗 하다니 해당 내용 삭제 및 공식 사과를 요구합니다. kbs에 트위터 담당자에 대한 진상조사 및 징계를 촉구합니다.\n",
      "kbs 기자 응원!   kbs 기자들이 머리띠를 묶고 있습니다. 3월 2일 0시를 기해 무기한 전면 제작거부 투쟁이 시작됩니다. 이번에는 물러서지 않겠습니다. kbs 뉴스를 살려내겠습니다. 응원해주십시오!\n",
      "kbs 정기 연주회가 또 취소되었군요. 지휘자 함신익의 문제인지 교향악단의 문제인지 궁금했는데, 다음 글을 읽으니 대충 짐작이 가네요. 함신익을 싸고도는 권력과 언론의 카르텔이 이토록 공포스럽고 위선적일 줄이야! \n",
      "kbs1에서 지금 브라질의 시위 상황을 보도하고 있네요. 한국에서 계속 벌어졌던 국정원 선거개입 규탄 시위는 한 번도 보도안 했는데. kbs의 오지랖도 참 대단합니다.\n",
      "kieeze anjj sushikonto (사진에 필기체 st로 작게 쓰여있습니다 kim_berry33 (kim_berry 전부 빵입니다. 상관없으신 분들이라면 오지랖 죄송하지만. 사실상 몇 장 외에는 전부 그런.\n",
      "kkkkk. getitbeautytv with ??? 제가 수작을 한 번 부려보겠습니다( ?° ??° 썸남저격! 지수를 향한 산다라의… \n",
      "korean men hate to be called as han am which is a sho for a korean man. (한국 남자들은 한남, 한국 남자의 준말,이라고 불리는 걸 싫어한다 팀장님 수첩에 적혀있던 건데 이게 얼마나 웃기고 이해가 안 갔으면 팀장님이 옆에 물음표를 몇 개나 쳐놨음.\n",
      "kt 꼴사납게 굴더니 쌤통. “: sk에 밀린 아이폰 선호도, kt 진작 잘했어야. 포스팅 내용에 절대 동감. kt의 고객 응대는 정말 헬 수준.”\n",
      "kt 직원의 내부 고발로 드러난 국민 세금 낭비 사업이 10년 넘게 그대로 진행되고 있습니다. 발주처인 철도시설관리공단은 예산 낭비임을 뒤늦게 깨달은 원죄 때문에 제대로 막지도 못하고 있습니다. \n",
      "ktx 등에서 사용하는 잡지, 신문을 납품하는 업체들이 담합을 했습니다. 이런 담합은 기차 요금 상승에도 영향을 주고, 세금으로 운영되는 공기업에 부담을 주는 행위입니다. 결국 국민들이 피해를 보게 됩니다. \n",
      "ktx 타면 귀 먹먹해지는 현상은 원래 있으면 안 됩니다. 터널에 진입하면 객실 내 여압은 물론 통풍 장치까지 차단해서 기압차에 의한 귀 먹먹함을 없앴다고 하는데 개뿔이나 창문 틀에 손대보면 밖에서 바람 다 들어옵니다. 노후화의 문제인지 설계의 문제인지.\n",
      "lee minwoo spotted on ig 커피를 요리하다 루프 앤드 한남점 오픈 2018.05.05 서울시 용산구 한남동 727-21 1f #서울 루프 앤드#루프 앤드 한 남#루프 앤드#나 마초 코라고 떼#버터크로와상#초코센베이#한남동카페#한남동#이태원 \n",
      "libera animas omnium defunctorum de poenis inferni luce, libera animas omnium fidelium luce. 그 자는 악마, 악마의 유혹 위선과 배신 타락한 영혼 \n",
      "life is a game : 인생게임 최근 장안의 화제인 게임으로 솔직히 얼마나 잘 만들었겠어 싶었는데 상당한 수작이다. 인생은 되돌릴 수 없다는 점을 러너게임으로 비유하여 되돌릴 수 없는 선형 구조를 가지고 있고, 아주 자연스럽게 인생의 통과 의례와 터닝 포인트를 누적하여 \n",
      "like this pa 야 이성적이고 싶어 이게 나잇값이라는데 싸게 주고 싶어 굳이 움직이지 않아도 돼 내가 하는 말이 수작이 되지 않게 기분 좋게 우리 물 잔으로 짠해 its just so good so good and the flow and rhyme is so pleasing in korean but lol in english man. oh boy\n",
      "mb 부인 김윤옥이 한식 세계화 사업으로 해외에서 1인당 474만 원짜리 다과를 제공하는 등 초호화 파티를 벌이며 mb 정부 5년간 1천400억 원의 세금을 탕진했다. 과연 이 큰돈을 오로지 먹는데만 사용했을까? 충분히 해볼 만한 의심이지 않을까?\n",
      "mb 사기 관련 모든 증거. 증인은 있었음에도 한나라. 새누리가 모든 수작과 공작질을 총동원하며 은폐. 인멸. 비호하며 집단 사기질을 쳐왔지. 가평 별장, mb와 같이 지었다. 11년 전 결정적 증언 | \n",
      "mb 정권은 도대체 국민 세금을 얼마나 탕진했나 한국당/새누리가 재집권하기 전에 반드시 해명해야 할 내용 \n",
      "mb 정권이 탕진한 국민 세금은 얼마나 될까? \n",
      "mb 정부 댓글 공작 관련 여론조작 자금 환수 민사소송 추진 댓글 부대에 투입된 세금을 개인 돈으로 물어내라 국민소송법 제정 재추진 앞서 세 차례 발의됐지만, 공무원들 반발로 폐기되었음 조세를 납부하는 주체가 국민이, 잘못 쓴 부분을 국민이 지적해야\n",
      "mb 정부 때도 총리실 특활비 청와대에 상납 매달 이 전 비서관에게 2백만 원씩, 나머지는 행정관 2명에게 현금으로 전 장진수 / 전 국무총리실 주무관 - 2백만 원은 eb라고 썼어요. 세금 도적질 적폐 청산 \n",
      "mb 정부, 국정원 특활비 즉 세금을 정말 사적으로 썼습니다. 검찰은 청와대가 18대 총선을 앞두고 친이계와 친박계 후보 지지율 확인을 위한 불법 여론조사에 이 돈을 쓴 것으로 보고 있습니다 \n",
      "mb 차명재산 전모 속속. 세금도 도곡동 자금으로 내 도곡동 땅 판매 대금 150억 중 >40억 원 mb의 논현동 사저 재건축비 >mb의 차명재산과 관련된 개인 세금 수억 원 내는 데에 사용 >10억 이시형이 써\n",
      "mb 추석인사에 수천 건의 악플로 화답한 시민들 =>최고 “?이러다 각하가 저수지에서 발견되면 그 많은 우리 세금을 찾지 못할까 봐 걱정이 됩니다.?나라도 어려운데 저수지에 있는 그거라도 있어야 좀 살지 않겠습니까.” \n",
      "mbc 배현진 전 앵커, 사표 제출…대기발령 상태…소속 부서가 없다 부당노동행위를 고발 안 하는 노동부 수사하지 않는 검찰 모두 정당성이 없는 문 씨의 사조직. 이런 사조직에 세금으로 월급을 주는 것은 횡령입니다.\n",
      "mbc, 한미fta 띄우기도 모자라 미국의 한미fta 경제효과까지 적극 홍보! 한미fta가 미국에 이익이라는 오바마의 홍보영상까지 그대로 퍼나른 mbc의 오지랖! kbs · sbs도 정부 입장 적극 보도\n",
      "mbc에서 대한민국 위선자 놈들 방송으로 딱 2시간만 대국민 방송을 하면 대한민국은 확 바뀐다 ㅋ 썩어빠지고 문드러지고 고리타분하고 높부심뽀를 고이 간직하고 있는 국민들이 그제야 정신을 차리겠지\n",
      "mbn 뉴스 8에서 자신은 일회용 컵을 애용하면서 문재인 대통령이 커피를 마시는 사진을 내보내며 커피 대신 국산차를 사랑했으면 일회용 컵 대신 텀블러를 사용했으면‥등의 댓글을 언급한 위선자 김주하는 iwc 명품시계, 에르메스 백이 부끄럽진 않은가? \n",
      "mb가 건물주로 있었던 중국집 이야기. 중국집 사장은 2층으로 증축하고, 증축에 따른 재산가치 상승에 대한 세금까지 내주는 대신 10년 연장하기로 했는데 2년 만에 쫓겨났다. 부인은 화병으로 사망. 그게 mb다. \n",
      "mb가 나라를 이렇게 말아 먹음. 380조 다 세금을 갚아야 할 빚 mb 정부서 특수채 380조 발행. 4 대 강 등 자금조달 \n",
      "mb가 동네 잡범이냐고 묻던 것들이 동네 잡범 조폭식 수작이다. 있을 리도 없고 있다 쳐도 꺼내지도 못한다. 민주주의 2.0 회고록에 참고할 자기 자료 복사해간 노무현을 기록물 도둑으로 몰던 놈들이다. 남의 자료 꺼내는 순간 대통령기록물 관리 위반죄 하나 더 추가될 뿐이다. \n",
      "mb가 탕진한 국민 세금 최소 189조 \n",
      "mb가 탕진한 국민 세금 최소 189조 《몇백만 원 먹고도 징역사는 국민 부지기 수다ㆍ나라 곳간 거덜 낸 놈이 버젓이 국민 세금으로 경호 받고, 활보하는 나라가 말이 되냐?》 mb야 das 주인 누구냐? \n",
      "mb가 탕진한 국민 세금 최소 189조 《배고파서 몇십만 원 훔치고 징역사는 국민 부지기수다ㆍ 대한민국을 거덜 낸 놈이 버젓이 국민 세금으로 경호 받고, 활보하는 나라가 말이 되냐?》 mb야 다스 주인은 누구냐? \n",
      "mb가 탕진한 국민 세금 최소 189조 님이 공유\n",
      "mb가 탕진한 국민 세금 최소 189조 원 \n",
      "mb가 탕진한 국민 세금 최소 189조 탕진만 한 게 아니라 그중에 많은 부분을 빼돌려 착복했지.\n",
      "mb는 추징해야 한다. [mb가 탕진한 국민 세금 최소 189조 # ]\n",
      "mb-새누리, 거짓과 위선 가면 벗겨내야 국민과 함께 mb-새누리를 심판하고 정의의 승리를 위한 기사단을 모집합니다. ‘mb-새누리 심판 국민위원회’ 출범 보도자료입니다. \n",
      "mb와 새누리당의 사전에는 진실이라는 단어가 없다. 민주통합당의 사전에는 전략이라는 단어가 없다. 통합진보당의 사전에는 위선이라는 단어가 없다. mb는 양심이, 박근혜는 도덕이, 한명숙은 머리가, 이정희는 꼼수가 없다.\n",
      "mg는 고료가 아닙니다. 저 무료 분으로 풀려 있는 것도 아직 못 받았어요. 결제 수익에만 의존해야는데 그 비율이 3:7입니다. 작가가 3. mg 아무리 올려봤자 결제 수익 배분 자체가 빻은 거니까 많이 벌수록 손해. 그러니까 최소 mg 올린다는 말에 홀라당 넘어가지 마세요.\n",
      "model or meddler? (사후 3:6-15: 예나 지금이나 교회에는 수고로이 일하면서 본이 되는 사람(model이 있는가 하면, 도무지 일하지 않으면서 일만 만드는 오지랖의 사람 (meddler이 있다. 게으름은 공동체의 적이다.\n",
      "ncck “종교인들도 세금 내는 것이 당연. 정부 그동안 직무유기 한 것”\n",
      "ncck 총무 김영주 목사 종교인도 국민인 만큼 세금을 내는 건 당연한 일. 오히려 정부가 그간 (종교인에게 과세하지 않아 직무유기했다 \n",
      "nct 팬파티 양도받지 마세요. 차라리 당일 남은 자리 현판 한다니 그때 노리세요. 양도받아봤자 팬 카즈에 본인 이름도 아닐 테고, 본인만 손해에요. 예사 기본 설정에서 아예 타인으로 바꿀 수도 없잖아요. 플미충, 양도 충 다 잡고 그 표 얻으시거나 걔네가 끝끝내 취소표로 돌릴 때까지 기다리세요.\n",
      "newbc 광화문 뉴스 ? 50년 미뤄온 종교인 과세, 또 늦춰서는 안 된다. 과세를 하더라도 실제 세금을 내는 건 소수의 대형교회. 종교인 과세 미루게 되면 문재인 대통령 개혁을 발목 잡는 결과가 됨. \n",
      "nll 대화록 삭제 흔적을 포착. 2007년 8월 정상회담 이후 대화록이 12월 대선 직전 삭제된 흔적을 발견 위선과 기만 거짓말로 일관했던 인간들 이를 어떻게 변명하냐?\n",
      "nll오리발당 새민련! 신혼집 말 바꾸기 논란 野 위선 어디까지? 지지율 폭락 만회 위해 무리수 우윤근, 집 모형 전달 퍼포먼스 벌이더니 은근슬쩍 말 바꿔? \n",
      "no more dream 거짓말이야 you such a liar see me, see me, ya 넌 위선자야 왜 자꾸 딴 길을 가래 야 너나 잘해 제발 강요하진 말아줘 (la la la la la 네 꿈이 뭐니 네 꿈이 뭐니 뭐니 (la la la la la 고작 이거니 고작 이거니 거니 \n",
      "nra가 오늘 공개한 홍보동영상 대통령은 자기 딸들을 총든 경호원들이 지키게 하면서 왜 국민은 총을 갖는 것을 규제하냐며 오바마가 위선자라고 공격. 참 어처구니없는 단체.\n",
      "oecd 유일 대한민국에서만 종교인이 세금 안내는 이유 헌금을 끌어모으는 초대형 교회의 목사를 중심으로 한 보수 개신교 단체의 강력한 힘. \n",
      "oge가, sado가 리그로 간 것에 대해서 불만을 갖는 핵심은 1 대리는 게임을 이용해서 돈을 버는 불법 행위 2 아무리 어려워도 대리를 하지 않고 정당히 노력하는 프로 많음 3 그 선수들을 제치고 대리 중이 리그를 가서 돈 받고 경기 뜀 이게 역겹고 싫은 거임.\n",
      "old 계란으로 바위 치기, new 마늘로 마늘 빻기 부수기\n",
      "on the chessboard lies and hypocrisy do not last long. 체스보드에서 거짓과 위선은 오래가지 못한다. -임마누엘 라스 커- \n",
      "out : 오늘도 이겨보도록 하겠습니다. 뭐 가볍게 3 대 1 정도? 한 판은 질 수도 있으니까. in : 씨 x 이긴다 무조건 이긴다 3 대 1? 개뿔 시-바 그냥 싹 다 4대빵으로 발라버리고 온다 \n",
      "pd 연합회 고대 영·김장겸. 공영방송 망쳐놓은 장본인 임기 보장을 내세우며 탄압받는 이미지 연출은 위선\n",
      "pq 조사  go go * 삼국지 특집* 원소의 사촌동생 원술! 성정이 교활하고 탐욕스러워 유비를 신분이 낮다 괄시한다. 스스로 성 황제라 칭하고 백성들에게 많은 세금과 노역을 시켜 원성을 듣다 조조 여포 연합군에 패해 죽는다. 누가 생각나시나요?\n",
      "primaniacs에서 마키아 레코드의 타마키 이로하, 나나미 아치요, 하나 메 마도가, 아케미 허무라의 향수가 출시됩니다! 현재 온라인 숍에서 예약 주문을 받고 있습니다. [상세] 전 4종 / 용량: 30ml [가격] 각 5850엔(세금 포함 [배송일] 6월 23일 이후 \n",
      "proplica 세일러 치지 문 프리즘 하트 콤팩트 가격: 8,100 엔 (세금 포함 예약: 18년 3월 9일 13시. 발매: 8월 예정 ** lr44 × 3 (테스트 용 건전지 포함 너무 이쁜데 대체 왜 때문에 자꾸 건전지 포함. ㅜㅜ \n",
      "q. 과거의 자신에게 하고 싶은 말이 있다면? a. 이렇게 구 애인하고 인터뷰할 줄 몰랐던 과거의 밍셕아,너 엄청 후회한다? 받아 적던 죤댸 개빡침. -김밍셕씨 혹시 정신 나가셨어요? -말버릇은 여전하시네요. 치고받고 싸우는 쉬첸 보고 싶다 히히 \n",
      "q. 보디가드 한조와 겐지? 맥 : 전에 제 전속으로 붙을 거라고 하던데요.(웃음 한 : 같은 집에 살면서, 겐 : 하루 24시간 철통 방어! 맥 : 믿음직한 거머리 같은 친구들이네요.(악의 없음 한 게 : 믿음직한 거머리 \n",
      "q: 명절마다 친척들 오지랖 때문에 미치겠어요. 대학 어디 갔니? 취업했니? 결혼은 언제 하니? 애 낳아야지. 좋은 방법 없을까요? a: 수르스트뢰밍 한 캔 따면 바로 해결됩니다. 아 참, 방독면 잊지 마세요! \n",
      " (개빡침 \n",
      " (주의: 개빡침 저건 패륜이긴 패륜인데, 부모가 패륜인 건지. 패륜이라는 건 윤리를 저버린 자라는 건데 그게 자식에게만 해당하는 말이 아님. 저게 어찌 부모 된 자가 할 행동이란 말인가?\n",
      " ,.,.,., .,,., 아 제발.,,.,. 레알로 다 역겹다.,,., 문포 메가를 질문한 놈 페이지 들어가 봤는데.,., ,. 암만 환상 첼라 나 이 같은 거 없다 해도 외관이 어린아이인데 은하 아이랑 레티시아 가지고 얄짤ㄹ을 그리고 싶나,,.,,.?? 어린애들 외관인 애들로 정말 그렇게 성적으로 소비하고 싶나,.,\n",
      " . 진자 우리 사이 너무 역겹ㅂ다.\n",
      "- .?!?! 짹!! ㅉㅉ 재액!!(충격\n",
      " .폭행범에까지. 본인들 집안 단속이나 잘할 것이지 ㅉㅉ 좀 생산적인 국정운영은 뒷전이고 허구한 날 적폐 청산한답시고 남의 허물이나 들추더니 말이야 그 꼴이 다 뭐니?\n",
      " : 박근혜 꼭두각시 황우여가 김일성 생가 방문 사진을 쏙 빼놓았다가 조갑제 닷컴에 그 사진 올라와 들켰어버렸네요. 박근혜는 황우여 사상검증 먼저 하기를. 제 집안일도 정리 못하면서 오지랖 넓기는 원.\n",
      " ;; 여혐에 이성애 중심적 빻음에 정병 혐오에 비만 혐오에 에이지쯤에 노잼드립에 안 물 안 궁자 의식 과잉에 내 이제껏 이렇게 가능한 다양한 혐오 넣기 첼린지는 본 적이 없네 \n",
      " ? 팬덤 머리채 잡고 빻은 집단으로 카테고리화하니까 기분이 좋나 봅니다 그냥 본인 말대로 눈이나 씻고 주무시길 \n",
      " . << 이거 너무 한남 느낌 디렉트로 느껴지는 마! 너희 이모티콘 찰떡이다 이기야 \n",
      " _운영자다 나 워마드 메가를 여시 다하니까 좀 잡아가라.!.!.!\n",
      " “빻은 걸 인지하고 있으니 문제없다”라는 주장이 얼마나 무의미한지 보여주는 내용이네요… 너무너무 해롭고 역겹습니다\n",
      " +개 화남 육두문자 쌸라쌸라!\n",
      " 20대 한남을 필요 이상으로 잔인하고 폭력적으로 묘사하는 이유 뻔하지 않나 결국엔 제저 씨를 빛나게 해주기 위해 서지 \n",
      " 21% 님이 기회주의자 같은데요? 이런다고 안철수한테 도움 될 것 같으세요? 애초에 오지랖 같았으면 하지 말았어야죠.\n",
      " 22마리의 임페. 랑 25의 꼬아 틀! 딱 평등하네요!(전\n",
      " pc 한 척은 다 하시더니, 결국 인간에게 점수 매겨서 그 점수대로 클래스 나눠 짝짓기 하라는 천박한 사고에서 못 벗어난 분이셨네. 재산이든 나이 든 외모든 내 마음에 들면 사귀는 거지, 웬 오지랖.\n",
      "  죽어 이 개 삐삐야 ㅡㅡ.\n",
      " 각자 함 뜨는 중에 수끼리 할딱이면서 뻡뻐하는 거 좋아함. 게 빻은 취향인 거 나도 아니까 조용히 해. 아쿠 아츠 초보컾이라 ㅅㅅ를 어찌해야 할지 몰라 다 자유에게 조언 듣는 이야기. 어버 하는 츄야 붙잡아 옷 홀랑 벗기고 선배가 모범을 보여야지 하면서 웃는 다자이 보고 싶다\n",
      " 갓 입문했는데 한남들 머가리 같이 깨고 싶습니다 선팔 하심 맞팔 할게요.\n",
      " 개 삐삐 씨삐삐 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 개 웃겨 자기들이 한 건 일단 아니라고 하고 우기기 너희들도 아미 일부만 보고 몇 날 며칠 가수 닮아 빻았다고 염불 외면서 일부 래디컬 페미놈들 빻은 행동은 못 본 척하니ㅋㅋ너희들이 보기에도 엿 같은 발언이긴 하지?. 자긍 \n",
      " 개빡침 \n",
      " 개빡침 \n",
      " 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침 개빡침\n",
      " 개빡침 머했다고 님원고안했져!!!! 유희왕만ㄴ쳐봤지 슬아기야!!! 기ㅣㅣㅣ (훈훈\n",
      " 개빡침 이준호 김준수 땜에 화남ㅋㅋㅋㅋ 보는사람까지덥게만들어섴 \n",
      " 개빡침 ㅌ \n",
      " 개빡침.내가 폭탄을 엘리베이터 밖으로 던졌는데. 폭탄에 자석이 있어서. 다시 돌아왔어\n",
      " 개빡침;ㅠ\n",
      " 개뿔. 빅 엿 먹은 기분임\n",
      " 거짓말도 작작해라. 무슨 백두혈통이노. 김일성 친조부까지 전라도 전주가 뿌리인데. 전주 모악산에 있는 김일성 조상들 묘가 너희가 전라도 전주가 뿌리인 전주김씨 혈통인 걸 입증하는데. 백두혈통은 개뿔.\n",
      " 경ㅁ멸하다는 뜻의 snub나 contempt 같은 거 너무 역겹고. 경멸하다는 despise써야겟ㄷ다. 여혐낭낭단어라서 외우겠네요!!!!! 시 펄\n",
      " 경희대 빻글 제보합니다 미투 운동을 자신의 연애 성공 수단으로 이용하려는 빻은 경희대 남 \n",
      " 고맙긴 개뿔 사과나 해라 이 미친 것들아 언제까지 눈 막 귀 막 할 거야 에로 남불 오지는 씹에리들 너넨 진짜 처맞아야 함 \n",
      " 공용 책상에 이런 게 적히고, 반 안에서 돌려쓰는 일기에 학교 앞에서 병아리나 팔 메가를 년이라는 둥 인신공격당함 게다가 쌍욕 섞인 뒷담도 깐다더라 \n",
      " 관변 단체 국고보조금 싹 다 없애야 합니다. 돈 받고 오는 사람들이 대부분일 텐데. 우리 세금이 저런데 쓰인다 생각하니 피가 거꾸로 솟습니다! ㅆㅂ\n",
      " 광고 모델 잘못 × 광고 모델 잘못 × 광고 모델 잘못 × 광고 모델 잘못 × 광고 모델 잘못× 모르면 외우세요. 지금 이게 모델이랑 뭔 관련이 있냐? 빻 워딩 쓰면서 악바리로 가 내리는 너네 우습고 역겨움\n",
      " 교환 아니 님들아. 가격 제시 왜 해요 플미로 티켓사는 거 멘틀 바사삭 안 당함? 사놓고 사기당했다고 하지말구요.플미충 용돈 왜 주냐고 나 혼자만 플미충잡고 있능곤가ㅜㅅㅜ조온나 힘드네요 누굴 위한 콘서트인지.플미충도 고척에서 콩 열어요? 수고비 왜 줘?\n",
      " 국방부 개빡침 \n",
      " 국방부 ㅉㅉ\n",
      " 군 일과 이후 외출 허용에 대한 여론조사 결과를 실은 기사인데 꼭 이렇게 여자 탓하는 사람들 있음. 여론조사 결과에 형평성 이야기 나오는 거 보면 각 안 나오니? 너무 역겹네 \n",
      " 그 남들 메가를 3년 상 끝난거닠 \n",
      " 그 입 다물라 역겹다 \n",
      " 그 입 다물라 역겹다 뻥 그만 쳐라 국민들을 바보 로아네 꼭 기억하고 심판할 거다 \n",
      " 그 입 다물라 역겹다 뻥이 그만 쳐라 뉴스나 보고 다녀라 국민들을 바보 로아네 꼭 기억하고 심판할 거다 \n",
      " 그냥 그만두시는 게. 어차피 라이브도 못하면서. 아 진짜 저런 생각을 하고 있다는 게 너무 역겹네요;;\n",
      " 그동안 휴가도 제대로 안 주고 빽빽이 스케줄 잡은 게 활동 일찍 접으려고 그런 건가 싶기도 함. 7개월 동안 뽑을 수 있는 거 다 뽑고 슬슬 일하기 귀찮아질 때쯤 대충 접는 거지. 웩 진짜 역겹다.\n",
      " 그래, 내가 웜련이다. 더 이상 코르셋 조이지 않고, 한남들에게 내 밥그릇 양보하지 않고, 냄 져 가들의 성 드립에 웃어주지 않고, 살 걱정에 끼니 거르지 않고, 더치페이 하는 개념 여자친구이지 않고, 비혼 비출산 외치며 절대 자트 닉스에 다시 굴복하지 않는. 나는 웜련이고, 메퇘지며, 꼴페미다.\n",
      " 그러니까. 부계성이 뭐야.ㄷㄷ 6번 리밋 걸리면 사람 어떻게 되는지 알아.? 개 빡침.,.ㄷㄷㄷ\n",
      " 그리고 페이브고 씨제이고 직접적인 본인 새끼들 없어서 괜찮다고 생각하나 본데 그래서 너네가 더 역겹고 싫은 거야\n",
      " 김구라 이경규 같은 한남틀딱 업소 가는 새끼들은 자기들 세력 확장하면서 성소수자라는 이유로 하차? 머 한 민국 꼬락서니 보소\n",
      " 김장훈!!! 가수는 노래로 감동을 주는 것으로 행복을 나누어 가져야 한다. 넘치는 오지랖을 주체 못하겠는가 기부나 독도지킴이는 국민적 공감을 나눌 수 있었다 세월호는 이미 반감을 사고 있는 정치적으로 이용된 초법적 깽판화되었다 좀 나대지 말라\n",
      " 김짼 화이 띵 빻기 보고 싶다!!!!!!!!!.!.!.!\n",
      " 김해 혼종의 도시네 다시 봤다 ㅉㅉ. 샤브 채식 인정\n",
      " 깡 : 깡! 한남은? 패 : 패야 제맛 \n",
      " 난 여자들한테 물건 팔아먹으면서 빻은 짓 하는 새끼들이 제일 보기 싫음 여자들 돈으로 먹고사는 주제에 돈 써주는 여자들을 위대하신 고갱 님이라고 받들진 못할망정 동등한 인간 취급이 이나마도 할 생각이 없다는 게 넘 \n",
      " 남 대통령이 입페미짓하니까 남자 경찰 놈들이 설치지 ㅉㅉ\n",
      " 남류 작가가 쓴 모든 문학작품. 굳이 한남이 주장하는 게 아니라도 일반적으로 띵작이라고 주장되는 게 여혐 쩌는 경우 전 많. 거의 한남이 주장하는 띵작이 띵작으로 떠받들 여지는 경우가 많지만.\n",
      " 남자 새끼들 욕할게 안됨 대리 받고 온 여자애들도 존.나 많네 링 남자 새끼들만 대리 사는 줄 알았더니 의외로 여자들도 많아 역겹\n",
      " 남혐멈 계정 주님 만화를 보고 울고 웃으며 항상 감탄했다. 요즘 내가 힘들어서 더 그랬는지도. 그분 만화에 울고 웃고 공감하고 저장하고 마음 찍은 내가 워마드다. 한남 학살할 예정인 내가 워마드다. 네놈들 다 죽일 내가 워마드다\n",
      " 내가 굳이 영 양예밍한테 너 배운데 cp 하나 못 참고 갑분싸 해서 되겠냐 어휴 ㅉㅉ 이런 말 하고 싶지도 않고 . 맨 플 하고 싶지도 않음 영. 머 그니까 네가 갈 똥길 잘 가시고 . 걸을 때 조신히 걸어서 옆에 사람에게 똥만 튀지 마 . 가는 길 안 말림 영\n",
      " 내가 졸업하면 몇 개는 꼭 한다 진짜 저런 거 볼 때마다 개빡침\n",
      " 내차례때 못 줘가지고 떼구님한탸 편지 전해달라고 좀 부탁했는데 받자마자 그 자리에서 뚝딱 열어서 읽어보기인 냐,,,, ㅠㅁㅠ 눈도 안 보이면서 . 나의 빻은 소리 그득한 편ㄴ지. \n",
      " 냄죠 새끼들은 하등해서 서로 기생 안 하면 못 사는 거 봊나 역겹노\n",
      " 너네 정말 역겹다 매출 올리게 앨범이나 사 이렇게 말하는 게 보여서 더 싫어\n",
      " 너무 웃기다 네임드 진짜 죽이네. 성남 사람들 진짜 쪽팔리겠다. 기껏 시장 뽑아놨더니 세금으로 댓글단이나 돌리고 ㅉㅉㅉ\n",
      " 눈이 티 일하는 꼬락서니 진짜 어휴.\n",
      " 뉴 속 블로그가 개빡침\n",
      " 님들 아쟁 총각 보세요ㅋㅋㅋㅋㅋㅋ 표정도 개빡침\n",
      " ㄷ ㄷㄴ ㄴ ㄷ ㄴㄷㄴ ㄷ ㅈ ㄷ ㄷ ㄷ ㅈ ㄷ ㅅ 말하는 꼬락서니 봐\n",
      " 다음 주에 사장 ㅃㅃ 영 요즘 개빡침\n",
      " 대놓고ㅜ노리는 거 매우 싫어 진짜 으 역겹다\n",
      " 대박 쌤통 대종상 여우주연상 후보 전원 불참하나. 초유 사태 | 다음 연예 \n",
      " 댓글 역겹네 진짜 아어;\n",
      " 댓글창 꼬락서니\n",
      " 돈 안 벌고 뭐 했어. 두 돌 된 아기를 cj에 취직시키고. ㅉㅉ \n",
      " 말하는 꼬락서니 봐봐ㅠㅠㅠ \n",
      " 머가리 빻은 안 신변 z ㅏ 염탐계 ㅅ 날파리 벌레샛키 미리 차단하세요\n",
      " 뭐가 개 빡침? 발가락이 개빡침?\n",
      " 민족당 거머리 같은 년 놈 들!!!\n",
      " 박대 가리 인증이네요 평상시 언행 꼬락서니에서도 느껴지더라고요. 굿즈 파는 거에만 정신 나간 모임 ㅉㅉ\n",
      " 반박 못하니까 꼴 페미 거른다.이래서 욕한다.하는 꼬락서니ㅋㅋㅋㅋㅋ제대로 말로 해보세요 좀 후 꼴페미.극단적.흑흑웅앵웅 하지 마시고 진짜 한남소추6.9느개비스타벅스빨대도둑 이런 거 들으면 극단적을 넘어서서 유약하신 멘틀에 깨져서 개복치처럼 죽어버리실까 두렵네요ㅎㅎ\n",
      " 베댓먹혓어요쌤들진짜개빡침제발\n",
      " 보기 역겹군\n",
      " 비번은 생일 음. 후방 주의. 빻네 모\n",
      " 비판 달게 받고 자중하는데 고작 이틀 잼 양심 어디다가 팔아먹었니 뿜게야 ㅉㅉ\n",
      " 빨간 알바들 징그럽게 달라붙네 거머리 같은 놈들 이재명 알바야? 박원순 알아야? 김무성 알바야 유승민 알바야? 넷 중에서 골라봐. \n",
      " 사과했다는 것도 본인이 기사 나갈 걸 알고 조급해서 한 거 아니냐고 진짜 역겹다\n",
      " 서울대생이 쌌다는 “79년생 한남 정대현” 이야기라는데 얘 169센티인 듯 근데 솔직히 180이하는 루저 발언에 화가 나려면 최소 175 정도는 돼야 하지 않냐 169면 180아래를 몽땅 루저로 퉁쳐준 데 대해 고마워해야 할 수준인데 배은망덕하다 \n",
      " 성괴 d 라인 입죠\n",
      " 세금 삥땅 치우다가 걸린 게 양심수?? 생계형 범죄자들 사면이 당연한 거지 그리고 문 대통령님 지지하지도 않고선 거짓말하지 마 17대 쥐새끼 지지선언 그리고 신틀러 지지한 거 세상이 다 안다 생떼 좀 그만 펴라\n",
      " 세월호 밀양 송전탑 심지어 해군기지까지 온갖 오지랖을 다 부리면서 유독 탈북자 문제에 관해서만 은 아무런 반응을 보이지 않은 편향이 비판의 대상이 되는 것이지요. 아예 영혼 이야기만 하던지\n",
      " 솔까 한 섬유 저들 팁 주거나 하고 싶어도 말하는 꼬락서니 보면 주기 싫어짐 망할 놈들\n",
      " 수법 뻔하죠? 역겹죠?\n",
      " 스 엠 꼬락서니\n",
      " 싄햠 씹고 연뎌됵 싕크1즈 다 쳐씹은 꼬락서니\n",
      " 시럽 마빡 데미 선수 너희 방송 두통 병수 낙토 자니 언론 빻죠 깔만 생각 종인 수녀 웅양 조조 잔치 비자 끼니 둥둥 망고 웨지 회향 새별 아영 여명 쓰니 진솔 오 나 똑똑해\n",
      " 시밬 나 1밖에 안쳤는데 14변려 뭐냐?? ㅌ 진짜 역겹다 환멸 나 진짜 \n",
      " 신경 쓰지 마세요 대부님. 이 바닥에 오지랖 종자들 득실거리는 거 잘 아시잖아요. 주목받고 싶은 관심병 종자들도 마찬가지고요. 날도 추운데 날파리가 따뜻한 곳을 못 찾았나 봐요.\n",
      " 신상 개털리넼 무섭다 이 기세로 전문적으로 프로미 붙여 파는 플미충들과 암표상들도 털렸으면 좋겠다.\n",
      " 실은 권태혁 하는 말마다 화나게 비꼬는 개객기였는데 어쩌다 저렇게 오지랖 넓고 잔정 떠는 게으름뱅이가 되어가지고는.ㅎㅎㅎ캐붕의 좋은 예입니다.\n",
      " 쌤통이다 밥맛 떨어져 \n",
      " 쌤통이다 양 키들 잘ㄷ 졌다 \n",
      " 쌤통이야쌤통>,.< 붕어 영애 술꾼 영애 폭행 영애 뭐이리만냐. \n",
      " 아 센 개빡침 \n",
      " 아 이래서 메가를 짓이 효과 있다니까??!! 그전까진 여자는 남자보다 지능 낮다고 하더니 한남 뚜까패니까 이제 드디어!!! 여남 지능이 동등하대!!!! 자 평등은 이렇게 실현되는 거야!!!\n",
      " 아 진짜 역겹다 못해 더러웤 ㅁ 흥분할만하지요\n",
      " 아, 흐. 아이작. 거기 잠깐만.! 왜. 또. 갈 것 같아. 잠시만. 실시간 신음 방송 일부러 마이크도 아래로 내려서 찌걱이는 소리 다 들리게 해주는 bj 제 키엘님. 아이작 개빡침.\n",
      " 아니 외국어 배우라는 엘프가 정작 한국어는 못씀. 한국말로 지끼셈 하여간 해외 빠순이들은 무식 그 자체 ㅉㅉ\n",
      " 아니 정말 한 남 모멘트인 게 브까라 원작에서 표도르는 아버지로서의 면모 1도 없는 스레 기고 작가가 가장 힘주어 말하는 게 아버지의 역할을 하지 못한 자는 아버지라고 할 수 없다 인제 그걸 5 서 1혁이 어떻게 만들어놨게요? >>너희가 태어나서 좋았어<<\n",
      " 아니 학교에서 게임하지 말라고 그렇게 얘기했는데 과제 1도 안 하고 게임만 처하고 이번 달부터 열심히 할 거야. 이런 말 해놓고 3일이 지났는데도 꼬락서니 그대로고 그래서 게임 깔려 잇는 거 지웠더니 하는 소리가 쉬는 시간에 한 건데 왜구래 이래 미친 거 아니가 여기 학교 왜 왔나 싶음\n",
      " 아흑.성괴. ㅜㅜ\n",
      " 알감자 무한 사랑  이 징한 인간아 거머리 같은 알감자 집착쟁이 같으니라고!!! \n",
      " 어이구ㆍㆍ에라 ㆍㆍ개뿔이다ㆍ 이럴진대 ㆍㆍㆍ세상 웃기는 짬뽕들 네 덜이 내다 버린 작금의 대한민국을 어찌할 거니 잉 이 조무래기 같은 인사 덜아 고냥 콱 오.커 발루 트위스트와 디스코 쳐버릴까 부다 이 잡통소덜을ㆍㆍ\n",
      " 얼마 전엔 일본 av 배우가 한국에서 데뷔하고 이번엔 오마이걸 신곡이 로리타 콘셉트가 명백한데도 아무런 피드백이 없습니다. 이대로 가만히 보고만 있으면 얼마 안 가 한국 아이돌 판도 아래 사진 같은 꼬락서니가 될 겁니다. 아래 일본 아이돌 그룹 멤버 한 명은 저 안무에 큰 수치심을 \n",
      " 여러분 그냥이 새끼 블록 하세요 보니까 개노 답임,, 공부하고 있는 게 법 쪽이라는데 법은 개뿔 이딴 짓이나 하고 앉아있습니다 빨리 블록 해주세요 \n",
      " 여성 직원을 많이 뽑으면 대잖아 멍청한 한남 냄져들아 \n",
      " 여자 앵커 옷 우중충하다고 표정 우울하다고 대뜸 욕하는 전화하는 한남\n",
      " 역겹고 더러운 새끼들 다른 사람들의 소중한 마음 가지고 장난치는 거 아니다\n",
      " 역겹고 한심한 딴따라들 . 주관도 없는 것들\n",
      " 역겹다\n",
      " 역겹다\n",
      " 역겹다!! 나름 논리로 배설물을 설파하고 계신 듯싶어 역겹네요!! 그 정도 지식인이면 오류 검증은 스스로 할 수 있지 않나? 안 하는 이유가 궁금하네? 돈? 권력? 인기? 명예?\n",
      " 역자 처음 하는 새끼 개빡침 \n",
      " 염소용 개쎄긴 개뿔; \n",
      " 영어 잘 못하는 나도 알겠구먼. 배웠다는 기자 놈들. 완전 콩글리시 하네. 기자 놈들 부모님이 불쌍하다. 너희 같은 놈들을 자식으로 둬서. 부끄럽지 않냐?. 권력에 빌붙은 거머리 같은 기자 놈들.\n",
      " 오빠 오지랖시전 너무 귀엽고 웃기닼 마지막에 상아가 길면 민폐래 그게 무슨 말이야ㅋㅋㅋㅋㅋ진짜 존웃 \n",
      " 오지랖 부리지 마 네 앞길이나 걱정해 \n",
      " 오지랖도 넓기도 하시네 우리나라 물고기 죽이고 환경 망친 것도 부족하시나 글로벌하게 다른 나라까지 물고기 떼죽음하시겠다 자기 앞가림도 못하는 주제에 난 나라 걱정까지 ㅎㅎㅎㅎ 아서라 쥐새끼 창피하다 옆 보좌관들 말려라 무엇 하는 얼치기들인가\n",
      " 와 이 좋은 기사에 첫 댓글 수준 진짜 흔한 고생하는 남자인 나. 일도 안 하는데 삐지고 불만 많은 여자. 구도 너무 뻔한 클래식 여혐이다 아 빻은 댓글 달면 손에서 폭탄 터졌으면 좋겠다. \n",
      " 요즘 우울하고. 맨날 화나잇는 사람. 블뱨 생각하면. 또 짜증 남. 남덕. 오지 마. 개빡침.\n",
      " 요즘 학교에 너무 빻은 소리가 많기에 \n",
      " 웃기죠 그리고 솔까 노통문통 비하하고 욕하는 사람이 한둘도 아니고 말입니다. 자기도 시간 끌다가 고발해서 경선 이후에 나 결과가 나올 텐데 진정성이 1도 느껴지지 않습니다. 그냥 경선 기간 계속 흙탕물 튀겨서 지지율 깎아먹자 수작으로 보입니다.\n",
      " 워너블 제발 플미충들 다 신고하자 선예매 끝나고 일반 예매도 끝나서 양도 구한다는 글 양도한다는 글 우르르 나오는데 가고 싶은 팬심 이용해서 사기 치는 놈들 꼭 있다고 사기당하면 결국 돈만 날리는 거잖아 플미충들 깡그리 다 신고하자 제발\n",
      " 원래 숏컷인 애들만 인증한다는 한 남 새끼들 있길래 제업 \n",
      " 웜련.노. 괄로해 주심 바로 맞괄 갑니다 미개한 유전자 따위 필요 없노 마! 한남은 다 최선을 다해 재기 해리ㅏ 일이야.\n",
      " 위선자 자식\n",
      " 이건 빻은 것도 아니고 머리가 나쁜 거잖아. 본인 멍청하다고 광고하는 걸 길게도 써놨네 \n",
      " 이러고도 버티는 것 보면 가관이다. 철면피가 따로 없네! 자식들 보기 부끄럽지 않나?\n",
      " 이런 것 다 문알충이 까놓은 문베충들 수작질입니다. 전혀 신경 쓸 것 없음. 박근혜 친박 패거리와 똑같은 짓거리하네. 곧 탄핵 당하겠는걸!\n",
      " 이런 삐삐 개 삐삐 이런 삐삐삐삐삐 씨삐삐 비플렛삐삐ㅣㅂ ㅇ요정도입니다.\n",
      " 이제 막 수면 위로 떠오르기 시작한 공개적 래디컬 페미들의 싹을 밟으려는 수작이 눈에 훤히 보인다. 그 졸렬한 새끼들의 주작이 성공하게도 두지 않을 거지만 만약 그렇게 되더라도 우리가 포기하는 일은 없을 것이다.\n",
      " 이제까지 `위안부 문제`에 대해 일언반구도 없었던 `문재인`의 위선적인 `위안부 정치 공세`로 더럽고, 추악한 행태,,,,, \n",
      " 인성빻맨 김상운 걔 오너입니다 \n",
      " 일러레 메가를 어쩌고 하던 애들이 일러 레카 고소한다니까 글 삭 튀하네 으이그 ㅉㅉ\n",
      " 입만 열면 v3 만들었다 4차 산업혁명 말하는 안 신 병자가 어르신들 폴더 폰 쓰냐?? 앱 깔면 다 나오 궁 미세먼지 심한 날은 경보 문자 뜬다 모지리.모지리.ㅉㅉ \n",
      " 자꾸 말 끝에 노 붙일 때부터 알아봤습니다. 개마 붙나 소환사 수준 ㅉㅉ\n",
      " 재우개빡침\n",
      " 저 번호로 전화 걸었더니 이 세금 낭비 중들이 전화선을 뽑아놨어 \n",
      " 저번에 얻은 네 핸드폰 번호로 전화를 걸어 당장 오지 않으면 후 두려 패겠다고 하니 영문을 모른 채 온 널 앞세워 너의 집으로 쳐들어온 지 벌써 하루. 협박은 옳지 않긴 했지만 지금 내가 똥오줌 가릴 처지냐. 꼬락서니가 이 모양인데. 제 귀와 꼬리를 보고 어리둥절한 표정을 짓는 널 보고는\n",
      " 정말 단순하게 생각해도 연장이 답인데 왜 그걸 모르냐고 멤버들 의견이라는 소리 하지 마 진짜 역겹다\n",
      " 정치인이 메가이냐고 묻는 거 첨 봄 한남인가요? \n",
      " 정확한 이유 없이 넘겨짚기로 고학년은 나를 ‘메가를’로 지목했고, 그 말은 곧 모두에게 퍼졌다. 아무도 이런 말이 퍼진다고 나에게 바로 이야기해 주지 읺았고 내가 알아챘을 땐 모두 자기들끼리 사실을 확정시켰으며 나를 꺼리고 있었다. 너희들이 말하는 매갈이 뭔지는\n",
      " 제의나 개빡침 \n",
      " 조민기가 미투 때문에 죽었다고 하는 사람 특징→한남이고 자기도 성범죄 저지름 이거 진짜 팩트, 미투 운동 반대하는 한남들이 반대하는 이유가 자신이 저지른 범죄 밝혀질까 봐 or 범죄 못 저지를까 봐 임.\n",
      " 죄송합니다 저 씹틀딱입니다 디시 2002년부터 했어요. 개죽이 왜 날 뷁 이런 거 알아요. \n",
      " 죠 팔 사과받으면 개 큰일 날 뻔.가해자가 부심 부리는 거 오지고 너무 역겹고.ㅠㅠ\n",
      " 중학생에 쳐 막자 봐야 틀딱빼고묵념하려나 어디 엑소를 건드려 조중동수 꼴 기러기들 삼성 돈이나 먹고 돼지 흥분제 공천이나 받아\n",
      " 지 들면 상 빻았노 응 서비스 응원봉 슬로건 반입금지 데여 ?? \n",
      " 지난 대선 때도 공약 만들기 위해 엄마들과 간담회도 많이 갖고 병설유치원 증원 책을 냈고, 보육대란 없애고자 전액 국고지원을 공약도 했었는데, 빌어먹을 심상정과 문재인 이가 개뿔 알지도 못하면서 멍청한 것\n",
      " 지질한 돈벌레 안초 덩이 저런 인간 밑에서 온갖 완장 차고 불법 특혜를 누렸으니 하는 짓이 그 모양 그 꼴이지 돈다발로 아들 학점 조작시킨 부모의 밥상머리 교육도 어련했겠으며 ㅉㅉ 엠비 아바타는 주인 옥바라지나 해라 30년 동안\n",
      " 지희야. 진짜 더럽고 역겹네.\n",
      " 직언이 뭐 어쩌고 어째? 이랬던 유승민이야 한번 들어봐ㅍ 유승민은 비서실장하고 그렇게 오랫동안 박근혜 옆에 있었으면서 최순실 존재 정말 몰랐어? 유승민은 이렇게 된 거 책임 없냐? 그동안 뭐 하다가 이제 와서 죽일 듯이 욕하는 유승민 꼬락서니가 참 남루하다ㅉ \n",
      " 진석사는 진정 정대세를 두둔하려고 하는 게 아니고 진중권 씨 말꼬리 잡아 비난하려는 욕심에 문제를 더 크게 키운 형국인 듯 오지랖이 하늘을 찌른다고 봐야 하나 뭐라고 봐야 하는지. 쯔쯧\n",
      " 진심 이거 그리면서 지금도 어이없는 게 내가 뭐 욕을 하거나 무례를 끼친 것도 아니고 그냥 고작 애교 안 부린 거랑 왜요?라고 물어본 거뿐인데 그거 갖고 서운하다느니 하면서 뒤에서 말한 아줌마나 그걸 갖고 뭐라 하는 엄마나 ㅉㅉ\n",
      " 진짜 남초에서 동원 얼굴 까는 거 몇 년은 된 것 같은데 몇 년 동안 내 감정 그냥 웃김이고 아무 타격 없음. 너희들 어떻게 생겼을지 눈에 훤하다 한남들 자 적다는 과학이다 \n",
      " ㅉㅉ 나한테 아디 준거 평생 후회감이 거다\n",
      " 찔리네요 배신 당하고 오랜 시간 지난 저는 저런 생각을 하게 되었지만 사실 딱 그 순간엔 저 새비가 존비 개 삐삐하고 있네.\n",
      " 참 나 뭐 사연 얘기야 허락받으면 괜찮다고 하지만 그 사람들이 들으면서 신기하다 이상하다 나아가서 역겹다 이해 안 된다 같은 생각할 거 알아서 착잡하네요\n",
      " 참 못났다 못났어 세상이 바뀌고 당이 바뀐 걸 당신네들만 모르고 있는 거야?? 돌려먹기 안되니 이젠 협박질을?? 저놈의 친목질 계빠질 꼬락서니 보면 전략공천 없애야지 능력 앞세워 경선 치르셔들\n",
      " 청소년 랟펨입니다! 쓰까에 있다가 래디컬로 넘어왔습니다.7 한남 패는 거 좋아합니다! 생물학적 여성만 받고 한남동 티젠 다 안 받습니다.7 혹시라도 제가 빻은 말 하면 가차 없이 패주십쇼.7 흔적 남기시면 허벌 괄호 하겠습니다!\n",
      " 초면에 죄송한데 아무리 봐도 댄 0싱 0 빌 0리 0님 얘기 같아서요ㅠ오지랖 같을까 봐 안 하려 했는데 팬아 터 님 그림까지 끌고 와 욕하는 게 어이가 없어서 멘션 보냅니다 \n",
      " 춘사장님아사업망해서그지되는게꿈이가사업신이왔는데 고작 2.3년 때문에 자기 발온 사업 신을 발로 찬다ㅉㅉ 복도 지지리 없다 \n",
      " 치유 커는 개뿔ㄹ 극비리 안 뛸 거야. 네 결론은 아리에 오너입니다 사지 찢겨 죽었다죠! \n",
      " ㅋㅋㅋㅋㅋㅋ말하는 꼬락서니 넘구려 아 짜증 나 미칠 것 같아 ㅎ \n",
      " 카드 받고 개 억울 개빡침…주심 말도 안된다고\n",
      " 캐시카우 버리는 꼬락서니란\n",
      " 커맨더 한동안 빛도 못 보다가 이제 0티어 되니까 귀신같이 까는 사람들 몰리는 거 보면 그냥 던파 유저 중에 이상한 놈들 매우 많긴 한 듯 키우지도 않는 직업이긴 하지만 역겹네\n",
      " 켘 틀딱들이 저 와꾸로 포즈 잡고 애쓴다 애써ㅛㅛ사진 퍼 오실 때 시력 민이 하셨겠습니다 ㅛㅛ \n",
      " 코멘트 너무 웃기죠 꼬락서니가. \n",
      " 콘서트 플미충 극협. \n",
      " 크렉 트윅 크릭 전등이 깜박거리다가 전반적으로 빻은 소재. 아무 내용도 퇴고도 개연성도 없다…왜 사는지…\n",
      " 키는 어느 정도에서 멈추고 나이는 계속 늘어나니까 틀 딱일 수락 로리 캐가 되는 건데 어중간한 틀딱층은 누님이가 많고 완전정신나간틀딱들은 로리 캐만 찾게 되니 이걸 만든 새끼는 급식 아니면 완전히 정신 나간 틀 딱이겠군\n",
      " 킹스맨 여혐 관련해서 딱 하나만 스포 들었을 때도 아주 가관이었는데 지금 여캐 관련 스포를 모두 듣고 나니 정말 매튜 본이 작정하고 내 영화 깐 페미년들아 엿 먹어라 하고 알탕 끓였다는 거 잘 알겠고욬 이렇게 악의적 빻남이라니요.\n",
      " ㅌ 저도 비행기 타면 슬리퍼 신고 클렌징 티슈로 얼굴 지우고 창가랑 머리 사이에 머리 끼우고 자서 도착하면 꼬락서니가 ㅎ 말이 아님 ,, 어기적 . 어기적 .\n",
      " ㅌㅌㅌㅌ 한남들은 보안율 0% 되는 거 아니오. \n",
      " 테런 이번 율리우스 상자 확률이라는데 진짜 현질십망겜 다 됐냐 확률 꼬라지봐 ㅌ \n",
      " 트친소 맘 박았다가 내 닉 꼬락서니 보고 취소함 (죄송합니다\n",
      " 틀 딱이니 많이 쓸 수 있을 듯?\n",
      " 틀딱 손석희 제대로 멕였네. \n",
      " 틀딱놈들 말투 봊나웃김 너 이거 캡처한다! \n",
      " 팔이 마시라! 문재인 사진 앞세우고, 문재인 사진 내걸고, 문재인 문재인 내세우는 선거철이면 개나 소나 하는 그런 짓거리! 역겹다 못해 이젠 토할 정돕니다. \n",
      " 페미니스트 친구에게 갓 건배에 대해 어떻게 생각하냐며 학교 남자애들이 찾아왔다. 그렇다고 사람을 죽이려 하면 안 된다 했다가 매갈이 되었다. 남자애들과 메가를 들 이 싸운다는 소문을 듣고 애들이 몰려들었다. 남자들이 쟤네가 걔네냐며 손가락질하고 웃고 지나갔다.\n",
      " 페이브는 양심이 1도이라도 있으면 고퀄리티라고 하지 마라 단어에 뜻을모르면쓰지마우리젭비들울리며페이브너님들안되라고빌고또빌고할거야 이쁜 애들 맘고생 도시키 많이 내들이 먼 데 어른이면 어른답게 나잇값 해요 욕심만큼 사업을 잘하면 또 몰라 기회가와도 잡을 줄 모르고 너 님 정신 차려\n",
      " 표창원…네가 존경해 마지않는 박정희는 4.3 희생자는 사람 취급도 안 했단다…이 한심한 인간아…ㅉㅉㅉ \n",
      " 플미충 나가죽어\n",
      " 하긴 교사들 중에 안티 페미니스트가 왜 없겠냐만. 상대를 무지한 사람으로 낮잡아 보고 맨스 플레인 하는 게 교사로서 학생을 대하는 태도와 겹치니 더 역겹네.\n",
      " 하이에나, 거머리 같은 놈들. 미꾸라지 같은 놈들이 대한민국을 온통 붉은 물로 도배를 해났으니, 정부의 힘도 한계가 있습니다. 이제 온 국민이 나서서 이 난장판을 하나씩 청소해 나가야 합니다. 행동으로 보여줍시다!!\n",
      " 한 남 걸러요 눈팅많이 하지만 활동 많이 하도록 노력할게요 디엠, 멘션 환영.ㅇ. 성소수자에 대해 편견 안 가지려고 노력하고 있습니다 선팔=맞팔 도멘 죄송해하지 마세요!!(근데 내가 트위터 잘 안 올려서 죄송할 일은 없을 듯 미자\n",
      " 한국 여자 모두 메가를, 워마드임. 네 엄마 네 여자친구 네 누나 네 여동생 네 여서 친 다 워마드 한다. 한국 여자 모두 다 워마드니까 그냥 포기해\n",
      " 한남 재기가 시급하다 \n",
      " 한남들 화나서 부들거리노 이기야 \n",
      " 한남들의 그림 잘 그리시네요 여자 아닌 줄 알았어요. <하는 거 솔직히 80퍼 이상이 여자는 순정만 그릴 줄 안다는 철 지난 사상 가지고 도태된새끼들아닌가 우린 한남들 그림 보면 딱 남자인 거 티나고요 . 쟤네 머릿속에선 >>메카 잘 그리면 여자 아님<<이거 너무 빼 박 잘 보임 ㅠㅠ멍청한 박대 가리들\n",
      " 한남만 골라 담는 맛이 그리 좋아.\n",
      " 핼러윈 때 틀딱춤 추면서 리겜했던거 \n",
      " 헤이트를 스포츠로 즐기면서 자기가 힙한 줄 아는 sns 인간이 저질 농담 2절 3절 하면서 웃기지 않냐고 히죽대는 술 취한 한남 생물체와 다를 게 무엇인지\n",
      " 현실 남매 원맥 덕촌 보고 싶어서. 아 오빠 내 초콜릿 네가 처먹었지 야 처먹었다니 말이 심하다 오빠한테 오빠는 개뿔 난 저런 못생긴 오빠 둔 적 없어 또 마음에도 없는 소리 하시네 우리 동생님 또 이 오빠가 한얼굴 하지? 닥치고 내 초콜릿 뱉어내 다시 사다 놔 내 킨더 초콜릿 \n",
      " 협박해서 상황 불리해지니까 이제 미투랍시며 나서냐? 역겹다 진짜.\n",
      " 홍어를 딱 부들부들 쪽바리 사학자 말이나 신봉하는 게 홍어들아 \n",
      " 회장 틀딱 얼굴 보고 가세요 이런 놈들헌티 돈 쓰는 거 아닙니다 \n",
      " 회칠한 무덤 같은 위선자 \n",
      "＂단 원고 교실 존치 문제 더 미룰 수 없다＂ 개 삐삐들아. 진실은 밝히고 난 뒤에 나 얘기하자\n",
      "＂좋은 대학 못 가면 성을 팔수도 있다고 훈화한 경남 창원의 여자고등학교 교장 ㅡ돼지 발정제가 경남도지사였고 보온병 포탄이 현 창원시장이고 비아그라를 세금으로 사 먹는 자가 대통령이었던 도시답습니다\n",
      "#4 동거하는 넨년 보고 싶다 둘 다 배운데 황은 공백기 궍은 곧 영화 개봉을 앞둔 상태 근데 궍 상대 배우랑 열애설 난다 궍 집 왔는데 현관 앞에 나와 있는 황 보고 눈 피해라 노이즈 마케팅인 걸 형이 모를 리가 없고 이해해 주겠지 싶었는데 황 개빡침 -나가. \n",
      "% 찬성합니다 하루빨리 처리해 주십시오 국민 세금 축내는 밥벌레들 빨리 집으로. 무한  \n",
      "(. 저 새끼가 뒤지려고. 말하는 꼬락서니 봐라? 뚫린 입이라고 못하는 말이 없네? 형 아 괜찮아요? 형아 반겨주는 멍멍이 여기 있는데(헤실헤실\n",
      "(4 수차례 노무현 대통령 묘역에 참배하는 나로서는, 이재명이란 사람의 봉하 마을행 자체가 무척 화나고 역겹습니다. 하물며 절대다수 시민은 그 참담한 마음이 더 클 겁니다. 만약, 이재명 논란 발생 직후, 재단이 좀 더 일찍 성명을 발표했더라면, 지금의 논란이 현저히 줄었을지도 모릅니다.\n",
      "(개빡침 \n",
      "(개빡침 \n",
      "(상 침묵 뛰기 전 : 헤헷 로그 뺨도 겁나치고 친구도 만들고 사랑을 꼭 할 거야*.*.!! (상 침묵 러닝 중 : 뒤지고 싶다 내 캐는 시비 충인가 사랑은 개뿔 \n",
      "(속보 문재인의 대북특사 성과 나왔다 핵무력 찾고 주접떤다. 개뿔도 없는 거 다 아는데 그거 껴안고 죽어라 문가 김가 그 졸개들까지 며칠 안 남았다. 지나침은 모자람만 못한 거란다.\n",
      "(스포주의 월드 워 z 광역 어그로녀 보고 개빡침 \n",
      "(스피커폰 안 해도 다 들림 (지금 체육 선생님 아버지 개빡침 이 *같은 **가 기껏 키워놨더니 학교에 가서 소꿉장난이나 하고 **이야! (멘틀 깨지는 체육 선생님\n",
      "(슥 둘러보더니 역겹다는 듯한 표정을 지으며 사람이 없는 곳으로 사라진다\n",
      "(역겹다,,\n",
      "(이 상황들은 대체 뭐야. 더러워, 더러워, 더러워, 더러워, 더러워. 그냥 다 역겹다고. 여기서 나가게 해줘. 나도 데려가 줘요.\n",
      "(제보 엄마를 밥해주는 사람 취급하는 놈 댓글에는 그냥 여자를 밥해주는 사람 취급하는 놈 ;;;; 진짜 연대에 타 그냥 한남밭이에요ㅠㅠㅠ \n",
      "(펌 체납 세금 들통나면 납부한다고 합니다. 국적 포기 들통나면 국적 취득한다고 합니다. 군 면제받은 것 들통나면 탄원서 있다고 우깁니다. 전향도 않는 주사파 녀석이 애국하고 싶다고 합니다 문재인 정부의 도덕성은 이중적이고 참 파렴치합니다.\n",
      "(한결같이 빻은 취향 \n",
      "* 와, 진짜 역겹네.\n",
      "*예상은 했지만. 역겹습니다.\n",
      "*제보 부산대에는 페미 같은 거 없음?? 링 그딴 년들 없으면 좋겠다 반수생으로서 진짜 -있는데 다 진압됨요 ㅎㅎ 고소 먹이니 취하해달라고 즈그 아빠까지 전화 옴 한 남한 남 거리더니 지 아쉬우면 남자들한테 매달리는 게 페미년들 현실 ㅎㅎ \n",
      "*제보* 에타 게시판에 페미글 올라온다고 에브리 타임 앱 리뷰에다 별점 테러 한 한 남들 세상 졸렬 \n",
      "*제보* 한남들처럼 말 많은 존재는 제발 공공장소에 나오는 걸 삼가주세요. 그 와꾸 보기도 지긋지긋하고 옆에 있으면 살인 충동이 들어요 법 블레스 유 \n",
      ", 행정관, 당신이 끼어있는 세상이 너무 빨갛구나. 보기가 정말 역겹다. 대한민국 국민을 위해 안구정화가 시급히 필요하다. 2018년 4월 4일은 내일은 국민 절대 반감 탁현민이 공직 사임하는 날이다. \n",
      ". 네놈 표정이 역겹다는 얼굴이었다. (팔을 툭툭 털고. 최악이야. 청구 등 어 놈.\n",
      ". 제보가 계속 들어오는데. 야 뒷개로 욕하지마썅노마 뭐? 손을 안 씻어?? 야 손 안 씻기는 개뿔 손 씻고 밑에까지 씻었어 티브이 소리 개 빵빵하게 틀어놓고 물소리가들리닠 \n",
      ".아 그건가? 사람 밑바닥 들춰내는 게 재밌으신가 봐. 당신 때문에 울고 화내고 짜증 내는 걸 보는 게 재밌어? 즐거워? 다른 사람을 소중하게 대하는 방법, 전혀 몰라? .역겹고 짜증 나니까 이제 진짜 안녕하자.\n",
      ".역겹군.\n",
      ": 박원순 부인 얼굴 기억나시나요? 정말 성괴죠. 모르긴 몰라도 그 정도 성괴 얼굴 만들려면 . 수억 들었을 겁니다. 성괴? \n",
      ": 웃고 있는 박원순 부인 강난희 싸진 빻은 성괴\n",
      ":시사저널이 개념 기사를 제대로 쓰네. 아이폰 단말기의 문제가 아니라, 이통사, 제조사, 기관이 국민들의 피를 빨아먹는구나! 거머리 같은 놈들!\n",
      ";;;;;;자야 되는데 잠도 안 오고 지금까지 강동호가 예능이든 뭐든 보여줬던 가식적 모멘트들이 생각나서 너무 역겹다 진짜 구토 나올 지경\n",
      "? 사발 라시아 꼬락서니 왜 이래 \n",
      "?? 여자는 무슨 남편 아빠 아들 홍삼 사다 먹이며 수발드는 존재야???? 응원은 개뿔 당신의 노예생활을 응원하는 거야??? \n",
      "????? exo 깜놀 개깜놀 화남 개빡침 \n",
      "???????? 아니 어쩌라고요 님 생각은 님 퍼블릭에 가서 싸세요 . 인터넷 공개적인 소셜네트워크서비스에 이 무슨 폐쇄적인 틀 딱하고 신지 ㅎㅎ<- 저한테 알림이 오는데 뭘 바랍니까 \n",
      "????????? 머가 역겹죠 ㅡㅡ\n",
      "?역시 남자 새끼들 가성비충 ㅉㅉ\n",
      "[ js한테 고추 빨게 해서 잡혔는데 질문 있어? [서이 전용] 아동 성범죄자가 세운 스레입니다 매우 역겹고 분노를 부르는 내용 관람 주의 \n",
      "[10/14 입고된 새 책들1] <붉은 선> 홍승희 <생각하는 여자는 괴물과 함께 잠을 잔다> 김은주 <온갖 무례와 오지랖을 뒤로하고 페미니스트로 살아가기> 화사 외 <여혐, 여자가 뭘 어쨌다고> 서민 <다시, 페미니즘> 이충현 <딸에 대하여> 김혜진 \n",
      "[ please] 아이고 노답들;;;;;;;; 플미충들아 돈 벌고 싶으면 아이돌 팔아서 돈 벌지 말고 알바를 해;;;;;;;;;; 진짜 뭐 하는 짓이야 쪽팔리지도 않냐 이렇게 돈 버려고 가입한 거면 너네가 공식 4기 아가 새라고 해도 되냐?? \n",
      "[개띵문] .요즘엔 여자들이 더 편하지. 여자들 쉽게 살면서 왜 남현이랑 페미함? 남자들만 힘든 일하고 자기들은 쉬운 일만 하고. 오히려 역으로 불평등한 거 아냐?.라고 하는 빻은 새끼들한테 앞으로 해줄 말. \n",
      "[게릴라 데이트 일반 남자 후기] 정지훈 때문에 길 마비됨 ㅡㅡ 개빡침 근데 즤젼잘생겨서 더 화남 괴리감 쥐잔 느껴져서 열 폭도 안되더라. 반박 불가 리얼 팩트 r e a l f a c t (비개 펌 \n",
      "[공유] - 민주당 여성 의원들 “광역자치단체장 여성 전략공천하라”, 미친 소리 하고 자빠졌다. 최초의 여성 대통령 나왔는데 나라 꼬락서니가 어떻게 되었더라\n",
      "[김종필] 대통령 되면 북한 엘 젤 먼저 가겠다니. 기가 막힌다. 정신이 제대로 박힌 색긴가 호남표에 이어 충청표까지 날려보낸 대표 노랑이. 고거 쌤통이다.\n",
      "[뉴스 zum] [한수진의 sbs 전망대] 이인제 “임금피크제, 기성세대 아들딸 위한 것” 국회의원을 비롯한 정치꾼들부터 줄여라! 이 거머리 같은 놈들아!\n",
      "[단독] 대통령 측 이정미 후임 지명한다면 헌재 변론종결 안돼 갈수록 가관이다. 양승태 대법관은 탄핵 판국에 걸 떡 되는 거야? 아주 질기고 거머리 같은 놈들 최종 변론기일을 27일로 양보해 주지 말아야 하는데 \n",
      "[단독] 명분 찾던 안철수, 7년 전 박원순에 양보 전 불출마 결심 | 다음 뉴스 인기가 천정부지였으니 대통령 생각이 났겠지. 그동안 아름다운 양보라 개사기 친 거 들통 ㅉㅉ\n",
      "[단독] 박근혜, 국정원 특활비 일부 내곡동 집 매입에 사용 의혹 | 다음 뉴스 국민 세금을 자기 돈처럼 썼네 무엇을 상상하든 그 이상이다 정말. 빛내서 집 사라는 최경환이나 503년이나 국민들 피 빨아먹는 거머리 같은 것들 ㅉㅉㅉ 쥐새끼 503년은 무기징역 100년 감이다\n",
      "[단독]세월호 국민적 아픔을 왜곡한 문자 퍼트린 공기업 임원 세금 처먹는 악마네 저 새끼\n",
      "[밀착 카메라] 기숙사 반대 대학가 주민들. 속 사정은? 자기들 불로소득 올리려 학생들에게 비싼 돈 갈취해 먹고살겠다는 게 말이냐 발이냐. 거머리 같은 족속들!\n",
      "[박근혜 징역 24년] 최순실 선고와 판박이. 별개 범죄 5개 모두 유죄로 더해져 | 다음 뉴스 순 우리 그네는 처벌해도 재용이는 손도 못 대는 판사들. 존경하는 판사님은 개뿔 판사 새끼들 재용이 풀어주려고 빨개벗고 덤비는 꼬락서니들 봐라. 판사 새끼들아 창피하지 않냐.\n",
      "[속보]바른 정당, 김명수 인준안 반대 표결 당론 확정 명불허전 ㅎㅎ 발정 당과 합체해라 얼렁!! 국정 마비시키고 세금 처먹는 인간ㅆㄹ 들. 국정 농단 국가전복의 적폐 집단들 헌재 해산 청구해야!!! \n",
      "[송영대의 독백] 활발하고 적극적이고 친화력이 좋은 분들이 있다. 그중 오지랖이 넓고, 부담스러울 정도로 들이대고, 나대는 분들이 있다. 그분들의 활약은 차분하고 조용한 분들에게 거부감을 일으킬 수도 있다. 적당히 들이대고, 나댔으면 좋겠다. 적당히.\n",
      "[전문] 안철수 출마 선언문 나는 야권의 대표 선수 이놈은 구토 나올라 한다 역겹다. 그만 보고 싶다\n",
      "[취재파일] 노승일 국회의원 되는 게 첫 번째 목표 이유는? 최순실 국정 농단 청문회에 처음 참석했던 날, 노 전 부장은 기자들에게 이렇게 말했습니다. 박근혜란 거대한 산, 거머리 같은 최순실, 그리고 삼성과 싸워야 합니다.\n",
      "[태평로] 南勞黨 폭동 떠받드는 대한민국역사박물관 (출처 : 조선일보 | 네이버 뉴스 나라 꼬락서니 참.인민 못되어 안달 난 연놈들.\n",
      ". 팬이니까 거른다 <는 게 실제로 있다고요?! 빻음도 정도가 있지;; 미성숙으로 치부하기에도 쪽팔린 수준. 역으로 그런 빻대 가리 들이나 걸러져야 함;\n",
      ".린이라고 부르면서 자기가 제일 잘한 판이나 많은 플레이 타임 부르는 게인 부심 진짜 역겹다\n",
      ".곤지암 후기. 인성 빻은 한남들 얼빡샷+발연기 보기 매우 힘들고 2/3 정도까지 이걸 내가 영화관에서 보다니 유튜브에 있어도 안 보겠다 하다가 후반부에 무서운 거 몰아쳐서 다리 풀려서 나옴\n",
      "‘남자는 계속 발기된 채면 성기가 너무 아프다’고 찡찡대서 동정 얻듯 그렇게 ‘이건 다 네 탓’ 하는 새끼들도 다 죽었으면 좋겠다. 진심으로. 나는 단순 발기가 아프지 않다는 걸 얼마 전에야 트위터에서 알았고, 개 같은 새끼들의 모조리 똑같은 수작에 치가 떨린다.\n",
      "‘분노’라는 감정은 특히 좋지 않아. 때로는 자신이 자신이 아니게 되기 때문이다. 그럼…자신이라는 ‘개체’가 상이한다는 것은 어떤 상태일까. 생각만 해도 역겹구나.\n",
      "‘쎈언니’컨셉을 소비하는 것도 유아 퇴행적인 콘셉트보다 나은 선택이 될 수 없음을 이야기한 것인데 딱 사유가 거기까지다. 페미니즘의 역사에 대해 단 한 번이라도 공부를 해봤다면 쎈언니 콘셉트라는 것도 결국은 상품화이고 속된 말로 빻은 것이라는 것을 모를 수가 없을 텐데. \n",
      "‘전 남자니까 당연히 여자를 좋아하죠’ <<<- 이 말하는 애 중에 안 빻은 애를 못 봄.\n",
      "‘커뮤 페미’가 유의미한 이유. 남초 한남들도 댓글에서 빻은 댓글들 조금씩 자기검열하고 있음. 한남 패기 효과 오짐 . 커뮤 페미라고 후려치지 마라 너희 핸드 냄이 입맛에 맞는 페미 할 거면 \n",
      "“국정화 반대하면 국민 아니다” 새누리당 이정현, 검찰에 고소·고발돼 . 고거 쌤통이다!! 불 끄네의 충성스러운 내시 환관 나부랭이시키!!! 담번 선거에선 국물도 없을 줄 알아!!!\n",
      "“돈 버려 면 딴 일하란 말이야. 왜 언론을 해? 다른 일을 하지. 내가 말한 게 복잡해? 다 탐욕 때문이잖아. 언론 입네 하면서 폼은 폼대로 잡고, 독립성이니 뭐니 하면서 위선은 다 떨고”(딴지일보 원종이 \n",
      "“돼지 족발” “기무띠” <-. 댓글 수준 알만한데 전 영부인 욕하면서도 여혐 안 끼워 넣으면 말을 할 수 없는 한남 \n",
      "“메가를 논란 중인 클로 저스, 앞으로 일러스트레이터에 대한 정보 공개하지 않겠다 선언” ? 앞으로 일러스트레이터 정보 공개 안 한다니까 개돼지 취급한다고 화냄 \n",
      "“자연인으로 돌아가겠다\"라는 정봉주 워딩 너무 역겹다\n",
      "“하나님이 이브를 왜 아담 갈비뼈 하나를 취하여 만드셨을 가 정답은 내가 한남 갈비뼈 하나를 부러트려도 된다는 소리다 새끼야.”\n",
      "「 날, 나를 대역으로 생각하지 마. 정말 역겹다는 거야. 」\n",
      "「아, 그런데. 왜 이리 역겹지?」 - no.3 유다\n",
      "「와타나베 나오미랑은 못 사귀겠어」 「마찬가지야, 왜 내가 고백한다는 설정이지?」 한남이나 일남이나 망상하는 게 종특 수준 \n",
      "【인간의 언어는 부자유스럽고 원시적이라고 생각합니다만, 이 단어는 훌륭하네요. 역겹다. 기분 나쁘다. 당신의 인격을 한마디로 표현할 수 있는, 범용성 높은 단어라고 할 수 있겠지요.】\n",
      "<긴급 속보> 새정치민주연합 공직자 출신 및 기업인 대거 탈당 선언 - 한인협 잘 됐다. 이들은 당의 혁신안을 반대하는 게 아니라 혁신 자체를 거부하는 것! 기득권 세력과 그 세력에 붙어있는 거머리 같은 사람들!\n",
      "<로리타 양복이 소아성애를 유발한다>라는 얘기도 페북발 떡밥인데 로리타 패션에 대한 무지와 자신이 생각하는 클-린 험을 남들에게 강요하려는 오지랖이 섞인 환상의 콜라보. 이렇게 멍청할 수 있나 싶다.\n",
      "<뻔뻔한 놈, 야비한 년들, 그리고 포철 수> 너희들이 어떻게 김기식한테 돌을 던지리? 혼수성 태는 뭐 그냥 뻔뻔한 새끼 야비한 입진 보들은 그냥 머리는 안 좋은데 잘난척하고 싶은 듯하고 포철 수야 뭐. ㅉㅉㅉ 이번 기회에 다 조사해서 걸러내서 다 사퇴시키자. \n",
      "<안물안궁>이 시급한 최고의 오지랖은 안나푸르나에서 만난 한국인 등산객 어르신들이었다. 신발은 그게 뭐냐 장갑은 없냐 어느 대학 다니냐 전공은 뭐냐. 제발 셧더퍽컵유어마우스 뿌잉뿌잉?(；▽；ノ\n",
      "<이러니 문베충이 사회악인 것. / 레드 홍의 욕먹을 인간인 건 확실하나, 상관없는 곳까지 끌어들여 즈그 문죄이니 욕 안 먹게 하려는 수작이 보여 더 욕먹는 것. / 문재원 소리를 안 듣고 싶어도 지지자가 듣게 하는 꼴.> 밀양 화제는 경남도지사 탓 아닌가요? \n",
      "<인간의 자존심과 수치심> 송파구 지하 단칸방의 세 모녀는 마지막 목숨을 끊으면서도 집주인에 빚은 남기지 않으려 마지막 목숨보다 인간의 자존심을 소중히 지킨다 그러나 지금 정치인 연놈들은 추잡한 거짓과 위선으로 똥개 목숨을 연명하려 수치심을 마구 유발하고 있다\n",
      "<조중동의 청와대 참모 저격> 무슨 사회주의국가도 아니고 (대한민국헌법은 개인 재산권을 철저하게 보장함. 왜 다주택자라는 이유만으로 비난하나? 다주택자=나쁜 놈 프레임을 만들라는 조중동의 수작이 역겹다. 다주택 보유는 자유시장경제체제에 맞게 보장해 주고, 누진 보유세를 때려야지 \n",
      ">>>프로미 거르지 제발 거르지 와가야. 답 없다 플미충들 진짜 왜 프로미들은 티켓팅을 잘하고 우리는 못할까 미스터리\n",
      ">>나 하나 안 해도 괜찮겠지<< 빻은 띵크입니다\n",
      ">>리본 달고 분홍색 치마 입고 귀여운 거 좋아하는 여성 = 수동적<<이라고 단정 짓는 것도 개빡침\n",
      "■이 지구상 다양한 직업 중에 정치인이란? 의원이란 직업이 가장 비열하고 교활하고 비굴하고 눈치 보고 아부하고 정의롭지 못하고 비논리적이고 비상식적이고 경우가 없고 안하무인이고 비신사적이고 위선자이며 썩었고 이중인격자들인 것 같다 특히 국당 소속 의원 제일 심각하다 ■\n",
      "■토론회를 보고 난 후 천정배는? ■ 한마디로 문 통전화를 기다리는 딸랑이! 또다시 호남 민 팔아 친노무 부역자 짓거리를 다시 서슴없이 하려는 노예근성 위선자! 천정배! 지역 유권자들에게도 지지 받지 못하는 자가, 열어 당 창당해서 호남 정치 말아먹은 자가 뻔뻔하다\n",
      "◆위기 봉착 안철수의 본색ㅡ자신이 배척하겠다던 기성 정치판보다 더 더러운 행각의 연속이네요 거짓말과 위선의 가공공장으로 전락, 지지도 타격 입자 신선한 가면 던지고 진흙탕 네거티브로 막장 본색을 드러낸 거죠\n",
      "● 미국의 치어리더들은 건강미가 넘쳐 보입니다. 한국은 색기가 넘치죠. 그렇게 입고 그렇게 춤추고 있습니다. tv의 걸그룹에서도 풋풋함보단 중년 남자들의 룸살롱 냄새가 더 진하게 풍깁니다. 한국적 위선은 미국의 천박한 상업 주의보다 때론 더 저속합니다. - 최종영\n",
      "··그리고 한가지 조언. 자네는 그 얼굴을 가리고 다니는 게 나을 것 같아. 난 참을 수 있을지도 몰라도 특히나 그런 표정은 보기에 역겹다네.(눈을 곱게 휘어 웃어 보인다\n",
      "… 아니야, 첼. 죽여 버릴 거니까. 내가 할 수 있는 한 제일 구질구질하고 역겹게 죽일 거야. … 이런 말할 애를. 진짜 짰단 말이야.\n",
      "… 아니야, 첼. 죽여 버릴 거니까. 내가 할 수 있는 한 제일 구질구질하고 역겹게 죽일 거야. … 펠 버전이 크면 렐이고 텔버전이면 알버스. 죽여버릴 거야 네가 됐던 나머지가 됐던 어느 쪽이던 무너지겠지 기쁘기 그지없겠구나\n",
      "……아, 그냥… 좀 죽여… 이 꼬락서니로 살라고… 미친…. ::지서율\n",
      "…그리고 남은 월 양국은… 어떤 기사가 완전히 짓밟았다면서? 쌤통이다.\n",
      "…역겹군. 인간들의 생각에는 진저리가 난다.\n",
      "☆우리 모두 트찔이지만 한남 트질 이는 특별히 숨만 쉬어도 처맞아야 하는 트찔이라는 점 기억해줘☆\n",
      "1 하나마루 마지막 화에서 곧 온다! 광고하고 질질 끈다 2 뜬금 폭로 질질 끈다고 공지한다 같냐? 1번이면 아니고 멍청이 들ㅉㅉ해도 그래 너희들이 초기도를 내주기는 하는구나 했을 텐데 욕 처먹고 싶어서 아주 난리 블루스를 추는구나 발바닥에 땀나지 않디?\n",
      "1 네이트 판이나 트위터 페북에 남편, 남자친구, 남선 후배 욕하는 글이 올라온다 ?? : ㅉㅉ 주작 냄새 너무 많이 나네요 찬 글 보기 싫네요 으 2 같은 게시판에 부인, 여자친구, 여 선후배 욕하는 글이 올라온다 ?? : 김치녀들 문제 너무 심각하네요 의무는 다하지 않고 권리만 누리는 모습이,,,\n",
      "100원 한 장 안 보태면서 댓글 ㅆㅂ 오지랖은 \n",
      "10개씩 사들고 응모권은 지가 다 쓸어가고 다시 재판하는 건 무슨 심본지?? 응모권 갖고 싶어서 재판하지 마세요 어차피 사람들 다 이니 가서 삼 차라리 가서 사는 게 낫겠다 ㅉㅉ 이니스프리\n",
      "11점이나 내고 진 골데는 진짜 답이 없다. 이대호는 150억이나 받아쳐먹고는 제 혼자 안타 하나 못 쳤냐. 와. 돈 그 마이 꼬라박고도 투타 둘 다 붕괴해서 털리는 꼬락서니 보면. 아이고 꼴데야. 해체하자. 마 그냥 단장이고 감독이고 주장이고 다 같이 영도다리에서 뛰어 내리 전단. 너희가 프로가?\n",
      "12. 내로남불, 나잇값 못 하는 사람\n",
      "13년 전 아내인 줄 착각해서 여대생을 성추행했던 녹색연합 사무총장 장원, 그리고 상대방도 동의한 줄 알았다며 카톡으로 찝쩍대던 인권운동가 고은태. 거기에 고은태 실드 쳐준 소설가 고종석. 이들의 공통점은? 모두 얄팍한 팬덤에 빠진 위선자들!\n",
      "13월의 보너스 아닌 13월의 세금폭탄? 연말정산 이것도 박근혜가 다 바꾼 것이다. 재벌은 감세해주고, 서민에게 한 푼이라도 더 걷어서, 최순실, 박근혜 배만 채워주고 있는 거지 같은 나라! \n",
      "159. ㄹㄹ? 너네가 감히 ㄹㄹ? ㄹㄹ 쓰지 마 이것들아. 비슷해 보이려고 애쓰는 것 같긴 한데 너넨 글러먹었어 ㅉㅉ\n",
      "15살부터 9년간 방송하면서 내가 굉장히 어린 편이다 생각하면서 살았는데 이제 어느새 군대에서 24살에 를 딱 소리를 들어야 한다니 쉬ㅂ.\n",
      "19장. 진짜. 장수부터가 너무 충격적이고 고의적으로 읽기 힘들도록 만든 것 같아서 너무 역겹다 전문가가 15분 동안 봐도 이해하기 힘들다는데\n",
      "1년 넘는 시간 동안 지속적으로 나와 배우자, 가족에 대해 악의적인 인신공격과 비아냥과 오지랖을 조리돌리는 아이디들. 며칠 전 또. 특히 플텍계정인 sahmbahk을 중심으로 조롱들이 계속되는데, 내가 가만히 있는 건 멍청해서가 아닙니다. 적당히들 해라 \n",
      "1분 10초 루한 대사 : 안전? 나, 그리고 이 장님? 이따위 개 한 마리를 의지하라고? 총총 : 개빡침의 표정 \n",
      "1위 점수 나올 때마다 입스밍 새끼들 땜 ㄴ에 개빡침\n",
      "2. 시비 거는 사람들. 시비를 걸어서 도발하는 것들 역겹더군요. 저는 너무나 화나면 말보다 행동이 제일 먼저 나가요 조심하세요.\n",
      "2. 예수가 위선적 바리새인들에게 분개하여 독사의 자식들아라고 꾸짖은 데, 한국 언론 보도는 예수, 국민들에게 x 새끼 발언 파문으로 보도. 3. 석가가 구도의 길을 떠나자 한국 언론은 국민의 고통 외면 저 혼자 살 길 찾아 나서라고 보도.\n",
      "2. 한미fta 재협상이 없기는 개뿔ㅎㅎ 미국이 재협상하자면 해야 되는 거지 미국이 재협상하자는데 타조처럼 모래에 머리 처박고서 재협상 안 하겠다고 말만 되뇌면 되나? 전용기 태평양 건너 오기도 전에 뽕빨이\n",
      "2.28 기념식 불참 욕 처먹으니까 갔나 보네 발정제 ㅉㅉ \n",
      "20:37 대한문 앞 박근혜가 뭐라 헛소리를 해대던 가증스러운 위선의 눈물을 흘리던 진실을 규명하고 총책임자(?가 처벌되는 그날까지 촛불은 계속될 것. 많은 사람들이 잡혀가고 다칠 것. 그래도 끝까지 가야죠. \n",
      "2000년대 중반에 “된장녀” 드립이 얼마나 횡행했냐면 학교 도서관 앞 150원짜리 커피 나오는 자판기에서 250원짜리 밀크커피 뽑아마시고 있다가 된장녀 소리 들었음 농담인데 뭐 어떠냐고? 남학생한테 너 왜 손 안 씻냐 한남이네 이러면 잘도 농담으로 듣겠다.\n",
      "2002년 나라가 시끄러울 정도로 당시 이회창 후보의 아들의 병역 의혹에 재검 받아야 한다고 떠든 자들이 당시 박원순 씨가 수괴로 있던 참여연대였지요. 그런데 13년이 지난 지금은 오히려 정치탄압으로 몰고 가니 그 위선이 역겹습니다.\n",
      "2012 나름 얽힌 이야기가 많아서 티브이에서 해줄 때마다 보는데 민폐 캐릭터로는 이 영화 주인공 무리들이 갑인 듯. 유압실 기계 고장 낼 때 개빡침.지들 살자고 인류 다 멸망시킬 기세\n",
      "2012년 문재인 후보 열심히 응원했더니 첨 보는 계정이 쌍욕부터 해서 깜놀했었는데 그게 국정원이 돈 주고 고용한 알바들. 세금 열심히 냈더니 표현의 자유 억압하며 욕까지 얻어먹을 줄이야. 쥐박이 이 시키 범죄의 크기가 이젠 가늠이 안된다!\n",
      "2015년 4월에 발견된, grey가 파일링 한 1927년 이혼 문서에서, 그녀는 그의 역겹고, 비인간적인 그녀에 대한 대우를 묘사했다. 그는 다른 여성과 함께 그녀가 스리섬 행위에 동참하도록 요구받았다.\n",
      "2016년 법원에서의 폭력 사태는 대한민국 민주주의 현주소를 보여주는 지표다. 5.18로 이루어졌다는 민주주의는 허상의 아지랑이였을 뿐. 5.18민주화는 폭력과 선동과 위선이 난무하는 사이비였고 가짜였다. (비바람\n",
      "2017.11.30 4화 위한 양(재벌 2세 役 - 배우님 쪼랏네. 조라 써. 무리에 동 카이스트는 개뿔. 간은 에틸.콩만 해가 지구 쫄보세끼 \n",
      "2020년 총선 끝나면 연합뉴스부터 정리해야지. 썩은 암덩어리를 국민 세금으로 키울 이유가 없지.\n",
      "20년 넘게 연락 안 하고 살다가 시아버님 돌아가시고 갑작스럽게 연락 와서 내가 이제 우리 집 큰 어르신이라고 그동안 제사 지내느라 수고했다 이제부터는 내가 하마 이러더니 개뿔 나보고 맏며느리니까 네가 우리한테 잘해야 한다고 대놓고 말할 때부터 알아봤다\n",
      "20세기에 퀄리티 좋았던 애니메이션 하면 꼭 버블 시대 이야기하던데, 제발 버블 시대 이야기하기 전에 일본의 어느 시기를 버블이라 부르는지 찾아보자. 무슨 지금도 10년 전이면 90년대지? 하는 시간감각 사라진 를 딱도 아니고(.\n",
      "21살의 여성이 의견이 다르다는 이유로 한남 소리부터 시작해 입에 담을 수 없는 비난들을 듣고 자살을 해서 사람들이 조문을 가고 명복을 비는 와중에 이러는 게 인간이냐 \n",
      "23화 줄거리 태재 개천 용지 개 낚시질 신쌍흑 개빡침과 프란의 돈지랄\n",
      "2500년 전 사람도 불혹이라는 간지 폭풍이 휘몰아치는 단어를 썼는데 영포리가 뭐냐 영포리가. 시퍼 이립도 못하고 기립도 안되면서 영포리는 개뿔.\n",
      "27. 동방신기? 이방 신기냐 ㅡㅡ 삼방 신기냐 ㅡㅡ 좀 제대로 해라 늙어서 뭐 하는 짓인지 ㅉㅉ\n",
      "27조 빚더미에도 명절 공짜 통행료. 세금으로 충당? 박근혜가 하면 뭔 짓을 해도 ‘잘한다’고 하다가, 문재인이 하면 같은 걸 해도 욕하는 인간이 정말 많습니다. 이들 모두가 박근혜 최순실의 ‘공범’입니다. 언론을 자처하는 댓글 부대원들도 예외는 아닙니다. \n",
      "3. 남자들이 창피해서 말하지 않았다. = 남자들은 여자들에게 당한 게 창피하고 내가 남잔데 당했다고 말하면 놀림당할 것이다. 얼마나 남자들은 자기들을 우위로 생각하는 거지? 역겹다 진짜\n",
      "3. 동물 학대 제가 거의 유일하게 트리거 눌리는 요소입니다 아무 잘못 없는 동물들 학대하고 버리는 거 진짜 역겹고 동물 키우시려면 최대한 여러 번 생각하고 조사하셨으면 좋겠네요\n",
      "3. 미투 운동 무고죄 때문에 위험하다 → 성범죄 무고죄 비율 0.5% 미투 첫 무고죄 남자 보여주면 저절로 닥친다 4. 저게 성범죄 면 대한민국 남자 90%가 성범죄자겠다 → 지금 한남 성범죄자라고 인정하는 건가요? 님 남혐하세요?\n",
      "30 돌았나 거의 열 배를 쳐 받고 있네 진짜 짜증 나 플미충새끼들\n",
      "30대 보고 늙었다고 아이돌 하지 말자 하는 사람 은 그냥 도쿄 한복판에서 스맙이랑 아라시랑 다 틀 딱이니까 아이돌 관둬라 하고 외쳐보면 되겠네\n",
      "30대 한남 및 기타 : 메갈로 피해 받는 건 뚱뚱한 여성이죠. 20대 한남(unupdated : 예쁜 여자들은 여혐 없음 꼭 못생긴 여자들이 그러죠 20대 한남(updated : 예쁜 여자가 하는 페미니즘이 진짜다. 뻔한 수작에 놀아나지 맙시다.\n",
      "30만인 서명 혼이 비정상인 정신 나간 인간 말종들이군요 ㅉㅉ\n",
      "3년 안에 쪽팔려서 이불 찬다에 한남 소추건다 \n",
      "3말리ㅡ주공 15+a 3벨레ㅡ주공 40 이제 누가 더 역겹지??\n",
      "3성이 떠날 날도 얼마 안 남은 것 같네. ㅉㅉ \n",
      "3수 해서 국민대 들어가 운 좋게 mbc 입사해 승승장구한 손석희! 최근 변희재 대표에 의해 표절 논란이 나오니 은근 슬쩍 교수직 버리고 도망치듯 jtbc로 건너와 위선 떠는 당신의 행태가 몹시도 역겹다. 거짓으로 얻은 지위는 사상누각임을 알기 바란다.\n",
      "44 고 프사고 탐라가 난리인데 난 그것보다 이재명 페북에 문포 사진과 영상으로 도배해 논게 더 열받는다. 사람 새끼라면. 문포한테 조금이라도 미안함에 대한 양심이 있다면. 저런 짓 못한다. 안철수보다 더 역겹다.\n",
      "4대강 사업, 英 가디언이 선정한 10대 애물단지에 꼽혀.명바기새끼는 이런 기사 안 보겠지요? 멀쩡하게 돌아다니는 걸 보면 정말 개빡침.\n",
      "4조에 31억 과징금 이게 법이냐? 이 나라 정부와 금융위와 사법부는 삼성을 위한 삼성에 의한 삼성의 비호 기관인 거냐? 참. 이래놓고도 일반 국민들에게 금융 실명 제니 차명계좌니 하면서 과징금과 법적 제재를 가하는 거냐? 이건 아니다, 이건 세금 내는 이 나라 전체 국민들을 바보로 만들자는 거다(펌\n",
      "4학년짜리 가슴 옆 살을 손가락으로 찌르면서 여기가 야들야들하고 상처 남아도 안 보여서 좋단 드립치고 스타킹 신은 애들 다리에 분무기로 물 뿌렸던 한남 선생 내가 정색하고 거부했더니 비싸게 군다며 너 옆구리 찔러보는 게 소원이라는 빻은 소리 했고요?\n",
      "5. 주체적으로 꾸미고 센 화장하는 주체적 코르셋을 조이기는 개뿔 화장하지 말아라, 꾸밈 노동하지 말아라 피부가 안 좋으면 파운데이션을 바르지 말고 피부과를 다녀라, 불편을 감수하면서 멋부리지 말아라, 머리 밀어라, 못 밀겠으면 쇼트커트나 투 클럭부터 시작해라 하는데 코르셋을 뭘 조이냐\n",
      "5.18 전야제와 세월호 특별법이 무슨 상관? 김무성에게 계란·물 투척하고 욕설 퍼부으며 강제로 내쫓은 건 오지랖을 넘어 자기들 스스로 그렇게 자랑스럽게 여기는 5.18 정신을 훼손시킨 똥·오줌 못 가리는 짓거리.\n",
      "5.18암매장이 있다며 호기롭게 광주의 이 땅 저 땅 파헤치던 분들 요즘 뭐 하시나요? 이런 음흉한 사람들이 뭔가 조용히 있으면 불안합니다. 어디선가 또 무슨 꿍꿍이를 하는지 걱정돼 기 때문이죠. 아무튼, 나라 세금 허튼 데에 야무지게 쓰는, 지금 누군가는 주머니 챙기고 있을 정말로 못된 자들입니다.\n",
      "503 구속 연장됐다고 해서 혹시나 찾아봤더니 역시나 틀딱들 울부짖으며 라이브스트림 하고 있네 엌 틀딱 유튜브 채널들 죄다 지금 울부짖으면서 우리 대통령님을 꺼내달라!!! 문재인을 죽여!!! 외치는 중 \n",
      "50대에 를 딱 소리 듣는 거 너무 웃기겠다 네이버 50대 알바들아 너희들 틀딱 관짜야 하는 것들이래 \n",
      "5명 중 최소 한 명은 역겨운데 왜 만나는 사람들은 다 딴 사람들이 역겹다는 걸까\n",
      "5명이네 뭐네 하면서 성범죄 피의자로 숫자놀이하는 사람, 경조사도 구분 못해서 프로필에 날짜 주절주절 적어두는 사람이라고 명확히 표현하니까 저 딴짓하는 인간들이 더 역겹다\n",
      "6. 결국 잡는 손 뿌리치면서 됐습니다! 당신들 다 매국노야, 각하가 돌아가시게 생겼는데 당신들이 죽인 거나 다름없어라고 울먹거리면서 뛰쳐나갔음 지나가는데 그거 보던 를 딱 들 이 다들 흥분해서 그래. 하고 사과함 \n",
      "6. 워마드는 30.40대 결혼 못 해서 히스테리 생긴 젊은 페미 질투하는 틀딱페미이다. 도 있습니다 \n",
      "60대 절반 이상이 박근혜 탄핵반대. 노령연금 싹 다 폐지하고 복지혜택 몰수하자. 나라 망치는 족속들에겐 세금도 아깝다.\n",
      "7cm 썩은 꼬챙이 달았다고 가보질 하는 개보다 못한 짐승아 어린 상대 여성은 평생을 트라우마에 시달린다 무엇으로 보상할 거냐!!! 어렸을 때 여중생을 공유한 놈은 반인륜적 짐승 짓을 하고도 고위 공무원으로 국민 세금을 축내고 있다는 사실이 개탄스럽다!!!\n",
      "80년대 아재들도 킹오파나 스파 오락실용 오리지널 아케이드 팩도 사서 소장하는데 심지어 베라 하드 값보다 비쌈 . 그거 하드 얼마나 한다고 허벌인 윈 98용 똥 게임을 크랙 해서 쓰냐 그걸 또 만든 새끼나 판세 끼나 도토리 키재기 나잇값 못하는 ㅄ\n",
      "82년생 김지영 보나 마나 깝깝할 거 뻔해서 안 읽었다 며느라기는 주인공 이름이 사린이라서 기대를 품고 견뎠는데 그딴 식으로 끝내면 안 되지 히치하이커 시리즈는 초반부에 지구 따위 날려버리고 시작하는데 이제 한남 한둘 정도는 죽여버리고 시작하는 “페미니즘 소설”을 볼 때도 되지 않았나\n",
      "82년생 김지영 알티했다고 메가를 이면 소녀 전선은 고추 작고 와꾸 빻아서 여혐충된 한남 전용 게임이라는 거네?\n",
      "82년생 김지영을 엘 엠과 아이린이 읽었을 때의 반응 차이 비교하는 트윗들 올라올 때 아미들 알에 반응은 팬들 반응이고 아이린 반응은 한남들 반응인데 왜 그걸 비교하냐며 욕하고 떼멘달았잖아 그런데 왜 지금 아이린 워너원 반응 차이 비교하는 트윗 알티하시는 거예요? 어제 그렇게 격렬히 욕하시더니\n",
      "82년생 김지영을 읽었다고 포커 태우는 한남을 본 내기분 \n",
      "82년생 김지영이 예스24 베스트셀러 1위가 되었길래(원래도 순위가 높았지만 아이린 덕에 더 높아진 듯 리뷰 보는데 별점 낮은 건 다 구매 딱지가 없음 역시 한남. 저기서 사지도 않았으면서 집요하게 악플 올리는 광기. 읽기는 했나 몰라? \n",
      "8개월 뒤면 최애는 혼자서 시작해야 한다는 것을 받아들이지 못하고 자립할 생각이 없는 팬덤의 행태가 비정상이라 느끼는 건 당연한 일이다 무식하면 용감하다고들 하지만 무식하기만 할 뿐 비굴하기 그지없는 자세로 자기들이 아닌 최애를 한없이 낮춰가며 덕질의 활로를 모색하는 것이 역겹다\n",
      "8만 명이서 네이버 채소 계정 두 개만 가져도 16만 개의 계정이네. 미친 것들. 이러니 수원역 앞에서 반란을 주도하는 일 베틀 딱 들 보호해주는 거 아닌가? 다 잡아서 조사해야.\n",
      "8시 뉴스나 한번 볼까 하고 돌렸더니 모조리 무슨 100일 보고대회니 뭐니 떠들고 하나마나 하는 쇼를 하고 자빠지고 방송이 하나같이 정권의 꽃가루 뿌리기에 몰두하니 국민을 위한답시고 개돼지 같은 국민만 쳐다보라고 개나 팔을 불고 있다. 영양가? 개뿔 같은 쇼 멈춰라\n",
      "90년생 김지훈 같은 책 쓰면 그걸로 떼돈 벌수 있을 거라고 생각했나 봐. 한남은 4100원짜리 커피 먹는 여자도 된장녀라고 욕했던 족속인데 그들이 책을 살 거라고 생각한 거니.\n",
      "90년생 위엄 ㅎㄷㄷ 틀딱노래도 아노 \n",
      "90년생이라고 한 것부터가 너무 역겹고. 구토 나와. 90년생이라고 한 거가.\n",
      "999가지 잘하다가도 1가지 잘못하면 개 빻은 사람이 되는 분위기, 좀 무섭다. 사람은 고쳐 쓰는 게 아니니 반성이란 의미도 없고, 성장은 무시된다. 태어날 때부터 성인군자로 태어나지 않으면 온라인에서 살다가 ㅈ되는 건 순간인 듯.\n",
      "9월부터 거의 매일 야근인 사람 붙잡고 얼굴에 좋은 기운이 도세요라고 말 거는 돌팔이들의 영업전략은 얼마나 구태의연한가. 이딴 식으로 해서 밥 벌어먹고살겠나 \n",
      "9월부터 고소한다고 이미 파다하게 도와달라고 하고 다녔는데 너네가 생쇼 해놓고 mou.? mou 같은 소리 하네 양해각서를 쓰고 이행하지 않은 것들 전부 찾아내서 고발 안 하는 게 아니라 고발하고 고소하는 게 맞고요. ㅋㅋ 지네가 뫄뫄하기론 했단 건 할 수 있는데 안 했단 증거가 됩니다 지긋지긋하다.\n",
      "bb 일러를 보고 방탄 멤버를 겹쳐 보는 거 역겹다 싫어 정도 보고 얜 아무리 봐도 .같아<< 어쩌라는 거지 타 장르 겹쳐보는 거 극지뢰이고 심지어 방탄 지뢰임\n",
      "cgv 하는 짓이 너무 노골적으로 돈독 오른 것 같고 시간대 나눠놓은 꼬락서니 보니까 다 패고 싶다\n",
      "dhc는 진심 쓰지 말자; 홈피에 사장이 역사가 어쩌고 빻은 소리 늘어놓은 글 자랑스럽게 게재하고 있었는데 거의 헤이스트 스피치 수준이었음. 그 이상한 여자가 하는 호텔 체인이랑 버금가는.\n",
      "esp 역겹죠? \n",
      "ewww gongvoo 나도 차단함 뒷개로 페미 비웃는 한남 \n",
      "gcda에 풀 발하는 한남 특징: 고추 작음 인생에서 해낸 거라곤 군대뿐임 \n",
      "girls can do anypang 해놓고 미러링이라고 하는 한남 \n",
      "girls can do anything 이 무슨 뜻인지 잘 모르시나 본데 빻은 말이 범벅인 당신의 목숨을 끊는 것도 할 수 있다는 뜻입니다 아시겠습니까?\n",
      "girl이 문제라는 게 아니잖아. 맥락을 좀 파악하자. 남자팀에게 마늘 보이즈 뭐 이런 이름 안 붙이잖아. 내가 웬만하면 한남 아니면 시비 봐도 모른 척하는데 지겨워 죽겠네 진짜 \n",
      "how pity you are ㅜㅜ에서 그치지 말라고 나를 불쌍하게만 보는 시선이 오래된 친구지만 진짜 역겹다 다른 애들 카톡에는 답하면서 정작 용기 내서 말했더니 물어놓고 내 말은 왜 씹는데. 다른 애들도 기형이라고 지나치게 안타까워하는 것도 속상하다. 맞아 나도 수술 부위 너무 아프고 생활도 힘들어\n",
      "jtbc 단독 합동 감찰반 돈 봉투 마련 법무부 직원 경위서 확보 누가 언제 어떤 명목으로 지시를 내렸는지 확인함 관련자들 소환 조사 일정 조율 다 찾아내어 이번에는 법을 바꿔 변호사 개업할 수 없게 만들어야 함 국민 세금으로 술 처먹고 똥개들. \n",
      "jtbc 미친 새끼들 이대 로스쿨 교수인지 개뿔도 아닌 좃문가넘 불러다 놓고 문 대통령이 트럼프한테 fta 재협상 하자라고 말하고 왔어야 한데 기러기들 미국으로 단체로 다 이민 가버리든가 뒤지시든가 \n",
      "jtbc 재벌 사이비 언론이 네이버 실검, 연관검색어에선 국정 농단이나 7시간을 루머성으로 차단한 것을 물고 늘어지네요 손주 놈 미친 언론이 자신들의 사기 공갈 선동 방송만 죽기 곤란하니 네이버를 물고 공범으로 끌고 가려는 수작질입니다. 어차피 언젠가 정권이 바뀌면 손석희는 감옥에서 죽어야 한다 \n",
      "jtbc. 너무 역겹네\n",
      "jtbc고 손석희고 유시민이고 위선적인 인사들뿐이야. 저쪽은. 하나같이 겉으론 잘난 지식인 표방하는. 알고 보면 편협하기 이를 데 없고 논리적 근거도 부족한 그들.\n",
      "k 단 순덕찐앰들이 악기 짓 해서 이 사단 내놓고 변방악개짓인 척 정치지 지려따 다 박제된 마당에 조본 방사능 처먹은 새끼들처럼 거짓말 100번 해서 진실로 말 들려 수작질 \n",
      "k7 메가를 일로 레 하차하느냐 여부를 보고 계정 삭제하려고 했는데 빠른 대응에 감동. 그나저나 메가를 짓 하려면 좀 너희들 말마따나 여캐 성 상품화나 하는 한남 콘텐츠 좀 만들지 말아라. 정신분열 아니냐. 한동안 시들했던 소녀 전선도 슬슬 다시 해야겠다. \n",
      "lg 우승한 게 언제 적이냐 진짜 역겹다\n",
      "mb 구속 수사하라 mb 자택·도심서 집회 잇따라 그것이 알고 싶다를 봤다 mb 집안의 가훈이 정직이라는데 정직은 개뿔 대통령 선거때에 표를 얻기 위해서 모든 재산을 사회에 환원하고 부부 살집만 있으면 된다 했으면서 실상은 생양아치 짓거리로 국민을 속였다 한번 꼭 보시길\n",
      "mb 국감 벼르는 與, 시적 폐로 반격 나서는 野 필리 밥 스터로 박근혜. 최순실 국정 농단을 물타기 하려 했듯, mb의 비리를 덮으려는 x 수작을 이번에도 펼치시겠다?\n",
      "mb 청계재단, 운영비가 장학금의 3배 ‘배보다 배꼽’ 퇴임 후에도 국민 세금 야금 야금 빼 처먹는 mb 전직 대통령 중 유일하게 전직대통령 예우를 누리고 있다 도둑적으로 완벽한 도둑놈이! \n",
      "mb 핵심 측근 선 지켜라. 정권 백 년 가나 강력 반발 | 다음 뉴스 쥐박이 넌 백 년 갈 줄 알고 세금 빼먹고 여론조작에 선거개입까지 했냐? 국정원을 이용해서? 나쁜 시키!!\n",
      "mb, 세금 탕진한 게 180조, 나랏돈 삥 뜯은 게 수십조라는데, 자유당 정제원이(mb 수사를 일개 보복으로 치부해서”문재인 정권이 잔인하다\"라며\"일개 개별 기업인’다스’를 검찰 수사한 단”다. mb는”노통 단골 칼국숫집까지 뒤졌단다”제원아? 정제원”국회에서 유모차 아줌마들에게 쌍욕 한 건 않잔 인하니?”씨 새야\n",
      "mbc 망친 주범들의 피해자 코스프레. 역겹다 배현진·김세의가 불법사찰 피해자? 어이없다\n",
      "mbc 스트레이트 나온 해수부 공무원 빨리 처리하십쇼! 해수부 장관님! 세금 받는 공무원이 어이가 없네. 보수단체에게 고발을 부추기는 거 보니 그게 해수부 공무원이면서 저런 사람이 해외 출장까지 보내는 역겨운 현실이 아직도 있다니? 빨리 처리하십쇼!\n",
      "mbc 스트레이트 방송시간 변경 강력 요청합니다. 너무 화가 나 잠이 안 오겠군요. 낼은 바쁜 월요일 아침인데. 세금 물 쓰듯 막 쓰고 있을 때 우린 왜 몰랐고 언론은 어디서 뭐하고 있었으며 봉급 받던 석유공사 직원 이 새끼들 뭐냐 싶습니다. 소주 생각나네 화나서!!! 명바기 이 새끼 당장 죽여버리고 싶은\n",
      "mbc 스트레이트 진짜 충성 소리 역겹다 너희들이 언론인이냐 \n",
      "mbc, kbs, ytn이 이번 총선 투표율 저조의 주범이다. 역대 선거 중에 이번처럼 노골적으로 편파적인 방송을 했던 기억이 없다. 그 주범들이 지금은 마치 투표방송에 최선을 다한 양 위선을 떨고 있다. 진짜 역겹다. 파업 노조 파이팅!!\n",
      "mbc에 뉴스 나왔네 혜경궁 김 씨 정의를 위하여가 김혜경 자신의 사진까지 올렸다고 더 이상 뭘 더 아닌척하고 거짓말 하나? 지운다고 없다고 했다는 이재명의 해명까지 뉴스에 다 나왔네. 역시 이재명 정계에서 물러나라. 역겹다.\n",
      "mb가 국정원 특활비 청와대 상납 전통을 만들어 박근혜까지 이어진 것이다. 돈에 환장한 연놈들이 세금을 마구 탕진한 것이다. \n",
      "n0 만 원 이상 콜거 해요. 이러는 플미충들 클 몽둥이로 다리 모아 다리다 뿐질러버려야 함\n",
      "oecd 국가 중 투표 제한 연령이 가장 높은 우리나라. 자유한국당에서 반대하는 18세 투표. 저 학생의 외침에 . 실실 비웃고 있는 김무성과 홍준표. 정말 역겹습니다. 국가를 위한 일은 단 한 가지도 안 하는 자유당. \n",
      "ooo 우파 새끼들 오일팔 폭동도 민주화라 해주고 ooo 짓 해서 지금 이렇게 되는 게 아닌가?ㅉㅉ \n",
      "응 서민. 그러면서 김대중, 노무현 때 서민들 죽이려고 북한에 돈 다 퍼주었음. 서민들 피 빨아먹은 거머리 같은 사람들이 바로 김대중, 노무현 패거리들임.\n",
      "다들 멍청하다. 특히 it 업계에서 일하면서도 논점 흐리고 있는 사람들. \n",
      "  이재명 최측근 뇌물 의혹 수사…성남시 재직 중 청소용역 입찰정보 전달? 이재명 최측근 뇌물사건 터짐. 경기도지사는 깨끗한 전해철!! 이 사람들 적이여 동지여? 좋아죽네? 정말 역겹다\n",
      "  죽어 이 개 삐삐야 ㅡㅡ.\n",
      " 허울좋은 진보는 완전히 썩어 빠지고 곪은 냄새가 나는 곳이 한국진보의 현실입니다. 인권을 개무시하는 진보는 이미 존재가치를 상실한 곳이다. 거짓 위선과 허풍이 난무하는 한국. \n",
      " 남자 장애인한테 온라인 여자친구인척하고 민증 사본 받아내고 명의도용해서 몇천 대출한 페북 계장도 잡고 나니 20대 남자였는데 저 중 남자들 많을걸? 넷카마들이 한남 돈 잘 뜯더라. 자적 자. 진짜 여아들은 협박에 성희롱 당하는 경우가 더 많을걸? 한국 남자들이 얼마나 가성비 따지는데 피해자인 척 오진다\n",
      " 닉네임을 언급하고 비판하는 것은 중요하다. 서울 불꽃 릠자 이다흰 유인석 김성준 등등등. 들을 가치가 없는 얘기를 하는 애들 말을 진지하게 들어줄 필요가 없고. 모아보면 한 사람의 입에서 빻은 말이 여러 번 나왔을 가능성이 농후함. 모아보면 한 줌의 여혐러들.\n",
      " 아시아식 유교주의가 저거다. 서양에서는 살부 살들 딱해서 젊은 남성들이 주도권을 쥐려고 하는데 아시아식 사대주의는 늙은 틀딱에게 알랑거리는 젊은 남성들이 여성과 약자를 갈아바치며 공유한다.\n",
      " 이거라도 괜찮은 분은 알티만 해주세요 백혀니 인화 사진이랑. 내 기준 포토북 최악임. 사지 마세요. ㅅㅂ. 화난다. 다른 업체 알아보거나 해서 돌아 오겠습니다.개빡침 \n",
      " 전봉준 투쟁단 폭력 진압 개돼지 대하는 경찰의 위선 하성태 기자 백만 민중 앞이면 절대로 못했을 짓! 그래서 더 괘씸하다!! 촛불이 백남기다 새끼들아!!\n",
      " 페미 나치가 이 세상에 한 번이라도 등장했는진 모르겠는데 한남은 나치가 맞다\n",
      " 한국인들의 오지랖이 태평양인 이유가, 부럽긴 한데, 자기는 그럴 용기가 없거나 되게 남의 눈치 보거나 혹은 그런 선택지를 선택할 능력이 안 돼서 자기는 그렇게 못하겠으니까, 그렇게 하는 사람이라도 끌어내려서 자기가 잘하고 있는 줄 정신승리하기 위해서 임\n",
      " 남의 팬심, 덕심에 잣대 들이대지 말아요 그런 생각 자체가 정말 한심하지 않나 나이가 무슨 상관이고 결혼 유무가 무슨 상관이며 덕질 대상이 무슨 상관인데요 내가 좋아서 덕질 하겠다는데 그건 너무 오지랖이지 이런 이야기 볼 때마다 화가 나네\n",
      " 내가 소위 운동권-자칭 진보라는 자들 포함-을 경멸하는 이유. 열등감, 인정 욕구, 선민의식, 밥그릇 탐욕이 뒤엉킨 위선자들을 (종 특이라 부를 정도로 흔히 보기 때문이다. 게다가 결정적으로. 무능하다.\n",
      " 로타가 특유의 콘셉트로 그렇게 욕을 처먹고 있을 때에도 최소한 모델의 동의는 구하고 찍은 사진일 거라고 생각했는데. 내가 아직도 한남에게 거는 기대가 과했던 것 같다\n",
      " 으 샹 만화가 조경규 작품 오므라이스 죔죔 그림체도 귀엽고 이야기도 좋아서 계속 봤는데 역겹다\n",
      " 인간적으로 옵티 할 때마다 겪는다,,,;; 솔 큐롯 돌릴 때 특히 그럼. 저런 놈들은 생식기로 생각하는가 봄,,, 끝나고 친 추오는 것까지 다 너무 똑같아서 역겹고 짜증 난다\n",
      " 저 글에 인용+멘션으로 비꼬는 말들 하는 사람들은 타인의 고통에 대한 공감능력 제로라는 거겠지. 그러니까 사람으로서, 나쁜 쪽으로 많이 모자란 사람으로 보임. 왜 저럴까 ㅉㅉ\n",
      " 지금 서양 특히 쌀 굴은 웨인 스틴 새끼 후로 정치나, 올림픽 의사 뽀이 등등 계속 고발돼서 그거 뉴스 매일 뜨는 거 보고 있는데 한남 민국은 함남 충+한남화된 대표빻도퇴백맘 콜라보로 갓치 체포된 거랑 온도차.\n",
      " 초등학교에 가서 어린이를 인질로 잡아 위협하며 언론의 관심을 받고자 했다니, 한남 범죄는 얼마나 더 비열해지려고 하나. 만만한 약자를 골라 화풀이하는 주제에 세상 제일 억울하고 불쌍한 척은 다하겠지.\n",
      " 플미충들 싹 다 엿 멕이자 \n",
      " 회색 작가님 올린 트윗의 캡처, 너무 총공꺵이라 헛웃음만 나온다. 와. 어디서부터 저 빻은 말을 지적해야 할지 감이 안 오네;;;\n",
      " 도대체 왜 민주당은 노무현 딸을 수사하면 총선용이고 탄압이라 하는가? 갖은 유언비어로 자신들은 국민을 선동하면서 자신들이 불리하면 탄압 운운한다. 정말 민주당이 역겹다. 궤멸 시키고 싶다. 위선자들.`\n",
      " 한국 사람의 이런 오지랖, 사람을 번식 기계로 보는 태도 진짜 싫다 미친 새끼 어디다 대고 애를 낳으라 말라 하는지\n",
      "야 그들은.천막도 잘 치고 길거리에 나와. 앵벌이도 잘하고 하라는 정치 공부는. 안 하고 허구한 날.길바닥에 주저 않아서 . 지,, 자식 애들이 보면. 뭐라 할는지!!?? 한 마디로.야,, 생쇼 그만한 그라 c8!!; \n",
      "<으으.역겹. 뭘 배우고 살았길래 저런 상상을 함;;\n",
      "sbs 세월호 통화 해수부 7급 공무원이 했다… 감사관실 조사 중 그냥 원하는 말해줄 사람을 구한 거 아냐. 이 수작을 부려놓고 모든 건 오해고 사과한다면서 세월호를 정략적으로 이용하지 말라 되려 훈계질을 해?\n",
      "sbs는 이슬비 해설위원이 정확하게 해설해줘서 좋은 대신 남자 아나운서 정석 문인구 갸가 너무 여자 경기 후려쳐서 mbc로 채널 바꿨는데 냄져 아나운서가 조신하고 조용한 편이라 그나마 볼만하더라. 여자 경기에서 남자 아나운서나 남자 해설 좀 빼. 한남 걔들이 뭘 아냐?\n",
      "sbs는 즉각 방송을 내려라 공정성을 잃은 공중파 보기에 역겹다 ˝거짓 방송 폐지하라˝…´정봉주 역풍´ 맞은 ´김어준의 블랙하우스´ \n",
      "sbs의 지금 태도는 거의 절망적이다 언 발에 오줌 누고 갔네 비교해서 더 욕먹게 해보려는 수작? 언론도 소속사도 경희대도 우리 얘기를 들어주지 않으니 우리가 이러고 있는 겁니다 \n",
      "sm이 정상적인 멘틀을 가진 회사라면 사태가 이쯤 됐으면 어찌 됐건 회사 차원이나 이수만이 보도자료를 내서 국민한테 사과하고 재발방지를 약속하는 게 정상이다. 시간이 지나면 잊힐 테니까 그냥 뭉개고 가겠다는 건가? 국민 우습게 알고 기러기들 동원해서 실드나 쳐대는 꼬락서니 가증스럽다.\n",
      "sns에 집 앞 풍경 사진 이동 동선 상세하게 올리는 거 진짜 위험함 친구 동생이 거실 밖 야경 찍어 올리고 집 근처 단골 카페랑 밥 집 몇 군데 포스팅했더니 40대 한남 새끼가 단골 카페 찾아와서 죽치다가 집 앞까지 따라왔다고 함 여성분들 자나 깨나 한남 조심 꺼진다던 한남도 뒤돌아 살펴보자\n",
      "soup나 soup 식의 옷들은 세상에 아무 불만이 없는 멍청한 애나 입는 것인 양 말한다는 자체가. 저게 진짜 한남스럽고 개저씨스러운 짓 아님? 나에 대한 오지랖은 안 되고, 남에 대한 오지랖은 무한대인가?\n",
      "spd studio 섬네일 다 자극적으로 한 거 보면 답 나온다 진짜 미친 한남이다 \n",
      "to. 플미충 돈 벌 일이 없어서 그따위로 사냐 \n",
      "to. 플미충 아잉 이러지 마세요 돌 아이들아.\n",
      "user 본인이 저희 아 그대 팀인 줄 단단히 착각하시고 대하는 패게 분들이 간혹 있으신데요. 저희가 패기를 구하든 뭘 하건 아 그러대 팀의 자유고 권한 아닌가요? 오지랖도 정도껏 떠세요. 정 보기 싫으면 언팔이나 블록 하시고요. 기분 썩 좋지 않습니다.\n",
      "voa ＂美 국무부, 북한의 ˙천안함 조작˙ 주장 일축＂ 당연한 걸 뭐 새삼스럽게 남측 조작이라고 하고 남한의 북한 졸개들은 이걸 맞장구치는 꼬락서니 하고는. 미국은 북 핵관련해선 안되면 북 폭하겠다고. 더 이상 할 것이 없이 아주 느긋하구먼.\n",
      "ytn 문 닫아라. 이게 오보라고? 정치공작이지. 어떻게 이런 얼토당토않은 오보가 가능한가? 국민 세금 받아서 이따위 장난질을 하는 걸 두고 보아야 하나? \n",
      "ytn이랑 연합은. 차라리 중계를 하지 말아라 아. 진짜 모피를 촌스럽게 안 보이려고 누가 사줘서 입혀 보냈다든가. 뭐 그런 게 평론이냐? 탈북자 데려다 뭐 하는 거야 진짜 너네 세금 가져다 쓰지는 말아라\n",
      "가글 맛 너무 역겹고.\n",
      "가끔 내 앞에서 나의 공감과 맞장구를 기대하며 메가를 욕하는 남자들 있는데 이기이기. 메가를 을 인터넷으로만 봐서 눈앞의 메간 볼 줄 모르노.\n",
      "가끔 카발 리어카 깃털이 아니라 검은 날개를 갖고 있으면 어떨까 생각해보는데. 그래도 반쪽은 역겹네.\n",
      "가끔은. 안 빻은 척 은은하게 빻은 게 대놓고 빻은 것보다 더 빡이 친다. 빻은 주제에 은근슬쩍 아닌척하지 마라.\n",
      "가뜩이나 힘겨운 인생살이, 가끔 잔소리꾼들이 끼어들어, 이렇게 살아라 저렇게 살아라 참견들을 합니다. 들어 보면 전혀 다른 가치관들을 가지고 있습니다. 그렇다고 자기들은 잘 사는가 하면 지질하기가 저와 진배없습니다. 쓸데없는 오지랖만 공설운동장이지요.\n",
      "가린 것은 이름. 오빠는 무슨 개뿔 무논리 \n",
      "가마니 보니 무식이 가득 한 것들이 현 정부에 불만 가지네 ㅎㅎ 무식이 밥 매기냐? ㅉㅉㅉ\n",
      "가만히 있는 나한테 빅엿 던져서 개고생하게 만든 새끼가 저기서 그런 적 없는 것 마냥 하하 호호 행복하게 승승장구하는 꼬락서니가 눈앞에 보이는대도 아무렇지 않게 허허 행복하구나 할 수 있는 사람이 그래 있기는 함. 한. 간디나 예수쯤 되는 사람?\n",
      "가만히 있으면 중간이라도 갑니다. 흰 리본이라니, 진짜 말이 된다고 생각하세요? 부친상 홍보하러 가셨어요? 리본을 돌려요? 자신이 직접 만든 거라고 말하고 다니신다네요 칭찬이라도 듣고 싶으셨어요? 오지랖도 병입니다 제발 가만히 좀 계세요\n",
      "가부장제 여성 억압이 구조도 남성들도 아니고 바로 여성들 때문이라는 참신하게 빻은 주장 정말 상상을 초월하는 대빻음월드\n",
      "가사 꼬락서니 보ㅏ라 얼마나 무수한 인생 배우들이 쓰러지긴 개뿔 얼마나 무수한 한남들이 성범죄를 저지르며 살았는가 . 송민호 여혐 꾸준하지요 민호야 천 번 말했다 여혐은 지능 탓이라고 닌 뭐 ㅎㅎ 여혐하게 생김 ㅎㅎ \n",
      "가서 관사를 때려 부시는 거 너무 >>감정적<<이지 않나 역시 한남은 >>감정적<<이라 큰일을 맡기면 안 돼\n",
      "가슴이 막 쿵쿵 뜀. 너무 빡이 친다. 지금 남현 막 솟구쳐서 내일 아침 출근길에 마주치는 한남들 다 도 함마로 뚝배기 깨부술 것 같음\n",
      "가식과 위선 덩어리 김기식 \n",
      "가온 거른다. 아니 어떻게 시상자가 하반기 치열했다고 했는데 ㅂㅌ 언급 1도 안 해주냐 무슨. 와 진짜 화난다 치열하긴 개뿔 2배 이상 차이 나는데 \n",
      "가장 역겨울 때는, 바로 그런 인간 유형들이 만인은 타고난 권리를 지닌다든지 모든 일에는 대화와 타협과 소통으로 임해야 한다든지 여하간에 제멋대로 놀아도 지 말에 귀 기울여 달라는 괜한 오지랖을 거창한 말로 돌려 지껄이는 경우다.\n",
      "가족 만들기 포기한 여자들이 페미니즘인 걸 정확히 간파해서 비아냥거리는 새끼도 아는 걸 왜 모르냐는 말에 한남도 맞는 말한다고 맞장구친다 면서 한남틀딱과 래디컬을 범주화시키는 짓. 아주 유치하고 유치해서 아무도 안 쓸 줄 알았는데 쓰시네요. \n",
      "가죽 잠바는 왜 벗었냐? ㅉㅉ 한심한. \n",
      "가증스러운 위선자 이재명\n",
      "가짜 대통령이 나오니까 숨어있던 친일파와 협잡꾼 기회주의자들이 더러운 본색을 드러내고 있다 예전부터 물밑에서 숨죽이며 위선의 가면을 썼던 자들이 수면 위로 그 본색을 드러내고 있는 것이다 더러운 똥물에 더러운 게 섞여도 별로 눈에 띄지도 않고 눈치를 못 채니까!\n",
      "가짜 보수 친일 양아치의 국가반역 내란 부정축재의 신화를 다시 쓰고 싶어 하는 너희. 가증스럽고. 역겹다. \n",
      "가해자가 미투를 지지한대. 역겹다.\n",
      "가해자는 안태근 사건을 덮으려 한 사람은 최교일임. 김재련 수작 부리지 마라. 손석희도\n",
      "가해자에 감정이입하는 한남들 한국 남자는 잠재적 범죄자가 아니라 실질적 성범죄자다 \n",
      "각질의 대표적 인물들 아닌가! ㅉㅉ \n",
      "간 철수 한국에 들어온 지 얼마 안 된 조선족 여성 영입?? 사람 영업하는 꼬락서니 봐라. 제2의 이좌쓰민 다문화? 다무나. 다 무뇌. 욕하고 싶다. \n",
      "간혹, 프로미를 하려던 플미충이 신고를 한다고 하자 원가 양도로 돌려드릴 테니 신고를 하지 말라고 하는 경우가 있습니다. 벌레와의 타협은 없습니다. 원가 양도로 돌린다 하여도 본래는 암표를 목적으로 하였으니 신고 리스트에서 제외해드리지 않습니다.\n",
      "갈수록 역겹네 저놈은\n",
      "갈수록 자매애 바닥났다고 토로하며 떠나는 사람들은 많아지고, 여초는 쪼개지고, 한남들은 징그럽게 뭉친다. 나는 두렵다. 나는 내일 아침이 늘 두렵다. 우리가 전쟁 중이라는 걸 모르는 동료들이 너무 많다. 그 점이 날 가장 두렵게 한다.\n",
      "감동했다느니 하는 꼬락서니가 한반도에 통일이 있다면 김정은에 의해 통일이 되겠구먼. ㅋㅋㅋ 제 이복 형을 죽였고 핵을 가졌어도 저렇게 공연단 초청 등으로 한반도 평화에 노력하는데 트럼프 저놈은 선제공격 위협으로 단번의 비핵화를 강요하니 그냥 전쟁광 늙다리네 \n",
      "갑자기 들어와서 죵 나만 지니까 개빡침 \n",
      "갑자기 예전에 생산직에서 아르바이트했을 때가 생각나네. 그때가 21살이었는데 40대 아저씨가 혼자 사냐고. 둘이 술 먹자고 추파 던진 거 생각남; 자식도 있고 아내도 있으면서 같은 직장동료로써 대우는 개뿔, 어린 여자 라면 사족을 못쓰지.;;역겹고 더러움\n",
      "갑자기 유럽여행이 너무 가고 싶지만 앨범 준비를 위해 미뤘다던 얘기가 생각나고. 화보 일정에 며칠 더 끼워 짧은 여행하고 온 거 생각나고. 그 와중에도 팬들 보여준다고 이런저런 사진 올린 거. 그러다가 헐렁헐렁 소리들은 거 생각하면 개빡침\n",
      "갑자기 헛구역질이 올라오는 건, 그대가 보고 싶다가도 진절머리나 게 역겹기 때문이다. \n",
      "갑질은 개뿔이. 소비자가 힘이 없으니까 불매운동으로 갑인 기업에게 요구 사항을 관철하는 게 갑질 이면 남양유업 불매운동한 사람들은 뭐 죄다 남양유업에 갑질 한 거냐? 노동운동이 언제부터 소비자 기만한 새끼들을 보호하는 게 노동운동이 되었는지 모르겠네.\n",
      "갓세븐 제이비 사행시 꼬락서니 성의 존낸 1도 없고 직업력 개빻은 거 어떡하면 좋아 아이돌 대체 왜 함? ㅠ 한남동 \n",
      "강경화 청문 채택 거부에 국민의 분노가 여의도 다리를 넘었다는 어떤 년, 위안부 할미들 같은 소수 지지를 들먹이고, 홍위병 문파들과 촛불 부대를 저들의 국민으로 끌어대며 은근히 그들 준동을 암시하는 수작질이다. 벌써부터 드러내는 좌익의 민낯ㅡ\n",
      "강경화 후보자 지지하며 눈물 흘리는 이용수 할머니 할머니 가슴속의 피멍을 야당들은 모른다! 문재인 정부 발목 잡고 나라를 엉망으로 만지려는 수작들 국민들은 절대로 용서치 않을 것이다! 자바국당 시래기들!\n",
      "강바닥 파내는데 몇조 원 갖다 부은 당에 있던 유승민이 세금이랑 예산 얘기하는 거 역겹다\n",
      "강아지 키우는 분들 개빡침주의 \n",
      "강연은 개뿔 그 나라엔 언론도 없다더냐? 입 막고 계좌 정리하고 수틀리면 튈라는 거지 출국금지에 협조 안 하는 놈도 공범!!! \n",
      "강연재 가니 김지예 오는구나.ㅉㅉㅉ\n",
      "강의하는 강사분이 저 세 한남 중 하나를 반장으로 뽑아놓고는 이건 남자들이 하는 일이라는 소리를 수업 중에도 자주 하신다고 함(. 그냥 그 소리만 하는 정도가 아니라 진짜 수업 중에도 세 한남한테만 자주 가서 가르쳐 주시고 그래서 여자들은 찬밥 신세라고 하는데 가장 가관인 건, 수업 후에 남는\n",
      "강일원 헌재 재판관까지 한다는 놈이 세금 탈루냐? 삥땅하다 1740만 원 세금은 납부했냐? 이런 양아치가 탄핵 심사를 한다고 개가 웃는다 이 게 너 마 1740억부터 갚고 탄핵 심사해라 이정미나 강일원이나 세금 도둑 뇬넘이 깨끗한 대통령 탄핵 심사 한단다 퉤 퉤 \n",
      "강정마을 말 바꾸기 위선자들. \n",
      "같은 공기를 맡고 있다는 게 역겹군요.\n",
      "같은 기사에 달리는 댓글들이 어쩜 저리도 확연히 차이가 나는 건지. 어쩜 저리도 다를 수가 있는 건지. 오늘 더 확실해졌다 아직도 ㄷ ㅇㅂ들은 조직적으로 ㅊㄹ풀밭에서 활동 중이란 걸 . 어휴 ㅉㅉㅉ\n",
      "같은 사고를 몇 년째 정치적으로 이용하는 미투 패거리들 역겹고 지겹다. 북에 가서 김정은 앞에 가서 재롱쇼나 가서 잘해라. \n",
      "같이 침대에 누워서 sns 한다고 동상이몽에서 본인이 야기했어요. 그 구역질 나는 트윗에 맞장구치고 호응해준 출마자도 똑같이 역겹다는 생각은 안 해봤어요?\n",
      "같잖은 세계를 만들어놓고서는 그 안에서 만족하려고 발버둥 치는 꼬락서니 너무 하찮고\n",
      "개 더럽고 역겹다 진짜 \n",
      "개 삐삐 \n",
      "개 삐삐 쌓아둔 거 나눠주지 맥주나 쳐잡숫고 씨비. 정말 화가 나네요. 알아서 할 수 있는 사람만 와달라. 도대체 공관이 하는 일은 국회의원 여행 가이드? 점심 전 화가 나서 밥맛 뚝\n",
      "개 삐삐가 진짜.\n",
      "개 새끼들이군! ㅉㅉ \n",
      "개 줘 씨들이 꿀 팁이랍시고 이제 겨우 고등학생이나 됐을까 한 어린 아들이나 친척 남자애들한테 너네가 지금은 몰라서 그런데 결혼 상대로 봐야 할 애들은 또래 친구가 아니라 초등학생 다니거나 유치원생 다니는 여자애들이 될 테니까 지금 튜터 잘하라는 말 너무 토할 것 같았다고. 빻은 드라마 방영을 제발 멈춰줘\n",
      "개 질척대네 역겹\n",
      "개념 남 그만 찾고 페미남 그만 찾아야 함. 혐애하면서 한남 먹어한다는 말하는 건 정신승리임. 그 님이랑 관계 유지한다고 내 에너지 쏟고 걔 비위 맞추느라 내 말 하나하나 자기검열하는데 왜 그게 먹어 인 거임?\n",
      "개념 말아 처먹은 놈들이 넘쳐나는 세상 ㅉㅉ\n",
      "개념 없는 년 놈들   소말리아 해적들도 누군가의 자식이라며 그 넓은 오지랖을 보여준 김제동!. \n",
      "개돼지 같은 새끼. 위선이라도 좀 부려 봐라. \n",
      "개띠용임 지금 어어어????? 어어어어어????? 지금 내가 ‘한’줌 ‘남’은 인류애라고 해서 한남이라고 했다 이 말인가????? ‘잣’은 ‘실’수면은 잦을 이지 무슨 실잦이야 개쩌는 끼워맞추기다 퍼즐 만렙인 듯\n",
      "개랑 사람이 같냐고 할 수 있는데 그게 왜 내 알바냐. 개키우는 사람이 개를 사람보다 더 가족처럼 생각할 수 있는 거 아니냐. 자기들도 별 씹오지랖으로 주접떨던 주제에 내가 애새끼 싫어해서 너희들 욕하는 건 왜 안 존 중요\n",
      "개멍청이 한남들은 재기해라\n",
      "개빡쳐진짜 애들이 윤지성 욕먹잖아 하는데 이유를 모름 아. ㅆㅂ 이유 없이 욕먹는 거 개빡침진짜\n",
      "개빡침 나랑 듀오가 트롤이야\n",
      "개빡침 대 환장쇼 목소리의 형태 후기. 솔직히 좋았던 것도 많았고 재미는 있었는데 별개로 화나는 건 화나는 것. 그래도 유즈루랑 마리아 보러 목소리의 형태 봐주시오. \n",
      "개빡침 엄마가 전화 와 서(근로계약서 보냄 나 지금 성추행 당해서 기분 안 좋아 끊자 햌ㅅ는데 왜왜 물어보고 뭐 입고 있었는데 민소매 이러니까 아 했음 아가 뭐냐고 당할만한 거냐고\n",
      "개빡침 화남 그래 가수들은 대선배니까 어쩔 수 없지. 보는 우리는 그다지 즐겁지 않네요 ㅁ슨 얘네 콘서트냐??? 가수 다 좋지만 이건 좀 아닌 듯\n",
      "개빡침 휴 잭맨이 그렇게 멋있고 장엄하게 로건 끝내고 로라에게 세대교체하고 떠나셨는데 로라 영화 안 만들고 로건 리부트 한다는 건 로라랑 로건에게 동시에 빅 싸이 엿 주는 거임 디즈니 새끼들 돈에 눈깔이 돌아가지고\n",
      "개빡침. ㅡㅡ. \n",
      "개빡침.없어져야될문명\n",
      "개빻만취성추행범한남새끼 네 마리 사이에서 여성 한 명이 위험한 것 같아서 그중 한 명 밀치고 그 여성을 밖으로 안내하고 집으로 보냈다. 야호님 함께 계셔서 할 수 있었던 일. 참지 않고 뭔가 할 수 있어서 다행이었다.\n",
      "개뿔 응원해줬더니 힘들다고 징징대잔어ㅠ우야란거 \n",
      "개뿔 준비도 안되고, 인재풀도 빈약하고, 공약도 없고. 시간이 팽팽 남아도니까 토론하자고 관광 대고. 당 재산 거덜 나는 줄도 모르고 이래저래 요구만 해대고. 그리고 결국 보여주는 건 자신들 밑바닥만 보여주고. 그러고도 모자라서 또 똑같은 말로 꽥꽥.\n",
      "개뿔의 영원 같은 소리 하는 효종아 \n",
      "개시 발 좀 빻은 말 하면서 레벨 인장 다는 거 너무 씹스럽네\n",
      "개식 겁해서 뿌리치고 반도리 노트도 다 놓치고 ㅡㅡ 노트 치면서 째려봤더니 그냥 타고 가는데 아 진심 짜증 나고 무섭고 역겹다 남이 지하철을 타든 말든 뭔 상관이야 그냥 가는 길 가지\n",
      "개웃기닼 지가 혼자 잘못 응모해놓고 잘못 당첨됐다고 당황하는거잖앜 개멍청햌 한글 못 읽나 봐 혼자 생쇼 한다\n",
      "개웃챙봊웃챙 윾-쾌하노 형님 덜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ그 와중에 김치녀라고 한 적 없는데 여성까지 싸잡아 넣는 김치 눈 찢어진 한남 수준 \n",
      "개이버가면 정말 화가 머리끝까지 난다. 제정신 아닌 것들 보고 있자니 나까지 돌 지경.이젠 댓글 조작 알바들이 미운 게 아니라 마냥 손놓고 있는 민주당이 밉다. 이게 도대체 며칠째인가. 네이버가 선수쳐서 분당 경찰서에 의뢰하는 수작 눈뜨고 뻔히 당하고. \n",
      "개저씨 역겹 느끼하게 바라보고 아가씨 아가씨 거리는데 눈깔 부수고 아가리 조잡아 꿰맨다.\n",
      "개 같ㄷ다. 오는 손님 꼬락서니 볼 때마다 그냥 짜증밖에 안 남.\n",
      "개표조작을 덮으려고 국정교과서에 올인해 여론몰이 총력전을 펼치는 새 미련과 기타 야당과 그 하수인인 어용 시민단체들과 대안언론, 파워 트위터들. 개표조작은 쏙 빼놓고는 역사왜곡을 막자며 정의로운 척 위선을 떠는데 참 역겹다.\n",
      "개화 난다. 손숙이 그 사람 하나 때문에 마음고생 하리라는 것도 화나고 그냥 다 화난다. 그냥 여자 희극인들 끼리 모이던 판 벌려, 쇼핑왕 누이 같은 콘텐츠가 더 나와야 할 듯싶다. 한남 구제해봤자 한남식으로 추락한다. 제 손으로 제 날개를 꺾는데 주변까지 힘들게 한다.\n",
      "갤러-잭으로 넘어옴-갤 깜 역겹\n",
      "거기다 슬쩍 김경수 끼워 놓고 난 김경수랑 같은 편이고 이재명은 김경수 까는 놈이라고 수작 부리고 있는 거죠. 선거전 내내 이재명에게 반문 프레임을 씌우려 하는 꼬락서니가 너무 역겹네요.\n",
      "거머리 같은 기러기들 추미애 대표 좀 그만 괴롭혀라 무슨 답변을 하든 어차피 너희들끼리 또 소설 써댈 거 아냐 김현 대변인이랑 매너손 김정우 당 대표 비서실장이 추댚 마크하느라 애쓰셨네. 추미애 대표는 결국 몸살로 오후 일정 취소하고 상경 \n",
      "거머리 같은 놈. 신고해 주세요! \n",
      "거머리 같은 놈들 모두 다 모여서 노는 꼴이 완전히 아웅다웅 딱 견적 나오네 ㅋ 덜떨어진 것들\n",
      "거머리 같은 놈들. 피땀 흘려 낸 혈세를 맘껏 퍼먹었구나. 저런 새끼들은 재판도 필요 없이 그냥 철퇴로 때려죽여야 한다.\n",
      "거머리 같은 미국 정치인 놈들 =_= 방위비 분담금을 야금야금 엄청 올리더니 =_= 이제는 ㅆㅂ 됐고 일본으로 밀려나갈 거면 그냥 조용히 나가라 =_= 니퍼트 대사만 우리가 엄청 분담금 잘 줬다고 흡족해했지 아마 \n",
      "거머리 같은 새끼들 진짜\n",
      "거머리 같은 새끼들! : 이명박 대통령과 맥쿼리 (영화 맥코리아: 맥쿼리자산운용이 자신들의 특혜 의혹을 다룬 다큐멘터리 영화의 상영을 막기 위해 법적 대응을 검토하고 있는 것으로 알려졌다.\n",
      "거머리 같은 자식들이(중얼\n",
      "거봐 저렇게 추잡하고 더럽게 논다 ㅉㅉ\n",
      "거지 같은 청와대 기자단들이 내 세금으로 밥 처먹고 커피 마시고 간식 사 먹고 지금까지 남의 돈을 자기들 돈처럼 쓰고 있었구나 아직도 청와대 기자단 해체 안 했니 장부 달고 밥 먹는 청와대 기자들이 있습니다 | 다음 뉴스 \n",
      "거지새끼들 꼬락서니 하고는.\n",
      "거짓 선동질로 권력을 쥔 자의 역사적 진실 타령. 역겹네.\n",
      "거짓 위선 구태 덩어리 안철수 국민의당 설 연휴 지나면 5% 이하 폭락한다,,, \n",
      "거짓 증오 위선의 썩은 새끼줄을 잡고 천국에 오르겠다는 정의 파괴 사제단 신부들과 이들을 편 드는 민폐다. 역시 좌익은 자충수로 망하고 악은 스스로를 드러내는구나.\n",
      "거짓과 위선으로 가득 찬 저런 모습이 더욱 혐오스럽게 합니다 저 사람은 단 한순간이라도 타인의 아픔에 눈물 흘려본 적이 있을까요? 박근혜처럼. 그러면서 저런 쇼를 하는 인간들을 제일 경멸합니다 진정성이라고는 1도 없는 mb 아바타. \n",
      "거짓말, 위선적 생기부에 쓴 악의적 표현, 삭제키로 장호영 기자\n",
      "거짓말쟁이. 알량한 위선 속 숨은가면. 그렇게 갖고 놀면서 재밌었을까. 거짓말쟁이. 한땐 그것마저. 그 가면마저 난 진실이라 믿었다. 믿고 싶었다. 그걸 부정하는 건 날 부정하는 거였으니까. 바보네.\n",
      "거짓선동과 음흉한 위선 서민 코스프레 .이 분야 노벨상 박원숭. \n",
      "거짓-증오-위선-분열로 찌든 썩은 새끼줄을 잡고 천당으로 오르겠다는 것인가? 사람을 속일 수는 있어도 全能 하신 하나님을 속일 순 없을 것이다. 거짓임이 드러나도 부끄러워할 줄 모르는 구제불능의 인간들은 法과 역사와 神(신의 심판을 두려워하라!\n",
      "건설 수상작으로 뽑은 심사위원 중에 박범신 있더라고. 한남이 쓰고 한남이 뽑은 이상스러운 소설이 발간됐어요 돌았군 돌았어 말세야\n",
      "걸그룹들 부른 의도 자체가 너무 역겹다. 그냥 너네끼리 방송하세요. 원래부터 아이돌 관련 기획도 아니고 그냥 자기들 방송에 굳이 걸그룹들 불러서 뭐 하는 짓이야 정말. 그토록 원하던이라는 자막부터 그들이 진짜야 거리면서 열광하는 것까지 너무 싫다.\n",
      "걸그룹이라고 쉽게 생각하고 그냥 애교만 부리면 되겠지 하고 폄하하는 사람 많거든 근데 따져보면 항상 웃고 있어야 욕 안 먹고 다이어트도 건강에 무리 올 정도로 해. 다이어트해도 근육 찌면 또 뭐라 해 진짜 극한 직업인데 그래도 자기들이 하고 싶은 게 있으니까 빻은 환경 견디잖아\n",
      "걸러야 할 빻은 사람에 아미 넣어놓고 정작 퀴혐 여혐돌 세븐틴 영업하는 마인드 무엇? 나는 방관하지 않고 고쳐나가고 바뀌었으면 하는데 순식간에 빻은 사람 됨\n",
      "걸렸죠? 역겹죠?\n",
      "걸스캔두애니띵은 메가를이니까 맨 카인드 캔 두 애니띵 하자는 한남. 죽어도 여자가 큰일 하는 건 못 보겠다 이거임. 와중에 뒷걸음 페미 오졌다 당연하게도 mankind는 남성을 인간의 디폴트로 놓는 단어라고 할 수 있습니다 \n",
      "검사 외전의 현실파? 충성심 역시 남다른 어록 말이 최소한 사람 말 같아야 비판을 하던 지지를 하던 할 것인데 이렇게 더럽고 위선적인 놈들에게 구역질이 난다 \n",
      "검찰, 70억대 뇌물수수 혐의로 이에게 구속영장 청구 근데 국회의원 불체포특권 문제로 국회 동의를 못 얻으면 구속도 못한단다. ㅉㅉ\n",
      "게 빻은 놈들과 방송할 때 나 재미 (개쌉소리하고 앉았네 . ○ ○ \n",
      "게다가 페미니스트 여성의 연애, 결혼은 굉장한 백래시 효과가 있음. 사회구조 부수자고 말하는 사람들이 그 구조 밑으로 기어들어가는 꼴이니까 이 운동이 존 ㄴㄴㄴ나 우스워지고 한남들 입장에서 봐도 입으로는 페미니즘 외치는 여자들이 여전히 남자랑 연애, 결혼해주는 걸 보면 존 ㄴㄴㄴ나 안심이\n",
      "게다가 학생이라지만 미성년자라는 근거는 없잖아? 어디까지나 학원이라고 몇 년이나 꿇은 만학도들이 입학하는 학원일 수도 있잖아. 그럼 다 성인이네. 성인끼리 서로 살인 좀 한다는데 그걸 가지고 쩨쩨하게 정발 금지시켜버리고. 한국 수준 ㅉㅉ\n",
      "게임 사이트들 너무 역겹 \n",
      "게임업계에서 여성을 소비하는 방식 진짜 역겹다 진짜.\n",
      "게임하는데 흉사 소리 들었다 내가 술도 취했고 걍팀보로 사람들이랑 장난치고 있었는데 어떤 한 남이 나랑 같이 빠대하자길래 그 사람 말 무시하고 장난치는데 내 목소리가 좀 애 같아서 애교 부리는 줄 아나 봄. 갑자기 흉자년 매우 싫다고 쌍욕 해서 충격받았다. 지금 병나발 불고 있다. 또 흑. 나 메 갈 수장인데\n",
      "게임하면서 누워있었는데 초등학교 저학년 한남이 대뜸 여자네. 이러더라. 멍청하게 핸드폰이나 하고 있네 같은 뉘앙스였고, 어디서 배워먹은 짓인지 모르겠지만 쯧쯧 하명 혀를 차더라. dont go wild kormale.\n",
      "게임하면서 실력으로 평가지 받을 때면 저 새끼는 현생에서 방구석에 처박혀서 이산화탄소만 내뱉는 돼지 한 남자 새끼라고 생각하며 고작 게임 하나 나보다 잘 한다고 입 터는 꼬락서니가 한남실 자지와 같이 안쓰럽다고 생각하고 있다\n",
      "결국 한다는 게 노무현 대통령 흉내 내면서 제 아내에 대한 인신공격을 멈춰주십시오? 제목부터 의도가 너무 뻔해서 정말 역겹다. 노 대통령 팔이 작작해라. 문제의 패륜 계정 주의 정체에 대한 의심과 李가 그 계정수와 보인 친목 질의 대한 해명 요구를 왜 김 씨에 대한 인신공격으로 비약하는 건가.\n",
      "결국에는 일부의 팬들 때문에 아주 그냥 일을 크게 만들더구먼 퍼나르고 퍼나르고 잘하는 짓들이다 진짜 짜증 난다 진짜 개 짜증 난다. 오지랖 지적질 좀 제발 그만해 이렇게까지 하니깐 속이 시원한가 모르겠다. 너희들이 하는 짓은 걱정하는척하면서 디스질 밖에 없지\n",
      "결국엔 작은 고추 발언으로 욱한 거 티 내는 미국 사는 한남. \n",
      "결국은 그 여자애 나보다 한 살 어린 거였다는 것. 말하는 꼬락서니부터가 새끼 어린 네였음\n",
      "결국은 체제 선전 인디 이시 끼들 은 알고도 모른척하는 거냐 마냥 퍼주기로 작정한 거냐 올림픽은 개뿔 존엄을 찬양하는 예술단인데 선수들은 간데없다마는 저 새끼들은 헤벌쭉 좋단다 아이고 .내 세금이야 ㅠㅠ\n",
      "결론부터 말씀드리자면 저는 거의 트위터 계정 생성부터 함께 해온 블랙스 바이벌이라는 장르를 접으려 해요 더 가까이하기에는 사장이 성추행범인 게임을 하고 소비하는 스스로가 너무 역겹고 수치스러울 것 같네요 다만 탈 더한다고 해서 지금껏 잡고 사랑해온 캐릭터들을 단번에 놓기에는 무리가 있는\n",
      "경기도 사는 사람으로. 전해철이 누군지 잘 모르다가 그 지지자들이 하도 상대방을 그것도 같은 당을 쥐어까대서 알게 됨. 지지자들 트윗꼬라지때문에 민주당도 찍기 싫어짐. 그만들 좀 해라. 역겹다\n",
      "경남 창원 정우상가 앞. 21세기인데 아직도 60.70년 냉전시대에 머물러 있는 한심한 인간들. ㅉㅉㅉㅉㅉ 미국과 소련도 서로 대화하는 시대인데. 밤새 부서진 채 발견된 제주 4·3 추모 시민분향소 \n",
      "경부고속도로 사고로 해당 버스회사의 5년 전 부당 보조금 사건이 다시 부각되고, 당시 조사를 선거후로 미루라고 시의원과 경찰에 압박을 가한 더불다 놈이 이제 와 그건 5년 전 일인데 어처구니없단다. 남의 약점에 거머리 같은 작자치곤 참 비열하고 뻔뻔하다\n",
      "경원아. 네 딸 캐리어 한 줄 더 써주어서 어디에 써먹으려고 수작이니? 왜 최순실처럼 정유라 거짓 이력 만들어서 ioc 위원 자리하려는 것처럼 네 딸 부정으로 대학 졸업장 주고 여기저기 위촉시켜서 나중에 한자리해먹게? 나쁜 ㄴ현. 친일에 매국행위. 불법을 자행하는 넌. 대역죄인이야.\n",
      "경제도 개뿔 모르는 거 같더구먼. 한심해! \n",
      "경향일보 기리기 기사 제목 뽑는 꼬락서니 좀 봐라.! 너희 새끼들은 정말 구제불능 맞다. 민주당 서울시장 예비후보들 안철수 마케팅 \n",
      "경험상 위선과 가식과 씹선비질을 혐오하시는 분들의 내적 진정성은 그다지 아름답지 않았다. 원래 사람은 반으로 썰어 놓고 보면 피와 똥이 찬 가죽 주머니인데 왜 그걸 굳이 열어서 확인하려고 하는가.\n",
      "계속 모집합니다(?? 혹시나 팀킴에게 못된 소리, 빻은 소리 하는 사람((한남 있으면 조지러 가실 파티원 구해요 \n",
      "계정을 다 털어 한데 모아 성 착취 성매수를 멈추라 한남 소추 민국\n",
      "고등학교 때 조부에게 증여받은 안철수 씨 세금 안 냈죠? 20대에 모친에게서 받은 아파트 세금 안 냈죠? 귀하의 따님 재산 내역 왜 공개 못하죠? 세금 안 내서? 불법 녹취. 대선 조작, 사실 조작. 어떤 것도 다 걸리는 당신은 어떤 종자입니까?\n",
      "고려대 에타 50 드디어 본심 나오셨죠? >그들이 기어오르지 못하도록 억눌러야 한다는< 믿고 고 한남이었습니다.7 \n",
      "고맙습니다. 할 줄 알았냐? 저 더러운 짓거리를 그저 오버쯤으로 감싸주는 너네 기자 집단의 조폭 같은 의리가 눈물겨울 뿐이다. 우리는 안 그랬다는 알리바이 만들라는 얄팍한 수작 집어치우고 하나만 해라. \n",
      "고발 드립 픅트하다 딱 걸렸네 ㅉㅉ \n",
      "고소 운운하는 것도 딱 찢베충이네 뭐 ㅉㅉ \n",
      "고슴도치 얘기는 뭔지 몰랐는데 탐라로 넘어와서 이제 알았네 미친아 역겹다 진짜\n",
      "서유럽 좌파 먹물들의 위선(고은태 선생님이 그렇다는 것이 아닙니다을 통렬히 비판한 극좌 트로츠키주의자-_-;\n",
      "고인 물 인성 ㅉㅉ\n",
      "고추 반으로 갈라서 도끼 자국 만들면 되는 걸 뭘 저런 것까지 산대. 머리에는 도끼 자국 만들고 싶은 생각 없니 한남들아?ㅎㅎ\n",
      "고추가 안 달리면 매일 성추행에 노출 당하고 언제 어디서 불법 촬영 당할지 몰라서 긴장해야 하고 대갈 빻은 고추들한테 옳은 말했다가 살해 협박 받으면서도 네가 말하는 그 사회시스템한테 도움받을 수도 없는 세상이라서요. 고추 달린 놈들은 안 겪어 봤으면 제발 좀 닥치시길.\n",
      "곡당들 머리 자르려다 추미애가 단호하게 나가니 지랄발광 원내끼리 뭔 수작질 한 거냐\n",
      "곤지암 그냥 대장이 개빡침 한대 치고 싶음\n",
      "골수 좌파단체 골수 좌파 시장 박원순의 정체다!! 누가 이 위선 가식 덩어리 반정부 좌파 시장 놈 박원순을 끝장낼 영웅은 없는가? 언제까지 위선 가식의 역겨운 짓을 보고만 있어야 하나? \n",
      "곰곰 생각해보아도 참 나잇값 못하는가 같음.\n",
      "곱씹을수록 짜증 나네 어쩔 수 없는 한 남이겠지 너희도. 그래도 직업이 아이돌인데 티는 내면 안되지. 아이씨에도 입 가리던 탠인데 과연 십 형 어떤 뜻으로 부르는지 모룰 듯. 그래서 더 화난다 서치 다들 많이 하는 것 같은데 팬들 하는 말들 잘 새겨듣길.\n",
      "공가 특징 1. 취조 2. 자기들의 견 반박시 묻어버림 3. 내로남불 마인드 4. 논리적인 맞말을 보면 꼬리 내리고 물타기 곡 5. 정작 필요할 땐 없는 오지랖 6. 불펌 7. 진지한 얘기 나오면 노잼드립치고 정색하면 댓글로 눈치 없냐고 하기 8. 뭐만 하면 불탐 (더 그로 같은 거 싫으면 관련 글을 안 쓰면 됨\n",
      "공부 이 씨 발 공 부 개 새 끼. (개빡침 \n",
      "공부를 남자만큼 잘하면 동등하게 여겨줄까? 정수기 물통을 갈면 동등하게 여겨줄까? 내가 다흰처럼 트랜지션 안 해도 ftm이고 정신적인 젠더도 인정하라고 일갈하면 남자랑 동등하게 여겨줄까? 전부 아닙니다. 한남은 자지 안단 걸 천대합니다.\n",
      "공연 관계자? 개뿔 누가 봐서 공연 관계자 공연 관계자가 스탠딩 입장도 전에 들어가 서있냐 팬을 바보로 아네 \n",
      "공정언론 망치지 말고 mb 낙하산들은 당장 공영방송을 떠나라! 거머리 같은 놈들아! \n",
      "공지에 금지한다고 빨간 글씨 때려 박고 밑줄 긋고 돼지꼬리 땡땡 쳐도 뎸 보내는 것들은 개뿔 안 들어 처먹는데. 나서서 아주 떠먹여주고 앉았네 ㅉㅉ\n",
      "공포와 혐오가 극에 달하긴 개뿔. 내 주변도 기사의 댓글에서도 북한의 영양상태에 걱정하고 안타까워하는 소리가 대다수였음. 앤 얼 것들은 북한의 열악한 실상이 까발려지니까 야마 돈 거지 딴 거 있나. 선동 좀 그만해라 \n",
      "과거 똥 덮으려고 발악하는 모습 역겹zo? \n",
      "과거의 영광은 지워지지 않는다고 했는데 자기는 깨우친 거처럼 말하면 멋있는줄알았나보지 저 사람도 되게 징하고 역겹다\n",
      "과연 당신은 깨끗하다고 말할 수 있는가 싫어하는 사람의 뒷담을 맘속으로 단 한 번도 까본 적 없다고 말할 수 있는가 앞에서 잘해주고 뒤에서 욕하는 위선의 가면을 단 한 번도 써본 적 없다고 말할 수 있는가 남 욕할 때아니다 당신 또한 가식이다. \n",
      "곽도원 좋아했던 배우였는데 이번 일로 아예 쳐다보기도 싫어짐. 사람 좋은척했었던 거구나. 변호사 내세워서 정에 치질 하는 모습이 진절머리 날 만큼 역겹다. 피해자들을 진정 생각했더라면 이윤택 사건이 다 마무리되고 나서 입장을 밝혔겠지. 후배들과 통화 건에 녹취하는 그 치밀성에 혀를 내두름.\n",
      "관심 엄청 많네 내가 뭐 때문에 힘든지도 모르면서 오지랖 작작 부리길 무례하다는 걸 알라고\n",
      "관심도 없으면서 관심 있는 척하는 거 역겹다 매번 자기가 어떤 사람들보다 위라고 생각하는 것도 역겹다,,!\n",
      "관심도 없이 날 안주로 소모하고 싶으시면 그쪽도 그 정도 각오는 하셔야 한다는 걸 각인시켜주면 서로 조심하기 시작한다 사실 그들의 오지랖이란 게 자신들은 전혀 해당되지 않을 거라는 방심에서 나오는 무례함 같은 거라 전혀 관심도 없으면서 꺼내보는 말이거든\n",
      "관심병 환자는 너인 것 같다? 가만히 덕질하는 사람 심기 건드리지 말고 못 보겠으면 차단하든가 그리고 공주님은 개뿔 너야말로 꿈에서 깨렴! \n",
      "관심이 그렇게 필요하니 ㅉㅉ 불쌍하다\n",
      "관심이 받고 싶음 참으세요. 성인이 다 되어가면서 아직도 지질하게 이런 글 쭉쭉 깝니까? 더럽네요 ㅉㅉ\n",
      "관저 집무실? 야 이 정신 나간 아줌마야 그럼 네 말대로면 탄핵당하고 직무정지된 상태인데 왜 아직도 거기 처박혀있냐고! 우리 세금 써가면서 네 집에 가! 썩 꺼지라고! 말 귀 참 못 알아들어! 언론 오보 땜에 혼란스러웠다고? 우린 너 땜에 5천만이 멘붕이야 박사모 빼고! 집에 가! \n",
      "광우 뻥 때는 625 사진전도 폭력으로 짓밟은 무리들이 세월호 학생들을 추모한다고 한다 그들이 625 때 전사한 우리 국군들을 추모한 적이 있던가 천안함 장병을 위해 꽃 한 송이 바친 적이 있던가? 더러운 위선자들이다\n",
      "광휘 독점으로 말이 많은 것 같은데 난 그거보다 롯데시네마의 모 지점의 젤 넓은 상영관을 눅데 소년 같은 영화가 차지했다는 게 더 화남. 거기서 007을 계속 보고 싶은데. 크기도 사운드도 다 좋았는데 다른 상영관으로 떨궈져서 개빡침\n",
      "굉장히 역겹구나.\n",
      "교복을 입는 건 자신의 임신능력을 과시하는 거다 빻은 소리도 정도껏 해야지 . \n",
      "교섭단체는 민평당이랑 개헌 합의는 자유당이랑 칭찬하는 건 바른다 정의당 너네의 본질은 무엇이냐 진보 정당은 개뿔 결국 너네도 여의도 기생충일 뿐이야 국민들이 원하는 건 국민소환제 대통령 연임제 국회의원 권한 축소야 진보 팔아 의원 권력 꿀맛에 빠진 똥파리 신세 정의당아 ㅉㅉㅉ\n",
      "교수 새끼 줄타기 하는 거 보기 역겹고 어떻게 하면 학생들 피 같은 돈 빨아먹을까 생각하는 거 눈에 보여서 개빡침\n",
      "교수도 아닌 조국이 최순실 보고 북한 같았으면 즉결 사형이라 했는데 너 같은 반역자가 북한 같았으면 장사정포로 살점 하나 남아나지 않았을 것이다 너 같은 표절자가 내 세금으로 밥 처먹다니 억울하다 서울대가 김일성대 보조원 아니냐 문재인 보조원 주제에 \n",
      "교수랑 다른 과 남자애들 미투 운동 유머 거리로 삼는 거 역겹고 불편해\n",
      "구글에 자궁 빵, 여군 만화 만 검색해도 나오는 수많은 빻은 이미지와 생각들. 이거야말로 잠재적 범죄 수준 아니냐. 이런 새끼들 안 잡아가고 고작 내앰져 성적 대상화 좀 했다고 지금 압수수색한 거냐고 \n",
      "구조 위해 촌각을 다투는 출동 중에 발생하는 접촉 등의 교통사고에도, 사비로 물어내야 한다는 저 사실을 방치한 채, 영웅이니 감동이니 떠들어대는 건 다 위선이다.\n",
      "구질구질하고 지질한 남직원들 얘기는 대충 역겹게 잘 그리나, 어적여 서사를 버리지 못하고 균형추 맞춘답시고 여직원 성희롱 에피소드에 꼭 꽃뱀 서사를 넣고 그랬지.\n",
      "구토 나온다 역겹고 짜증 나 ㅡㅡ\n",
      "구토 나온다. 역겹다.\n",
      "구토 나온다. ㅉㅉ\n",
      "국가 폭력 희생자 추념식에 국기 맹세, 애국가 제창… 지독한 국가주의 역겹다.\n",
      "국가의 근간인 헌법을 개정코자 하면서 개인의 이익 운운하는 저 무리들은 단언 하건대 평생 동안 이념 서적은 읽었을지 몰라도 인문교양서적은 단 한 권도 읽은 적이 없을 겁니다. ㅉㅉㅉ 저런 게 동물농장의 나폴레옹입니다. 개돼지 무리들의 왕초! \n",
      "국당 이언주는 북핵 위기에 나라가 풍전등화인데, 시민들 세금 축내며, 여의도 불꽃축제 즐긴다 씹더니만, 기러기들 북핵 위기에(안철수와 국당들이 폭탄주 말아먹어도 안철수가 달라졌다란 기사에 오버런 돼는게나향욱에 국민들은 개돼지라 먹을 거만 주면 된다는 거다.\n",
      "국민 물가 못 잡는 게 진짜 직무유기죄. 내로남불넘버원 ㅉㅉ \n",
      "국민 사위는 개뿔 .나는 너 같은 덜떨어진. 인간 사위로 안 맞았다\n",
      "국민 세금을 개인 변호사비로 썼군요. 욕도 아까운 말종 밉니다. \n",
      "국민 세금을 도둑질했으면 조용히 조사받고 죗값을 치러야지 뭔 헛소리를 지껄이는 거냐? 검찰 소환에 불응하겠다고? 지금도 최경환이 너를 보호해줄 힘이 있다고 생각하는 거야? 한심한 놈.ㅉㅉ \n",
      "국민 엿 먹이는 놈들을 세금으로 3500명이나 먹여살렸다고? 쥐새끼 나와라. 책임져야지? 국정원 민간인 여론조작팀 3500명 운영했다며? ㅋㅋㅋ 진짜 돌아버렸냐\n",
      "국민들이여! 꼭! 알아야 한다. 기식이 두고 진영 논리로 정상적 출장이라 임명 철회 이유 없다는 공산주의 기숙사 리더 외 졸개들이나 도덕성이 결여된 너희도 그런 외유했으니 따질 이유가 없다는 더듬다 추한 애들 발언이 반국민적 추잡한 치부다 추한 애도 썩을 대로 썩었구나 싶다 세금 내지 말자 할만하다\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국민의당文대통령, 시진핑에게 기자 폭행 유감 표명하라 와 호래자식들 이 순간에 어떻게든 대통령과 엮고 기자들한테 잘 보이려고 수작 부리네 징글징글하다 통합 꿈도 꾸지 마 새끼들아\n",
      "국정원 세금 7억이나 삥땅쳐서 해 입은 옷들, 더럽게 촌스러워요. 순실이 취향하고는! \n",
      "국정원 언론장악 문건과 함께 더불어민주당 언론장악 문건도 조사했으면 합니다만 안 하면 그거야말로 정치검찰 아니겠습니까 사법부 독립은 개뿔 장악 오지고요 국정원 언론장악 문건 있다 방송 간부· pd도 블랙리스트 \n",
      "국정원 특수활동비를 박근혜 청와대가 상납 받았답니다 그리고 조윤선. 연기 완도 매달 500만 원이나 상납 받았음 이것들 현직 근무할 때 자기들이 최고 우아하고 고상한척하더니 위선자들 이런 것들이 국민을 위한다고 국정원 돈이 국정원께 아니며 국민의 피 같은 돈인데 도적 놈들\n",
      "국정원이 가짜 뉴스 공장이었다. 독일처럼 1건당 600억씩 벌금 물려라. 국민 세금으로 봉급 받는 자들이 국민을 속이는 이런 범죄를 저지르다니. 마땅히 호된 벌을 받아야 한다. \n",
      "국정원한테 돈(세금 받은 보수논객 80인 명단 공개. 국정원 개들 - 전원책, 변희재, 조갑제, 김진, kbs 사장 고대영 등 전원책. 잘난체는 젖나 게 하는 놈이 결국 돈 받고 짖어대는 개였어. \n",
      "국회 거머리 같은 종자들! \n",
      "국회 꼬락서니 돌아 보고 떠들어라. 전과자 성폭행 뇌물 온갖 불법비리 연루자 천지가 국회야 .전과자 들에 나라를 맡기지고?? 국회가 범죄자 피난소다. \n",
      "국회는 치외법권 지역이라 인식하는 혼수 성태의 갑질이 참으로 가관이다. 이런 새끼들 언제쯤 안 보고 살 수 있을까? \n",
      "국회의 원전 번이 개인 정보였어? 미친 국가들. 자유 당국 개들 선거 때 문자 보낸 것도 같은 방법으로 고발해야지. 국민을 상대로 입막음해보려는 수작일진데 끝장 보자 자유한국당, 국회의원에 대규모 비방 문자 검찰 고발 \n",
      "국회의원은 법위에 군림하는 귀족입니까, 신의 아들입니까? 맞습니다 그들은 귀족이고 신의 아들입니다. 다 아시면서. 한때는 이랬습니다. 그때만 자 나면 신의 아들이 됩니다. 철저하게 국민을 속이고 기만하면서 나라의 세금에 기생하는 기생충입니다. \n",
      "군대 갔다 왔다고 깝죽거리는 한남들 교육해주시노. 김치 남들아 서양은 여자들도 군대 갔다 오는 거 모르지? ㅉㅉ \n",
      "군대 다녀온 남자들 밴댕이네. 일과 후 사병 외출 반대하는 비율이 13%나 높아 ㅉㅉ\n",
      "군대, 군대 캠프보다 코리안 워홀 쓰기 운동 여혐 민국에서 여혐 민국으로 워홀 가는 건 한남뿐. 그게 뭐 대단하다고 가산점을 받냐.\n",
      "군대는 나라에 따질 문제고 생리는 대자연 멱살 잡을 문제라고 하면 남덕들 본성 바로 나옴 네 메갈련이지 나오더라\n",
      "군대도 안 갔다 온 놈들이 수두룩한 당의 놈들이 군기 해이, 임전태세 어쩌고 하는 게 왜 이리 역겹지? 너희들이랑 너희들 자식놈들은 군대 가긴 했냐?\n",
      "군대랑 임신이랑 비교하는 새끼 덜은 다 한남인가 \n",
      "군표 다 썼는데 턴베리에 매물이 없어서 파마의 화살 직접 만들고 잇는데 기분 아주 째지고 더러움 아니마 개빡침 벌써부터 화남 아;;\n",
      "굳이 웜련이 아닌 나를 증명해야지만 한남을 팰 수 있다는 생각들이 이해되질 않았다. 맞는 말이어도 워마드 같은 워딩에서 거부감을 느끼고 출처에서 거부감을 왜 느끼지? 글의 본질이 더 중요한 거 아닌가? 싶었고 강남역 때의 고마움을 떠올리며 굳이 웜련이 아닌 나로 정체화하긴 싫었다.\n",
      "궁금해 알려죠 본계는 모하 눈 계정인데 젝팬덤 얘기가 나와? 아이돌이랑 상관없는 사람들이 젝팬덤 빻았다고 그래? 오지랖 태평양이네. 그리고 누가 네 새끼들이야?\n",
      "궁물조작당 주제에. 협치는 개뿔. \n",
      "권순욱 정치 신세계. 언론사들 정부 지원금은 한시적으로 지급하는 건데. 국회에서 계속 연장 시키고 있다고. 당장 국회는 언론사 정부 지원금 지급 못하게 연장 그만하라! 받아쓰기도 못하는 기리기 언론들 더 이상 못 봐준다! 국민들 세금이다! \n",
      "귀걸이 아빠 입이 고급이건 말건 상관없음. 본인 돈으로 사 먹으면. 죄다 세금으로 처먹어서 짜증 나는 거지 국회의원 때 사 먹은 1억 밥값. 그거 하나만 봐도 이미 싹수가 노랬었던 거다\n",
      "귀걸이 아빠란 별명 정말 굿임 혐오 표현 전혀 없으면서 아들 취업 특혜 한 내로남불 인성과 위선과 가식을 제대로 깔아뭉개는 표현 혐오 표현 없으니 딴죽 걸지도 못하지 \n",
      "귀걸이 아빠와 위.대하신 수령님을 존경하는 주사파, 언론, 민노총, 전교조 들의 끊임없는 노력 중에 언론의 힘이 가장 크죠! 월남이 패망한 첫째 이유가 우리나라와 똑같이 부패한 언론 때문에 병력과 전술면에서 비교가 안 되는 연합군이 굶주리고 군복조차 없는 월맹에게 패했죠. 거짓 보도로 민심을 선동해서죠.ㅉㅉㅉ\n",
      "귀걸이 이 녀석 참으로 뻔뻔하다. 노건호도 저리 뻔뻔하더니. 입지나 보 자식들은 배운 것이 뻔뻔함과 이중적 가치관인가. 쥐새끼처럼 청와대 들락거리며 쌀톨 나를까 걱정이다. 다.국민 세금이다. 네 아비 귀걸이 아빠 꺼 아니고!!\n",
      "귀여운 콘셉트인척하면서 유아화하는 거 넘역겹당.\n",
      "규리 아빠 이거 뭐 하는 겁니까? 노무현재단을 겁박하는 겁니까? 님들이 그럴 자격이 얼마나 있죠. 노통 마지막 때 다 도망간 애들이, 노무현 대통령님 돌아가시고 와서 장자방 노릇이나 하는 너희들이 역겹다. 님이 대선 기간 동안 촬영 도와준 거 고맙게 생각하는데요, 지나친 모습 실망이네요 \n",
      "그 게임 역겹긴 하더라\n",
      "그 ㄴ 웃기네. 전에 지각했던 욕은 그보다 몇 배 더 막장이더니 누구 욕한 것 캡처해서 올리고, 뭐라고? .참 네가 막장 쌍욕 한 것, 본 사람이 한 둘인지 아냐? 저런 위선 철면피를 보겠나? 거기 딸랑거린 양심 죄는 느덜이 받아 이것들아.\n",
      "그 돈으로 여성을 위한 은행 만드는데 기부나 하던가 참여라도 하세요. 조돌 사무실에 쌓였다가 폐기처분되며 여성혐 지수만 높이는 그딴 개 같은 짓 하지 마시고요. 볼 때마다 역겹고 웃깁니다. 노예가 착취자에게 자발적 조공하는 모습.\n",
      "그 드리러 빻은 말 개정 트위터 안 하는 거 개뻥같은게 사고가 트위터에 개 찌들어있는데요 나는 혼자 피씨하고 깨어있어서 너희 우매한 드리러를 가만히 못 보겠어.; 식으로 말하는 거 제정신이신지;; 여기저기 마음 박으면서 다른 사람 빻았네 마네 판단할 시간에 자기 행동은 진짜 정당한지 생각 좀;\n",
      "그 많은 외국인 중에 새누리와 똑같은 사람을 골라. 대단하다. 학력위조 미인대회 입상. 남편 죽음 방조 거짓투성이 위선자 필리핀 국결녀 이재 스민 그를 공천한 닭 그네 …\n",
      "그 말을 듣고 나의 모든 자비심을 거둘 수밖에 없었다. 지금도 그렇게 생각할걸. 성중립화장실을 무섭다고 거부하다니 의식이 빻은 무식하고 멍청한 여자들.\n",
      "그 뭐 뭐 사이트 포함 ㄴㅂㄹ 검색해도 나오는 게 하 r ㅏ다 동인지 불법스캔번역본인뎈 진짜 그거 보고 오만전이 떨어졌다 국내에 저작가 빼고도 픽시브존잘님 동인지 포함 창작 비엘 책 도는 거 진짜 개짜증 나고 개빡침 좀 사서 봐라 커피값 수준이데\n",
      "그 뭐시냐 이와 아이돌님도 좀 있으면 아시겠지만 경찰 출석 통지서라는 거 약간 rpg 게임에서 npc에게 주는 전직 증명서 같은 물건입니다 상대방이 절 부르는 호칭이 한남씹치새끼에서 선생님으로 바뀌게 되거든요 약간 게임에서 클래스 체인지한 느낌임\n",
      "그 사람이랑 헤어지긴 싫고 ,, 다른 사람은 만나야겠고 너무 이기적이고 빻은 거 아니냐? 진심이었던 사람은 모가 된다고 . 역겹네 정말 ,, ㅜ\n",
      "그 어린 여자 관객들이 주는 돈이 너희들 페이인데 그거 받고 싶으면 한남끼 누르든지 아니면 돈 받지 말든지. 너희들 연습 중 얻어먹은 서포트, 공연장에 들어오는 간식, 도시락, 너희들 밑에 있는 사람이라 너희들 조공으로 갖다 바친 거 아니에요. 어떤 경우로든 욕 지껄이고 가는 건 상식적이지 않다.\n",
      "그 얼굴에 역겹고 더러운 수염이나 깎으면 믿어줄까?. ㅉ\n",
      "그 여자 이름 쓸 때 대통령이라고 부르지도 말아라 역겹다 \n",
      "그 여자애를 식모라고 놀려서 울리는 남자애들이 있었다. 생수통을 들어서 억울하다며 동일노동 동일 임금을 말하는 여자에게 남자의 고충을 말하는 남자들은 독생자가 아님. 주변에 그렇게 키우는 여성보호자들과 남성 보호자들이 반드시 존재한다. 맨 박스의 희생자라니 개뿔. 한남에겐 그런 게 없어.\n",
      "그 역겨운 장면을 보게 되는 건가요? 생각만 해도 역겹다 박사모\n",
      "그 입 다물라, 쳐다보는 것만으로도 오염될까 두렵고 역겹다. \n",
      "그 중립축 새끼들 이미 어디로 기울어져 있는지 뻔히 보이는데 중립인 척하죠? 역겹죠?\n",
      "그 질문하는 방식이 비열하다는 거임. 그것도 모르는 수준으로 토론은. 개뿔.\n",
      "그 짓을 겪어도 저 꼬락서니라니 ,, 답이 없네 이제 정말 싫어졌어 뻔뻔하네 진짜;\n",
      "그건 역겹다.\n",
      "그걸 또 행동하는 위선이 낫다며 강철 짤 써가며 뽕차는 새끼는 무엇이며\n",
      "그것도 있는데 작년 부만 축 고 삼 사건 생각하면 아직도 개빡침 그래놓고 글님이 배려해주셔서 뭐 어쩌고저쩌고 찬양글 보는데 진심 역겨워서 할 말 1도 없어지고 싹 다 불락함\n",
      "그것만 봐도 그 오지랖이 단순한 선의가 아니라 약자에 대한 비열한 공격이라는 걸 잘 알 수 있다. 아니 선의라면 왜 남자 쪽에 말을 못하니? 여자 쪽이 그런 정신 공격에 만만하다는 걸 잘 알아서겠지. 개객기들.\n",
      "그것이 알고 싶다 소름. 으 역겹!\n",
      "그것이 알고 싶다. 국정원 댓글 사건 얘기하네. 딴 건 몰라도 그 셀프감은 년! 그 마스크는 누가 좀 벗겨야 하지 않겠음? 아직도 세금으로 먹고산다는 거 난 도저히 용납이 안되는데?\n",
      "그게 재밌어? 막 감동을 느껴? 객관적이고 건조한 시선으로 현실을 보여주기는 개뿔. 난 이런 것도 찍을 수 있다 으으 나의 거친 내면세계 이러면서 딸 치는 거지.\n",
      "그나마, 손혜원은 성격대로 화끈하게 대놓고 위반하는 바람에, 속물이나 위선자 소리는 안 들음. 한데, 다른 양반들 당시 맨션 살펴보면, 하나같이 이리 돌려 말하면, 미개한 당원들은 눈치채지 못함을 전제한 맨션뿐임. 가식에, 위선에, 선민까지. 우웩\n",
      "그나저나 뻐꾸기 운운하는 모 후보 역겹네요. 민주당 어려울 때 뭐 하셨는지, 문재인 정부 탄생에 어떤 역할을 했는지 물어보고 싶습니다. 뒤통수 실컷 때리다 무임승차하신 분이 할 말은 아니죠.\n",
      "그나저나 애가 아픈데 엄마가 지금 직장 다닐 때 나고 말한 의사 ㅅㄲ 진짜 황당. 대체로 저런 오지랖이 가능해지는 순간이 바로 전문가들이 권력화되는 시점이렸다\n",
      "그나저나 여왕 어쩌고 달고 복종한답시고 꾸익 대는 건 뭔 상황이야? 가관이다. 애초에 변기년 달고 오지 그랬니\n",
      "그나저나 이젠 멤버 생일파티에도 플미충이 초장부터 난입하겠구나. 팬클럽 카드-티켓-신분증 이름 같은 것 정도로 충분한 안전장치가 될 거라고 생각한 거라면 진짜 뇌가 업는 거고ㅠㅠ 아니면 모, 플미충들도 팬클럽 가입시키려고? 숫자 올리고 싶으니까?\n",
      "그냥 난 별소리 안 하련다 이제. 노동 인권 운운하면서 자르면 안 된다던 새끼들이 다른 건수 잡아서 자르려고 드는 꼬락서니 보니까 이거는 답 없다 그냥 자기들끼리 죽창 찌르라지.\n",
      "그냥 무조건 최악이지 한 명은 개뿔. 애인은 뭔 죄냐. 애인한테나 잘하던가. 헤어지던가. 비만 남이면서 매력 있는 외모의 여자 타령 어이구. \n",
      "그냥 사이코패스에 불과하던데요. 그게 공연 문화면 조폭들 폭력도 다 공연문화. 한마디로 지랄발광 개미 친구 짓. 여자 머리채 흔든 그 남자 백드롭. 개빡침 주의.\n",
      "그냥 쉬세요. 자격이 없어요 댁은. 위선자 재명 님. \n",
      "그냥 스스로 imf로 뛰어드네 미친 주사파 정권 새끼들 ㅉㅉ 내수는 ooo에 수출로 먹고사는 나라에서 환율 내주면 그냥 자살하겠다는 거지. 도대체 무엇을 하려고 천조국에 저런 어마 무시한 걸 내줬는지 . \n",
      "그냥 이게 딱 현실이잖아 피해 사실 아무리 밝혀져봤자 가해자는 잘 먹고 잘 살고 피해자는 잘리거나 스스로 퇴사하고 이런데도 도태 남들은 옛날일 끄집어낸다고 배액 거리겠지. 공감능력 한강에 던져버린 것들.ㅉㅉ \n",
      "그냥 지 좋아서 하는 거고만 다들 뭔 거기에 굽신대. 내가 미처 못 보거나 그런 거 보여주면 그냥 고마운 걸로 끝나는 거지 무슨 님님 붙여가며 자아라곤 개뿔 없는 짚신벌레들 마냥 이리저리 떠도는 거 보면 저걸 사람이라고 키워서 내놨다 싶어서 부모가 짠하다 이거예여.\n",
      "그냥 포기해 이 새끼얔 페미니스트들 너 같은 한남 필요 없으니까;;\n",
      "그냥. 논란을 떠나서 클베 지금까지도 느꼈지만 진짜 개 멍청하다는 생각밖에 안 드네 이달고 팬들에서 여덕 빼면 대체 뭐가 남는다고 저러는 거야 미친 거 아냐? 그나마 남은 한 남들 중에서도 1/3이 달덕 할게 이들이다. 이 미친 놈들아 ㅆㅂ 개저씨헤남들 팬으로 둬서 대체 뭐가 남는 단 거여\n",
      "그니가.,, 성범죄자나 빨면서 소비하고,,, 온갖 여혐은 다하면서 한남이라는 말만 해도 스위치 눌려서 쿵쾅쉬익대구 에효 역겹다ㅜ\n",
      "그니까 다른 새끼들 게 많아 역겹\n",
      "그니까 애초에 팬클럽을 만들자고 유료 팬클럽 해서 선예매하자 물론 경쟁 지금만큼 치열하겠지만 타 팬이고 성범죄자고 플미충이고 이딴 놈들 없이 엑스엘끼리만 티켓팅하자고요\n",
      "그니까 철수야 주적주적으로 주접 좀 떨지 마라. 개뿔도 모르면서. \n",
      "그니까. 매달 1억씩 40억 넘게 상납 받아쓴 건 불법이지만 관행이었으니 처벌하지 말고 제도 개선의 계기로 삼고. 30억 증여받으며 10억 세금 낸 건 합법이지만 부도덕하니 물러나라고? 어휴. 개기름 번지르르한 저 대 덩이 놈들.\n",
      "그니까요 진짜 그렇게 고인 물진 하더니. 쌤통이다 싶기도 하고 휴 미리 차단해두길 너무 잘한 것 같아요 ㅠ 이참에 앞으로 영영 안 보였으면 좋겠다.!!\n",
      "그니까요. 거머리 같은 새끼들\n",
      "그대의 글이 애국보수 국민들 두 번 울리고, 자중지란과 분열의 늪으로 내몰고 있음을 어찌 모르나.애국 국민들 진짜 속마음도 모르면서 디지털 정당은 개뿔.무고한 피해자는 내치고 배신자엔 꼬리치는 게 통합이라니.썩을 \n",
      "그들의 성장이 기재되는군요. 저는 어떤 친족으로 기억될까요? 남자애들 개무시하고 여자애들만 이뻐하는 메가를 년이 더 클지, 끝까지 결혼 안 하고 모임 때마다 나만 이뻐하고 할아비와 큰아빠 말은 1도 안 듣는 본받고 싶은 고모/이모로 남을지 말입니다. \n",
      "그래 그걸 문 새끼에게 좀 얘기 좀 하라고. 이 새낀 예전이나 지금이나 북에 의한 폭발이라 쳐 주장하고 있으니. 역겹다. \n",
      "그래 우리도 못하고 타 팬덤 티켓팅 연습쟁이들도 예매 못하고 플미충도 예매 못하고 다 못하고 뒤지자.\n",
      "그래, 난 네가 원하는 대로 죽을 거야. 죽기 전에 이런 말하는 게 우스워? 내가 발악하는 게 역겹냐고! 나도 그래. 그래, 나도 역겨워.\n",
      "그래,,, 빻은 생각인 거 알면 혼자서만 생각해,,, \n",
      "그래놓고 남자들은 큰일에 관심 많은데 여자들은 뭐냐(성별 검색어 순위 남자는 정치, 차 여자는 가정 용품이었음는 빻은 한남 6969969696969명. 반대로 남자는 현실에서 엉덩이만 긁고 앉았고 여자한테 노동력 다 전가하고 있다는 소리네\n",
      "그래도 it 뉴스 정리해주는 거 때문에 보고 있는데 이런 소리 하면서 자기네가 뭐 잘난 줄 아는 거 되게 역겹다. \n",
      "그래서 못생긴 아이돌 봇 이딴 계정에 잘못도 없는 남들 들 못생겼다는 이유로 올라오고 까이는데 얘도 꼭 올려주세요! 하는 곳이 트위터 말고 또 있나요? 인권 운동가들 많은 만큼 빻은 말 싸지르기 제일 쉬운 곳이 또 트위터 맞는데 뭘 아 환멸 세상아.\n",
      "그래서 블라인드 채용도 성별 제외 블라인드 하니 묻지도 따지지도 않고 어이쿠 남자니까 뽑아드립죠 한은 꼬락서니 역겨워\n",
      "그래서 재명이는 이 년과 시시덕? 역겹다 위선자 \n",
      "그래서 저에게 요즘 새로운 목표가 생겼습니다. 빅 이슈의 전국화.너무 거창한가요. 우선 경인권에서 올해 안에 새로운 판매 지를 3개 이상 개척해볼까 합니다. 너무 오지랖이 넓은가요. 한 번의 시행착오를 거쳐서인지 이제는 별로 두렵지도 않네요.\n",
      "그래서 전 씹선비라는 단어를 입에 담는 사람을 경계합니다. 이것만큼 윤리, 도덕을 냉소적으로 바라보는 단어가 없는 거 같아요. 또 이건 벌레들이 만들어 낸 단어이기도 하죠. 윤리와 도덕이 위선이 되고 조롱 당하면서 패륜이 솔직하고 쿨한 것이 되는 사회와 조직은 건강하게 성장하지 못 합니다.\n",
      "그래서 초창기에 매 갈리아의 방법론적인 부분에 대해 반대한 사람들은 어떻게 되었느냐 → 여자가 이렇게 화가 났는데 갑자기 냉정해져서 여자 입 막으려 드는 냄져 쯤으로 자동 라벨링 되었지요. 이 부분에 대해 지적하면 다시 → 자기 욕먹는 건 죽어도 못 참는 한남이 되었다.\n",
      "그래서 회충이가 특검까지 갈 사안은 아니라고 한 거구나. 역겨운 위선자 같으니.\n",
      "그래서? 기르기야, 다시 물 막아 썩은 녹조 라테 한잔할까나? 쪼개살리자고? 일단, 국민 세금 22조 쏟아부은 4대강 보가 세계 10대 흉물 건축에 뽑힌 거나 잘 보도해봐라. 멀쩡한 강바닥 뒤지지 말고 시간 나면 세금 도둑 쥐박이 뭐 하나 좀 알려다오. 우린 그게 더 궁금하단다. 기르기야 \n",
      "그러게 나는 매주 로또 삼천 원어치를 사면서 복권이란 수학 못 하는 사람이 내는 세금이라고 생각하고 있었지만 문득 정신을 차려 보니 타임라인의 나와는 비교할 수 없이 명민한 수학적 사고를 가진 사람들도 다들 모바일 기차게 의 개돼지가 된 것은 마찬가지였다.\n",
      "그러게나 말이에요 오지랖이 바다 같죠? 제 새끼 입에는 거미줄 치는데  박근혜가 불쌍해? 거지새끼들이 주제넘게 공주 걱정해주고 있네.\n",
      "그러면서 고결하다 깝죽거리는 것들 역겹다 정말\n",
      "그러므로 마피아로 다시 가게. 정말이지 이런 유의 거짓말은 하기에도 역겹군.\n",
      "그런 식으로 오지랖/개마 너/반말 찍 찍 하는 당신네를 보고 있으려니까 부끄러움은 보는 이의 몫이어서 한국 여권 꺼내기도 싫고 한국인이기도 싫어서 그럽니다. 내가 당신이 반가우면 당장 한국어로 말을 하겠죠 나도 네이티브 스피커인데.\n",
      "그런 취향을 가진 사람이 당당하게 거리를 활보한다고 생각하면 역겹습니다. 아동이 성적인 대상으로 묘사되는 매체를 보면서 성욕을 느끼셨나요. 정말로 당신은 비정상이에요. 그 취향은 절대로 용서받을 수가 없어요. 취향이라고 하기에도 두려워요 사실은.\n",
      "그럴 일 없으니 걱정 마세요. 세무적으로 문제 있다면 이런 청원과 상관없이 당연히 조사받겠죠. 댁처럼 결벽증 있는 제가 아니라서 역겹다는 말은 돌려드리죠. 어디 초면에 막말 따위나 하는 주제에. 꺼지세요.\n",
      "그럼 한국인들보다 “더 나은” 플레이를 보여주시던가. 자기 자리 뺏길까 봐 관광대는 꼴 진짜 역겹네 \n",
      "그렇게 당신의 비참한 현실을 판타지로 소비한 나를 역겹게 생각했길 바라.\n",
      "그렇게 따지면 원작 내 공컾이 아닌 자기가 아무렇게나 엮는 커플도 원작 파괴인데 왜 그건 안 잡을까요 아무리 나 세계관으로 한다 해도 결국 2차인 것을 ㅉㅉ 이게 그 임피인데 진짜 노 답. 진짜 사건도 많았고 그로 인해 팬들도 다 떠나가는데 파들이 빨아주니까 정신 못 차리고 우물 안 개구리죠 뭐 \n",
      "그렇게 살면 안 피곤해요? 오지랖쟁이야 이제 그만해라를 친절하게도 얘기한다. \n",
      "그렇게 염원하는 출생률 높이기 위해서라도. 자신이 생존할 수 없는 상황에서 누가 아이를 낳아. 그리고 남초 커뮤 보면 애 키우는 것에 생활비 쓰는 것도 요즘 남자들이 아까워해. 아이 낳은 지 얼마 안 된 아내가 저임금 일자리 빨리 취직해서 돈 벌어오지 않으면 욕하더라. 진짜 지질한 한남들의 시대임\n",
      "그렇지만 나 제일 오늘 어처구니 없었던 게, 클라이언트가 나한테 직접 와서 구글에서 사진 불펌해서 그냥 써달라는 거였음; 너무 개빡침.\n",
      "그룹 내에 고만고만한 와 꾸중에 그나마 나은 애들 자기들 인기 멤인 거 알고 거만한 거 개꼴 값이던데\n",
      "그리고 기안 7 작가 자체가 좀 역겹기 때문에 완벽하게 종결됨\n",
      "그리고 난 아저씨가 빻은 소리를 해서 화가 났는데 아저씨는 왜 화가 난 거예요? ㅋㅋㅋ여자들이 비싼 구두 좋아하면 아저씨 마음에 막 화가 차올라요? 진짜 소갈머리 밴댕이 저리 가라네 \n",
      "그리고 남성 친구랑 택시 타면 대부분 말이 없는데 나 혼자거나 여성 친구랑 타면 온갖 쓸데없는 얘기부터 오지랖일 정도로 질문해오는 거 너무 짜증 나고 불편한 것도 여성들에게흔한일이라면 으 너무 경멸이고 부럽고 짜증 난다 택시는 절대 혼자 타고 싶지 않음 ㅜㅜ\n",
      "그리고 남자는 자신보다 강하고 빛나고 잘난 남자를 사랑하고 숭배한다 여자도 그런 남자를 숭배하고 남자는 절대 여자를 숭배는커녕 동등하게 존중할 수 있다고 여기지도 않는다 꾸준히 남자친구 남편에게 평등하기 위한 목소리를 내고 행동해봐라 불쾌해하고 화내는 한남의 더러운 와꾸를 보게 될 테니\n",
      "그리고 다른 오빠 바보 취급도 그만 좀 했으면 그런다고 너희들한테 의지할 거 아니고 젝키는 젝키끼리 사이가 겁나 좋아요 거기에 너희들이 끼어들 자린 없어 콘 5분만 봐도 알 수 있어요 그니까 타 멤버 병풍 삼아 지질한 짓거리 그만 좀 해 서열은 개뿔 똥 싸고 있다 진짜\n",
      "그리고 동상이몽에 나와 하는 짓들 보면 역겹죠 부부가 참.\n",
      "그리고 맨날 전우수 까는 사람들 웃긴 게 >빻은 오 딱 후를 후려치는 나<라는 프레임에 갇혀서 일정 주기되면 갑자기 뜬금없이 퍼블릭 머리채 끌어잡고 나옴 퍼블 리틀 님들이 매우 그렇게 소비하는 게 더 빻았어요 아셈? 충분히 매력 잇고 예쁘고 잘생기고 설정 대박인 캐릭터 그딴 식으로 소비하지 마세요\n",
      "그리고 번호 알려준 게 원해서 알려준 것도 아닌데 상황 파악 못한 방범대 새끼도 진짜. 거기서 내 대학 물어보고 oo 학교 학생이 싸네? 이 딴 식으로 말한 새끼 진짜 바로 앞에서 지 자식새끼가 보고 있는데 말하는 꼬락서니 하고는 네가 그러고도 방범대냐 솔직히 할 게 없어서 하는 걸로 밖에 안 보였지만\n",
      "그리고 샘 록웰. 진짜 연기 너무 잘해서 영화 보다가 중간에 스크린 뚫고 들어가서 내가 죽여버릴 뻔. 진짜 혐오스럽고 역겹고 끔찍한 백인 남자 진액 지구 내핵부터 끌어모아서 권기옥 만들어버린 캐릭터 . 근데 슬픈 건 현실에 많잖아 샹\n",
      "그리고 소설에서 그 남자들이 주인공한테 너 메갈련 이었냐 거품을 무는 거임\n",
      "그리고 야 네 부모님은 (덕질할 돈으로 챙겨드렸어? 너 그 돈 어디서 나는 걸로 하는 거야 하면서 나를 걱정해주는 척 오지랖을 떠는 경우도 있는데 진짜,, 네가 돈 내 통장에 꽂아준 거 아니면 무슨 상관일까,, 좀,, 내 돈 쓰는 거에 오지랖 떨지 말기 하자,, 쓸 돈은 두고 쓰는 거 당연한 건데 굳이 납득시키고 싶지도 않음\n",
      "그리고 여기서 부모님은 혿에게 말도 걸어 보고 뭐 여러 가지 노력하셨으면 좋겠어. 그렇지만 홑은 이미 부모님에 대한 원망으로 가득 차 있는 상태니까 저게 좋게 보일 리 없지. 당연히 갑자기 왜 저러지? 역겹네. 이런 식의 생각으로 증오는 더 짙어져 갈 거고\n",
      "그리고 이번팬싸에서 내가 들은 말 중에 제일 화난 게 경호원이 이찬이고 나발이고 뒤로 가라 이 말이었음 진짜 오버였음ㅋㅋㅋ 그거 듣고 우리 개빡침ㅇㅇ 여자 경호원이었음ㅇㅇ\n",
      "그리고 일 이따위로 만들고 블레싱 뒤에 숨어있는 일송정인지 플라타너스인지 너 반드시 나와야 하고 빌어먹을 오지랖으로 극비로 해도 될까 말까 한걸 이 꼬락서니로 만든 당신 외 블레싱 악기들 죽어도 해명 받아낼 겁니다.\n",
      "그분들 이론대로라면 메가를 자른 게임은 망해야 하는데 오히려 갓흥겜되니까 어금니 꽉 물고 욕하죠? 역겹죠? \n",
      "그야말로 위선에 가득 찬 여자입니다. 탁 씨를 두둔하기 위해 모든 여성의 인권을 휴지처럼 가벼이 날린 저렴하고 천박한 여자이기도 하고\n",
      "그은데 바이너리 트랜스젠더라고 여성성을 억압한데! 아아악! 내가 남자였으면 역겹다고 했었겠지 이 이중적인 녀석들아!!!\n",
      "그의 머리엔 가쓰오부시가 깃들지 않았으나 눈동자는 본연의 것 그대로였다. 어쩌면 힙합에 맞춰 춤을 추며 부락 부치노 대신 다이어트 콜라를 잡는 것이 삶에 권태를 느끼는 그에 좋은 탈출구였을지도 모른다. 하지만 그의 재산을 생각하면 모든 게 내 코가 석자인 나의 오지랖이어서 그만두기로 했다. \n",
      "그중에서 이용섭이 젤 싫음. 대통령 제일 중요한 공약 일자리 위원회 위원장으로 정치권으로 크게 복귀 시켜 줬으면, 양심상 다음 총선에서나 나오던지 지금 지지율 높게 나와서 될 거 같으니 나가는 꼬락서니가 너무 싫음. ㅡ.ㅡ;;\n",
      "그쪽이나 잘하세요, 오지랖 평수 늘리다가 죽고 싶지 않으면. \n",
      "근데 그거 혐오이고 한남이랑 존똑인거 알지?\n",
      "근데 꼴에 무서워서 가로로 긁지 이것마저 역겹다\n",
      "근데 당신이 뭔데 남의 프라이버시를 털고 평가하는데? 오지랖 돋는구먼ㅉㅉ \n",
      "근데 메가를 때문에 내 삶이 더 힘들어진 것 같아 그건 참 개 같군요 서 벌 것들.\n",
      "근데 사람들 웃긴 게 내가 힘들어서 내가 무슨 무슨 병 아닐까라는 말을 흘깃흘깃 던지면 에이 네가?라면서 웃는다. 늘 힘든 건 나고 내 몸 주인은 나고 내 고통을 다 받는 건 난데 자기가 다 안다는 듯이 역겹게 말해.\n",
      "근데 서울시장이면 자연인 아닌가 자연인으로 돌아가겠다는 말 자체가 좀 역겹네요.\n",
      "근데 오달수랑 김기덕이랑 조재현 등등등은 언제 감옥 갈? 아무 소식 못 들었는데 이러다 또 슬금슬금 나와서 영화 찍고 돈 벌고 하는 거 아니야? 역겹네.\n",
      "근데 왜 그 꼬라즤내고. 그럼 욕 안 먹게 잘 좀 해다. 그리고 너네 성 폭력범 자정 못하는 거랑 강혁민 욕 유무 비교하는 것부터가 머가 리 너무 딸리고. 네 트젠인데 래디컬이니 많이 하는 거면 진짜 죽여버린다 \n",
      "근데 요즘 힐ㅁ 감독에겐 기자, 심판, 선수 로 감독에게 하는 것과 아주 다르게 공손하게 대접하는 거 보면 더 짜증 나고 화나는. 더 욕하고 싶지만 같은 인간이 되기 싫어서 여기까지는 개뿔 인종차별주의자 새끼들 다 나가 죽어라ㅏㅏㅏㅏ\n",
      "근데 웃긴 게 뭔지 알아? 인터넷에서는 강남 언니 같은 얼굴만 모아놓고 성괴니 뭐니 하면서 낄낄거리는데 막상 오프에서 성괴를 보면 이쁘네 여신이네 하면서 학학 거림. 이율배반적인 놈들\n",
      "근데 이걸 마치 27일 a 양의 시간 특정이 있고 나서야 안 것처럼 언플을 해대는 이 가증스러움은. 도! 대! 체! 역겹다.\n",
      "근데 진짜 예전부터 빻은 남초 사이트에서 지내서 빻은 성향이 된 여덕은 링 구제불능임. 일단 거기서 공주 대접받고 성녀 취급받는 거에 너무 익숙해져 있고 남자가 옳다 이런 생각이 깊이 박혀있어서 나중에는 여자가 하는 말을 봐도 왜 이래; 모든 남자 안 그러는데; 이런 생각만 계속 함\n",
      "근데 확실히 내 주변에도 20대.20대 중반 넘어가면 탈 더하는 애들이 많긴 함…. 그리고 웃긴 건 탈 멍하면서 마치 자기는 오타쿠가 아니었던 마냥 기피증을 보임 이게 진짜 로레알 개빡침 \n",
      "근데. 할 본 알피지가 빻음의 계보라기보단 헬본컬쳐 아니. 헬 돈 자체가 빻음 국가 아닌 감\n",
      "글렀음ㅉㅉ;\n",
      "글쎄, 당신 기분만 괜찮다면? 다들 역겹다고 하는데 괜찮으려나.\n",
      "긍정적 사고가 쉽게 되는 사람이 타인의 불안과 우울을 보고 쉽게 자기가 조언할 위치에 있다고 생각하는 오만이 너무 역겹다\n",
      "긍정적인 지적과 오지랖의 차이는 모냐면 지금 당장 고칠 수 있는가 없는가의 여부라고 앗 너 앞머리 갈라졌어 여기 거울!>좋은 지적 너 머리 자른 거/염색한 거 별로야 안 어울려>기분 나쁨만 초래하는 개썅오지랖에 이제 와서 어쩌라고 되는 고나리ㅠ\n",
      "기가 막힌다. 이거 경남도지사 보궐선거 준비하시던 분들이 한 번 소송이라도 내서 법원에서 다퉈 보아야 하는 것 아닐까? 그나저나 보수는 법질서를 존중하기는 개뿔;; 홍준표 이건 정말 쌩ㅇㅇㅊ네;; \n",
      "기간 지난 영장이래 캬 남 경찰들 이제 머리가 넹글넹글 돌았어? 기본적인 것도 안 지켜? 와 진짜 설마 기간 지난 영장인 줄은 몰랐는데 일처리 꼬락서니 역시 한남이다 형님 저 새기는 끝났습니다\n",
      "기능 악당이라면 완전히 미치던가. 그런 애매한 양심을 핑계로 위선자 역할을 하고 있는 건 다름없잖아? 역겨워 오르카 너였더라도 마찬가지였을 거야 기능 네놈은 네 양심에 죽을 거야 오르카 .마음대로 생각해 죽기 전, 너와 내가 마주한 날\n",
      "기다려야지ㅋㅋ 플미충들 ac 가운데 b.\n",
      "기러기들 얼마나 또 진상 짓을 했으면 ㅉㅉ 무사히 공연 마친 게 남쪽 기리기 못 들어오게 한 덕분이었네. \n",
      "기러기들 정말 역겹다\n",
      "기러기들과 안철수의 사랑놀이 역겹네. 서울시민들이 안철수가 넘겨준다고 넘어가는 거냐? 솔직히 대통령 병들어서 시장보단 대통령 되려고 넘겨준 척 한 거 아니냐 지금도 간 보고 있는 거고. 정치 참 더럽게 한다. 안철수, 박원순에 넘겨 줬던 45% 지지율 되찾을까 | 다음 뉴스 \n",
      "기러기들이 더 민주에 수작을 손혜원 의원님 힘내세요!.송영길 의원님도ㅎㅎㅎ\n",
      "기러기들한테 민주주의는 사치. 홍준표처럼 힘으로 겁박하고 박근혜처럼 개무시해야 바짝 엎드리지 문포처럼 대우해주면 머리채 잡고 기어올라서 자기들 발밑으로 기게 만들라고 하더라고. 권력 감시는 개뿔. 권력의 개 주제에 웃기 놈 들.\n",
      "기러기의 자신의 존재감을 위한 꿈틀 현상은 역겹습니다. 존재감을 보여 주려면 정론직필의 사명감이 우선인 것이죠. 기러기 그들만 모르는 상식입니다.\n",
      "기르기로는 부족하다 역겹게 썩은 부패한 폐기물 든이다.\n",
      "기르기야 손흥민한테 패스 안 하는 토트넘 다른 선수들 비판한 적 있냐? 국대에서 손흥민한테 패스 안 하는 전북 현대 이재성 비판한 적은 있고? 왜 손흥민한테만 탐욕 부린다고 개질할 이냐 ㅉㅉㅉㅉㅉㅉㅉㅉ 기리기 어 그로 수준 \n",
      "기리게들 제목 봐, 데 넣고 삼성 챙겨주네. 이건희 차명계좌 고율 과세 1천억이란다 5조에 고 세금이 1천이면 2% 자리인데? 차명계좌는 불법이고 5조면 2조 5천억이 정당한 세금이야 기리기 새끼들아.\n",
      "기리기 기사에 틀딱들 작업 중입니다. 들려주세요. 댓글들 가관입니다. 머리에 우동사리 가득한 말만 하죠 ㅋ\n",
      "기리기 새끼들이 나라 망신 다 시키고 댕기네 ㅆㅂ 중국은 아직까진 공산국 가야. 공권력이 얼마나 센데 한국서 하던 짓 하다가 쌤통이다 미국 가서도 나라 망신 시키더니 나라 망신 겁나 시키네 \n",
      "기리기 새끼들이 노무현 소환 직전에 한 짓이다. 이명박한테는 찍소리도 못한다. 이명박이 이재용 다음 우리나라 부자다. 그만큼 국민 세금 센타깐거다. \n",
      "기리기 수준하고는. 구토 나온다. ㅉㅉ\n",
      "기생충 핵폐기물 같은 것들. 새빨간 거짓말로 나라 말아먹고, 팔아먹는 대역 범죄를 천지가 보는 앞에서 나팔불며 저지르는 극악범죄자들. 못 배운 어르신들 세뇌해 피 빨고 방패 삼아 사기행각 이어가는 이 거머리 같은 매국노들. 하늘이 용서치. 않을 것이다.\n",
      "기자가 똥 멍청이냐? 경찰이 수작 부리냐? 언더파 2개라고!!! 이것들아!!! \n",
      "기자는 개뿔. 기에 기질 하다가 처맞은 거지. 하여튼 한국산 기러기들은 세계적인 망신거리임. \n",
      "기자는 건들면 안 돼요. 정권은 5년이지만 우린 영원하거든요. 투철한 동업자 정신 칭찬합니다!! 바뀐다고 생쇼를 하더니 개뿔 똑같네! 명불허전 엠 빙 신\n",
      "기자들 두들겨 맞았다고 중국과 전쟁을 선포해야 된다는 국회의원이 탄생했다. 중국과 전쟁을 하면 어떤 결과가 나올까요? 이런 정신 나간 새끼가 국민들 세금으로 밥 쳐 먹고산다.\n",
      "기자들은 민의에 의해 선출된 적이 없어도 기자증 하나 목에 걸고 정부부처를 출입하고 고시에 합격한 적이 없어도 정책을 난도질하며 그 흔한 학위 하나 없어도 세상 만물에 대해 오지랖이 넓음을 자랑할 수 있는 직업 언론사주와 제벌 등의 돈 받고 그들의 입맛에 맞는 소설 쓰는 앵벌이 조폭\n",
      "기획자가 디자인 참견하면 정말 개 빡침 모니터 옆에 붙어서 색상 하나하나 지가 지정까지 하면서 이렇게 이렇게 해달라 해서 안된다고 이상하다고 해도 괜찮다고 말한 대로 해달라 해서 해줬더니 디자인이 뭐 이따위 내고 한소리 뭐? 이 년이.\n",
      "길 가다 진짜 가래 끓고 칵퉤하는소리 진짜 역겹다\n",
      "길 가다가 지뢰 만남 역겹;;;꼬라보고 갔는데 눈 녹는 줄\n",
      "길거리 개저씨 를 딱 들은 .푸다닥. 왜 이렇게 방귀를 뀌어댈까 바텀 알바 뛰다가 괄약근 재기했냐\n",
      "길거리 담배 연기 북한산 대동문의 막걸리 냄새는 이제 점점 없어지는 추세. 야구장 바닥의 맥주 냄새도 역겹다는.\n",
      "김 차남이라는 말을 쓰며 한남을 줘패는 외국 여성을 보면서 한국 여성에 래디컬이라고 부를 만한 게 있었나 싶은 충격을 먹음. 김치녀라고 비하하던 놈들에게 겨우 한남을, 그것도 인터넷에서나 하고 일상에서는 자주 쓰지도 않는데 아주 시기적절하게 김치나.예♪하는 걸 보니 충격일 수밖에.\n",
      "김경수 의원님 제발 버텨주세요 ㅠㅠ 이읍읍씨는 아주 살판났듯합니다 혜경궁 김 씨 논란 덮으려는 수작 더럽고 역겹네요\n",
      "김구라 장동민 유세윤 전현무 김성주 등등의 빻은 놈들 전부 다양성을 차별하는 새끼들이잖아;;;;;;;;;;;;;;;;;;;;;; 어디서 다양성 존중을 위해 남기란 소릴 함부로 해;;;;;;;;;;;;;;;\n",
      "김기덕 진짜 비주류인 척하지 마라 그 남초 커뮤니티에 정장 입고 커피 들고 가는 직장 여성 보면 패고 싶다는 한남 글이랑 딱 똑같은 정서면서 \n",
      "김기식 땡처리, 삥땅? ㅎ 이 시 끼 하는 꼬락서니. 인턴 여비서와 해외 출장? ㅎ 뻔할 뻔자. 이 새끼야! 정말 네 가슴에 손을 얹어봐라. 너도 안희정이한테 배운 거 아니냐? 희정아, 네가 기식이한테서 배워야 했지 빈. 네 여비서 승진을 시켜줬으면 어땠을까?\n",
      "김기식 발언 모음 (아래 사진 .자신에게 해당하는 말을 뻔뻔하게 남에게 해대는 내로남불 위선의 극치 \n",
      "김기식 별로 안 좋아하는데, 그간 관행으로 굳어진 것을 갖고 그것에 대한 반감만 이용해서 한 사람에게 모두 뒤집어씌우는 건 역겹다 못해 이렇게 해서 그 관행이 깨질 것도 아니라서 참담함. 그리고 피감 기관 비용으로 출장 가는 거 시비 거려면, 기업의 외부 감사 비용도 시비 걸어야지.\n",
      "김기식 신임 금감원장에 대해 비난하는 적폐 야당 국가들은 적폐 삼성이 저지른 반헌법적, 불법행위들에 대해 언제 한번 나선 적이 있나? 하는 짓들 보면 구토 나올 정도로 역겹다!!!\n",
      "김기식 이놈은 정말 거머리 같은 놈이다. \n",
      "김기식과 해외 다녀온 인턴 여직원을 밝혀라 김기식아. 누가 누구를 감독하고 평가한단 말이냐 너 같은 적폐는 혈세로 밥 먹을 자격 없다 위선자 새끼야 \n",
      "김기식의 행태를 보면 이 천박스럽고 뻔뻔스러운 것들의 기질을 고스란히 드러낸다 조금이라도 양반 기질이 있다면 쪽팔리고 양심 때문에라도 그 자리에 못 있을 것을 비열하고 천덕스럽게 눈치 봐가며 지키고 있는 꼬락서니가 이것들의 실체이다! 이런 것들에 뭘 기대할 수 있나? 양아치들보다 못한 것들한테?ㅉ\n",
      "김민정 님께서 간과하시는 맘 충이 서사의 주범 1. 독박 육아하게 만든 농편 란 남 2. 남의 새끼 밴/낳은 여자라고 칭하는 한남 3. 기혼 유자녀 여성 혐오 서사를 주작하는 한남 \n",
      "김보름은 후원도 끊기고 선수 생활 다 접어야 되는 지경까지 왔는데 조민기는 증거 없고 여자가 꽃뱀인 거고 애꿎은 사람 몰아가지 말란다 둘 중 하나만 해 미개한 한남\n",
      "김비오 박훈 변호사와 1억 원 내기 진행하겠다 | 다음 뉴스 고만 좀 해라. 역겹다. 좀 많이 들아. 한 사람인 생 조져놓고 뭔 짓들이냐?\n",
      "김생민 기사에 이런 댓글들이 달렸다는 게 너무 역겹다 \n",
      "김생민 너무 역겹다 스튜 피해라\n",
      "김생민 너무 역겹다. 가정에 충실한 이미지 잔뜩 팔아먹어서 더. 당장 하차시키고 송은이 김숙이 더 재밌게 짰으면 좋겠다\n",
      "김생민 미투 스튜핏. ㅉㅉ 왜 그래 피해주고 사는지\n",
      "김생민 성추행? 역시 한남은 지뢰다 곧 터질 냄저와 이미 터진 내미 저뿐\n",
      "김생민 역겹네\n",
      "김생민 역겹다\n",
      "김생민 역겹다 제가 원래는 좋은 사람인데.에서 이해할 수 없는 더러움을 느꼈다\n",
      "김생민 역겹다 진짜 소름 끼치게 역겹다\n",
      "김생민. 역겹다. \n",
      "김생민도 역겹고 주위에서 저딴 말 한 사람들도 역겨워 너네가 다를 게 뭔데\n",
      "김생민이 셀링 포인트로 팔았던 게 여타 한남들과는 다른 성실함과 반듯함이었잖아. 알탕에 부역하지 않는 이미지로 여성층의 호응도 얻었던 건데 결국 가장 알탕스러운 방식으로 실망을 주네. 남자들 사이에서는 약자고 배제당해도 여자 앞에서는 남성 권력 휘둘렀다는 게 역겹고\n",
      "김성 탠 똠방대고 나대며 머리가 나쁜 놈이다. 노조 막노동 출신 공부 안한 티가 너무 난다. 자식아, 국민들이 너보다 더 머리 좋아 제발 생각 좀 하고 한 박자 늦게 말해라. 예능 나가서 박근혜 씹고 탄핵 주도하고, 청문회 스타하고. ㅉㅉ. 그게 모두 네 목을 딸 거란 생각은 못했지? 안민석 같은 놈 \n",
      "김성태 어깨 힘들어가는 꼬락서니 눈뜨고 못 보겠네. 어이구.ㅆㅂ\n",
      "김어준이 석사 출신 전문가를 인턴으로 강조하는 건 야비하다고 실드 했다. 네가 석사를 안 해서 석사가 전문가인 양 말하는데 석사는 한 부분을 공부하는 예비단계다. 학부생보다 논문 체계를 좀 알고 자료 모아서 쓰고 통계분석 정도 할 수 있는 수준이다. 전문가는 개뿔. 찌그러져\n",
      "김용민 또 투표로 저 짓거리했어요? 한두 번도 아니고 상습적이네요. 역겹게.\n",
      "김용태·하태경 최순실 의혹 특검 수사해야 | 다음 뉴스 너희들이 봐도 창피해 죽겠지? 그럼 우리 맘은 어떻겠노 이 거머리 같은 새누리야\n",
      "김우명이 역겹대 ㅌ ㅌ ㅌ ㅌ \n",
      "김인성은 또 누구냐? 계속해봐. 평화 올림픽 망치는 일제시키 나라 망치는 역적시키야! 김일성 아니면 허위사실 유포로 국제 의원 빠찌 때 버려라. 나라 망하라고 고사 지내는 니딴게 어디 국민의 세금을 받아먹어.! 하.퉤!!!! \n",
      "김일성 기쁨조를 상상하며 야설 쓰는 한국 언론들 레퍼토리 다들 아시죠? 그들이 상상하는 성적으로 방종하고 여자들 착취하는 남성 권력자가 있잖아. 그거 구현한 거네. 더러운 한 남자 새끼.\n",
      "김정숙 은 착한 히잡 박근혜는 나쁜 히잡 김정숙 히잡 착용은 현지 문화에 대한 예의 박근혜 히잡 착용은 여성 인권 탄압의 상징 이게 정상적인 사회정의라고 외치는 이들은 민주주의 적이며 사회의 해악임, 참으로 역겹다.*. \n",
      "김종인 팽 수순 밟나. 고립무원 오히려 당내 일각에서 비례 2번이면 사실상 보상을 받은 것 아니냐는 목소리까지 나올 정도다. 펌. 막말한다고 정청래를 멋대로 컷오프 시켜놓고 자기가 막말로 이놈 저놈 다 욕하는 위선적 노인네.\n",
      "김진표 류는 시험 한 번 잘 보면 평생을 검증 없이 우려먹는 사회 탓에 국민 정서와 반대로 가도 전문가 영역이려니 하고 다 용서가 되는 줄 아나 보다. 전문가는 개뿔, 우리 손자 새기보다 세상을 모르는 놈이! 자칭 보수 기독교 지도자란 놈들에게 환멸 느꼈냐?\n",
      "김치녀 방치한지 10년! 한남충 생긴지 몇 년 됐죠? 여윽시 한남. 여자 패는 건 좋지만 내가 처맞는 건 못 견딤!\n",
      "김치녀 어쩌고 할 때는 가만히 있다가 이제 와서 한남으로 주홍글씨 찍기에만 뭐라 하냐 한 번도 가만히 있었던 적 없었음. 그런 주장하다가 맨날 저 치들한테 번 팔러 소리나들었지. 근데 이제는 일반화 못 참는 줄 서 큰 이 됐네?\n",
      "김치녀의 대립으로 한남을 내민다는 게 얼마나 웃기는 일이냐고. 거기 담긴 의미와 실제 언어적 표현으로 드러나는 경멸감과 과격함을 비교해 보라고.\n",
      "김치만 종특 : 떼창, 오지랖\n",
      "김태년 세금 국민에 돌려주는 추경. 6월 내 처리 초과 세수를 활용해 한다는 점에서 국민이 낸 세금을 국민에 돌려주는 추경이라고 강조\n",
      "김태륭도 김태륭인데 김동완은 여론이 이러니까 은근슬쩍 탑승하면서 sns 하는 거 역겹네 난 예전부터 김동완이 왜 축구 해설을 하는지 도무지 이해가 안 감 \n",
      "김현이 안전행정부 소속으로 폭행 사건 하루 전날 내놓은 보도자료 기가 막히는군요. 당신을 구하러 온 구급대원 왜 폭행하나요? ㅡ김현. 이 위선과 가식에 성질만 더러운 여자야, 당신을 데리러 온 대리기사는 폭행해도 되냐? \n",
      "김홍걸 사회 원로를 찾아와 덕담을 나누는 자리에 녹취했다는 건 처음 들어본다. 안 씨는 과거에 어떤 지저분한 정치인도 하지 않았던 그런 행태를 보여 주면서 기존 정치는 썩었다. 새정치를 말하는 것은 위선적이다. 기억을 더듬을수록 안 씨는 노 답이다.\n",
      "깁스에서 냄새난다. 역겹다. 진짜 벗고 싶다.\n",
      "까도 까도 삥땅 친구만 드러나는구나 김기식은 조만간에 쇠고랑 좀 차야겠다 깨끗한 척은 다하더니 ㅉㅉㅉㅉㅉ 검찰, 김기식 기부금 법 위반 추가 고발 병합수사(종합 | 다음 뉴스 \n",
      "깨굴님사진폰배경해놔서인지 국텡이 티켓 플미충도 짜증 나 죽겠는데 사기 중한테 당하고 열받을만 한데 그렇게 속상하지 않고 교훈을 얻은 것 같고 막 편안하다. 그렇지만 권리는 누릴 것이다 내일 신고하러 가요 국카스텐 티켓팅에 개입하는 불손한 세력들 다 쉣더퍼커 \n",
      "꼬락서니 보기 싫은 새끼 저 새끼 안 보고 싶은 것도 큰 이유임 어느 이유에서든 1도 얽히기 싫은 타입\n",
      "꼬락서니 하곤. 다시는 이런 짓 하지 마시길. 광주에서 현직 시장. 3선 국회의원. 전국인지도 있는 중진. 쟁쟁한 남성들과 경쟁하며 정책과 실력 열정으로 온 힘을 다해 맨발로 뛰는 양향자 후보도 있다. 어렵지만 정정당당하게 선택받겠다고 한다. 당신들 뭔데? 공천 맡겨놨어? 빚쟁이야? 왜 이리 뻔뻔해? \n",
      "꼬락서니들 보아하니 마감 한 거 같지는 않고. 너희들 어디냐? 어디서 들어왔어? 말 안 해? 벙어리야?\n",
      "꼬락서니들 보아하니 맞고 싶어서 온 것 같지는 않고. 너희들 어디냐? 어디서 들어왔어? 말 안 해? 벙어리야?\n",
      "꼬락서니들 보아하니 문상 온 거 같지는 않고. 너희들 어디냐? 어디서 들어왔어? 말 안 해? 벙어리야?\n",
      "꼬락서니들?보아하니?문상?온?거?같지는?않고. 너희들?어디냐??어디서?들어왔어??말?안?해??벙어리야?\n",
      "꼬락서니에 지긴 싫어서 양쪽 다 손해라고 하는 꼬락서니 봐라 미중 무역전쟁의 결과는 모두의 패배일 수밖에 없다 현실은 중공만 개쪽빡이지 \n",
      "꼴에 가식적으로 비위 맞추는 거 너무 역겹다\n",
      "꼴페미 보기 역겹다\n",
      "꿈의 제인 보는데 역겨워서 못 보겠다 진짜 이렇게까지 역겹게 만들어야 되나. 내가 나이브 한 건가.\n",
      "나 꼼수류들이 사회적 주류 행세하는 거 역겹네요.\n",
      "나 너무 역겹다 진짜 토할 것 같고 자꾸 이럴 때 친구들한테 매달려서 하소연하는 것도 너무 미안하고 내가 너무 이기적이라서 그냥 나한테 화나. 나 어떻게 해야 해. 그냥 내가 죽으면 되는 거 아닐까? 나 너무 역겨워 내가 살아있는 거 자체가 너무 미안할 정도야\n",
      "나 시오니즘 기업 피하느라 화장품은 소위 백화점 브랜드 안 쓰고 로드숍 위주로 쓰는데 말이지. 요즘은 >>미사일 하나 사주기 vs 성범죄 기업 후원하기<<를 하고 있는 거 같아서 역겹기 짝이 없다.\n",
      "나 약간 반에 있기 싨ㅇ서 어제 동성애 역겹다고 한 얘가 내가 시 쓴 거랑 그림 보더니 아 개오글거려 하면서 머라 하길래 정색하고 나 그렇게 말했던 애들이랑 연 다 끈ㅅ엇다고 했더니 걔랑 걔 친구가 내 뒷담 까더라 남의 창작물 비웃는 거 무엇. 역겨운 사람이 쓴 거라 그런가? \n",
      "나 진짜 너무 역겹고 지금 진심으로 탈주하고 싶음\n",
      "나 철학 하고 싶은데 역대 우리 학교 철학과 여자 교수 0명에 현재 성희롱하는 교수 있는 데다가 작년에는 단톡방 성희롱 건도 터졌음 교수나 학생이나 수준 ㅉㅉ임\n",
      "나 팔로 해주는 사람들이 다 내 편이면 좋겠다 250명의 내 편. 하지만 사실 내가 빻은 소리 하면 이 애호박 새끼야 정신 차려 (심한 욕 or 조용히 블록 < 이럴 사람들뿐이어서 굉장히 믿음직하고. 어. 어. ?\n",
      "나 힘들 땐 너 일이지 자기 일 아니라고 나 몰라라 하시던 분들이 이제 와서 가족 운운하는 거 역겹죠?\n",
      "나가뒤지라 이거에요. 힘든 상황이라 익명의 힘을 빌린 사람에게 하는 말 꼬락서니가 ㅜ\n",
      "나경원 24억 떼먹고. 다른 사학도 다 그러는데. 사학법 개정하라. 왜 내가 낸 세금을 너네가 꿀꺽하고 그 돈으로 땅 사고 건물 사고 삥땅 쳐 먹냐. 게 잡 것들아. \n",
      "나경원 씨. 자꾸 숨기려 하면 할수록 더 추해집니다. 진실은 1억 원짜리 두꺼운 메이크업으로도 가려지지 않습니다. 또한 서민 운운하던 국회의원이 청담동 고급 피부클리닉 다닌 위선과 가식도 가려지지 않습니다. 그러니 주진우 기자를 이제 그만 괴롭히세요.\n",
      "나경원도 전과 후가 있네 이런 성괴네 난 이런 성괴 보고 미인? 또 후회한다 나경원은 성괴다 이 정도 고치려면 최대 1억? 나만 그런가 피부 미용은 딸만 한 게 아닐 것 같은데 \n",
      "나는 겁쟁이지만 너는 빌어먹을 위선자야.<라고 본즈한테 울며 따지는 커크 보고 싶어 요\n",
      "나는 그저 치아 카나가 보고 싶었을 뿐인데 트위터가 이걸 보여줄 때마다 너무 가슴이 아픈 것이다 하지만 점점 이 페이지를 자주 보게 되니 그런 감정도 무뎌져서 조용히 새로 고침 하는 걸 보니 이 페이지에 정이 들긴 개뿔 헛소리하지 말고 검색 결과 똑바로 좀 출력해 큰따옴표도 붙였잖아 \n",
      "나는 나잇값을 못하는 생선 한 마리\n",
      "나는 날 개돼지 취급하는 것들은 그게 회사든 아님 국회의원이든 절대 용서 않는다! 내가 박근혜 최순실에 분노한 이유도 국민을 개돼지로 봤기 때문에! 국민은 개돼지가 아니야! 우리 권리 우리가 찾자! 개헌? 개뿔이다! 나쁜 놈들! \n",
      "나는 내가 타인에게 상처를 주는 걸 혐오한다. 그게 아무리 작은 생채기라도 상처는 상처인 거니까. 그래서 매일 말할 때 필터링하고 조심스럽게 말하다가 어쩌다 한 번 말이 잘못 튀어나갔을 때, 그러다가 타인이 상처를 입었을 때 안 그래도 혐오스러웠던 내가 더 역겹게 느껴진다.\n",
      "나는 노빠고 문파 광신도;;지만 그전에 dj 대통령도 존경하고 민주당 뿌리라 생각하기 때문에 김홍걸 위원장 필두로 동교동계도 민주당 내서 한 축이 돼서 잘 어우러져 갔으면 좋겠음 국물로 간 노 답 틀딱들 말고.\n",
      "나는 대학 내 학교폭력은 어떻게 해야 하는지 궁금해서 검색해봤는데 내용은 전부다 학교폭력 가해자가 되어버렸는데 대학 가는데 문제 있나요라는 질문이다 역겹네\n",
      "나는 딸 가진 모 부들이 역겹다. 나는 그들이 남자님 모시는 하녀가 되라고 (딸을 안 낳으면 남자님들 모실 하녀가 사라지니까 딸을 낳았다고 생각한다.\n",
      "나는 모든 애들을 좋아하고요, 걔는 특별히 날 더 이해해주고 챙겨주고 매일매일 학원도 같이 가고 해서 당연히 더 정 생기지. 차이는 있잖아 그냥 너 혼자 생쇼 하지 마라 보는 내가 다 역겹다 아주;;\n",
      "나는 어른들한테 중2 때 걸린 우울증=중2 명으로 여겨지는 게 너무 싫다,,, 중 2도 청소년이고요 우울증 걸릴 수 있어요,,, 사춘기라 그래 이것도 매우 짜증 납니다. 사춘기라 예민한 게 아니라 네가 빻은 발언을 한 거라는 걸 왜 몰라요.\n",
      "나는 육체노동자가 고소득을 올리는 것에 분개하는 트윗을 보면 진짜 역겹다.\n",
      "나는 이재명을 지지한다. 그러나 이재명이 어떤 새끼처럼 위선자짓을 하거나 말을 바꾸거나 퇴물 냄새가 나거나 뒷거래를 하거나 비상식적인 일을 한다면 그날부로 손절할 것이며 5년간 신나게 부려 먹을 가치가 있기에 그를 지지하는 것뿐이다. \n",
      "나는 이재명이 못 견디게 역겹다. 내가 지키고자 하는 가치들을 다 건드린 놈.\n",
      "나는 작품 감독 꼭 검색해서 확인하는데, 복부비만이고 머리털 흰 색인 할 아저씨 백남 감독이 여성 서사를 연출했다면 이제는 모욕감이 든다 여성의 시각을 고려했다고 해도 모욕감이 든다. 페미 굿즈 만들어 파는 한남같이.\n",
      "나는 저런 생쇼보 면 구역질 난다. \n",
      "나는 정말 모르겠다. 역겹다.\n",
      "나는 지극히 역겹고 잔인하고 소름 끼치던 아이였답니다\n",
      "나는 진짜 이 정도 말했는데도 나에게 동의하지 않는 저 우매하고 한심한 군중/배우 빠/작품 빠/빻은 애들 스탠스가 너무 싫어\n",
      "나는 한남 특유의 자기 주변 여자 이겨먹으려는 언행이 너무 싫음 방금도 나이 차이 얼마 안 나는 커플인지 부부인지 들어와서 여자분이 샌들 보는데 내가 보기엔 사이즈 과부족도 없고 그냥 딱 맞는데 냄자가 자꾸 한 사이즈 큰 거 달라는 거임 난 냄져말 귀담아듣지 않기 때문에(특히 여자가 신발 신을 때\n",
      "나는 한복이 참 아름답다고 자부심을 느꼈었다! 그런데 우리나라 고유 한복이 외국에 천박하게 헐값으로 선전되는 게 괴롭다! 모델은 추잡한 질푸니에 독재자의 딸 그리고 위선에 찌들어 헤픈 썩소를 가진 늙은 마녀가 이렇게 한류를 망치다니.! 역겹워 구역질 난다\n",
      "나도 나 말하는 꼬락서니 보면 진짜 찔러 죽이고 싶어 ㅜ\n",
      "나도 내 실명, 얼굴 걸 고하는 전공 작업 페리 주제로 하는 사람인데 나 개빻고 코르셋 개쩔었던 시절 있으니까 앞으로 하면 안 되고 여.응연히 빻은 사람이네?\n",
      "나도 덕이라 덕들의 말도 이해하긴 하는데 덕인 자는 자고로 가슴에 손을 얹고 받아들여야 한다 우린 너무 그런 이미지와 꼬락서니에 오래 노출되었고 그 수위가 높아져 있고 수위 조절의 문제는 스스로 조절 가능하다고 말하기엔 멍청이들의 트롤링이 너무 치명적이다\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나도 전ㅎㅁ 싫어하지만, 남의 연애사에 누가 못생겼니 누가 한남이니 말하는 것은 그의 애인에게 실례가 아닌가. 또 그와 별개로 그의 행실이 별로였음에 월평이 당연해질 수 있는가? 나는 아니라고 보는데. 비판의 수단으로 미러링을 써야지 미러링이 주 목적이 되어서는 안 된다고 생각해.\n",
      "나도 한때는 광팬이었는데 요즘은 석희 저놈 이름도 듣기 싫다. 역겹다. \n",
      "나도 항상 성괴라는 표현 들을 때마다 짜증이 난다. 성형을 해서 예뻐진 연예인들에는 열광하면서 성형이 예쁘게 안된 사람들에게는 어찌나들 가혹한지.\n",
      "나라 꼬락서니가 어찌 되려는지? 국민의 70.80% 탄핵에 찬성한 박근혜를 아직도 아직도 옹호하는 인간들이 있으니. 아녀자가 어디 나가서 남의 애를 배어와도 할 말은 있고 억울한 점이 있다 했다. 무식한 것들.\n",
      "나라 꼬락서니가 왜 이 모양 이 꼴이냐? 테러범에 국민이 납치 되질 않나 백주에 인질사태가 나질 않나. 하루 걸러 사고 나니 이것 불안해서 살겠나. 썩을 놈들\n",
      "나르샤 위선자들이 틈새다 당주도 권 뺏어 쥐려고 지도부 물러나라는 연판장 돌려. 그럼 즈그들은 늘 뭐 했나? 불과 반년 전까지 당 대표하던 김무성 이 책임을 모두 현지지도부에 돌리는 꼴이 가증스럽다.\n",
      "나를 뮤즈로 두는 것에 거부감은 없지만, 내가 뮤즈라고 해놓고 결과물이 형편없으면 진심 개빡침 뭐라구? 그 토사물이 나란 말이야? 정말 죽여버리고 싶어!\n",
      "나만 그런 거 아니었구나 나 아까 5시간 동안 무슨 생쇼 한 거지 현타 개세게 옴\n",
      "나만 애니 얘기나 후원 나올 때마다 채팅창에 ㄴㄷㅆ 역겹나??? 애니도 연예인이나 크리에이터같이 똑같이 덕질하는 장르 중에 하나인데 그걸 자꾸 배척하는 느낌이 듦. 아이돌 후원 나오면 그렇게 우리 언니 오빠 누나 형 거리면서 애니한테만 그럼 나도 아이돌 파지만 그런 거 보면 참.\n",
      "나미 친 년 바른 정당 남경필 대선 출마 축하식 최고 회의에 참석 그냥 나대지 말고 새누리당을 떠나라 거머리 같은 년 \n",
      "나쁘지 않아요 진짜 울고 싶어요 흑흑 어차피 현판 뛰어도 못 구할 거,, 양도충들 다져라,,,,,\n",
      "나오지 좀 말라고 진짜(개빡침 \n",
      "나와 생각이 다른 사람들을 무조건 조 이빨로 규정 씹어대는 애들이 있는데 새누리당 보수파 친구들이 더 경멸하고 싫어한다! 그들의 말에 의하면 처치 곤란 거머리 같은 골치덩어리라는 것이다 \n",
      "나와 토. 무지한 여성을 의식화한다는. 그 말투가 너무 역겹고. 본인은 전지전능하다는, 모든 걸 다 안다는 그 말들이 너무나 구토 나와. 한때 세월호 얘기에 절박해서 혹하고 넘어간 내가 한심해.\n",
      "나의 개저씨 나의 화나는 부분이 뭐냐면 보잘것없는 흔한 40대 한남 웅앵웅 으로 뽑아놓은 배우의 와꾸가 절대 한남의 평균이 아니라는 것. 그렇다고 초 잘생긴 배우로 뽑은 것도 아니어서 한남들이 나 저 정돈되지 않나?라는 여지를 줄 수 있는 캐스팅으로 했다는 거다 현실은 술배 땀범벅 개저씨\n",
      "나이 많은 남자들이 어린 여자 앞에서 과시하는 재력. 너는 삼각김밥 먹지? 우린 백반 먹는다 야 너무 역겹잖아 \n",
      "나이 먹었으면 나잇값 좀 해요 자기들은 맨날 자신들보다 나이 많은 사람 그렇게 까대면서 왜 정작 자신들 뒤는 안 돌아봐\n",
      "나잇값 더럽게 못하네\n",
      "나잇값 참 못한다 나 새끼\n",
      "나잇값 해야지 ㅂㄷㅂㄷ\n",
      "나잇값도 못하는 인간이 되었네. 에라. \n",
      "나잇값은 해야지 오프만 나오면 남한테 눈치 주고 계정이란 계정은 다 블록하고 모른척하시고. 보니까 관련 없는 내 지인은 왜 블록 하셨어요? 그리고 예전부터 앙상블 스타즈 의 텐쇼인 에이치를 좋아하신다고 말씀하시던데 게임도 안 하면서 어딜 비벼대세요. 원스타는 게임 스토리 유포를 금지\n",
      "낙선 국회의원들 임기 종료 앞두고 해외연수 가는 게 유행이란다 마지막에 보도블록 깔듯이 끝까지 국민들 피 빨아먹는다 더 가관은 국회의원 보자 관 자르고 가족이나 친척들로 다시 채용한단다 자상하게도 가족까지 챙겨주시니. 퇴임 후 연금까지 받고. 거머리 같은 놈들\n",
      "난 그게 젤 싫음 내 친구들이 우로 빠각 벌어준 돈으로 너네 명품 입잖아.ㅋㅋ;; 하는 거 개빡침 네가 벌었냐? 네가 너네 오빠 본인이여??\n",
      "난 나보다 어린애들이랑 노는 게 편해,라면서 20대로만 만들어진 그룹에 껴서 ultimate형 오빠 듣고 있는 30대 한남치고 개빻남 아닌 경우 없었다.\n",
      "난 밖에 나가면 욕 절대 못하게 생겼다고 하는 외모고, 연락해본 새끼들은 알겠지만이라고 부르는 거 허락한 새끼들한테는 상냥한 편이거든? 사회생활하고 개인 사정 이해해줄 만큼 근데 요즘 꼬락서니 보면 그냥 다 들고부터 꼬리뼈까지 후려치고 싶다? 뇌가 후장에 달린 새끼들 \n",
      "난 스토리 영상 다 패스하고 있는데 같이 메인 미는 부대원들이 토할 것 같다, 역겹다고 난리 나셨음\n",
      "난 아무나 죽이진 않아. 별 같잖은 것한테 시간이 소비된다는 것 자체가 역겹거든.\n",
      "난 언제나 여혐을 남현 소리 하면서 퉁치며 저울질하려고 빻은 소리 하는 사람 볼 때마다 인류학 자랑 사회학자조차 정말 손쉽게 설명하고 있는 이것을 이해를 못 한다는 건 대체 목 위에 있는 건 대체 뭔지 제일 궁금하더라. \n",
      "난 이 새끼들의 ‘승은’ 마인드가 너무나 역겹다.\n",
      "난 이제까지 인사이트가 온갖 개떡같은 기사를 싸지르고도 한 번도 사과하는 꼬락서니를 본 적이 없다. 하루 종일 쫄쫄 굶어가며 밀려드는 응급환자들 진료하다가 밤에 김밥 먹은 것으로 야식 파티라는 제목을 뽑아내는 권 결여(gilyeo@insight.co.kr 기리기 개인의 문제 그 이상의 것이 있다는 말이다. \n",
      "난 저 냄새나고 역겹고 더러운 짐승을 꽉 잡고 안 놔줄 거다!\n",
      "난 조무사 워딩이 너무 싫어 왜 그 단어를 비하 목적으로 쓰는 거지? 역겹게\n",
      "난 진짜 그런 태도가 매우 싫다 아주 가까운 곳에서도 볼 수 있는데 왜 싫냐면 남자로서 살다 보면 사회에서 당연히 할 수밖에 없는 짓 <<이라고 생각하며 자기합리화 및 자기 연민을 거하게 들이키는 그게 보일 때마다 아주 역겹거든요\n",
      "난 진짜 이해가 안 되는 게 기혼자들은 결혼을 했으니까 한국의 가부장제에 협조를 한 거다 라는 말. 진짜 말도 안 되는 말 아님? 기혼여성들은 가부장제의 피해자인데요. 피해자들을 비난하면 어쩌잔 거임. 저 논리 한남들이 피해자들한테 쓰는 논리랑 뭐가 다름.\n",
      "난 진짜. 로리도 쇼타도 보몈 기분 이상하고 나쁘다. 불쾌해 쇼타보다 로리가 더 양도 많고 더 노골적이고 더 역겹다 싶은 걸 보는 빈도가 높고 여태까지 범죄의 대상이 되온 역사와 현실에서 지금도 벌어지는 아동 성범죄가 많으니까 진짜 영원히 사라졌으면 좋겠다. 너무 싫어\n",
      "난 친노다. 그리고 노무현의 친구 친문이다. 친노의 이름을 팔거나 활동했던 자들이 김두관. 변희재. 조경태. 천정배. 정동영. 김병준. 등 다 알만한 정치적 영향력이 있는 자들이다. 그런데 이것들은 친노였던 적이 없다. 그냥 기생하며 피 빨아먹는 거머리 같은 존재였을 뿐.\n",
      "난, 당신이 왜, 국회의원으로 국민 세금 낭비하는지 모르겠습니다. 민평련 친목도모를 위해? 아님 고인 되신 남편 명예 지키기 위해? 아니면 똘만이들 데리고 보스 노릇하는 재미? 이제 그만 물러나셔도 됩니다. 그동안 할 만큼 하셨습니다. 이젠 너무 역겹습니다.\n",
      "날 ㅈ도 모르는 별 같지도 않은 코딱지 같은 ㄴ이 내 눈앞에서 나한테 턱짓하며 날 씹는 꼬락서니를 보게 되다니. 가서 머리통을 후리고 싶었다. 진짜 별 거지 같은 꼴을 다보네. 쫓겨나는 것이든 제 발로 나가는 것이든 놈 상관. 그냥 어딜 가서든 가시밭길만 걷길 바란다. 저주하는 거예요.\n",
      "날씨가 좋아서 잘 보이나? 거리에 괴물들이 너무 많다. 이름하여 성괴. 티 좀 안 나게 하고 다니지\n",
      "날조 난 그런 거 알 거 없고 너도 역겹다\n",
      "낡은 틀딱 . 후 좌파 통진당 민중당 놈들이죠\n",
      "남 걱정하지 말고 너나 잘하세요 먼 오지랖입니까? 생면부지인데 반말 지껄이는 인간을 호래자식라고 어른들이 말씀하십디다\n",
      "남 성형한 데에 왜 저렇게들 관심이 많지. 게다가 여자니까 성형한다는 것들은 또 뭐야. 개인이 선택한 걸 가지고 전이 낫네 못생겨졌네 성괴네 뭐네 하는 인간들 꼴 보기 싫다.\n",
      "남 지사!!! 역시 무식하면 용감하군요. 남찻하지 말고 본인 앞가림이나 잘해 보시지. ㅉㅉㅉ \n",
      "남 험하기 싫어도 한남 와꾸만 보면 없던 남혐이 막 생기던데. 근데 강다니엘 못생겼다\n",
      "남경필의 구타 영상. 반성이나 참회로 보기보다는 관심받기 위해 참 가지가지 한다며 혀를 내두르는 사람이 더 많으리란 것을 알면서도 했을 것이라는 생각에 더 비루하고 역겹다. 정치인들의 삶이란 참.\n",
      "남매들은 빻은 발언해도 인 스타로 알려주세요 웅양 하면 다시 핥아주고 여배는 자필 사과문에 기사까지 나는 거 너무 투명하고 역겹다 정말 너무하다\n",
      "남성분께서 여성 코스를 하시던 여성분께서 남성 코스를 하시던 본인 마음입니다 오지랖은 ㅈ까 주세요 코스어 분들은 그냥 제 사랑받으세요 엉ㅇ엉\n",
      "남성이 아버지한테 고추 물려받고 여자 좀 주무르는 게 뭐 잘못이라고 ㅉㅉ \n",
      "남성차별 네트워크;;같은 빻은 소리 하는 놈들은, 높은 확률로 우익이고 한국인과 중국인을 죽이자 몰아내자 일본을 지키자(? 같은 지리멸렬한 헛소리를 한다.\n",
      "남성형 파는 여자면 남초 오딱꾸 판에선 어떻게든 해보려고 수작 부리고 여초 판에선 부역자 소리 듣는 거 아닌가. 더블 고통.\n",
      "남의 불륜을 두고 그건 잘못됐어라는 기사 써젖히는 매체들. 전형적인 한국식 오지랖과 뭐가 다름. 작작들 좀 해라.\n",
      "남자 기러기들은 쓸데 없는 기사 싸지 말고 성범죄 글 올린 한남 새끼들 검거되면 좀 크게 크게 터뜨려라 이 새끼들아. 가해 의식 있나 그런 기사는 왜 숨겨?\n",
      "남자 너무너무 싫다. 한남 너무너무 싫다. 대놓고 빻은 남자도 싫고 깨어있는 척하는 남자도 싫고 중립인 척하는 방관 남도 싫다.\n",
      "남자 외모 가 내리는 게 싫음? 여자는 천년의 역사 동안 외모 평가 당해왔는데 여혐 하늘 한남 얼굴로 가 내리는 게 진짜 그렇게 슬픔? 민윤기는 자기 사진 찍는 사람들 보정 안 하면 카메라로 정수리 찍어버리겠다는데 지 못생긴 거 알고 있단 거잖아 ㅌ ㅌ 아 진짜 한남충새끼들 곡도 지 같은 것만 써요\n",
      "남자 캐도 조크기로 순위 나열했었나요? 그랬으면 저는 할 말이 없기는 개뿔 스페 캐릭터 대부분이 20대도 안 넘은 미성년자인데 신체 부위 크기를 가지고 순위를 매겨서 나열한다는 거 너무 구역질 나는데요!\n",
      "남자가 돼서 고추도 작고 ㅉㅉ \n",
      "남자가 쓴 줄 알았던 빻은 댓글들도 답글 달아서 지적하면 남자라고 합리화하면 속이 편해지냐고 자기는 ㅇㅕㅈㅏ라고 말하는 사람도 많았다 정말 충격적인 내용 더 많아서 구토 나올 것 같았던 적도 있었음 정말 인스티즈만큼 유해하고 코르셋 조이고 남자 챙겨주는 여초는 없다\n",
      "남자친구가 그걸 보고 내가 개 싹수 없는 년이랑 사귀는구나. 싶어서 이후부터 맨날 남편만 들음. 나중에 그 얘기 듣고 개빡침. 개생퀴. 둘 다 개생퀴. 둘 다 나쁜 놈.\n",
      "남쪽 빨간 새끼들 하는 꼬락서니 보니 한심하거든. 개정은 이 단계적 개선 즉 우리는 단계 단계 조금씩 핵 폐기할 테니 너네는 그때마다 돈 왕창왕창 가져오라 그러다 우리 배부르게 되면 우리는 트집 잡아서 핵폐. \n",
      "남창 역겹ㅡ\n",
      "남편이라는 새ㄲ 1기 말하는 꼬락서니 봐라 하 차 ㅁ내\n",
      "낯짝 두꺼운 호래자식 하나가 노원병에 바른 미래 달고 기어 나오려나 보네. ㅉㅉㅉ\n",
      "내 기억에도 이런데 대체 그 목소리를 어떻게들 듣는지 이해 안 됨. 애 감금해놓고 성매매시키는 곳에서 애가 연예인인 거 알아보고 제발 도와달라고 하는 걸 자기는 너 같은 애가 좋다며 성매매, 성폭행이지 이건 뭐 암튼 그걸 했다고 알려진 놈을. 기러기들이 어디까지 소설을 쓴 건진 모르겠지만 역겹다\n",
      "내 대학 친구 트위터에서 여자화장실 옆 칸에 남자가 있었다는 글 인용해서 소까들 이 사람들은 트랜스 인권에 관심이 없나 보다란 말 보고 분개해서 개빡침 소까들 이 뭘 더 중요시하는지 저 글에서 너무 투명하게 보이기 때문이다.\n",
      "내 마누라에게는 그러지 말라는 이재명 씨 표창원 씨 등에게 묻고 싶다.자기 마누라는 귀하면서 당신들이 박통에게 한 짓은 그래도 되는 건지.참으로 나쁜 분들이다.대한민국 싱글 여성들은 이런 정치인 어떻게 생각하시는지.이런 분들 이런 대사하시는 걸 보면 참으로 역겹다.\n",
      "내 본진들 다 여혐 가득이라서 개빡침 그러고 살지 말자\n",
      "내 비린내 역겹다고, 이것들을 치우라고 몇 번 말했느냐. - 6회 中 \n",
      "내 상태 따윈 1도 관심 없으면서 관심 있었던 척하지 마 역겹다\n",
      "내 생에 최고 한남 ; 나 이 새끼랑 초창기 때 전데 하겠다고 전화 80 통하고 별 풍선 막 쏴주고 ; 하 돌았지 돌았어 \n",
      "내 자식 먼저 생각해서 모든 딸을 강남 8학군 보내고 가슴에 노란 리본은 왜 저렇게 달고 다닐까? 솔직히 진짜 역겹고 화가 난다 너 땜에 누군가 피해를 보고 위화감 조성과 상대적 박탈감 주고 교육부 장관을 한다고 설치는 꼴이 역겹다 틀 딱인 발악으로 보인다 \n",
      "내 주변에 착한 애들 뿐이라 몰랐는데 수학여행 오니까 시비 털리다니 너무 역겹다\n",
      "내 친구 셉틴 콘서트 땜에 막 양도 글 찾는데 개 싹수 띠-벌 세상에 플미충 다 뒤졌으면 \n",
      "내가 너무 끔찍하고 진절머리나 게 싫고 역겹고\n",
      "내가 만났던 노조 간부들은 하나같이 노동자들의 피를 빨아먹는 거머리 같은 것들뿐이어서 나는 노조를 싫어해\n",
      "내가 메가를 워마드를 경멸하는 것이 자신들이 한국 페미니즘의 시초인 줄 안다는 거야. 그 이전까지 호주제 폐지, 여성노동자 인권 상승, 성범죄의 범죄화 등에 평생을 바쳐온 이들의 노력을 지워버리는 그 행태가 역겹기 그지없어.\n",
      "내가 썼지만 보기 역겹다\n",
      "내가 올린 페미니즘 트윗에 한남 새끼들이 빻은 답멘션 달 때마다 네 고추 너무 작아서 사타구니에 여드름 난 줄 알고 차버렸다고 하고 싶은데 사실 적시에 의한 명예훼손 걸릴까 봐 안 하는 중임\n",
      "내가 인맥이 넓은 줄 아는 사람들 수조 역명을 봤는데 인맥은 개뿔 난 그런 거 오래전부터 신경 안 쓰고 살았던 세럼이다 쌍쌍바들아;; 너희들 비열한 목적 때문에 다가가지만 않으면 자연스럽게 생기는 게 그게 인맥이고 지인들이야 그리고 제발 사람을 금처럼 따져서 친해지려 하지 마 눈에 다 보인다\n",
      "내가 진짜. 충격적인 걸 발견했다. 탕비실에 이게 계속 있길래 아 누가 시켰길래 계속 있지 했는데 저거 안에는 다 먹고 박스만 저렇게 방치해뒀어. 심지어 저거 최소 3주 됐음. 진짜. 한남들. 노 답이다. \n",
      "내가 한남이었으면 피카부 뮤비에서 피자 보이 죽였을 때 눈치 까고 탈 독했다 개념도 눈치도 업는 새끼들\n",
      "내일이 모친 생신이란 걸 깨닫고 부랴부랴 딸기사 가는 꼬락서니가 몹시 추하더라\n",
      "낼부터 학교 가서 5일 동안 같은 반 남자애들 빻은 말하는 거 듣고 있을 생각하니깐 토하고 싶음 ㅠㅠ\n",
      "냄저들 여성 혐오 발언만 하지 않으면 되는 줄 아는 거 너무 화나요 사소해 보이는 것까지 화내는 여성들을 보고 늘 그렇게 화내면 힘드시겠어요ㅠㅠ 와 같은 회의론자 자세 취하는 거 너무 위선자같고나는 님은왜 화나지 않으세요? 왜 화내는 여성들이 슬프기만 하신지\n",
      "냄져는 할 수 있는 일이 몸쓰는 일 밖에 없다고 폭로하는 한남 역시 여혐은 지능 문제다 이기야 \n",
      "냉정하게 이번 정부의 장관급 지명자들이 과거와 비교해 더 더럽거나 모자란 인간들은 최소 아니라고 봅니다. 다만 착한 체하는 위선의 정도는 역대 최강이죠. 구역질 납니다 ㅠㅠ.\n",
      "너 같은 경상도 일 제충들이 애국자라고야 닉꼬라지봐라\n",
      "너 같은 새끼랑 같은 공기 같은 반인데 너무 역겹고 구토 나와서 너랑 짝할 때까지는 마스크 써야겠다\n",
      "너 같은 잉여도 또 없을 거야 ㅉㅉ 고2 맞음?\n",
      "너 같은 한 남이 수요란다 기본적인 머가리도 안 굴러가노 \n",
      "너 메가이지? 그런 걸 왜 물어? 너 한남이야;? 에이 설마; 성차별하고 여자 패고 댕기는 한남이야;?\n",
      "너네 엄마 워마드 네 첫사랑 메가를 네 딸내미 페미 나치 네 할머니 갓 건배다 이기 조국 여자 다 잡아가라 이기 \n",
      "너는. 언제나 그런 식으로 행동하니? 역겹다, 얘.\n",
      "너도 똑같은 부류의 역겨운 년 이거든!! 전여옥 “홍종학, 역겨운 ‘서민 코스프레’…위선 좀 작작 떨려” \n",
      "너도 은하 선도 여혐충!! 너희들 여혐 하늘 방식 한남이랑 존똑이라ㅛㅛ 한남인 줄 알았자나ㅛㅛㅛㅛ 나는 느가 비 제사상에 너희 마가리 올리고 제사상에서 춤추기 같은 욕 못할 줄 아나 봄 \n",
      "너목보 재방 보는데 음치 출연자에게 소감 물으니까 게스트가 본인 이상형이라고 하는 거 대체,,,, 한남들은 어떻게 이렇게까지 예의 없고 무례하고,, 소감 말하라 했지 누가 이상형 물었냐고\n",
      "너무 어처구니없는 소리에 격한 말 쓰려다 순화 하여간 자기 맘에 안 들면 나쁜 거야! 틀린 거야! 하는 게 자신이 세상의 진리요 하는 거 같아서 추하고 역겹다 뭐 세상의 중심이신가 보네\n",
      "너무 역겹고 약은 사람들이 많다\n",
      "너희 아비들이 남아선호사상 대를 이어야 되네 어쩌고 하면서 아들 우쭈쭈 해가지고 지금 성비가 x 같은 거고요, 너네 마인드 썩어빠져서 너희들 안 만나겠다는 거고, 자연스럽게 너네끼리 번식 경쟁 심해진 거 가지고 여자들이 선택하는 위치에 있는 거 인정 못 하면서 김치녀니 웅애웅 하는 꼬락서니 보기 싫다\n",
      "너희들 친구 목질과 정치지에 문포 이용하거나 팔지 마라 역겹다\n",
      "넌 참 역겹구나.\n",
      "네.멋지시다 성폭행범 파티로 빻은 한샘이라도 애국자로서 국내 기업 꺼 소비해주시고. 문맥도 모르시고. 역시 한국 남자 빻음 지수 다른 나라 남자에게 넘길 수 없죠!\n",
      "네가 나에 대해 어떻게 생각하는지 모르겠지만, 내가 보는 네놈의 모습은 역겹군.\n",
      "네거티브 보다 더 비열한 전략이 양비론임. 네거티브는 더럽기만 하지, 양비론은 위선과 가식 없이는 불가능한 행위임. 한마디로 구역질을 유도하는 행위. 역겨움 그 자체. 신발\n",
      "네댓 또 먹혔음. 어떡해. 네댓 또 바뀌었음. 제발 와주세요. 쟤들 새벽에도 움직임. 우리 화력 떨어졌나. 네이버 댓글 심각해요. 네이버 공비 공이라도 눌러주세요. 오소리들 이러고 있음. 조직은 개뿔이 ㅆㅂ 저런 얘기 볼 때마다 저분들이 나라는 구하는 중이라는 생각. 시간 날 때마다 갑시다\n",
      "넵. 뇌 사이즈가 개미 똥만 해서 그래요. 자극에 움직이는 원숙미 때 같은 거죠. 이성이란 거 생각이란 게 없는 짐승이라서. ㅉㅉ 인간이란 생각을 할 줄 알아 인간인 것을.\n",
      "노란 리본 숭배자들의 위선에 정말 구토 나오는 하루하루다. 피감 기관 돈으로 9박 10일 외유 다녀온 게 잘한 거냐? 인턴 여직원 대리고 외유 다녀온 것이 잘한 거냐? 두 사람 관계 의심은 필연이다. 족발 참여연대의 위선 매국 수구좌파의 위선 정말 구역질 난다. 애국우파는 정권 장악하고 바로잡아야 한다!\n",
      "노무현 대통령 능력까지 낮게 깔아보시며 김근태 편드신 거는 잊으셨나요? 아주 하는 짓이 우원식스럽네 인생 그따위로 위선적으로 살지 말길 바랍니다 \n",
      "노무현, 문재인 대통령에 대한 패륜을 일삼던 그 계정이 네 마누라 것인 것도 중요하지만 그 사실을 알고도 몇 년 동안 그 계정과 노닥거린 네가, 그 가식적이고 위선적 모습이 역겹다는 거야. 알겠냐? ㅉㅉ\n",
      "노예가 노예로 사는 게 너무 익숙해지면 놀랍게도 자신의 다리를 묶고 있는 쇠사슬을 서로 자랑하기 시작한다. 침략 기독 침략 가톨릭 추종자들과 그런 침략 기독 식민지의 노예들이 그런 꼬아지며 김구대중영삼이승만명박지원순반기문재인추종노예 꼬락서니들의 그런 놈들은 매국 애족의 글로벌을 퍼트린다.\n",
      "노통 부동산 정책 씹어돌린 놈, 한미fta 나라 팔아먹는다고 노통 저주한 놈들 땜에 내가 노통을 같이 씹었다ㅜㅜ 그런 ㅅㄲ들이 민주당에 겨들어와 주인 행세하는 꼬락서니 눈뜨고 못 봐준다.\n",
      "누구 재명이 8% 때 당에서 생떼 부리던 거 다 받아줬다 토론이 선거 꽃이라 매? 너희는 선택적 기억상실이냐? 지지율 겨우 10%?? 단어 선택 주황색 찢빠 답네 ㅉㅉ\n",
      "누구나 인정했듯이 국민의당은 안철수 당이었다. 그런데 심상정은 마치 정의당이 자신의 당이라고 착각에 빠져있는 것 같다. 안철수가 그렇게 부러웠나? 당 대표와 지도부, 당원들의 의견은 개무시하고 혼자서 개헌에 북 치고 장구 치며 생쇼를 다하고 있는데 솔직히 역겹기까지 하다.\n",
      "누군가 말했다, 성괴를까지 말자고. 공장에서 대량생산품이 나오듯, 대량생산된 성괴들의 등장으로 싼 가격에 미녀를 먹을 수(? 있다고.\n",
      "뉴스 보고 있는데 김생민 진짜 역겹다\n",
      "뉴스에 잠깐 공연 비춰주는데 다른 가수들은 얼굴들이 굳어있는데 레드벨벧들만 좋아 죽는 얼굴이네요? 공부 안 하고 벌거벗고 엉덩이 흔들어대느라 나라가 어떻게 돼가고 있는지? 전혀 모르나 보네요?. ㅉㅉㅉ.\n",
      "느 개 비 네 트위터 꼬락서니를 보고 말하세요.\n",
      "늘 그 소 해외 팬덤이 어딨어 해외 팬 많은데 천막 콘에 텅텅 콘이냐 아가리 빻은 소리 작작하고 스민 이나 쳐돌려 그따위 성적으로 대상은 바라지도 마라 \n",
      "능력은 개뿔도 없으면서 권위는 오지게 설치는 새끼들 너무 많음\n",
      "늦게 가면 밥 차려 달라고 안 한다 라면은 내가 끓여 먹어-가 가사분담 반반이 되고 비리로 1+1 교수직 꽂은 게 내조라는 빻은 머가 리 보소 철수가 페미니스트 깔깔깔 떼굴떼굴 \n",
      "님 대체 시스 여성을 맨날 서로 성희롱하고 웃으며 넘기고 이런 식으로 생각하는 것임?? 무슨 빻은 조본 애니처럼 여자들끼리 가슴 만지고 가슴 사이즈 커졌어. 이런 거 생각하는 것임?? 성희롱해놓고 공론화되니까 내가 시스 여성이었다면 여자 성희롱해도 문제없었을 텐데!라며 억울해하는 중임??\n",
      "님 되게 해일 앞 조개 운운하는 진보한남개저 같은 거 알아요.? \n",
      "님 정말 레알 리티 이게 참프루 제정신인가요???? 정의당 청년 부대표가 당내 후보 경선에서 메가를 낙인 찍기가 웬 말입니까\n",
      "님들 그거 아심?? 보검<< 김유신 왕의 74대 후손임 하는 꼬락서니 보면 바퀴벌레 후손 같음\n",
      "님들 대한민국 보수 얼굴들입니다 조폭 정당 대한 당 원내대표 후보들 친박에 성희롱에 박쥐에 하나같이 핵폐기물이다 끔찍하다 내 세금으로 저어 뜰 배 터지게 쳐 먹고 있으니 \n",
      "님들 양도 플미로 받는 거 자랑스러운 거 아니에요; 뭐가 좋다고 자랑 멘션을 해 공연은 애들이 하는데 왜 돈을 플미충한테 줘\n",
      "님들 짱 귀여운 후리도 데 아카리 보고 가지 않을래?? 여기서 아무것도 안 보이는데요. 이러면 틀딱인증하는거니가 참고해 샘 \n",
      "님이 누구한테 언제부터 심판관의 자격을 부여받았나요? 마타도어. 역겹다\n",
      "님이 돼지 눈에 돼지만 보인다고 하고 역겹다고 한 건 악플이 아닌가요? 님도 막말 쩔면서 내로남불 오지 시네.\n",
      "님이 안 한다고 해서 남의 최애 못생겼다 빻았다 하지 마세요 네 애정캐만 존중받아야 합니까 아인 내가 사랑해줄 거고요 많은 분들에게 사랑받고 있고요 님이 함부로 입 털 그런 거 아닙니다 이 빻은 새끼야 털리고 싶냐\n",
      "닝겐님 다 같이 게임할 때 초면에 엄청 예의 없이 구시대가 갑자기 친한 척 오시면서 “저희 친구죠 시에라님?”하시길래 벙쩌서 “아.네ㅎㅎ”했더니 “친구는 개뿔”하고 면박 주셨죠. 굉장히 무례한 분이셨던 거 기억하고 있었는데, 무례 정도가 아니라 인간 말종이네요.\n",
      "다 필요 없고 추방하면 됨. 저런 것들이 어학원 강사를 하고 있으니 ㅉㅉㅉ 지하철서 외국인이 동양인 비하 추태. 욕설·폭행까지 \n",
      "다들 그런 경험 있지 않나 타 그룹 열심히 방송 나올 때 응원해주고 투표도 하라 해서 하고 음악다운도 받아주고 했는데 정작 내 그룹 예능 나와서 자랑하면 반응 1도 없고 뭐 해달라 할 땐 들은 척 1도 안 하는 거 인형개 빻은 인간들.\n",
      "다들 아닌 척을 하지만 루저는 쓸모 있어요. 왜요? 오지랖이 넓거든. 누가 뭘 하는지 다 알아요. 속에 화도 많고. 늘 대접 못 받고.\n",
      "다시 한다고 하면 그 발언을 한 사람이 더 역겹다\n",
      "다음 아고라에 이거 왜 이래. 나 자위대 나온 여자야라고 글을 쓴 네티즌을 고소 고발해 벌금 물린 표현의 자유 운운한 그 여자. 역겹다.\n",
      "다이소 방충제. 냄새 오지네 역겹고. 다 버림 포장한 박스다 열국\n",
      "다이쇼 로망이라도 사쿠라대전은 우익이 아니고 라임색 자기 담은 우익인 건데. 어차피 이젠 둘 다 알면 틀딱 소리밖에 못 듣는다.\n",
      "단도직입적으로 하는 말인데 네놈이 하는 꼬락서니가 참 재수 없다. \n",
      "담마진(두드러기으로 군대 면피한 더러운 새끼 황 교활 이런 자가 종북이다. 붕 신 틀딱들아 \n",
      "담배 4갑 훔치고 경찰서에서 두렵고 무서워 죽음을 선택해버린 세상 물정 모르는 순진한 고교생도 있는데, 행정관 은 도대체 어떤 사람일까? 아. 그만 사임해라. 청와대 탁현민 이제 그만 해임시켜라. 탁현민 지켜보기가 갈수록 너무 역겹다. \n",
      "담임 꼬락서니 왜 그럼? ㅠㅠㅠㅠㅠㅠㅠㅠㅠ 하나야 괜찮아?? 힝.ㅠㅠ 담임선생님이라면서 그따위로 해도 되는 거임?? 자기 학생인데.;;;\n",
      "답할 시간이니, 사과할 시간이니, 애초에 생각은 해둔 건지 도망치는 건지 받는다고 용서해준다고 해준 적도 없는데 역겹게 굴기는.\n",
      "당 관계자를 동원해 조작하는 거 누가 가르쳐 주더냐? mb가 그러라고 시키더냐? 새정치는 개뿔. 오물 정치구먼.! \n",
      "당신 같은 혐오자들에게 왜 믿어달라고 해야 할지 모르겠다 그리고. 도대체 그냥 당신들이 뭘 믿고 그 꼬락서니로 행동하는지. 안타깝네요. 뭔가 자기 상상 속의 논리를 만들어서 밀고 혐오 자끼리 뭉치는 거 넘보기 숭 하나요. \n",
      "당신 슬픔을 지나치는 내가 역겹죠 혼자 있고 싶은데 외롭죠 그럴 거야 당신이 한때 잘못 끼운 톱니바퀴가 당신 새벽을 산산이 부숴놓을 줄 몰랐죠 어디부터 잘못됐는지 모르죠 아니 모른 척하고 싶은 거죠 이대로 이불을 머리끝까지 덮고 괜찮다고 되뇔 거야\n",
      "당신도 아웃이야. 그런 심보로 큰일 하겠니? 조국 같은 놈이 분탕치는 걸 아군에 총알로 사용해? 그것밖에 안되는 놈이 무슨 애국한다고 설치노 가볍구나 나경원 정우택 용서한 거니? 탄핵반대 외친 것이 위선인 거니?? 끼리끼리 노는구나 배신자들이랑 뭐가 달라 \n",
      "당신들은 역겹다. 역겹고 멍청하다.\n",
      "당신이 보낸다는 이 위로와 명복이 진심인지 가짜인지 유족과 고인들이 어떻게 믿을 수 있나. 가식과 거짓 위선으로 찌들어 있는 당신 같은 인간의 말은 신뢰성이 떨어지지 않나. \n",
      "당원보다 당사자가 더 하시니 문제이지요 당장 몸은 뺏겼어도…부터 블러 처리한 본인만 부각되는 포스터… 진심으로 역겹습니다\n",
      "당최. 남의 사생활 장소까지 찾아가서 욕하는 꼬락서니가ㅋㅋㅋㅋ 진짜 할 일 더럽게 없는 냔들인가 보다\n",
      "대기업 주식 놀이할 돈은 않고 국민들에게 검증받는 토론회 지출할 돈은 없다는 놈이 이재명 박이죠??? 써글롬 ㅉㅉㅉ 대신 제대로 토론회에서 검증합시다. 패륜찢\n",
      "대꾸하는 게 지레 찔려서 목에 핏대 세우고 말하는 꼴이다. 오래전에 방치한 글, 비공으로 돌리고 때에 맞게 반박하는 꼬락서니 하며 공론화할 생각도 없는데 표절 쪽이 누군지 알고 비공으로 돌린 게 실수 아니냐 하는 훈수지? 머리가 나쁘면 입이라도 싸 물지는\n",
      "대놓고 악질 행세하는 애들보다 손석희처럼 아닌 척 위선 떨면서 비열하게 등에 칼 꽂는 새끼가 더 재수 없음\n",
      "대놓고 여혐하는애보다 광화문도 같이 나가고 세상 진보 인간인 것처럼 목소리 내면서 정당한 척 여혐 하늘 애들이 더 역겹고 비열함\n",
      "대리 중 새끼라고 땅땅! 하면 뭐해 해외 팀 구해서 꾸역꾸역 프로 우계에 발붙이려고 하는데 으 역겹네\n",
      "대법관은 개뿔 병우 밑씻개들이지 \n",
      "대용. 언제부터 한남들이 벌이나 나비처럼 이로운 곤충이었나요 해충들 주제에 ㅉㅉ.어이없성.\n",
      "대중교통 옆자리 한남이 세상에서 제일 증오스럽고 역겹다\n",
      "대통령은 개뿔. 안철수 lq 좋은 줄 알았는데 알고 보니 닭 수준이었네요ㅋㅋㅋ \n",
      "대통령은 정말 잘 뽑았는데 국회에 국민 세금만 축내는 기생충들이 너무 많단 말이야. \n",
      "대통령하고 일반 국민하고 같냐 이 지하철무료틀딱아 \n",
      "대한 당 매국 를 딱 들. 일본이. ㅂㄷㅂㄷ대는 소리가 여기까지 들린다! 아이고 좋아라! 비핵화! \n",
      "대한 당 뭐 하는 짓이냐! 세비 반납해라. 일 안 할 거면 국회의원 사퇴를 하던지 . 저런 꼬락서니를 언제까지 봐야 하는 거야. 개헌 때 국회의원 소환하는 거 빼기만 해봐라 . 해산하고 다시 뽑자고 ㅆㅂ \n",
      "대한민국 정부이길 포기한 문재인. 하는 짓이 역겹다. 김정은에게서 어떤 메시지를 들고 오는지 모르겠지만 그것이 꼭 김영철이어야만 했는가? 비열하고 역겨운 문재인 정부. 하는 짓이 북한 김정은과 하나도 다를 바가 없다. 입으로만 국민 국민. 비열한 위선자.\n",
      "댓글 꼬락서니하고는 정말 골때리네. 자연인은 뭐고 겨울은 뭐고 봄날은 뭔데.? 묻지 마 맹신자들과 개 돼지들 맞구먼. 선전선동하는 것들 말은 멋지게 해요. 참으로 역겹다.그래도 좋겠다. 아직도 열나게 빠는 한심한 것들이 있어서. 자연인으로 가기 전에 자숙하기 전에 피해자에게 용서가 먼저 \n",
      "댓글 꼬락서니하고는 정말 골때리네… 자연인은 뭐고 겨울은 뭐고 봄날은 뭔데? 묻지 마 맹신자들과 개 돼지들 맞구먼. 선전선동하는 것들 말은 멋지게 해요… 참으로 역겹다.그래도 좋겠다…아직도 열나게 빠는 한심한 것들이 있어서… …자연인으로 가면 자연 오염되는데… \n",
      "댓글 웃긴 게 이제 안철수 깔 때 손석희도 같이 까임 쌤통이다, 이 새끼야\n",
      "덕질만 하고 싶은데 돌아가는 꼬락서니가 너무.\n",
      "데이트 폭력 볼 때마다 너무 역겹다 너무 역겨워서 다 칼로 찌르고 불지르고 싶어 어차피 가해자들은 피해자들 생각 하나도 안 해주잖아 피해자를 떠올릴 땐 자기가 불리할 때 선처해달라니 많이 할 때뿐일 거잖아 진짜 너무 역겹다\n",
      "데이트 폭력을 장난처럼 말하는 빻은 한남. 한남 대잔치. 한 남국 대학교. \n",
      "도대체 삼국지로 배울게 뭐라고 사람 많이 죽이는 거? 포로도 다 죽이고 실리 챙기는 거? 선동해서 내가. 그리고 승리자가 정의라고 미개한 개돼지들 선동하는 거? 그리 잘나서 지금 시진핑이 집권하냐? 그러니 틀딱 소리 듣고 살지 ㅉㅉ.\n",
      "도대체 왜 이 짤 하나 때문에 노동자가 노동권을 박탈당해야 하는지 모르겠다. 이 짤은 빻은 소리 하는 누구 나한테 쓸 수 있는 짤 아닝가. 대상이 남성일지, 젠더 퀴어일지, 트랜스일지, 여성일지 모르는 살인데 설마 여성인권을 이야기해서 그렇다면, 너희의 한남의 열등감이 너무 저열하고 지질하다 \n",
      "도대체 왜 준 팬이라고 이름 달고 이재명을 지켜준다는 거지하는 짓마다 더럽고 역겹다\n",
      "도대체 인간이 어디까지 더러워질 수 있는 거지. 끔찍하다 역겹다 혐오스럽다 정도로는 표현이 안돼.\n",
      "도대체 인기랑 페미니즘이 무슨 상관? 쿵쾅쿵쾅 메퇘지 운운은 상대방 기분을 나쁘게 하려는 전략인가? 라기엔 타격이 너무 없는 공격인데? 그러다 그들은 진심으로 그렇게 생각하는 거라는 결론을 내리고 보니 빻은 뇌가 얼마나 멍청해지는지 잘알겠다 \n",
      "도대체가 정부 예산안 통과 무산 소식만 있고 정부의 예산안을 설명하고 야당은 어는 사안에 반대하는지 보도하는 놈은 한 놈도 없음. 경제부총리가 설명하는 풀 영상이라도 내가 봐야 한다는 거냐? 여야 정치 싸잡아서 혐오 무관심 조장하려는 기러기들 수작 너무 심해.\n",
      "도대체가 한남이 맨 박스를 쓴 적 있냐고 남자가 집 구해야 되고 데이트 비용 다 대야 된다고 우는소리하는데 팩트는 투명 김치녀 만들어 패면서 기안 내나는 데이트에 반지하 얻어오면서 여자 등골 빼먹고 살 궁리하는 것들이 맨 박스?? \n",
      "도둑년들 또 세금 잔치하려 하네. 진심 역겹군. \n",
      "도멘 죄송하지만 저희 친오빠 전적을 알려드리겠습니다 1. 키 170에 얼굴 바닥에 갈았음 2. 욕 씀 3. 군대 상근인데 맨날 저녁 7시에 맨날 봄 극협 4. 상근 월급 나오면서 삥 뜯음 5. 나 끌고 가서 반강제로 내 돈으로 편의점에서 쇼핑함 6. 공부는 개뿔 7. 인성 파탄 8. 그냥 노 답 9. 진짜 노 답\n",
      "도멘 죄송합니다 치마를 입었다고 말하는데 그러면 당연히 속바지일 거라는 건 뇌가 빻아서 생각을 못하는 건가\n",
      "도멘 죄송합니다,,,, 저희 반 얘들 대화하고 너무 똑같아요,,,, 역겹다 진짜,,,,\n",
      "도멘 죄송해요 그런데 저도 그런 비슷한 일이 있었거든요 원피스 입고 택시 탔더니 남 기사가 저보고 술집 나가? 이랬던 기억 ㅎㅎ 그때는 코르셋 벗기 전이었는데도 기분 나빠서 뭐라고요? 다시 말 해보라 했더니 꼬무룩 하고 아무 말 안 하던 늙은 틀딱 남 기사가 생각나네요 ㅎㅎ\n",
      "도의원들이 지사 후보 경선 전에 특정 예비후보를 공개 지지한 것은 지방선거 실시 23년 만에 처음 벌어지는 진풍경이다 이해관계 이권+@. 줄 세우기. 이러한 행위가 청산해야만 하는 구태, 바로 적폐 아닌가. 성공하면 은공은 필수. 추하고 역겹고 혐오스럽다.\n",
      "동네 양아치 수준도 안되는 년 너무들 이 청문위원이랍시고 앉아 껄떡대며 완장 칠하는 야만스럽고 미개하고 역겨운 꼴들을 지켜봐야 하는 이 슬픈 대한민국의 현실. 언제쯤이면 이런 것들 사라진 문명시대에 살수 있을까 거짓을 진실이라 포장한 위선 다들이 넘쳐난다\n",
      "동네에 나 맨날 벚꽃샂진찍는 스폿 잇는데 비바람믾이쳐서 꽃 다 떨어졌겠다ㅜ 꽃 떨어지지 마 한남 고추나 떨어져\n",
      "동의한다. 그리고 애교 있는 여자를 좋아하는 한남도 여기에 해당한다. 멀쩡히 한국말 잘하는 여자들을, 3-4살 언어 수준으로 만들어 놓고, 그걸 진심으로 좋아하는 한남도 오리엔탈리즘에 절여진 개번탈 양남만큼, 아님 그보다 더 미친 새끼들임. \n",
      "돼지 새끼들 준 역겹네 트위터 하면 욕먹는 이유를 모르는 네 덕 같은 새끼들도 있고 페미니즘은 악이다 틀린 말 하나 없네\n",
      "되게 얼척없는 소리 들었는데 매장마다 시드 세럼이 품절이 나버린 곳이 있다는 거다 결국은 오늘 그런 매장에선 굿즈만 사야 하는 꼬락서니. 개표구로 아나 미친 것들이 진짜. 한국소비자원에 글을 좀 쓸까 봐 안 그래도 화나는 대\n",
      "두 가지 얘기할 부분이 전에부터 얘기한 거지만 정츼인들 아의 동화시키는 거 역겹고 뭔가의 소름 끼치는 일이었는데 역시 문제 터졌고 정ㅊ ㅣ는 정 ㅊ ㅣ일 뿐이니까 제발 좀 그 역겨운 것 좀 같다 치우고 버리라니까 소름 끼치고 구토 나옴 괴상망측함\n",
      "둘 다 대한민국에서 암적인 존재죠.뇌암과 골수 암적 존재들입니다.ㅉㅉ \n",
      "듣보 신문이 찌라시나 쓰고 있네 수준 ㅉㅉ 청와대 참모진들이 인지도 생기고 크는 게 싫으니깐 별 트집을 다잡네\n",
      "듯 뜻이 아니라 떳떳이겠죠. 무식한 알게 틀딱 새끼야.\n",
      "디 아이콘까지 플미하냐 이 양심도 없는 플미충들아 머만 나오면 얼마나 플미붙여 되팔지만 생각하는 양심 리스 인간들 \n",
      "디스패치 보도 방식 너무 역겹다 . 심지어 그 와중에 미투의 본질 운운하고 있고\n",
      "딱 메가를 수준이네 아직도 봄 동남 정상 남자 찾냐? 아 말만 들어도 웃기네 정상남이랰 그딴 게 어딨노 xy는 그냥 장애 자지 ㄷ ㄷ\n",
      "딱히 새로울 것도 없는 게 찢베충들이 펴는 주장은 이명박 빨던 를 딱 들 이 썰 풀던 거랑 비슷해서. 도덕적 흠결 있다☞능력만 있으면 됨. 능력도 없어 보인다☞너희들은 잘났냐? 이런 걸 어떻게 찍어주냐? ☞너 좌파!! 똑같아. 완전 판박이.\n",
      "떡 검어 거의 잊혔던 정유라 기소를 만지작거리고 있단다 단 하루라도 조용하게 있으면 주사파에 조인트라도 까이나? 무엇으로 꼬드겼는지 모르나 박통의 1심 판결전 기소하면 럭비공이 진술 내용 뒤집을까 방치했던 그 속내 누가 몰라? 2심에 대법도 있다 ㅉㅉ\n",
      "떳떳한 가해자들이 정말 역겹고 꼴 보기 싫어요. 왜 가해자가 떳떳한 세상인지도 모르겠습니다.\n",
      "또 나온 내로남불. 지겹고 역겹다! \n",
      "똑똑똑!! 그의 마음을 열면 내가 아닌 당신 있다. 거머리 같은 사람은 지워지지도 않고 피를 빨고 추억을 갉아먹고 버티는 중이구나. 죽어. 그만.\n",
      "똥 멍청이 들 욕심만 있지 돈 벌 줄 몰라 더 큰돈 벌 수 있는 기회가 왔는데 이런 ㅉㅉ 큰돈 계속 만져봐야지\n",
      "라이언 레이놀즈 역겹다 진짜 \n",
      "래디컬 페미니즘은 개뿔이 목적이 래디컬이 아니라 수단이 래디컬이면 그건 래디컬 페미니즘이 아니라 테러리즘이야 벌레들아.\n",
      "러시아 선수 정색하고 있는 거 멋지다고 알티 돌던 것도 그렇고 한국 경기도 진지한 얼굴로 경기하는 거 정말 멋지다고 친구랑 얘기했는데 그날 한남 악플들은 대부분 “웃지도 않고 뚱한 얼굴로 뭘 잘났다고 소리 지르고 그러냐(순화”는 식이 어서 이 새끼들은 여자가 오래 안 웃어주면 미쳐버리는구나 싶었다.\n",
      "레드벨벳 조이가 드라마 스케줄 조정 불가 때문에 평양 공연 불참하는 걸로 문파들이 또 설쳐대는데 평창 아이스하키 단일팀 때도 그러더니 문재인 대통령 치적 홍보를 위해서라면 생업 스케줄까지 다 포기하고 무조건 희생해야 한다는 마인드. 문슬람식 전체주의 역겹죠? 얘네 촛불 들었던 애들 맞음? \n",
      "록히드마틴 대변인 유승민, 송영길 의원의 정확한 일갈입니다. 매국질을 짧게는 십 년 길게는 수백 년 밥 먹듯이 해처먹은 놈들이 누구더러 매국노라니. 저 새낀 박근혜 또는 김진태 또는 어버이연합보다 더 나쁜 위선자 새낍니다.\n",
      "류현진 기사에 한 남 새끼들 댓글 꼬락서니. 스포츠 남자 선수들 기사 댓글은 다 저 꼴이지, 선수 못 한다고 욕할 때도 부인 성희롱 못 잃는 새끼들. 플러스 내조 타령 밥 타령. 제가 뭐 나 되는 줄 아는 내 조감별 사한 남들은 죄다 네이버 스포츠 댓글난에 똬리를 틀고 있음. \n",
      "리 물어본다님 글이 이해가 간다. 현실에서 꽃뱀 케이스잖아 그거라던가 미투 지겨워 그만할 때 됐잖아 하는 사람을 보면 상대가 남자건 여자건 너무 화가 나고 역겹고 토할 거 같다. 진심으로. 그 말 한 사람이 사람 같아 보이지 않음.\n",
      "리 왜 농촌총각이고 개그맨 노총각이고 뭐고. 이 사회는 남자들만 사람이라 보급품처럼 여성을 못 붙여줘서 안달이야? 여성도 주체고 자기 삶의 주인공이고, 노총각들하고 결혼이나 해주려고 태어나 존재하는 물건 아니거든? 뭐 같은 대한민국 노총각 우쭈쭈문화 욕 나오게 역겹다, 진짜.\n",
      "리츠와 낙서 사실 오늘 그림 겁나 인 그려져서 개빡침 ㅡㅡ 화난다 인체랑 손발 연습 좀 해여겄다 \n",
      "링 이건 배려가 아니라 무시란 걸 왜 모를까. 설마 이걸 고마워할 거라고 생각한 건가? 진짜 역겹다.\n",
      "링 좃뱀들.여자들 앞에서는. 조신 남자임. 저 한 남아님. 하면서. 뒤에서는 또 호박씨 깔 수도 잇자 너 그 남들의 특징. 속이 좁아가지고. ㅉㅉ. 조신 남이면. 집에서 밥이나 할 것이지. 어딜 감히 게임을 같이하려고. 재기나 하길.\n",
      "마른 몸만 예쁜 몸처럼 느껴지고 그래서 내가 너무 싫어 굶어도 살이 안 빠지는 게 너무 지긋지긋하고 역겹고,,.,.\n",
      "마저 쌍 환희 년 ㅉㅉ\n",
      "만우절 빙자해서 남조 롱 하는 거 진짜 보기 역겹다\n",
      "말만 들어도 역겹다.\n",
      "말하는 꼬락서니 봐라 역시 우리나라에서 자율은 개뿔 유저 개돼지로 알고 돈 빨아먹을 생각만 하죠?\n",
      "말하는 꼬락서니 ㅆㅂ 역시 믿고 거르는 애니프사남 .\n",
      "말하는 꼬락서니가 3 패배한 개의 애처로운 소망 따윈 한 귀로 흘려넘기고. 무슨 노래 가사냐 \n",
      "말하는 꼬락서니가 4 선민의식 쩌네 그래.전생의 네가 싫어하던 게 인종차별과 신분 평등이었으니까 이해해보련다 \n",
      "말하는 싹수 좀 봐 정말 짜증 나게라는 문자 내용을 보고 깨닫는다. 너무 흔하고 경미해 발에 채는 수준의 경험담이어도 폭로해야 하고 위선에 철저히 속았음을 인정하고 그것을 빌미로 내 무지를 두둔하지 않아야 하며 더욱 강력하게 규탄해야 한다.\n",
      "맘충둘 ㅉㅉㅉ\n",
      "망원 가는 길이였는데 개저씨 때문에 기분 잡침 으 더럽고 역겹다\n",
      "맞아요 코스어 사진 보면 하나같이 다 구관인 형 같아요 무해하고 례에쁘고 뭔가 본인 의지라곤 없어 보이는 ㅋㅋㅋ그런 콘셉트로 찍는 인간이 한둘이 아닌데 주체적은 개뿔. 자기들 같은 인간 때문에 실제 초등학생도 성적 대상화당하는 마당에. 자기합리화좀 그만했으면 좋겠습니다\n",
      "맞아요! 이미지 세탁!! 아주 적절한 표현이네요? 미친 것들!! .ㅉㅉ\n",
      "맞아요, 제 이기심이에요. … 당신에게서 가엾고 역겹기 짝이 없는 나 자신을 보고 말았으니까…\n",
      "맞을 짓을 했네 그러니까 왜 김치 남짓을 해 개념 남이 있으면 안 당했지 ㅉㅉ \n",
      "매번 그랬지만 날이 갈수록 더 고쳐지지 않네. 국회 파행이 무슨 의무사항인 듯이. 보란 듯이 쳐 파행하는 꼬락서니하고는. 선거가 다가오니 이제 서민들 품으로 잠시 돌아가서 아양을 떨겠지만. 표 구걸 연놈들.\n",
      "매일 내가 역겹고 싫다. 혐오스럽고 죽고 싶다.\n",
      "맨 박스도 없는 한남들에게 맨 박스를 씌어주면 그게 면죄 부지. 초등 성 평등 연구회가 아니라 한남 유충 사용 반대 연구회라고 하시지. 한남 비위 거슬리면 하지 못하는 운동이라니 멘틀이 개복치인 게 한남 수준이네\n",
      "머리 텅텅 빈 거 인증하는 동대 한남. 자기가 일침 가한 줄 알고 뿌듯해하고 있을 게 눈에 선하다. \n",
      "먹는데 건드는 거 개빡침\n",
      "먼저 찾아온 게 누군데 역겹데ㅠ\n",
      "멋진 사람이라면 누구든 증오와 분노와 연관되고 싶어 하지 않습니다. 예전에 사람들이 구강성교에 대해 느꼈던 것과 같은 방식입니다. 저요? 들어본 적도 없어요. 역겹네요. \n",
      "멍멍이 새끼들! 엑소 대상 주기 싫어서 별 수작 다 쓰는구먼! 그래! 한번 해보자! 웨이보에서 yinyuetai，트윗으로 바꾸면 되지! 어우! 어이없어서! 중국에 리들 다 트윗으로 몰려와 한국에 피들이랑 만나면 소통도 더 잘되고 화력 더 세질 거라는 생각 안 해봤니?\n",
      "멍청한 놈 백업 안 하고 뭐 했어? 아까운 줄 모르고 ㅉㅉ 네 머리가 그런 기발한 것도 생각할 줄 안다 야\n",
      "멍청한 주제에 자존심만 높은 한남\n",
      "메이드복 입고 목줄하고 손 뒤로 묶이고 보쿠 톨가 입이 콘돔 어느 정도 펼쳐서(? 물려주니까 무릎 꿇고 보쿠토 가식이에 씌워 줄라 하는 아카 아시 보고 싶다. (현실=개뿔 1도 안됨 근데 좋다. 손도 사용하려 하면 묶여있고 그냥 콘돔 퉤 뱉고 요도 혀로 할짝할짝 핥으면서 주인님 하는 께지 주세요.\n",
      "며칠 전까지 민주당을 개같이 비난하며 자신만은 자신의 길을 가겠다고 한 천하의 위선꾼 안철수가 이젠 하는 말이 민주당이 변했다고 한다. 안철수! 이 더럽게 미친 새끼야! 세상의 선과 악을 규정지을 만큼 네까짓 게 그리 잘났냐? 독선적이고 천하의 불통인 새끼야!\n",
      "면상만 봐도 역겹다 그만 우려 처먹어라 우리도 좀 살자 너희들만 민주투쟁했나? \n",
      "모든 국민 중 국민의 혈세를 받는 자멸당 것들은 슬픔이 뭔지 모릅니다 오직 무정부 흠집 내는데 혈안이 되어 있습니다 저 거머리 같은 족속들.\n",
      "모르겠다 리틀 포레스트. 한국의 농촌을 떠 올리는 순간부터 오지랖과 영감들의 더러운 난봉 질부 터 떠오르는데, 너는 너 나는 나, 너에 대해 깊게 묻지 않겠다가 불문율인 일본의 개인주의가 바탕이 된 일본 농촌 이야기를 한국에 어떤 식으로 풀지.\n",
      "모범택시 탔는데 사상이 너무 빻음;; 처음에 머리색 이쁘다 해서 고맙다 하다가 여자는 이뻐야 된다 돈 욕심부리고 시집도 안 가는 여자는 바보다 꾸며서 이쁘게 다니면 남자가 와서 팔자가 핀다 여자는 꽃이다 하면서 엄청 빻은 소리를 5분 동안 하고 있다\n",
      "몰아붙이는 방식으로 그 권력을 유지한다. 남자를 계도해야 한다느니 한남만 패 자느니 하는 소리는 그래서 역겨울 정도로 순진한 발상이다. 뇌주름 사이사이에 유니콘의 마법가루 같은 걸 들이부어도 남자들은 안 변한다. 자지 권력이 계속 유지되는 한은.\n",
      "못 배워 처먹은 놈아 닭 년이라니 네 어미 뻘이다 그래도 전직 대통령인데 나라 꼬락서니가 망초다\n",
      "못생기고, 고추 작고, 뇌 빻은 새끼들 그만 만나십시오. 사랑하다가 사망합니다. 이 남자는 다를 거라는 생각은 언제나 틀립니다.\n",
      "무릇 장수된 자의 충은 왕이 아닌 백성을 향해야 한다. <김훈-칼의 노래>중 민중에게서 떠나 무능 정부와 야합하며 민중들의 혈세만 빨아먹는 거머리 같은 정치 모리배들 이순신 장군의 호령 소리! 들리는가!!!\n",
      "무선통신 원리, 태양광발전장치 붙은 집, 초기 에이즈 치료제, 그리고 느타리버섯 식용 재배<< 여자가 했음. 한국 최초의 우주인도 여자임. 그렇게 차별받고 공격받으면서도 성과 내는 게 여자임. 세상 모든 걸 냄저가만들었다고 생각하는 오만함이 역겹고 저런 사상 가진 남자들 꼭 재기하길.\n",
      "무슨 수사기관이야??? 저놈이 저기 왜?? 언론이 빨아 주는 생쇼 정치 누가 mb아바타 아니랄까 봐. 요새 조선 논조를 국민의 소리로 세탁하는 기능 충실히 수행 중 간 철수는 조선을 엄호하고 국민을 드루킹 취급 이제는 대 놓고 붙어먹음\n",
      "무책임하게 피하려고 했던 게 아니라니 지나가던 개도 비웃겠다 최에 팔아서 끝까지 자기 옹호하고 싶니? 앞으로는 사과하는 척 책임지는척하는데 당연한 걸 되게 열사인 척 ㅉㅉ 너희들이 똥 싸질러놓은 걸 누가 치워? 뒤에선 차단 빵이나 그만 박아 그게 제일 추해\n",
      "문 앞에 다 써놓자 내리고 타는 거라고 엘리베이터 도착해서 문 열리자마자 지 타겠다고 밀고 들어오는 꼬락서니 하고는 시 발 야 나 좀 내리자 무식한 새끼야 \n",
      "문 오소리들 마인드ㅡ안철수는 v3도 아버님이 시켜서 만들었겠네? 뇌가 없어 너희들은ㅉㅉ.\n",
      "문가랑 유가가 씹어 묵어도 된다 아이가**. 터진 아가리라고 ㅉㅉ\n",
      "문베충 쉑기들 안희정과 정봉주, 김어준 건 덮으려 안철수 서울시장 출마설 흘리고, 죽어라 검색하는 모습이 역겹다.\n",
      "문베충들이 할 말 없음 위장술도 뛰어나요 국정원에서 배웠나? 앞에서는 서민쑈 뒤에서는 도적질 도적 놈들이 드글드글한 민주당이 뭐 잘났다고 납작 엎드려 국민들에게 미안해야지 도적질에 재미난 놈들 뭐가 절세 개뿔 오죽하면 신적 폐 청산 얘기가 벌써 나오냐고 쑈질로 국민 눈멀게 하니까 재밌냐? \n",
      "문용린 교육감, 이게 학생들에게 할 짓인가요 북한 인권 챙기는 오지랖보다 학생 인권부터 인정, 존중하는 교육 현장을 만들어라! 학생들이 인권 조례법 때문에 선생님을 존경치 않는다? 자유와 방종을 구분하는 교육하길\n",
      "문재인 속마음 국민은 개뿔 평생 재벌과 대기업 이명박근혜 보호하며 살 거다 맨날 속는 흑수저 노예들아! 내 아들이 먼저다! 이 개 돼지들아! 나를 신처럼 여기고 날 보호하고 날 위해 죽고 날 위해 싸워라 이 무지한 국민 노예 개 돼지들아! \n",
      "문재인 싹수없는 놈아!! 대통령 보고 위선적인 태도 보이지 말고 사과하라고!! 성완종이를 2번이나 특혜 사면해준 노통과 문재인 네놈이나 국민에게 사과해라!!\n",
      "문재인 아들 부정 취업 의혹, 사실이었다! 아무도 모른 채용공고에 혼자 지원 당연히 합격! 문재인 후보의 위선 시리즈 (아들 취업 특혜 관련 시민사회단체, 노무현재단 기부금품 불법 모집액 4년간 159억 확인 고발해도 기소 안되지, 이런 돼지들! \n",
      "문재인 이집트 꼬락서니 나겠네 축하한다 .부엉이바위!! \n",
      "문재인, 안희정, 두 능참봉은 싸 들에 찬성하고 있다. 특히 문재인은 강정 미군 기지를 중단하자고 변명하면서도 싸 드는 찬성하는 이중적, 위선적 행태를 보인다. 이런 자들이 대선과 다름없는 이 시국의 야당 경선에서 경쟁하는 기괴한 모습을 본다. 가증스럽다 \n",
      "문재인은 매주 개혁 공약 발표하고, 나머진 매주 문재인 까기 발표한다고 눈 뒤집혔어. 나라가 망하기 직전인데. 말이지. 손 떨린다. 비겁한 위선자 새끼들. \n",
      "문죄인이 지금 한민구 장관하고 맞짱 뜨고 있냐. 참 가지가지 한다. 죄인아 그냥 짐 싸서 시골에 내려가라 국민이 쪽팔려 죽겠다. 65세 틀딱 노인네가 장관들하고 싸움질이나 하고 이게 나라냐 \n",
      "문죄인이 직무실을 광화문으로 옮긴 덴 다 멀쩡한 직무실 내버려 두고 또 국민 세금으로 광화문에 제2의 청와대를 만들어야 하나 전 세계적으로 나라의 상징이 대통령 직무실이다 북한이 수령 궁을 바뀌는 걸 봤냐 이것도 또 거짓말이다 청와대 못 바꾼다 또 거짓말하는 거다 \n",
      "문파 역겨운 이 년은 원판 갈아엎은 홍어 성괴.\n",
      "문희상은 대한항공 처남 청탁, 문재인은 노동부 산하기관 아들 특혜취업 의혹! 두 문 씨 취업 청탁 문고리 권력 십상시냐? 뒤로는 구린 짓, 앞에서는 정의가 뭐 어쩌고 어째? 인간의 탈바가지를 쓴 위선자들! \n",
      "물 마시는 게 너무 역겹네 흑흑\n",
      "물려받을 재산이 썩어 넘치면 초졸로 살 수도 있지 하여간 트위터 놈들 오지랖은\n",
      "물로 칭, 진짜 역겹고.\n",
      "물론 틀딱들 문제가 없었냐면 그건 아닌 게 1980년대 중반 이전인가 tv에서 방송되던 어린이 만화영화의 대다수가 미국이나 일본에서 제작된 것임이 언론을 통해 보도됨에도 비용 문제라는 이유로 국산 애니 제작이 이루어지지 않은 걸 보면 할 말이(.\n",
      "물론입니다. 이명박, 박근혜가 해쳐먹은 돈에 비하면 90억은 껌 값 아닌가요? 껌값 드로 통일도 대비하고 국민들 입장에서는 환영해야 정상입니다. 박사모 등 친박단체들 피켓 및 플래카드에 북폭을 원한다며 미국에 바라던데 그것들부터 처리해야 합니다. 틀딱들말이져.\n",
      "물질적인 거 바라고 모인 몇백 명 아닌데 빵 줬다고 안타까워하는 거 지자 웃긴다 ,, 당신 덜의 오지랖에서 맘 속애 천박함이 티 난답니다\n",
      "뭐 배가 불러 평가 질리냐고? 그럼 뇌 없는 새끼처럼 경기 보고 아 졌다 영 이러고 마냐? 남의 경기 평가지 하는 것도 아니고 내가 내 팀 경기 가지고 이렇다 저렇다 하는데 뭔 오지랖이야 저건\n",
      "뭐 배우들 무대인사도 아니고 일반 상영인데 암표상이 있어 시 발 심지어 무인 플미충들보다 더 많아 더 아이고 (쓰러짐\n",
      "뭐라는 거예요 교수님 수강신청이 네트워크에 영향을 안 받는다니 네가 수강신청을 해봤어? 몰알아틀딱아\n",
      "뭐래 새꺄 제대로 안 해? 절해도 모자랄 판에 진짜 말하는 꼬락서니 봐 \n",
      "뭐래? 교사는 철저히 점수로 뽑으니깐 멍청한 한남들이 떨어지는 거고 저거는 점수가 높은데도 여자라고 안 뽑는 거잖아 탐라 더러운 거 봐라 ㅉㅉ 머리까지 나쁘노\n",
      "뭔가를 극복해낸 한남 새끼 - 절대 만나면 안 됨\n",
      "뭣 때문에 개 같은 짓을 하는지 참거머리 같은 놈  일러바치자> 여러분, 선관위가 아니라 서울시에서 직접 집행하고 있는 주민 투표 홍보는 여러분이 알고 계신 182억 말고, 별도의 예산에서 추가로 비용. ://dw.am/ldoc7\n",
      "뮤뱅 자막 틀딱체네\n",
      "美·北 긴장감 최고조. 강경화 장관, 나 홀로 휴가 망중한 미국-북한, 피 튀기는 썰전. 청와대, 강 건너 불구경? 도대체 이것들이 언제 장관이 되었다고 휴가를 가냐 머리통에 뻘건 물이 들어서 그저 놀고먹으며 내 세금을 가져간다 문죄인 패거리들 \n",
      "미개한 냄비 어 저 미들 ㅉㅉㅉ 추하다 \n",
      "미국도 화이트 트래시 새끼들 많은데 tk 틀딱들 수출해서 강성대국 이룩하면 안 되겠냐\n",
      "미국식 펜스룰=와이프 외 여성과 따로 사적 관계를 가지지 않음 한남식 펜스룰=여성 직원을 안 뽑음 공적 상황에서 여자를 배제함 한남들 지능 낮아서 공사 구분 못하는 거 팩트.\n",
      "미국을 한반도에 편입시킬 능력이 있는 자라도 인격에 문제 있는 자는 지지 못하겠다. 이재명 역겹다.\n",
      "미국의 치어리더들은 건강미가 넘쳐 보입니다. 한국은 색기가 넘치죠. 그렇게 입고 그렇게 춤추고 있습니다. tv의 걸그룹에서도 풋풋함보단 중년 남자들의 룸살롱 냄새가 더 진하게 풍깁니다. 한국적 위선은 미국의 천박한 상업 주의보다 때론 더 저속합니다.\n",
      "미디어워치. 존 풍뎅이와 같은?‘강남좌파’들이 입으로는 특목/자사고를 비판하면서 정작 자신의 자녀들은 특목/자사고에 진학시키는 이중적 행태를 해 왔다고. 요 거시가 좟파들의 기본 모습이지요. 위선으로 똘똘똘.\n",
      "미래 개뿔이 \n",
      "미래는 없고 생쇼나 한다//이명박근혜 탓 질러 무능을 감추며 과거로 회귀하고, 여기저기 흔들어 만든 자리는 내 사람 네 사람 꽂아 넣는 도적 집단의 추태다/ 집권초, 여민관에 일자리 상황판 생쇼 하더니, 사상 최고의 실업률 기록했단다 (볼수록 가관이다 \n",
      "미모가 수단이 될 수 있다는 것이 이 인사들의 사고관과 가치척도 때문이라는 게 지나치게 생생하게 느껴지니까 역겹다는 거임 다 칼푹찌해서 죽이고 싶음 \n",
      "미성년자의 주체적 성노동 << 헛소리 그만해라 빻은 소리도 정도가 있지 미자한테 비비냐\n",
      "미소녀 모에 게임의 소비자와 창작자의 수준이 정확히 일치한다는 게 너무 우습고 환멸난다 누가 더 낫고 그렇다 할게 전혀 없이 똑같이 빻아가지고 날이 갈수록 같이 사이좋게 손잡고 얼마나 멍청한지 차력쇼 중 \n",
      "미안한 마음을 가진 나에 도취되어 있는 가해자들 너무 역겹\n",
      "미ㅊ네이 낄낄빠빠를 몰라 ㅉㅉ\n",
      "미쳐가는 문벌 구정권 북한 김영철 내 자식 죽인 놈이 내가 낸 세금으로 좋은 호텔에서 귀빈 대접받으면서 잘 처먹고 잘 잔 아니 미쳐버리겠디 \n",
      "미쳐가는 틀딱달빠들 \n",
      "미쳐날뛰는 틀딱들 \n",
      "미취학 아동모델에게 한 머리카락 웨이브며 볼 터치며 입술이며 진짜 너무 소름 끼치고 정말 옷은 일단 거의 아이들의 활동성을 고려하지 않은 데다가 성인 여성 옷의 디테일을 그대로 적용한 걸 넘어서서 저게 대체 애들을 구경거리 만드는 게 아니면 뭔지 진짜 너무 역겹다.\n",
      "미치겠네욬 한남 아니랄까 봐 줏대도 없고.\n",
      "미친 강영훈 깔짝 깐족대는 거 정말 웃겨 진짜 박제형 개빡침 ㅜㅜㅜㅜㅜㅜ개웃겨ㅜㅜㅜㅜㅜㅜ \n",
      "미친 거 아닌가요 말 못 하는 동물이라고 해서 고통을 못 느끼는 것도 아니고 생각을 할 수 없는 것도 아닌데 사람이라는 이유 하나로 저딴 미친짓을. 역시 한남이네요 피해 동물들만 너무 걱정돼요 이런 거 기사 안 내고 뭐 한댑니까.\n",
      "미친 거 아님? 어디서 ㄷㅇ 댓글이야 개빡침 계정도 비공개네 신고 곡\n",
      "미친 것들 땜에 난 교회에 나가기 싫다. 이명박 때부터 안 나갔다. 모두 위선으로 보였기에. 틀린 말에도 아멘 아멘 하는 소리도 역겹다. 거짓으로 교인들을 눈멀게 하고 목사가 그런다고 또 맥을 같이하는 교회가 싫다. 거짓으로 사회를 분열시키고 선동하는 저 무리들 제대로 심판받기를 희망한다.\n",
      "미친 나라 꼬락서니 잘 돌아간닼 \n",
      "미친 내 친구 제시 불러서 파는 플미충한테 점점 가격 올려서 112까지 불렀다가 잘 가요, 내 사랑. 이러고 계폭함 아 개웃 \n",
      "미친 새끼 뒤지려고 어데서 여자가 담배를 피우시는데 오지랖 질리고 확 마\n",
      "미친 생각하는 꼬락서니 보소 ㅇㅂ 를 >육 변기<로 읽는 거 보면 평소에 뭔 생각하고 사는지 정말 잘 알겠다 \n",
      "미친 서가대 양도 못 한대다들 플미충 신고 먹이러 가자. \n",
      "미친 손가혁 또 댓글 알바 푸레임. 좀 바꿔라 그 지겨운 레퍼토리. 수준하고는 ㅉㅉ\n",
      "미친 여자 한 명의 오지랖 때문에 청와대에서 김정숙 여사가 얼마나 알뜰하고 얼마나 서민적으로 살아왔는지를 낱낱이 밝혔다. 10년 전 홈쇼핑에서 샀던 옷을 입고 다니며 하나의 옷을 몇 번씩 입는데 사치로 혈세를 몇 억씩 쓴다는 미치광이들에게 한 방 먹였다. \n",
      "미친 오지랖도 정도껏 \n",
      "미친 이게 뭐야;;;ㅇ광고 꼬락서니 보소 \n",
      "미친 컴퓨터 꺼지는데 한 시간 걸려?????부숴버린다 아개빡침 미친 컴퓨터 아아아더펍봐야된다구웅!!!!!!!!\n",
      "미친 트위터 놈 타래로 엮인 트윗 하나 눌렀을 때 위 트윗 안 보여줄 때 개빡침\n",
      "미친 틀딱 할배가 자기 나잇값 하느라 왕정시대의 공주 취급을 하며 대통령을 지키겠다고 나서는 거랑. 젊은 사람이 결혼도 한 할배를 지켜준다고 나와서 대통령을 왕자도 아닌 소동물 취급하는 거랑. 뭐가 더 소름 끼칠까.\n",
      "미친 틀딱새끼들이 오냐오냐해주니까 완전 겁대가리 상실했구나. 직무유기한 경찰은 파면시키고 미친 폭도 새끼들 전부 구속해야 됩니다.\n",
      "미친 플미충 아저씨들 알 바가 용해서 현판도시켜 번호 받았다니까 우선 현금으로 몇 장일지 모를 만 원짜리 줌 \n",
      "미친!!. ㅉㅉㅉ\n",
      "미친개.를 물어뜯어 죽일 걸 뒤에 서 보고. 잘 안다. 그건 두 연놈 새끼 가 다 정신 이 빠지게 만든 네 오랫동안 사람 개 꼬락서니 가 안돼 네\n",
      "미친개들이 미친 듯이 짖는 것은 두려움이 극에 달했기 때문입니다. 김일성, 김정일 일당이 죽인 우리 민족이 수백만에 달하는데 어찌 하늘이 분노하지 않겠습니다. 그런 자들을 추종하는 남한의 위선자들도 마찬가지입니다. 총선과 대선에서 반드시 승리해야 합니다.\n",
      "미친걸까ㅌ 지금 지하철에 할배가 ‘아들딸 많이 낳습시다’라고 적힌 띠 매고 임산부 배려석에 앉아있음 아 한남 망해라 진짜\n",
      "미친ㄴ!! 대한민국이 호남밖에 없나? 어떻게 대놓고 호남이 간절하고 호남의 손을 놓지 않고 잡아야 한다?ㅉㅉㅉ \n",
      "미칠 것 같음 진짜 걸즈 캔 두 애니띵의 그 애니 땡이 아이돌 파는 거고 꾸밈 노동하는 거고 어쩌고저쩌고면 의미 값 0인 거죠. 한남들이 그거 가지고 뭐라 안 하잖아요. 남성 권력에 아무 타격도 없는 말을 굳이 저 문장에 넣을 필요가 없다고요 왜 이렇게 문락맹들이 많은지?ㅠㅠ\n",
      "미투 교수 방 안 빼냐 조팔 새끼 역겹다\n",
      "미투 기사 메인에 뜨면 클릭할 때 머뭇 거림. 가슴 먹먹하고 답답하고 혈압 올라서 거기에 달릴 댓글들이 예상되면서 두통 올 거 같고 그래도 눌러보게 된다. 한남 죽이고 싶어진다는 말임\n",
      "미투 생존자 때문에 죽은 게 아니라 자기 업보가 돌아온 거니까 이 머 한 남 빻은 소리 할 예정이었으면 닥쳤으면\n",
      "미투 운동 당했다<- 미투 운동 이런 말하는 새끼들은 성폭행범들이니 저딴 말을 하는 거겠지 정말 웃기네 이래서 한남은 안됨\n",
      "미투 운동 땜에 쫄리는 한남 새끼들이 한 둘이 아니겠지. 이 기회에 다 쓸어버려야 된다.\n",
      "미투 운동 앞에서 무고죄 형량도 높여줘 웅앵웅 하는 한국 남자 죽여버리고 싶다.?차로 치여버리고 병원에 누워있는 한남 앞에 가서 교통사고도 안타깝지만 보험 사기치는 새끼들이 더 못된 거라고 소리 지르고 싶다.\n",
      "미투 운동 조롱 좀 하고 학생 성추행 좀 했다고 하일지가 잘리면 어떻게 되겠어!! 너도나도 빻남성희롱성범죄 교수들 몰아내고 학생들은 클린 해진 학교에서 엉덩이 삼바를 추겠지!!!\n",
      "미투 운동과 안희정 전 도지사 성폭행을 자기네들 웃음거리로 소화하는 빻은 저희 회사 ☞남직원들☜ 때문에 퇴사 심은 나날이 높아져만 갑니다. ¿퇴사만이 답이겠죠?\n",
      "미투 장난질 그만하자. 미투 가지고 노는 것들. 아. 이래저래 모두 역겹다.\n",
      "미투, 왜 진보에만? 보수는 여성해방에 무관심 마 시끄럽다. 좌파들 추잡한 성행이 각에 전 국민이 역겨운데 어디서 진보 타령인가? 시간 갈수록 좌파들 민낯 드러나자 이젠 여성해방운동으로 덧칠하는 꼴이 더 역겹다.\n",
      "미투. 한남. 메가를. 이게 뭐라고 피해 의식 전 장아찌같이 굴어\n",
      "믻나 방청 제일 재밌었던 점: 현석이랑 심사위원들이 빻은 소리 하면 청중들 다 같이 미친 거 아니야???? 왜 저래 진짜;; 웅성웅성하는 거\n",
      "민노총 위원장 틀딱남은 발언 한번 했으면 냄저답게 찌그러져서 박수나 칠 것이지 눈치 없이 마지막에 또 한번 발언대에 오르더라. 이 한남 외엔 전부 여성들의 발언이어서 크.린. 굿.\n",
      "민주당 거머리 같은 놈들. 질기다 질겨. 정말 구역질 난다. 정부조직법 또 표류?? 아.이 나라가 정말 한심하다. 경부고속도로 만들 때부터 저 쥐 랄 하더니 아직도 떼를 쓰고 있다. 민주당 정말 구역질 난다. 모두 몰살 방법이 없나?\n",
      "민주당 너희들 다 이렇게 생각하냐 진짜 배부른 돼지들 맞네 지지자들이 하루하루 팩트체크하고 올리는 글들 안 보고 너희들 하고 싶은 말만 하고 있다는 증거네 소통은 개뿔이나 더도 덜도 아닌 그냥 참여 정부 시즌 2 에라 \n",
      "민주당 박모 의원과 9명이 와서 외상을 달고 갔다”면서 “안 된다고 하니 꼭 준다고 (했다. 맨날 자기 돈 안 내고 세금으로 접대만 받다 보니 돈 내는 것을 모르나 보다” 적었다“국회의원은 돈 내고 먹으면 안 되는 거였어?”라며 “진짜 대한민국 상류층의 현주소다. 부끄럽다” \n",
      "민주당 사망선고받은 전경련의 생명 연장, 동의 못해 전경련은 악의 원인이다.뒷구녃 거래로 탈세 말고 제대로 된 세금 내고 기업 운영하라. 그 돈을 서민 증세로 내고 있는 국민들이 너무 힘들다. 더 이상 노략질 마라.\n",
      "민주당 정성호 물러나라. 너 뭐냐? 고의적으로 민주당 해치려는 수작질이었냐?\n",
      "민주당 홍익표 의원 명박이 사기꾼 사자방 대충 손실만 14조 6천억 된다 잠이 안 온다고 함 4대강 땅 파는데 쏟아부어 국민 세금은 통과시켜 주면서 최악의 실업률에 문재인 정부 일자리 추경 반대하는 부패 야당들 꼭 천벌받을 거 국가들 \n",
      "민주당과 문재인 정부가 열일 하는 건 무시하다가. 안철수의 립 서비스 한마디에 헬레에 하는 거. 정치호 대병 걸린 정혐충들이 진보 행세하는 거. 익숙한데도 또 역겹다.\n",
      "민주당은 열등의식에 사로잡힌 파괴 집단 같다. 세계 어느 나라 정부도 민주당 같은 야당이라면 두 손 두 발 다 들것이다. 온갖 위선과 독선을 일삼으며 입만 열면 외치는 민주 민주! 도대체 민주당이 말하는 민주의 정체는 무엇인가. 그 가증스러운 입을 찢어놓고 싶다.\n",
      "민주당이 힘들고 어려울 땐 1도 신경 쓴 적 없는 인간들이 문재인 대통령 지지율 높고 민주당 지지율 높으니 입당해서는 자기들이 엄청 민주당이었던 거처럼 구는데 진짜 역겹다. \n",
      "믾백 황강 비계에서 풀었던 좋아하는 19금 상황들을 최대한 안 빻은 위주로 (  모아모아모아이석상 했습니다. 성인인증 당근 필요합니다. \n",
      "믿고 거르는 조선일보 기사이기는 하다만, 여직원에 말 안 섞고 톡으로 지시. 미투 이후 또 다른 차별이라는데. 나도 남자이지만 한남들 정말 너무나 한심하기 그지없구먼. 성희롱 안 하고는 여성과 대화도 못하는 한심한 수준이면 이것들부터 퇴출해야지 정상적인 회사. \n",
      "믿었던 사람한테도 믿고 위로받고 기댈 수 있던 지인들한테도 배신 아니 버림받았지 욕도 많이 하더라 이런 내가 지겹다 그딴 걸로 언제까지 지질하게 우울감에 빠져 살 거냐고 네가 무슨 비운의 주인공이냐고 역겹다고 꺼지라고. 응 그날 이후로 난 깨달았어 아무도 내 편은 없다고 연기일 거라고\n",
      "밀양 찾은 홍준표 대표 “구정 앞두고 화재사고 또 난다” 국민이 낸 세금으로 월급 받아쳐 먹고사는 놈이 국민에게 악담을 퍼붓고 있습니다. 반드시 심판해서 사회에서 영원히 매장 시켜야 합니다. 구정 전에 이놈 집과 자유한국당 당사에 불었으면 좋겠습니다.\n",
      "밀양 화재 유족 준표 새끼한테 소방법 반대했잖아 여기 왜 와하니까 민주당 애들이 여기도 있네 준표 수행원 예의도 없단다 사실을 얘기하면 민주당이고 국민 세금 받아쳐 먹는 놈들이 주인한테 예의가 없단다 \n",
      "밀키 올 리 사과문 더 가관인 게 이제는 고객이 충분히 사과받을 시간이 10일이나 있었는데 왜 이제 와서 터뜨렸는지 의도를 알고 싶다고 함 미친 것이 아닌지?\n",
      "ㅂ_ㅂ 타도 플미충 \n",
      "ㅂㄷㅂㄷ 메일 주소도 없고 전화번호도 없고 회사 주소도 없어 이와이는 가진 거라곤 기원이밖에 없어 개빡침\n",
      "ㅂㅇㄹ 뜻이 여성 가슴을 비하한 말이며 보 x 플 하이루 붙인 걸로 알아요 보검이란 그 제 이가. 역겹네요 ㅠㅠㅠ 이거 땜에 ㅈ알도 생긴 걸로 알아요.\n",
      "바라고 있다는 뜻임. 그러다 보니 여자들이 정신 차리고 변하자는 말보다는 한남 빻피소드, 한남 올려치기 같은 한남 덕진이 훨씬 더 많이 유통됨. 한남 빻피소드 난 그런 거 제대로 읽지도 못하겠더라. 일단 화가 치밀어서 너무 고통스럽고 저 여자는 왜 저 지옥불에 제 발로 들어갔을까, 그리고\n",
      "바로 이전 회차의 케이윌과 대조되었는데 케이윌 냉장고 살펴볼 때 박준우가 여자 만나려면 술은 필수랬나 그 비슷한 빻은 말을 했을 때 케이윌이 에이 그게 무슨 소리에 오라며 부정했기 때문이다.\n",
      "바른 정당 의원 놈들 중에서 한 두어 놈 분명 비리 있을 텐데. 단체 교섭권을 박살 내야 한다. 잘 하겠거니 했더니. 개뿔이나. 천성은 절대 변하지 않는 것이다. 나라 팔아먹은 후예들 집단.\n",
      "바른미래당 서울시장 예비후보님 황당한 게, 이제까지 주야장천, 우리당은 세련됨과 pc 함을 추구하는 젊은 이미지의 정당으로 자리 잡아야 하며, 그 시작이 인권감수성과 성 평등이라고 손가락 쥐나게 트윗질을 했는데. 예비후보자라고 나오신 분이 pc 하지 못한 빻은 워딩을 걸고 계시니 기가 차다는 거지.\n",
      "바이는 남자랑 여자 좋아해야 돼! 근데 너네 바이들 아직도 한남 못 잃어서 관광대냐! 얼른 여자끼리 뭉치게 레즈에 붙어라!!!! 이게 지금 뭔. 레즈랑 바이랑 한방에 후려치고 있네 안녕하세요 바이 레즈 통합위원회 새끼야\n",
      "바이크 타는 빻은 냄저들 다 죽었으면\n",
      "박 대통령 때는 다 박 대통령에게 뒤집어 씌우더니 이젠 내각을 호되게 질책하는 쇼를 하며 책임을 피하려는 수작! 툭하면 국회일 집어치우고 더 부을 당이 길거리에 나가 시의 질이나 하던 것들이 정말 눈 뜨곤 못 봐줄 만큼 위선이네요. 문재원 정말 더러운 놈입니다. 실력도 없는 놈이 정권 도둑질이나 하고 \n",
      "박 대통령 때문에 보수가 다 죽는다는 홍준표의 말은 대법 판결 앞둔 홍준표 자신이 살기 위한 수작 아니던가요 문산 d가 실정에 실정을 거듭해대는 이런 시국에 박 대통령 출당시키는 게 그렇게 시급한 일인지 묻고 싶네요 특검 놈들이 죄 없는 박 대통령 구속 연장을 한다는데요 \n",
      "朴 대통령, 청년희망펀드에 2천만 원 기부. 월급 더 20%씩 생쇼를 하고 있네\n",
      "박 대통령께서는 사법부 보이콧하셨다. 난데없이 박근령 씨가 항소했다니 정말 기가 찰 일이다. 왜? 박 대통령과 내왕도 없으신 동생이 오지랖 넓게 항소했는가? 박 대통령이 항소심 출석 않더라도 언론에서 계속 망신 주게 하려고 작정했나? 아무 의미 없는 재판! 사법부는 죽었다!\n",
      "朴 마중에 화환까지 보내. 신연희 강남구청장 논란 틀딱녀\n",
      "박근혜 멍청이를 다국어 천재라 극찬한 기리기 언론이 박근혜 당선 일등공신이었다. 문재인과 박근혜 비교하는 것조차 역겹다. \n",
      "박근혜 정권 때 유리알처럼 투명하고 높은 도덕성을 요구하던 자들이 정권 잡았는데 도대체 왜??이럴까요? 하하하. 이런 정권 지지하는 개돼지들이 나라 망치고 있네요 개돼지들. 위선자들. \n",
      "박근혜 정부와 삼성의 공통점. 1. 강자에겐 굴종적이고 약자에겐 위압적이다. 2. 하고 싶은 말만 한다. 3. 듣는 척만 하고 소통이라 주장한다. 4. 다수를 위한다 하며 측근 소수만 챙긴다. 5. 공히 위선적이다\n",
      "박근혜 추종 박사모 맞불 집회에. 늘어나는 노인 혐오 를 딱, 노인 중 등 비하 신조어. 나라를 혼란스럽게 만든 주범이라는 극단적인 주장까지. \n",
      "박근혜 추종 박사모 맞불 집회에. 늘어나는 노인 혐오 를 딱, 노인 중 등 비하 신조어. 나라를 혼란스럽게 만든 주범이라는 극단적인 주장까지. \n",
      "박근혜가 빼돌린 나랏돈 $$억이 박근혜 소유인 용에서 발견되다?! 그렇지 죄수실이는 구속 도어도 그 운영구조가 그대로 남아있으니 태극기 틀딱 지원금으로 혈세가 빠져나가고 있는지도! 죄수실이 알박기 인사는 그 자리에 지금도. 그네 저 친일파 년을 사형해라ㅡ \n",
      "박ㄹ혜닮았네 개빡침\n",
      "박범계, 기자들과 식사 후 외상 선거법 위반 논란 박범계 포스포 갖고 안철수 탓하며 되지도 않는 공격하더니 꼬락서니 봐라. 죄다 이런 놈들이라니깐. 워낙 공짜 좋아하는 거지시 키들이라 김영란법 1등 공신 안철수가 눈엣가시일 거다. *음식점 운영하는 a 씨가 29일 페이스북에 올린 글 \n",
      "박보검 수면바지 산거 솔직히 너무 지하상가에서 수면바지를 사가지고 선물하고. 음. 윤아 선물이랑 비교하면 더 짜증 난다. 그냥 선물은 그 사람의 센스 보여주는 건데. 한남 특유의 무신경함\n",
      "박보검이 모델 한 와이셔츠 갖고 있는데 카라가 차이나 카라라서 개빡침 근데 내가 산 건 아니라서 그냥 입고 있다.\n",
      "박사모 울 사장도 문재인도 잘 하는 게 있긴 있다고 칭찬. 뭐냐니깐 외교 를 딱 들은 왜 이렇게 해외순방 죽고 못 삼?\n",
      "박사모 칼퇴 했습니다. 서울역 쪽 틀딱들 삼삼오오 집에 가는 거 봤음\n",
      "박사모 트리 딱이 죽어서 이 세계에 환생했더니 진짜 왕이 있는 세계라 엉엉 울며 왕당파의 수호자가 되는 소설. 공주님의 기사 같은 게 되면 더 좋고.\n",
      "박사모 회원들의 ‘9가지 만행’을 폭로한 식당 사장님 via 하여간 나라에 도움 안 되는 인간들이네요. 애국은 개뿔\n",
      "박사모들은 완전 폭력배들이네. 집단폭행 현행범들인데 왜 체포를 안 하는지. 이철성이가 두둔하니까 경찰이 저 모양이지. 답답합니다. 미친 틀딱 영감탱이들\n",
      "박영선만 보면 역겹다는 생각이 드는 건, 다 내가 미움이 많기 때문일 것이야. 우상호를 봐도 짜증이 나네.\n",
      "박영선이 법사 위원장 할 때 갑질은 유명하다 정부 예산안을 자정이 지나도록 국회를 마비 시키더니 자정 지나 통과를 시켜주고 곧바로 외국으로 놀러 나갔다가 국민들의 비난으로 다시 들어왔다 더 웃기는 건 사무실 화분에 도청기가 들어 있다고 게 수작을 했다 화분에 있으면 찾으면 되는데 생쇼 했다 \n",
      "박원순 보면 한심한 게…7년간 서울시장 하면서 온통 자기편으로 서울시 관련 사업에 쭉 심어 놓을 정도로 치밀하고 열심히 준비했는데 어쩌다가 문재인에게 목덜미를 물려서 자기 목소리 못 내고 끌려다닐까? …ㅉㅉㅉ 그저 욕심만 많아가지고…능력도 안되는 게…\n",
      "박원순은 이념 때문에 자기 자식의 장래를 뭉개버린 패륜적인 아버지입니다. 박원순은 진실과 정의를 외면하는 거짓말쟁입니다. 박원순은 인격과 양심이 없는 위선자입니다. 박원순은 자유대한민국의 헌정질서와 국민의 미래를 파괴하는 종북 좀비 떼어의 괴수입니다\n",
      "박원순의 위선은 국가적 재앙 \n",
      "박원순이 13일 전남대학교 강연에서 박근혜 정부는 문맹의 정치…정의 위해 싸워야☞야 역겨운 새끼야! 온갖 위선 가식적인 일은 다하는 놈이 감히 대통령을 비판하고 정의를 들먹이나? 더러운 좌파 시장 놈!! \n",
      "박원순이 네거티브 없는 선거의 승리라고 떠든다 훗날 역사는 가장 추악한 더러운 실체를 언론마저 눈 감은 비겁과 위선의 승리라고 기록할 것이다 박원순은 선거 승리 후 주진우와 첫 번째 인터뷰 예약을 했다고 한다\n",
      "박정희도 겉으론 가장 청렴한 듯이 행동하였으면서도 죽은 후에 청와대 집무실 금고 두 개 중에 하나는 박근혜가 챙겨가서 얼마가 들었는지 모르고, 다른 하나에만 9억 원이 넘은 돈(현시가 450억 원 정도?을 챙겨놓고 있더란다. 위선자가 제일 나쁜 종자다!\n",
      "박종철 임종석 같은 386 세대가 부르짖은 건 민중이 주인 되는 세상 즉 공산주의 체제 공산화 운동이다 거짓과 위선 시대착오적 이 시대 골칫덩어리ㅡ 서울대에 붙은 대자보 내용의 일부다. 운동권이 영웅시되는 이 개 같은 세상을 모두 규탄하자\n",
      "박주선 文 대통령이 입장 표명하면 이낙연 인준할 수도 김광수 결정적인 도덕적 흠결은 아니지만 靑 입장 나와야 주선이 네 이놈! 네까짓것이 벌써부터 대통령을 길들이기 하려는 수작이구나 시끄럽고ㅡ 반대하든지 말든지 맘대로 하거라 궁 물들은 공중분해될 것이다\n",
      "박즴인 혼자 자취하는데 학교 갔다 와 보니까 거실 엉망진창 돼있고 그 가운데 너구리같이 생긴 동물이 딱 앉아있음 즴 근데 집에 동물 들어온 건 둘째치고 거실에 무슨 폭격 맞은 것 같아서 개빡침 - 야 너구리 너 죽을래? \n",
      "박지원 씨가 전두환으로부터 동백 훈장을 받았다는 것이 사실인가요? 경악!! 이네. 어찌. 이중인격자, 위선자, 기회주의자 박지원\n",
      "박지원 추미애, 문 대통령 향한 화풀이를 국민의당에 하는 것 빡 치르 정치 9단이란 새끼들 머리 박아 수작질 9단이겠지 추미애가 더벤져스만 골라 대표 비서실장에 임명하고 있구먼 문미옥에다 이번엔 김정우 어디서 이간질이냐\n",
      "박지원은 연대 없다며 호남표 단속 . 손학규는 단일화 물밑 협상 . 저열한 유권자 눈속임 .노회한 정치인들의 수작질이라고 밖에 \n",
      "박지원은 호남 정치의 개뿔도 아닙니다. 쭉정이가 말장난 하나로 분수에 넘치는 자리를 얻으려는 교활한 정치인이죠. 다음 총선에는 없어질 사람임이 분명합니다. 박근혜 좀비들과 함께. \n",
      "박창균/박창규 한글도 모르는 틀딱들 뭔 sns는 한다고 하는지. 저러고 다니면서 밥 먹고살고 있는 게 다 신기하다. 험난한 인생 살고 있을 듯.\n",
      "박하사탕 24일 시네마 톡 양도합니다. (설경구 참석\n",
      "박효신 팬미팅 정회원(개인 넘버 있음 인증 + 본인인증합니다 양도 걸리면 입장 뒤에도 잡혀 나옵니다 ***그리고 제명*** 양도하겠다는 플미충들한테 혹해서 시도하지 마시고 솔트에 신고나 멕여주세요 \n",
      "반기문 씨 알고 보니 전형적인 틀 딱이시라 온 국민들이 오졌습니다 인정하고요\n",
      "반기문 이런 작자들이 대의를 위한다며 세계 평화를 외친다는 게 얼마나 위선인지 아시겠습니까? 이 위선 앞에 세계 평화가 제대로 올까요? 한일협정 참 잘했네요 이게 un 수장에 수준입니다.\n",
      "반기문 전 유엔사무총장, 중국이 주도하는 국제 보아오 포럼 이사장 내정 최순실이 점지했던 차기 대통령이 문재인에게 용돈을 받고 살더니 이젠 짱꼴라 앞잡이가 됐네 참 지저분하게 먹고산다 ㅉㅉㅉ\n",
      "반기문 측, 실패한 총장 이코노미스트 혹평에 반론 . 어쨌든 기문이는 기회주의자 더럽고 얍삽한 인간의 대표적 유헝 악마보다 더 나쁜 게 위선적인 인간이다.\n",
      "반기문과 꽃동네의 죄 1. 어르신 눕혀 놓고 음식 먹인 죄(목에 걸려 큰일 나므로 살짝 앉힘. 2. 어르신 용 턱받이를 빼앗은 죄. 3. 민주주의와 거리가 먼 자을 힘 있는 자라고 협조하고 생쇼까지 협조 가담한 죄. 4. 조작 쇼하면서 부끄럼을 모르는 죄. 어휴! \n",
      "반남. 빻은 스토리 그만하라 했죠.?ㅎ \n",
      "반대편을 설득하고 자기편으로 만들어서 세를 불릴 생각은 안 하고 맨날 빻은 놈 멍청이 틀딱 더 배우고 오세요 등등 깔보기만 하니까 반대세력이 우후죽순 불어나는 거지.\n",
      "반문들 분탕질 미연에 차단하기 위함인 건 아는데, 그래도 개빡침\n",
      "반미 하면서 미국 물 좋아하는 것들. 쌤통이다 다 추방돼라 너희들 좋아하는 나라로. \n",
      "반반 개어 이업 개죽는다고요 하아 개빡침진자 창피 공 맞고 점프 안 해도 한 번에 안 뒤지는 대 괜히 나대다가 공 따라 이 단점 프로 뒤진 적도 있음\n",
      "반발 학부모들 식판 시위. 여당 내부에서도 파열음 경남도지사 홍준표의 무상급식 중단에 항의하는 민심, 식판 시위. 종북몰이만 할 줄 아는 극우가 보수 코스프레에, 서민 코스프레까지. 위선과 행세의 극치.\n",
      "반지하나잃어버려서개빡침\n",
      "받고 학교에서 터졌는데 보건 선생님이 우리 생리대 구비 안 해놓는데? ㅎㅎ 이러면 개빡침  생리통 졵나짜증나!!!!! \n",
      "받는 사람의 기분 생각 안 하고 내가 좋아해서 좋은 의도로 해주는 건데 뭐가 나쁘죠? 하는 건 정말 한남들 기본 정서인가 봐.\n",
      "발색은 이게 젤 좋았는데. 그냥 안 이뻐도 되니까 이렇게나 만들어주지 개빡침 \n",
      "발정 당과 더불어 성폭행 당위 거짓과 위선 왜곡 편가르기 흑색선전 등 선동에 쉽게 넘어가는 미개한 국민이 양당 기득권 부패 온상이었어요. 양아치 김어준류 가짜 뉴스 음모론 선동을 끊고 아이들이 살아갈 미래를 보세요.\n",
      "밥 건 플미충이 접근해 오길래 개 단호하게 거절함 ㅎ \n",
      "밥 딜런이 한국에 온다 희망 편: 감동적인 노래, 탐라 대화합, 좋은 무대 절망 편: 플미충, 내 자리는 없음, 7월의 무더위, 락페랑 겹침\n",
      "밥 잘 사주는 예쁜 누나 1회 리뷰: 개빻은 얼굴에도 밥도 못 사주겠다고 관광대는 한남들의 세상 속에서 여자는 예쁜데 밥까지 잘 사줘야 하는 세태를 풍자한 제목이었다 모두 의심을 걷어내고 이 드라마에 기대를 걸어보자\n",
      "밥 잘 사주는 예쁜 누나 재밌다. 이런 게 현실 반영 드라마 아니냐. 성희롱 하는 개어 씨부터 지질한 양다리 한남 남친이라닠 드라마 보는 내내 너무 화나는데 중간중간 정해인이 나와서 행복해짐. \n",
      "밥도 못 처먹는 거지새끼들이 선물은 개뿔! 평창 똥간마다 선물이라며 기생충알이나 뿌리고 갈 새끼들이!. ˝온 겨레에 새해 첫 선물 드리자˝ ˝시작이 반˝ 남북 수석대표 모두발언 \n",
      "밥맛! 총체적으로 넌 밥맛! 네 얼굴 목소리 꼬락서니 모든 게 완전 밥맛! # 뮤지컬 위키드 (2013\n",
      "밥맛! 총체적으로 넌 밥맛! 네 얼굴, 목소리, 꼬락서니 모든 게 완전 밥맛! 작은 디테일 하나하나가 내 온몸에 닭살 돋게 해.\n",
      "밥상은 무조건 여자가 차려야 한다고 엠티 가서도 음식은 여자가! 음식은 여자가! 노래를 처 부르는 새끼들이 셰프 딱지는 남자만 달 수 있다고 쿵쾅대는 꼬락서니 하고는 ㅉㅉ\n",
      "밥ㅊ먹고 살기 힘들겠구먼. 생긴 꼬락서니 하고는\n",
      "밥해주는 아줌마란 표현을 굳이 사용한 건. 요리하는 직업을 비하하려는 의도와 아줌마라 폄훼할 의도로 쓴 것. 한남들에게 아줌마와 요리사가 어떤 위치인지 드러나는 것. 물론 요리사 중 성별이 남자인 사람은 종목 상관없이 셰프라고 부르겠지. 이렇게 여혐 하늘 인간이 조선 의열단원이라고 하다니. \n",
      "방귀가 잦더니. 총선에 간 보고 국무당 후보 만나는 해당행위 짓이나 했던 손학규. 당신 같은 위선자는 대통령 되면 안 된다! \n",
      "방금 9시 뉴스에서 암표에 대한 뉴스나옴 플미충아 보고있냨 \n",
      "방금 싸만코먹었는데 맛있더라 를 딱 들 이 먹는 아이스크림인 줄 알았는데\n",
      "방금 인터파크에 전화해 봤는데 플미충 인파 측에서 책임 일체 안 진답니다.\n",
      "방금 전까지 위선적이어서 역겹다 어쩌고 하면서 인성 터트리고 있었음.,\n",
      "방금 친구가 보여줘서 알았는데 너무 충격이다 너무 역겹다 cgv \n",
      "방금 탐라에서 혐짤 봤는데 일본에서 소추라고 불리는 사람의 크기가 일반 한남보다 훨씬 커서 약간 웃으면서 눈물 훔침\n",
      "방금 티엔에 전화했더니 티엔에서 신고받고 지금 확인 중에 있다고 대처 방법 나오는 대로 공지 띄울 테니 기다리라고 유선 답변 받았습니다 님들아 절대 암표 플미충 표 사지 마세요! 누구도 수고해달란 적 없습니다!\n",
      "방송 다 하차하고 집이랑 빌딩 팔아서 광고 회사에 손해배상해야지? 그 정도는 해야 진정성 있는 사과 아님? 자기한테만 관대한 거 진심 역겹네 \n",
      "방송사 빻은 방송 폐지 리스트 ? 우리 결혼했어요 << ok! ? 아육대 << ok! ? 오빠 생각 << ok! ? snl << ok! ? 정글의 법칙 ? 마스터키 << new!\n",
      "방음 하 너무 좋아요 윱 뺨 쓰다듬자가 때리면서 왜, 비명이라도 지르게? 하고 비웃고 비명 섞인 신음 나올 때까지 박았으면 좋겠다 (빻은 취향\n",
      "방자경 씨. 아니 종북일지 모르는 할미요. 생긴 거 보니 딱 봐도 틀딱에 박사모에 시위 현장에 가서 가짜 뉴스 정보들만 투합해서 선동하는 작자 같은데 이번에 당신 잘못 걸렸어. 젊고 깬 시민들이 많이 하는 트윗에 가짜 정보 알려서 매스컴 타니 좃댓다싶지?이참에 콩밥이나 처먹고 와라. 윤 씨면 종북은 어떤 논리야?\n",
      "방탄 좋고 나 만족하려고 돈 쓰는 거지 빅 히트가 일 잘해서 돈 쓰는 건 아니고요 빅 히트 일 잘한다고 생각해본 적이 없어서 모르겠음 고소 경과 어떻게 됐는지 들려오는 소식도 없도 플미충 잡겠다고 말만 했지 개선된 사항 1도 없잖아요?\n",
      "배 아프면 그냥 배 아프다고 말해라 누가 봐도 역겹다 \n",
      "배달의 원호 2-2 얺웃음버튼은 ‘ 빻아드립니다’입니다. 제 기쁨 슬픔 웃음 버튼은 얺입니다,,,♡ ♡ ♡ \n",
      "배부른 도ㅐ자기들의 단체 이기심. 역겹네요.\n",
      "배신감은 배신감대로 들고 기분은 더럽고 역겹고 아주 환장할 거 같은데.\n",
      "배우를 소모품처럼 쓰는 감독 개빡침\n",
      "배현진, 김세의나 복귀시켜라. 누가 누구를 평가하냐? 걔네들은 자신의 욕망에 충실하기라도 하지. 너희의 위선과 교만이 역겨울 뿐\n",
      "배후에 요 동렬이 있는 거 같던데요. 염동열이나 죄짓고도 왜 벌주냐고 행패 부리는 애들이나. 적폐 덩어리들이네요 ㅉㅉ\n",
      "백기완 통일문제연구소장 자본주의 위선 타파. 이게 민중사상 \n",
      "백남기 농민 쏜 살수차, 수압 제한 장치 고장 나 있었다 ㅡ고의적 살인을 실수라고 변명하려는 수작입니다 경찰청장까지 모두 일단 구속수사해야 합니다. 비리를 비리로 덮고, 살인을 살인으로 덮는 악마들.\n",
      "백도 경시한테 수작 부린다고 빼빼로 꺼내 무려고 했는데 기습뽀뽀하고 쿨하게 가는 경사 때문에 빼빼로 손에 쥐고 허탈하게 웃는 백 \n",
      "백인 남 수업이고 백인 남 땀 냄새 리얼 역겹다\n",
      "버거킹이 사기 치는 거 아니냐? 35% 할인한 가격이 4,300원이다. 햄버거 꼬락서니를 볼 때 이건 사기라고 밖엔 이해하기 어렵다. 오늘 이후 버거킹 굿바이다. \n",
      "버스 안에서 올레 와이파이가 잡혀서 개빡침\n",
      "번 더스테이지 진짜 개별로 임 생각할수록 개빡침\n",
      "번짐 개빡침 넌 실패작이야 \n",
      "벌구가 틀 딱인데 무슨 틀딱타령? 좌파건 우파건 무조건 이명박 씹는 계정도 주의해야 하겠네요! \n",
      "벌써 보인다 말꼬투리 잡혀서 당황하는 요니 ㅎㅅㅎ 하지만 빻은 말로 곤란하게 만들면 가만두지 않겠습니다 라스 \n",
      "벌써 플미충이 판을 치네.\n",
      "벌써부터 3층을 플미충들이 기본 10만 원씩 프로미 붙여서 파는 게 보인다. 그 돈 내고 가면 21만 원 내고 엑소 느낌 나는 면봉 보러 가기 인가.\n",
      "벌써부터 플미충 나대는 소리 들린다ㅠㅠ \n",
      "벌어나비는 부끄러워 숨기라도 했는데 저런 시 쓰는 한 남들은. ㅉㅉ\n",
      "범죄 일으키고 사과하는 거 이제 그냥 보기 싫음. 사과하는 거 자체가 잘못된 게 분명 아니지만 범죄지 한색기 제대로 사과하는 꼬락서니를 못 봄.\n",
      "범죄에서 법리를 따질 때는 행위 여부를 따지지 고의성을 먼저 따지지는 않지요. 민주당 선관위의 고의성 주장은 사건을 덮기 위한 수작에 지나지 않습니다. \n",
      "범죄자가 구속됐는데 국내 경기 침체 우려된다며 귀신 씻나락 까먹는 소리하고 자빠진 재벌 패거리들! 경기 침체는 개뿔! 포승줄이 너무도 잘 어울리는 범죄자 이재용, \n",
      "범죄조직 두목 이명박과 중간 보스 범죄 현황 도표. 도표에 오르지 못한 잔챙이들까지 포함하면 어마어마한 도둑떼들이다. 이들이 대한민국 정치 경제를 휘어잡고 국민들 세금을 도둑질했다. 건국 이래 최대 부패집단이다. 교도소가 부족할 것 같다. \n",
      "법관 독립? 양아치 법관들 독립 시켜줘서 뭐 하게? 독립은 누구로부터 받는 게 아니라 스스로 만드는 거야! 권력의 속성은 다 그래! 주는 놈한테 기는 노예근성이 있거든. 양심선언이 전제되지 않는 독립은 위선이야! 권력의 우산 아래서 비나 피하려 드는 쌩양아치놈들에게 개뿔! 무슨 독립?\n",
      "법관이 사적 영역에서도 품위를 지켜야 한단다. 법관들이 사생활에서 품위가 없어도, bbk 의혹 제기했다 정봉주 징역 1년 선고하는 공적인 망나니 짓이나 안 했으면 한다. 정권 눈치 보는 판결하며 사법살인 저지르는 품위보다, 대통령도 놀려먹는 판사가 훨씬 낫지 않은가. 품위 있는 판사가 다 위선자 더만\n",
      "법도 개무시하는 이 여자 제정신인가 미처. 년 아\n",
      "법원의 판단을 존중합니다 비서 하나 잘못 들여 인생 쫑 나고 가정까지 파괴되고. 간통 여가 피해자 코스플레이라니 기가 막혀 화가 나네요 진정 위로를 받아야 할 사람은 안지사 아내와 자식들입니다. 4번씩이나 해놓고는 숫처녀 행세하는 꼬락서니가 역겨워 토 나오 갰네. 거짓투성이. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "법이 빻은 건 맞지만 제재가 있고 나이 제한을 걸어 둔 성인물을 뚫는 법. 그걸 공공연하게 공유하는 건 아니라고 봄\n",
      "법적 대응은 개뿔,, 반성을 모르는 미친 인간들,,  안철수 대표 용산소방서 방문, 소방관들 격분, “대통령 놀이 그만하라” 댓글 폭발, 국민의당 법적 대응 ← 어익후. \n",
      "베충 를 딱 들 이 제천 유가족 동영상 퍼트리면서 문지 지자들 자극함 악플 달기를 바라는 것 같은데 절대 넘어가면 안 됨.\n",
      "베충이들 북한 못 잃어하는 거 보니 역시 일성ㄷㄷ북한얘기만나오면 충에 벌떡 뛰어오는 거 보소 네댓 자꾸 뒤집히는 거 보니까 개빡침.ㅇㅏ.\n",
      "변명 덩어리 안철수!! 이런 무책임하고 위선적인 사람이 대선에 나갈 생각을 하는 거지? 파렴치한이다! \n",
      "변명이 많은 사람은 위선적인 사람이 많다 이유가 많은 사람은 거짓된 사람이 많다 핑계가 많은 사람은 가식적인 사람이 많다 과시욕이 많은 사람은 허세에 능한 사람이 많다 욕심이 많은 사람은 외골수적인 사람이 많다 \n",
      "변승욱 대기자 우리 언론이 미국 세금 탈류 증세 걱정하나 미국 기업을 대변한다 울 대통령 트럼프 의중을 알고 있었고 우린 이케 할 것이다 비행기 안에서 자료까지 주면서 부탁함 미 폭스 기사는 쓰지도 않고 중요한 기사는 빼버린 자국 대통령 죽이는 언론 개시 키들 \n",
      "변호사 출신 이재명이 성남시장 하는 동안 법 잘못 철거민과 힘없는 사람들 상대로 온갖 고소고발을 일삼더니. 자기부정이 끝내주죠. 이재명 토론하는 꼬라니 보니, 지난 청문회 때 거짓 들통나 엉덩이 들썩거리며 어쩔 줄 몰라 하던 김기춘이 떠올랐습니다. 인생 진짜 더럽게 사는 이재명. 분명 벌받을 겁니다.\n",
      "변희재 대표 정치검찰한테 개빡침 ㄷㄷㄷ 민민 껌 찰 \n",
      "별 멍멍이 새끼들은 선의면 아무 데나 다 오지랖 떨어도 된다고 생각해서 큰일이다.\n",
      "별로 관심도 없었지만, 알게 되었더니 기분이 나쁘다. 하지만 한 편으로는 그저 화풀이, 증오하고 싶은 대상을 찾아 다 쏟아내는 것으로 밖에 보이지 않아서 그 당당한 행태가 역겹기도 하다. 그냥 다 같이 자멸하자고 말하는 것 같은.\n",
      "별명 싸움이 꼬우 신 제3자면 신경끄느세요 오지랖이 태평양이세요? 특허 특허 거리는데 모든 연예인이 특허 냄? 그냥 쓰는 거고 겹치면 서로 마음 안 좋으니까 쓰지 말란 거지 우리만 그런 것도 아니고 모든 팬덤 간이 그러는데 그냥 일반인이시면 팬덤 문제 신경 끊으세요 그리고 세종대왕 드립도 자제 좀\n",
      "병원 한번 데려가니까 고양이 개빡침 진짜 네가 아픈 걸 어떻게 해. 예상해보는데 나갔다가 오면 이불에 오줌 싸 널 듯\n",
      "병을 연성 소재로 쓴 빻은 창작 세계관 \n",
      "보건 사회 연구원에 민원 많이 넣고 계시지요? 저는 늘 하던 대로 국회에 압력 넣는 쪽으로 머리를 굴려보았습니다. 보사연은 국무조정실 산하라서 정무위의 소관기관이 됩니다. 정무위 소속 의원실에 전화해서 세금 들여 한남 같은 연구를 한 보사연을 조져 봅시다.\n",
      "보검이 얼마를 처먹는데 쌉소리하네 진짜 그럼 나도 데이트 폭력하고 빻은 얼굴 들이대서 영상 찍고 돈 나눠주고 문상 깊카주면 범죄가 사라지냐 \n",
      "보검이라는 말만 들어도 약간 역겹네요. 사진을 보니 더더욱 역겹고요. 이대휘 만세!!\n",
      "보기 역겹고 징그러운 것들은 이제 그만 사라져라. 제발. \n",
      "보기가 역겹군.!\n",
      "보기만 해도 역겹네요 -/-\n",
      "보는 내가 다 힘 빠지는 움짤. 겁나 빨리 달리려고 자세 잡고 있는데 애들 다 반칙함 개빡침 \n",
      "보니 누나 웅재 노래 듣고 개빡침\n",
      "보다 좋은 후보를 선택하기 위한 국민의 알 권리를, 그 권리의 보장을 주장하는 당원들의 노력을 당신은 처참히 깔아뭉개 버렸다. 당신의 그 알량한 욕심을 채우기 위해 위선의 가면을 쓰고. 그러고도 감히 민주를 말하고 공정을 얘기하며 정의를 부르짖지 말아라 듣기 역겹다.\n",
      "보석 신청 김기춘 보석신청을 받아들이지 말라는 문파들아 너희들 말대로 보석신청 받아들이지 말아라 단 나중에 입장이 바뀌었을 때 또 딴소리나 하지 마라 문죄인 위장전입자 임명 반대라 해놓고 이낙연 강경화 . 위장전입자 대폭 임명 위선자 새끼들\n",
      "보석들 번식도 못하는데 야함을 느끼고 연애도 한다니 정말 음란하다 (오로지 고대인만 빻은 생각을 한다\n",
      "보수가 뒤끝이 없을 것이라 오지게 착각한 김무성개틀딱놈들 \n",
      "보수는 정말 얼마만큼 보수를 받을까? 돈 없인 안 움직이는 게 보수라는데! ㅉㅉㅉ 돈의 노예들! \n",
      "보수는. 개뿔. 수구 극우테러범이지. \n",
      "보여달라고 하던 애새끼들이 지금 대학생이겠군. 왜 나라 꼬락서니가 이 꼴인지 알만하다.\n",
      "보연 씨는 말투가 다릅니다. 아마 가끔 관리했거나 공무원이니까 노출 안되게 알티를 주로 담당한 듯. 오늘 혜경궁은 틀딱냄새가 나고요.\n",
      "보적 보라고 우기는 한남들 현실 \n",
      "보조배터리 산지 2주 만에 고장 나서 개빡침\n",
      "보철이라고 하니 뭔가 있어 보이지만, 입천장을 대신해서 구강과 비강을 가로막아 주고 치아를 대신해 주는 사실상 큰 틀니다. 그리고 난 의왕 산다. 그러니까. 내가 틀 딱인 왕이다!!\n",
      "보통 한남은 키 작으면 정말 아웃인데 임시완은 작으면 작을수록 요정이야\n",
      "보트론과 갓겜 써니 하우스의 근본 없는 크로스오버. (어디서 틀딱냄새 안 나요??? 사실 랜스의 재스민 코스튬이 보고 싶었을 뿐이었지만, 생각보다 네오-피지/ 나나-키스 싱크로가 좋아서. 근데 틀딱내 오진다 정말.ㅠㅠ \n",
      "보편적인 멘틀을 가진 회사라면 사태가 이쯤 됐으면 어찌 됐건 보도자료라도 내서 국민한테 사과하고 재발방지를 약속하는 게 정상 아닌가? 시간이 지나면 잊힐 테니까 그냥 뭉개고 가겠다는 건가? 국민 우습게 알고 기러기들 동원해서 실드나 쳐대는 꼬락서니가 이명박근혜 정부와 판박이다.\n",
      "보험회사 개빡침 \n",
      "복길이 - 성형 실패로 성괴가 된 남자. (6 \n",
      "복지는 국민이 낸 세금으로 혜택받는 것이 아니라 권리이고 국가의 의무입니다. 거저 얻는 것이 아니라 합당하게 받아야 하는 권리라고요. 안희정 도지사는 진보를 떠나 민주적 인식을 제대로 이해하는 사람인지 정말 의심스럽네요. 그 양반 정치언어 정말 싫어요. \n",
      "본계 덕계 트친의 개빡침 \n",
      "본계에서 아직 한남과의 연애, 결혼 못 버린 사람 있는 것 같을 때마다 답답하다ㅛㅛ 도시락 싸 들고 말리고 싶어. 유니콘은 존재하지 않으니까 유니콘인 거고 진정한 조심 남은 스스로 재기하는 남자인데. 나중에 속았다며 후회하지 말고 돌아오세요. 딴 건 몰라도 연애, 결혼은 진짜 아닙니다.\n",
      "본인 괜찮다고 말해달라고 그러는 건가? 이런 식으로 말하고 생각하는 사람들이 사실 제일 무서워 난 진짜 지금 살 때문에 죽어버리고 싶은데 그런 식으로 생각하는 거 너무 역겹다 이해 못 하겠다는 눈으로 쳐다보는 것도 너무 싫다\n",
      "본인들은 못 느끼는 선민의식 쩌는 모습들이 정말 역겹다. 나는 전해철이 되든 이재명이 되든 기존에 적폐 패거리들에게 농락되었던 모든 것들이 정상화되기만을 바란다. 이재명을 지지하겠지만 전해철이 돼도 열렬히 응원할 것이다. 높은 지지율을 믿고 날뛰는 선민의 싯 쩌는 저들이 진짜 싫다\n",
      "본인보다 좋은 자리면 돈 더 주고 사례한대 아니 뭐 다 같은 11만 원 좌석 아니에요? 그렇게 하면 본인도 플미충아닌가? 교환하려는 사람도 플이 충으로 만드는 거 아님? 돈이 남아 도시면 앨범을 더 사세요 애들한테 선물을 보내던가\n",
      "본인이 빠는 장르가 좀 빻을 수도 있죠 빻은 부분을 인지 못하거나, 빻은 걸 안 빻았다고 올려치는 순간부터 이상해지는 거야 그리고 궁극적으로는 좋은 작품을 좀 더 소비하는 쪽으로 가야 하는 거고\n",
      "봊나 어이없어; 노래 봊.나 크게 부르면서 그 한남 특유의 잘 나가는 척하면서 노래 부르기; 더럽고 역겨웠음. 계속 여자 얘기하고 무슨 사진 찍어달라고 부탁한 여자들이랑 누가 놀았는데 부러웠다 뭐 자지가 가만히 있지 못했네 마네,, 진짜 바로 뒤에서 어머니랑 같이 있었는데,,,\n",
      "봤냐? 자기 밥은 알아서 스스로 배식하는 문 대통령. 자유당처럼 권위주의, 특권의식에 빠진 새끼들은 절대 못하는 행동. 1억 피부과 나경원 너 말이다. 세금 내라 24억 원. \n",
      "부부가 뭐 하는 짓들인지. ㅉㅉ “진짜 싫증 나고, 천박한 것들.” 이렇게밖에 더 이상 표현할 말이 없으니까 능, 제발 우리 당에서 꺼지세요!!\n",
      "부창부수라고 년 놈이 똑같네. ㅉㅉ\n",
      "부탁드릴게요. 인공기랑 틀딱드립 좀 그만하세요 제발. \n",
      "北 군인 집단 탈영, 이유는. | 다음 뉴스 전역했는데 집에 안 보내줌 -> 김부자 우상화 시설 건설한 뒤에 아오지 탄광에서 일하라고 해서 말년 병장들 개빡침\n",
      "북괴 놈들이 우리 군의 f35a 도입을 반민족적 범죄행위란다 미친 새끼들 자기들 백성은 쫄쫄 굶기고 허구한 날 미사일 쏘아되고 핵무기 개발하는 것은 친 민족적이란 말인가? 하여간 이놈들이 하는 짓이랑 문정권이 하는 짓 이랑 도긴개긴 내로남불 타령하는 것이 어찌 이리 똑같노 ㅉㅉ\n",
      "북괴 방문할 때 대한민국 기자 단 1명도 동행하면 안 되는 상황은 그만큼 떳떳하지 못하다는 증거다 이 사실 하나만 놓고 보더라도 남북회담이니 미북회담이니 요란 떠는 것이 수작질이며 사기극일 확률 100%\n",
      "북괴+성괴 ㅉㅉ.: “北 김정은 6차례 성형 수술” 김정일 국방위원장의 후계자 김정은이 후계자로 내정된 뒤 공식 석상에 등장하기 전까지 모두 6차례 성형 수술을 했다는 주장이 제기됐습니다.\n",
      "北에 사전 문의했다? 안 했다?. 文-宋, 물고 물리는 진실공방 진실공방은 개뿔. 16일에 결정한 게 맞구먼. 기사 제목 갖고 장난치냐? 그리고 허위사실 유포한 송민순은 감옥 가자! \n",
      "북을 두드리든, 한복 입고 춤을 추든, 오만 잡스러운 말로 욕을 하든… 이 모든 너저분한 짓거리보다 더 웃기는 게 여러분을 사랑하기에 반대한다는 푯말이었네요. 가증, 위선, 거짓…등이 한꺼번에 밀려와 역겨움을 참을 수가 없네요\n",
      "북한 정권을 유지시켜 한국에서 기득권 유지에 연연하는 親盧(친노 세력의 위선과 대한민국의 정통성을 부정하는 從北(종북 세력의 반역성을 폭로하지 못한 박근혜 후보에 대해선 아쉬움이 남는다. 그러나 비정상적 정치사. \n",
      "북한 특수군의 머리띠 김대중 씨 석방(제34광수 가짜는 가짜로 통하고 거짓은 거짓으로 통한다. 공갈도 공갈로 통한다. 노벨평화상이 좋아도 거짓과 위선으로는 . 그 가치와 의미는 아무것도 없어 .\n",
      "북한에 눈 돌아간 트리 딱이 일선 베스트들 정모중이넼 50대들 미국에 환장한 거 보소 미국 두둔할 거면 가서 이민 가서 살아 \n",
      "북한이 핵 실험을 할 때마다 우리의 원망은 방위산업 비리 똥 별들에게 돌아가야 한다 그 윗대가리 이명박에게 돌아가야 한다! 북한이 저 gr할 때 우리는 뭐 했어? 그 많은 세금 거둬가서 갑질 빼고 뭐 했어! 이게 다 이명박과 똥별 탓이다! 감옥 가!\n",
      "분기마다 빠는 캐릭터가 바뀌면 3개월마다 여자친구를 갈아 치우는 놈이라고 놀림당하지만 10년째 한 캐릭터만 빨고 있으면 그땐 또 틀 딱이라고 놀림당하는다\n",
      "분노가 치민다. 저 간악한 거짓선동의 수괴 문재인이가 나의 분노를 북돋우구나! 저 위선자 공작선 거의 주범, 종북 수괴 임수경과 이석기 비호자 문재인! 결단코 용서치 않으리라!\n",
      "분노의 틀 따. jpg \n",
      "분명 지금도 유명한 사람들 중에 남자들끼리는 알면서 말 안 하는 구린 놈들이 수두룩할 거란 생각이 제일 기분 더러움. 잠재적 아군은 개뿔 그냥 드러나지 않은 범죄자들 투성이야.\n",
      "분명 페미는 뚱뚱하고 몸무게 1톤이어야 하는데;; 허둥지둥. 분명 다른 메가를 들은 뚱뚱할 거야. 허겁지겁!!@!.! 뭐야. 얘넨 친구 잘못 사귀어서 물든 걸 거야!!!! 키보드 퍽퍽 씩씩.\n",
      "분통이 빨갱임 닌 몬데? 저 늙어가 뇌가 텅텅 거리 노 그래잘난 너희 보수들이 나라 해놓은 꼴 봐! 안보 그 마이 아가리 털더니 개뿔,, 방산비리.,전부 일 마이 포켓 너네 세 끼들 gp gop jsa 처보내봣나 총알 통과되는 방탄조끼 입고\n",
      "불 잘 알? (뭐지 이 새끼는;; 한남 불알 떼는 법 잘 알아요? (오. 놀 줄 아는데 \n",
      "불경한 여자ㅡ 하지만 때로 부적(초경혈, 여학생 양말. 방석. 등이 되기도 하는 여자ㅡ집안을 망하게 하고 대를 끊을(남자한테 불임 원인이 있어도 여자ㅡ 정말 다 역겹다.\n",
      "불난 집에 기름 퍼붓는 천하 잡 것들. ㅉㅉ \n",
      "불량 청소년의 눈길은 슬금 피하고 길 잃은 아이는 지나치면서 연예인 학력위조, 열애설에 열광하는 그따위 오지랖은 시궁창에 처박아 버려라\n",
      "불법사찰 의혹 이인규, pd수첩 카메라에 줄행랑 ://durl.me/225yj 줄행랑도 공무수행의 일부냐.? 거머리 같은 새끼.\n",
      "불쌍해 . 왜 그래 케이팝. 하던 대로 하면 서로 좋잖아 난 새로운 걸 시도하는 게 정말 싫어 틀 딱이라 예민해\n",
      "붙지 말아 이 거머리 같은 양반아!! 그 흉물스러운 것도 내려놓으라고요!!!\n",
      "브레이크 고장 내고 절벽을 향해 질주하는 열차의 운전자가 당신이다. 남북통일이라는 가치를 내걸고 절대권력을 향해 질주하는데, 탁현민 (2018년 4월 4일까지만 행정관 당신 같은 사람이 폴딱거리며 운전을 해대니 국민 보기에 전체적인 모양새가 영 더러운 거다. 알고는 있나? 역겹다. \n",
      "브로 팬에 마틴 프리먼 나온대서 푸쉬쉭됨 아니 진짜 백인빻남들 낄끼빠빠못하고 아무 데나 다 튀어나와\n",
      "블록 했더니 뒷개로 찾아오는 거 너무 역겹고 무섭고 소름 돋고요 내가 신세 진 건 많은데 자꾸 그러면 당연히 블록 하지\n",
      "블언당했네 저 한남 개 싫어하고 자살 관련해서 웅양 왜 자살하려고 하냐 남들 힘들 건 생각 안 했냐 이러는 거 진짜 싫어하니까 이해 안 가는 분들은 빨리 블록이나 불언이나 하세요 사찰은 하지 말고 한남 나에게도 찾아와서 갤털고 이거 너지? 어디 살아 이럴까 봐 무섭다.\n",
      "비계 풀었음 와 진짜 이게 현실이다 이 악기 년들아 아 진짜 개빡침 \n",
      "비교하는 자체가 역겹고 구역질 남 어디다 갖다 대시나\n",
      "비렁뱅이처럼 떠돌던 경기동부 새끼들이, 어쩌다 이재명에 묻어 우리 당에 흘러들어와 집권 여당 메이저의 꿀맛을 보더니, 아주 당을 통째로 집어삼키려고 환장을 했구나. 너희들 파렴치 거지새끼들의 그 더러운 수작을 우리가 보고만 있을 줄 아니? \n",
      "비밀은 없다 흥행 못한 거 생각하면 또 개빡침\n",
      "비슷한 거로 어 무슨 컴퓨터 화면 주르륵 지나가는데 01010101이 8개씩 혹은 16개 내지는 2의 지 두 개씩 짝 지어져있지 않다던지 하면 개빡침.\n",
      "비전 아닌 애들 하는 꼬락서니 보면 왜 빛전빛전 걸렸는지 이해가 갑니다. 새끼야 장판 안 피하냐?\n",
      "비트 레이트 뻥튀기한 음원들이 그렇죠.  같은 320kbps라도 음질이 거지인 게 있군요. 받아놓고 보니 보컬 다 뭉개지고 음 다 깨지면 개빡침\n",
      "비판을 주업으로 밥 빌어먹고 사는 새끼들일수록 자신을 향한 비판은 감당하지 못합니다. 한마디로 위선과 독선의 결정체인 거죠. 재섭 이서.\n",
      "비혼 여성 동지 분들 우리 다들 한남 꼬무룩시키는 샤네루빔 같은 허울 좋은 정신승리 갖다 버리고 월세 살던 분이 전세 가시고 전세 살던 분이 집 계약했다고 등기부등본 올리면 서로 축하해주고 자극받고 그랬으면 좋겠음.\n",
      "빌어먹을 기리기 놈들 내가 낸?세금으로?밥까지 처먹고?있었네 관행처럼 청와대 외상장부 밥 먹는 청와대 기자들이 있습니다 b 씨는 “월로 치면 수십만 원 선”이라며 “장부에 이름을 달면 월 말에 일괄 계산해서 직접 청와대 행정실로 가면 계산을 해준다\"라고 말했다\n",
      "빙썅짓하려고 왕이가 자랑질 하는데 눈치 없는 민이가 오지랖 부려서 레오한테 차이는 거 보고 싶다. 아우 요즘 연영과 킹카 자꾸 들이대서 귀찮아 죽겠어 연영과 킹카? 누구? 레오라고 있어. 중동 혼혈에 키 크고 잘생긴 모델. 지금도 자꾸 전화 온다 화나\n",
      "빙은 돌았네 완전 망령 난 올댓 아이스쇼에 캐스팅을 자기들이 뭐라고 지시함 나름 협회란 게 동네 아줌마 아저씨들 떼거지로 다니면서 오지랖 펴는 짓거리 똑같이 함 오만 거 간섭 다하면서 뭐 하나 떨어질까 기웃대다가 덜렁 집어가고 그러다 정작 싸움 나면 모른척하고\n",
      "빻|||탄괜 들은 정말,,,, 답이 없다,,,, 웬.? 가사 표절도 정도껏 해야지 무식한 거 티 내나 이젠 소속사 탓하며 웅앵거릴 일 없겠네 자기네가 잘못한 거니 해외 작품들은 아주 맘대로 갖다 쓰는 프리 소시지? \n",
      "빻남덕: (무나 받은 굿즈를 소중히 품에 안고트페미메갈쒸뽤련들아.! \n",
      "빻남덕새끼들 맨날 해외 하여 솔 가수 의상 들고 와서 프로정신 운운하며 옷 짧게 입어라 뭐라 하는데 우리나라 여들이 비욘세처럼 못 입는 이유는 그런 말을 하는 너희들의 존재 때문이잖아 \n",
      "빻남새끼덜아,,투디세카이에선,,, 이 얼굴이 못생김 취급이다,,,,,,,,,,, 낄 데 안 낄 데 구분해라,,,,,,,,,,(피눈물 줄줄 \n",
      "빻은 (사랑하는 오빠들의 고추나 걱정하며 드러눕는 어린 여성들인 빠순들!! 파이팅입니다!’ \n",
      "빻은 걸 빨아주고 좋아해 주면 더 빻은 걸 가지고 나오는 게 세상의 이치.\n",
      "빻은 말 좀 그만해 \n",
      "빻은 말을 하면 뚝배기 깨고 싶으니까 입을 다물었으면 좋겠다.\n",
      "빻은 말하고 싶어도 참으세요. 성인이 다 되어가면서 빻은 말을 못 참습니까? 더럽네요 ㅉㅉ\n",
      "빻은 면상 돈 고남일수록 래디컬 페미들한테 terf런들 죽이고 싶다 쉬익쉬익 하더라.냄저놈이 페미 이론 가는 무슨. 아직 박사 끝내지도 못한 주제에 멋모르는 돈 다들 사이에서 선생님 소리 듣다 보니 주제 파악이 안되고 나대는 거지. 여자는 생존이 투쟁이고 여성운동이야\n",
      "빻은 애들 맨날 본질이라는 단어 뭣도 모르고 쓰는데 개빡침. 하나 마나 한 말 엄청 함\n",
      "빻은 얼굴과 터진 인성을 동시에\n",
      "빻은 질문에도 자연스럽게 넘어가는 대위 센스 이러니 내가 휘 좋아하지 \n",
      "빻은 한남 글을 올리면 알티가 몇천 알티 만 알티되는데 비혼 이 출산하자 00 하자는 고작 몇백 알티밖에 안 됨 내가 시험해봤다\n",
      "빻은 한남이랑 감히 비교하기도 싫은 배우님. 시사 언론에 민감하고 늘 찾아본다고 한 배우님답게 역시나 여성 혐오에 대해서 늘 생각하고 계신 것 같다 저런 질문에 여배우도 같다고 바로 말한다는 것 자체로 항상 생각하고 있다는 뜻이겠지요. 정말! 항상! 반하고 갑니다. \n",
      "뻔하고 진부하다 이 새끼들아 좀 색다른 방식으로 빻아보자 어쩜 이렇게 예상과 한치도 다르지 않을 수가 \n",
      "삔 또 상한 틀딱 사울 팽한 테 패드립까지 치는 호드 대 족장 \n",
      "ㅅ ㅏ발 진짜 뭐만 하면 머릿속에서 음악 장르 불문 자동 스트리밍 되는 거 개빡침ㅁ 오늘은 클래식 부문으로 38282828개 나왔는ㄷ데 신왕의 궁전 같은 거 38282829개 나와서 멘ㄴ탈 터짐\n",
      "ㅅ ㅣ발 이름도 양도 충이야 플미뒈지길\n",
      "ㅅ ㅣ발 진자 별의별 플미충 샊히들 있다 제시 30 이상 시라니 ㄹ ㄹ ㅅㄹ 99000티켓을 얼마에 불려 장난하나 \n",
      "ㅅ메르시가 살려줫는대 바로 뒤지면 진짜 너무 미안하고 개빡침\n",
      "ㅅㅂ 너는 성인이 다 되어가면서 기본적인 지식도 없습니까? 역겹네요 ㅉㅉ \n",
      "ㅅㅍ 화장실 남자만 열려있어서 개빡침\n",
      "사과 같지도 않은 사과쇼 하더니 악의적으로 편집해서 강경화 까는 게 눈에 보입니다! 손석희가 이젠 조갑 제급이라는 사람들도 있어요. 언론인은 개뿔 비열하기가 진짜 가관. 역겹네요\n",
      "사과 같지도 않은 사과하는 꼬락서니가 꼴 보기 싫은 거 순위권이다 진짜\n",
      "사과 하라니까, 여행 다니고 맛집 탕방 하다가 딱 걸려서 사과쇼하고 자숙의 시간을 가져? 개뿔이다. 이제 맛집 탐방도 못하게 생겼으니까 정치나 하자. \n",
      "사과는 개뿔. 범죄 소굴 궁 물주 작당을 통진당 해체와 같은 수순으로 해체합시다. (억울한 통진당에 비유한 건 미안합니다 \n",
      "사과는 받아줄 마음이 있는 사람한테나 하는 검느니다 용서가 당연한 것처럼 구는 꼴이 너무 역겹고.\n",
      "사는 집 아니면 팔아라? …文 정부 18개 부처 장·차관 37%가 다주택자 // 자기들은 안 하면서 국민들에게 팔라고? 역겹다!!!\n",
      "사드 마을마다 하나씩 놓든지? 틀딱들\n",
      "사드 반대를 위해 전국에서 성주로 모였다는 5천 무리들, 반국가 단체와 5대 종단 평화기도 같은 수작들은, 제주해군기지에서 우리가 지겹게 봐온 좌익종빨들의 반대 시위와 다름없다. 어수선한 대선 시기를 틈타 국가 안보에 재 뿌리는 반역들이다\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "result=[]\n",
    "fr = open('testset.tsv', 'r', encoding='utf-8')\n",
    "rdrr = csv.reader(fr,  delimiter='\\t')\n",
    "\n",
    "it =0\n",
    "X_test=list()\n",
    "y_test=list()\n",
    "data_test=[]\n",
    "for line in rdrr:\n",
    "    it+=1\n",
    "    #print(line)\n",
    "    data_test.append(input_sentence)\n",
    "    a = line[0]\n",
    "    b = line[1]\n",
    "\n",
    "    \n",
    "    if '1' in b:\n",
    "        b=int(b)\n",
    "        b = 0\n",
    "    elif '2' in b:\n",
    "        continue\n",
    "        b=int(b)\n",
    "        b = 1\n",
    "    elif '3' in b:\n",
    "        b=int(b)\n",
    "        b = 1\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    if(a==''):\n",
    "        continue\n",
    "    print(a)\n",
    "  \n",
    "        \n",
    "    a_t=' '\n",
    "    j=[]\n",
    "\n",
    "\n",
    "    c_t=' '\n",
    "    for e in a.split(' '):\n",
    "        a_t +=e+' '\n",
    "\n",
    "        c_t = list(tokenize_all_reviews(a_t))\n",
    "        \n",
    "        if(len(c_t) <=3):\n",
    "            continue\n",
    "        if('.' in e):\n",
    "            b_t = list(tokenize_all_reviews(a_t))\n",
    "            j.append(b_t)\n",
    "            a_t=' '\n",
    "        elif('?' in e):\n",
    "            b_t = list(tokenize_all_reviews(a_t))\n",
    "            j.append(b_t)\n",
    "            a_t=' '\n",
    "        elif('!' in e):\n",
    "            b_t = list(tokenize_all_reviews(a_t))\n",
    "            j.append(b_t)\n",
    "            a_t=' '\n",
    "        \n",
    "\n",
    "    if(len(j) == 0 ):\n",
    "        b_t = list(tokenize_all_reviews(a))\n",
    "        j.append(b_t)\n",
    "    elif(len(j) > 0 and len(a_t)>=3):\n",
    "        b_t = list(tokenize_all_reviews(a_t))\n",
    "        j.append(b_t)\n",
    "        \n",
    "    if(len(j)==0):\n",
    "        print(\"EE\")\n",
    "        continue\n",
    "\n",
    "   # print(j)\n",
    "   #print(\"############################################\")\n",
    "    X_test.append(j)\n",
    "    y_test.append(b)\n",
    "\n",
    "    \n",
    "read_f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12329\n",
      "3175\n",
      "(12329,)\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12329,)\n",
      "(3175,)\n",
      "[[0, 0, 0, 0, 69890, 41803, 7245, 373, 0, 0]]\n",
      "[[0, 62755, 68419, 321700, 0], [168, 446271, 1813, 0, 0], [3294, 0, 152467, 14013, 0, 0], [0]]\n"
     ]
    }
   ],
   "source": [
    "from numpy  import array\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(X_train[4])\n",
    "print(X_test[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlwngud3028/venv-python3.6/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/home/dlwngud3028/venv-python3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879129\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "weights = list()\n",
    "\n",
    "for i in range(0, len(embed_lookup.wv.vocab)):\n",
    "    cc = embed_lookup.wv.index2word[i]\n",
    "   # c = embed_lookup.vocab['shit'].index\n",
    "   # print(c)\n",
    "    try:\n",
    "        #print(fm[cc])\n",
    "        weights.append(np.ndarray.tolist(embed_lookup[cc]))\n",
    "    except KeyError:\n",
    "        weights.append(np.ndarray.tolist(np.random.rand(300,)))\n",
    "    k+=1     \n",
    "    \n",
    "weights = np.array(weights, dtype=np.float32)\n",
    "weights = torch.from_numpy(weights)\n",
    "\n",
    "weights = torch.FloatTensor(weights)\n",
    "print(len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12329,)\n",
      "(3175,)\n",
      "[[0, 18209, 94637, 459, 0, 15678, 0, 34894, 18209, 94637, 459, 4180, 0, 1601, 18209, 380403, 45, 165931, 35267, 728, 0], [0]]\n",
      "[list([[0, 0, 0, 0, 673299, 146306, 885, 61047, 12420, 231569, 275751, 54, 0, 66061, 18193, 39, 278130, 55632, 89, 231090, 218, 489, 921, 0], [173942, 56926, 0, 1222, 171853]])\n",
      " list([[0, 0, 482311, 266862, 68012, 501, 7403, 0, 0, 10659, 9675, 501, 418526, 0], [482311, 87673, 0, 281785, 393506, 0, 0, 55516, 0]])\n",
      " list([[0, 234773, 47, 0, 0, 89, 5180, 0, 102, 41643, 0, 42830, 0, 169308, 0, 0, 233023, 14256, 123254, 70, 26, 670, 1729, 5180, 8284, 0]])\n",
      " ...\n",
      " list([[1263, 486, 1912, 0], [0, 590, 0, 19075, 0, 0, 0, 0, 479563, 506, 1428, 24789, 0], [0]])\n",
      " list([[32943, 169385, 12535, 0], [0]])\n",
      " list([[32943, 9370, 76, 17021, 49262, 560340, 0, 0, 184006, 27202, 0, 43779, 0, 54, 0, 0, 2820, 296978, 318625, 0, 1677, 51643, 0], [98673, 6829, 8128, 20132, 387, 113579, 8390, 22328, 0]])]\n"
     ]
    }
   ],
   "source": [
    "from numpy  import array\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(X_train[6])\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_batch(mini_batch):\n",
    "    mini_batch_size = len(mini_batch)\n",
    "    max_sent_len = int(np.max([len(x) for x in mini_batch]))\n",
    "    max_token_len = int(np.max([len(val) for sublist in mini_batch for val in sublist]))\n",
    "\n",
    "    if(max_sent_len==1):\n",
    "        max_sent_len=2\n",
    "        \n",
    "    if(max_sent_len >= 100):\n",
    "        max_sent_len = 50\n",
    "    if(max_token_len >= 500):\n",
    "        max_token_len = 100\n",
    "        \n",
    "   # print(\"Max_token_len: \", max_token_len)\n",
    "   # print(\"Max_sent_len: \", max_sent_len)\n",
    "    main_matrix = np.zeros((mini_batch_size, max_sent_len, max_token_len), dtype= np.int)\n",
    "    for i in range(main_matrix.shape[0]):\n",
    "        for j in range(main_matrix.shape[1]):\n",
    "            for k in range(main_matrix.shape[2]):\n",
    "                try:\n",
    "                    main_matrix[i,j,k] = mini_batch[i][j][k]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "    return Variable(torch.from_numpy(main_matrix).transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_accuracy_mini_batch(tokens1, tokens2, labels,  sent_attn):\n",
    "    y_pred = get_predictions(tokens1, tokens2, sent_attn)\n",
    "    _, y_pred = torch.max(y_pred, 1)\n",
    "    \n",
    "    correct = np.ndarray.flatten(y_pred.data.cpu().numpy())\n",
    "    labels = np.ndarray.flatten(labels.data.cpu().numpy())\n",
    "\n",
    "    num_correct = sum(correct == labels)\n",
    "    return float(num_correct) / len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score,f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def test_accuracy_full_batch(tokens,  labels, mini_batch_size,  sent_attn):\n",
    "\n",
    "    sent_attn.eval()\n",
    "\n",
    "    p = []\n",
    "    p2 = []\n",
    "    l = []\n",
    "   \n",
    "    probs=[]\n",
    "    #print(\"SDfsfsdf \" ,len(tokens))\n",
    "    g = gen_minibatch2(tokens, labels, mini_batch_size)\n",
    "\n",
    "    for tokens1, tokens2, label in g:\n",
    "        embedding = nn.Embedding.from_pretrained(weights)\n",
    "        tokens1 = embedding(tokens1.long())\n",
    "        tokens2 = embedding(tokens2.long())\n",
    "        \n",
    "        y_pred3 = get_predictions(tokens1.cuda(),tokens2.cuda(),  sent_attn)\n",
    "        _, y_pred1 = torch.max(y_pred3, 1)\n",
    "        \n",
    "\n",
    "        p.append(np.ndarray.flatten(y_pred1.data.cpu().numpy()))\n",
    "        l.append(np.ndarray.flatten(label.data.cpu().numpy()))\n",
    "        \n",
    "\n",
    "\n",
    "    p = [item for sublist in p for item in sublist]\n",
    "    l = [item for sublist in l for item in sublist]\n",
    "\n",
    "    #print(p)\n",
    "  \n",
    "    p = np.array(p)\n",
    "    l = np.array(l)\n",
    "\n",
    "    recall=0\n",
    "    precision=0\n",
    "    ROC=0\n",
    "    \n",
    "\n",
    "    print(\"test 갯수 :\", len(p))\n",
    "    precision = precision_score(l, p, average='micro')\n",
    "    recall = recall_score(l, p, average='micro')\n",
    "\n",
    "    \n",
    "    F1score = f1_score(l,p,average='micro')\n",
    "\n",
    "\n",
    "    \n",
    "    #ROC  = roc_auc_score(l, p2)\n",
    "    print(\"F-1score : \", F1score)\n",
    "\n",
    "    print(\"AUC : \",ROC )\n",
    "    \n",
    "    num_correct = sum(p == l)\n",
    "    \n",
    "    \n",
    "    print(p)\n",
    "    print(\"############\")\n",
    "    print(l)\n",
    "    print(\"맞춘갯수 : \", num_correct)\n",
    "    return F1score, (float(num_correct))/ (len(p)), precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_data(mini_batch, source, targets, sent_attn):    \n",
    "    max_sents, batch_size, max_tokens, embed_size = mini_batch.size()\n",
    "       \n",
    "    y_pred = sent_attn(mini_batch,source, max_sents)\n",
    "    \n",
    "\n",
    "    loss = criterion(y_pred.squeeze().cuda(), targets) \n",
    " \n",
    "    \n",
    "    return loss.data.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=True):\n",
    "    assert inputs.shape[0] == targets.shape[0]\n",
    "    if shuffle:\n",
    "        indices = np.arange(inputs.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, inputs.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_minibatch(tokens, labels, mini_batch_size, shuffle= True):\n",
    "    for token, label in iterate_minibatches(tokens, labels, mini_batch_size, shuffle= shuffle):\n",
    "        token1 = pad_batch2(token)\n",
    "        yield token1, Variable(torch.from_numpy(label), requires_grad= False).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_minibatch2(tokens, labels, mini_batch_size, shuffle= True):\n",
    "    for token, label in iterate_minibatches(tokens, labels, mini_batch_size, shuffle= shuffle):\n",
    "        token1 = pad_batch(token)\n",
    "        token_x=[]\n",
    "        for i in token:\n",
    "            c = []\n",
    "            for j in i:\n",
    "                for k in j:\n",
    "                    c.append(k)\n",
    "            token_x.append(c)\n",
    "\n",
    "        token2 = pad_batch2(token_x)\n",
    "\n",
    "        yield token1, token2, Variable(torch.from_numpy(label), requires_grad= False).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_batch2(mini_batch):\n",
    "    mini_batch_size = len(mini_batch)\n",
    "    max_sent_len = int(np.max([len(mini_batch[x]) for x in range(0,len(mini_batch))]))\n",
    "    if(max_sent_len==1):\n",
    "        max_sent_len=2\n",
    "        \n",
    "    if(max_sent_len >=300):\n",
    "        max_sent_len = 100\n",
    "        \n",
    "    #print(\"max_sent_len:\", max_sent_len)\n",
    "    main_matrix = np.zeros((mini_batch_size, max_sent_len), dtype= np.int)\n",
    "    for i in range(main_matrix.shape[0]):\n",
    "         for k in range(main_matrix.shape[1]):\n",
    "            try:\n",
    "                main_matrix[i,k] = mini_batch[i][k]\n",
    "            except IndexError:\n",
    "                pass\n",
    "    return Variable(torch.from_numpy(main_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_batch(mini_batch):\n",
    "    mini_batch_size = len(mini_batch)\n",
    "    max_sent_len = int(np.max([len(x) for x in mini_batch]))\n",
    "    max_token_len = int(np.max([len(val) for sublist in mini_batch for val in sublist]))\n",
    "\n",
    "    if(max_sent_len==1):\n",
    "        max_sent_len=2\n",
    "        \n",
    "    #print(\"max_sent_len:\", max_sent_len)\n",
    "    #print(\"max_token_len#:\", max_token_len)\n",
    "    if(max_sent_len >= 50):\n",
    "        max_sent_len = 20\n",
    "    if(max_token_len >= 300):\n",
    "        max_token_len = 100\n",
    "        \n",
    "    main_matrix = np.zeros((mini_batch_size, max_sent_len, max_token_len), dtype= np.int)\n",
    "    for i in range(main_matrix.shape[0]):\n",
    "        for j in range(main_matrix.shape[1]):\n",
    "            for k in range(main_matrix.shape[2]):\n",
    "                try:\n",
    "                    main_matrix[i,j,k] = mini_batch[i][j][k]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "    return Variable(torch.from_numpy(main_matrix).transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def check_val_loss(val_tokens, val_labels, mini_batch_size, sent_attn):\n",
    "    val_loss = []\n",
    "    for token, label in iterate_minibatches(val_tokens, val_labels, mini_batch_size, shuffle= True):\n",
    "        token_x=[]  \n",
    "        for i in token:\n",
    "            c = []\n",
    "            for j in i:\n",
    "                for k in j:\n",
    "                    c.append(k)\n",
    "            token_x.append(c)\n",
    "            \n",
    "        \n",
    "        embedding = nn.Embedding.from_pretrained(weights)\n",
    "\n",
    "        tokens1 = embedding(pad_batch(token).long())\n",
    "        tokens2 = embedding(pad_batch2(token_x).long())\n",
    "        loss =test_data(tokens1.cuda(),tokens2.cuda(),  Variable(torch.from_numpy(label), requires_grad= False).cuda(), \n",
    "                                    sent_attn)\n",
    "        val_loss.append(loss)\n",
    "    return np.mean(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "879129\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_early_stopping(mini_batch_size, X_train, y_train,X_dev,y_dev,X_test, y_test,\n",
    "                          sent_attn,  sent_optimizer, loss_criterion, num_epoch ):\n",
    "    start = time.time()\n",
    "    loss_full = []\n",
    "    \n",
    "    \n",
    "    epoch_counter = 0\n",
    "    sent_attn.train()\n",
    "    \n",
    "\n",
    "    cur=0\n",
    "    for i in range(1, num_epoch + 1):\n",
    "        loss_epoch = []\n",
    "        g = gen_minibatch2(X_train, y_train, mini_batch_size)\n",
    "        for tokens1, tokens2, labels in g:\n",
    "            embedding = nn.Embedding.from_pretrained(weights)\n",
    "            tokens1 = embedding(tokens1.long())\n",
    "            tokens2 = embedding(tokens2.long())\n",
    "            torch.cuda.empty_cache()\n",
    "            #print(\"!!! :\", tokens1.shape)\n",
    "            loss = train_data(tokens1.cuda(),tokens2.cuda(), labels.cuda(), sent_attn, \n",
    "                              sent_optimizer, loss_criterion)\n",
    "            loss_full.append(loss.item())\n",
    "            loss_epoch.append(loss.item())\n",
    "\n",
    "        torch.cuda.empty_cache()      \n",
    "        print ('Average training loss at this epoch..minibatch ' ,  np.mean(loss_epoch))\n",
    "        vlos = check_val_loss(X_dev, y_dev, mini_batch_size, sent_attn)\n",
    "        print( 'Test Loss at ',i, ' is ',vlos)\n",
    "        cur2, acur,pre2, recall2 =test_accuracy_full_batch(X_test, y_test, 32,entireContext_model)\n",
    "        print(\"f1-score(test) : \", cur2 ,  \"accuracy :  \", acur, \"recall :\", recall2, \"precision :\", pre2)\n",
    "        sent_attn.train()\n",
    "        torch.cuda.empty_cache()\n",
    "        if(cur < cur2):\n",
    "            cur = cur2\n",
    "            print(\"saving...model\")\n",
    "            torch.save(sent_attn.state_dict(), 'abusive_detection.pt')\n",
    "            \n",
    "\n",
    "                \n",
    "            \n",
    "        print(\"************************************************************************************************************\")\n",
    "\n",
    "        print ('Loss at %d minibatches, %d epoch,(%s) is %f' %(i, epoch_counter, timeSince(start), np.mean(loss_epoch)))\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(\"************************************************************************************************************\")   \n",
    "            \n",
    "   \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12329,) (12329,)\n",
      "\n",
      "KFold**************\n",
      "train index: (10960,) validate index: (1369,)\n",
      "[    1     2     3 ... 12325 12327 12328]\n",
      "X_train1 index: (10960,) X_dev index: (1369,)\n",
      "############################################################\n",
      "[list([[0, 0, 85036, 0, 392469, 1803, 27917, 472, 104, 3947, 2365, 123, 2280, 5815, 104103, 0]])\n",
      " list([[120521, 116, 1977, 501, 122245, 116, 154867, 34894, 33420, 2523, 0, 2339, 37943, 0], [1301, 39471, 3004, 479222, 754247, 13816, 10136, 7781, 0, 9198, 81732, 0, 6432, 0, 0, 416069, 506, 0]])\n",
      " list([[8489, 200558, 26, 3606, 51105, 79, 6890, 0], [0, 48645, 110159, 6981, 58, 22684, 115, 32123, 0, 49068, 0], [442, 97556, 55534, 17261, 743, 562, 16280]])\n",
      " ... list([[0, 22466, 5918, 0, 0, 0], [2393, 456581, 2751, 0]])\n",
      " list([[68639, 63049, 49257, 0, 598, 22487, 8701, 363, 78, 26106, 0], [87, 510, 151683, 0, 85331, 166413]])\n",
      " list([[7094, 59429, 4404, 76, 112948, 0, 94364, 79922, 0, 102948, 745, 0, 100777, 43036, 7150, 0, 14575, 0], [11215, 17288, 18583, 0, 366001, 6069, 35199, 4718, 12640, 507550, 998, 960, 0, 0]])]\n",
      "1\n",
      "#######################\n",
      "[list([[40939, 0, 0, 13480, 4063, 0]])\n",
      " list([[0, 470642, 10393, 0, 14033, 1760, 742148, 47, 2292, 0], [144971, 12615, 3947, 35645, 29279, 2918, 165931, 0, 38, 13475, 489, 20]])\n",
      " list([[0, 278306, 25452, 876, 1052, 187, 0, 0, 5317, 0], [514983, 0, 0, 0], [0, 3017, 2800]])\n",
      " ...\n",
      " list([[7094, 567067, 0, 0, 10321, 2746, 5346, 703, 47661, 118418, 1984, 0, 0, 14006, 223216, 34565, 4017, 0, 6638, 247385, 147, 5113, 0], [935, 0, 21147, 0, 0], [87, 6432, 11646, 254822, 892, 0, 0, 908, 365, 5070, 182850, 506, 167996]])\n",
      " list([[7094, 0, 1095, 88490, 0, 2295, 0, 15710, 1720, 5982, 7074, 5143, 494107, 0, 0, 0], [915, 764, 160, 2762, 6590, 0, 2892, 9770, 0]])\n",
      " list([[7094, 180410, 17851, 0, 55104, 2746, 1284, 1688, 1354, 0, 1059, 2217, 415178, 754504, 1354, 178100, 273165, 54, 0], [915, 182945, 0, 1511, 0, 3585, 117872, 92816, 229, 0, 145803, 0]])]\n",
      "Average training loss at this epoch..minibatch  0.5052847710127631\n",
      "Test Loss at  1  is  0.48506832\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5274621212121212\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 0 0]\n",
      "맞춘갯수 :  1671\n",
      "f1-score(test) :  0.5274621212121212 accuracy :   0.5274621212121212 recall : 0.5274621212121212 precision : 0.5274621212121212\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 1 minibatches, 0 epoch,(0m 15s) is 0.505285\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.5036328197456896\n",
      "Test Loss at  2  is  0.48873362\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5280934343434344\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 1 1 0]\n",
      "맞춘갯수 :  1673\n",
      "f1-score(test) :  0.5280934343434344 accuracy :   0.5280934343434344 recall : 0.5280934343434344 precision : 0.5280934343434344\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 2 minibatches, 0 epoch,(0m 31s) is 0.503633\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.502691826938341\n",
      "Test Loss at  3  is  0.48675728\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5280934343434344\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  1673\n",
      "f1-score(test) :  0.5280934343434344 accuracy :   0.5280934343434344 recall : 0.5280934343434344 precision : 0.5280934343434344\n",
      "************************************************************************************************************\n",
      "Loss at 3 minibatches, 0 epoch,(0m 47s) is 0.502692\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.5018726335838437\n",
      "Test Loss at  4  is  0.48365924\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5271464646464646\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 1 1]\n",
      "맞춘갯수 :  1670\n",
      "f1-score(test) :  0.5271464646464646 accuracy :   0.5271464646464646 recall : 0.5271464646464646 precision : 0.5271464646464646\n",
      "************************************************************************************************************\n",
      "Loss at 4 minibatches, 0 epoch,(1m 3s) is 0.501873\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.50084547419101\n",
      "Test Loss at  5  is  0.47898087\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5277777777777778\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 0 1 0]\n",
      "맞춘갯수 :  1672\n",
      "f1-score(test) :  0.5277777777777778 accuracy :   0.5277777777777778 recall : 0.5277777777777778 precision : 0.5277777777777778\n",
      "************************************************************************************************************\n",
      "Loss at 5 minibatches, 0 epoch,(1m 19s) is 0.500845\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4960411073019107\n",
      "Test Loss at  6  is  0.47253758\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5271464646464646\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  1670\n",
      "f1-score(test) :  0.5271464646464646 accuracy :   0.5271464646464646 recall : 0.5271464646464646 precision : 0.5271464646464646\n",
      "************************************************************************************************************\n",
      "Loss at 6 minibatches, 0 epoch,(1m 35s) is 0.496041\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4930399839455883\n",
      "Test Loss at  7  is  0.47823644\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5277777777777778\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 0 1]\n",
      "맞춘갯수 :  1672\n",
      "f1-score(test) :  0.5277777777777778 accuracy :   0.5277777777777778 recall : 0.5277777777777778 precision : 0.5277777777777778\n",
      "************************************************************************************************************\n",
      "Loss at 7 minibatches, 0 epoch,(1m 51s) is 0.493040\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.48594427155330777\n",
      "Test Loss at  8  is  0.46027705\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5274621212121212\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 1 1 1]\n",
      "맞춘갯수 :  1671\n",
      "f1-score(test) :  0.5274621212121212 accuracy :   0.5274621212121212 recall : 0.5274621212121212 precision : 0.5274621212121212\n",
      "************************************************************************************************************\n",
      "Loss at 8 minibatches, 0 epoch,(2m 7s) is 0.485944\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.48010155372321606\n",
      "Test Loss at  9  is  0.4580618\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5280934343434344\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  1673\n",
      "f1-score(test) :  0.5280934343434344 accuracy :   0.5280934343434344 recall : 0.5280934343434344 precision : 0.5280934343434344\n",
      "************************************************************************************************************\n",
      "Loss at 9 minibatches, 0 epoch,(2m 23s) is 0.480102\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4712059084946911\n",
      "Test Loss at  10  is  0.45658016\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5303030303030303\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 1 0 1]\n",
      "맞춘갯수 :  1680\n",
      "f1-score(test) :  0.5303030303030303 accuracy :   0.5303030303030303 recall : 0.5303030303030303 precision : 0.5303030303030303\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 10 minibatches, 0 epoch,(2m 39s) is 0.471206\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4709771741181612\n",
      "Test Loss at  11  is  0.44493508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 갯수 : 3168\n",
      "F-1score :  0.5321969696969697\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[1 1 0 ... 1 0 0]\n",
      "맞춘갯수 :  1686\n",
      "f1-score(test) :  0.5321969696969697 accuracy :   0.5321969696969697 recall : 0.5321969696969697 precision : 0.5321969696969697\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 11 minibatches, 0 epoch,(2m 55s) is 0.470977\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.45941360962266725\n",
      "Test Loss at  12  is  0.44229576\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5517676767676768\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 0 0 1]\n",
      "맞춘갯수 :  1748\n",
      "f1-score(test) :  0.5517676767676768 accuracy :   0.5517676767676768 recall : 0.5517676767676768 precision : 0.5517676767676768\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 12 minibatches, 0 epoch,(3m 10s) is 0.459414\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.44886798900552094\n",
      "Test Loss at  13  is  0.43382287\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5445075757575758\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 0 1]\n",
      "맞춘갯수 :  1725\n",
      "f1-score(test) :  0.5445075757575758 accuracy :   0.5445075757575758 recall : 0.5445075757575758 precision : 0.5445075757575758\n",
      "************************************************************************************************************\n",
      "Loss at 13 minibatches, 0 epoch,(3m 26s) is 0.448868\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4404270445617537\n",
      "Test Loss at  14  is  0.41619805\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5760732323232324\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[0 0 0 ... 0 0 0]\n",
      "맞춘갯수 :  1825\n",
      "f1-score(test) :  0.5760732323232324 accuracy :   0.5760732323232324 recall : 0.5760732323232324 precision : 0.5760732323232324\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 14 minibatches, 0 epoch,(3m 42s) is 0.440427\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.43134620366618037\n",
      "Test Loss at  15  is  0.40974444\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.59375\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 1 0 0]\n",
      "맞춘갯수 :  1881\n",
      "f1-score(test) :  0.59375 accuracy :   0.59375 recall : 0.59375 precision : 0.59375\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 15 minibatches, 0 epoch,(3m 58s) is 0.431346\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.43104282720014453\n",
      "Test Loss at  16  is  0.4092606\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.610479797979798\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 1 0]\n",
      "맞춘갯수 :  1934\n",
      "f1-score(test) :  0.610479797979798 accuracy :   0.610479797979798 recall : 0.610479797979798 precision : 0.610479797979798\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 16 minibatches, 0 epoch,(4m 14s) is 0.431043\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4231826599376897\n",
      "Test Loss at  17  is  0.4196087\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6044823232323232\n",
      "AUC :  0\n",
      "[0 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 0 0]\n",
      "맞춘갯수 :  1915\n",
      "f1-score(test) :  0.6044823232323232 accuracy :   0.6044823232323232 recall : 0.6044823232323232 precision : 0.6044823232323232\n",
      "************************************************************************************************************\n",
      "Loss at 17 minibatches, 0 epoch,(4m 30s) is 0.423183\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.42541667609475553\n",
      "Test Loss at  18  is  0.3960034\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.59375\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 1 1 1]\n",
      "맞춘갯수 :  1881\n",
      "f1-score(test) :  0.59375 accuracy :   0.59375 recall : 0.59375 precision : 0.59375\n",
      "************************************************************************************************************\n",
      "Loss at 18 minibatches, 0 epoch,(4m 46s) is 0.425417\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4162395689636469\n",
      "Test Loss at  19  is  0.3972911\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6114267676767676\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 1 0]\n",
      "맞춘갯수 :  1937\n",
      "f1-score(test) :  0.6114267676767676 accuracy :   0.6114267676767676 recall : 0.6114267676767676 precision : 0.6114267676767676\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 19 minibatches, 0 epoch,(5m 2s) is 0.416240\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4153395192697644\n",
      "Test Loss at  20  is  0.39341104\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5991161616161617\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  1898\n",
      "f1-score(test) :  0.5991161616161617 accuracy :   0.5991161616161617 recall : 0.5991161616161617 precision : 0.5991161616161617\n",
      "************************************************************************************************************\n",
      "Loss at 20 minibatches, 0 epoch,(5m 18s) is 0.415340\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4187878156080842\n",
      "Test Loss at  21  is  0.40034458\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5956439393939394\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 0 0]\n",
      "맞춘갯수 :  1887\n",
      "f1-score(test) :  0.5956439393939394 accuracy :   0.5956439393939394 recall : 0.5956439393939394 precision : 0.5956439393939394\n",
      "************************************************************************************************************\n",
      "Loss at 21 minibatches, 0 epoch,(5m 34s) is 0.418788\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4114555837586522\n",
      "Test Loss at  22  is  0.40568042\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6306818181818182\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  1998\n",
      "f1-score(test) :  0.6306818181818182 accuracy :   0.6306818181818182 recall : 0.6306818181818182 precision : 0.6306818181818182\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 22 minibatches, 0 epoch,(5m 50s) is 0.411456\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4121964149332295\n",
      "Test Loss at  23  is  0.3927447\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5997474747474747\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 1 0]\n",
      "맞춘갯수 :  1900\n",
      "f1-score(test) :  0.5997474747474747 accuracy :   0.5997474747474747 recall : 0.5997474747474747 precision : 0.5997474747474747\n",
      "************************************************************************************************************\n",
      "Loss at 23 minibatches, 0 epoch,(6m 6s) is 0.412196\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.408620729111135\n",
      "Test Loss at  24  is  0.41390634\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6338383838383839\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 1 0]\n",
      "맞춘갯수 :  2008\n",
      "f1-score(test) :  0.6338383838383839 accuracy :   0.6338383838383839 recall : 0.6338383838383839 precision : 0.6338383838383839\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 24 minibatches, 0 epoch,(6m 22s) is 0.408621\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.4065987481735647\n",
      "Test Loss at  25  is  0.39875618\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6559343434343434\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 1 1]\n",
      "맞춘갯수 :  2078\n",
      "f1-score(test) :  0.6559343434343434 accuracy :   0.6559343434343434 recall : 0.6559343434343434 precision : 0.6559343434343434\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 25 minibatches, 0 epoch,(6m 38s) is 0.406599\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4026460895159592\n",
      "Test Loss at  26  is  0.37680435\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6171085858585859\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[1 0 1 ... 1 0 0]\n",
      "맞춘갯수 :  1955\n",
      "f1-score(test) :  0.6171085858585859 accuracy :   0.6171085858585859 recall : 0.6171085858585859 precision : 0.6171085858585859\n",
      "************************************************************************************************************\n",
      "Loss at 26 minibatches, 0 epoch,(6m 54s) is 0.402646\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.4035620209760964\n",
      "Test Loss at  27  is  0.3798947\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6107954545454546\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[0 0 1 ... 0 1 0]\n",
      "맞춘갯수 :  1935\n",
      "f1-score(test) :  0.6107954545454546 accuracy :   0.6107954545454546 recall : 0.6107954545454546 precision : 0.6107954545454546\n",
      "************************************************************************************************************\n",
      "Loss at 27 minibatches, 0 epoch,(7m 10s) is 0.403562\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.40343446626017493\n",
      "Test Loss at  28  is  0.38616335\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6676136363636364\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 1 1 1]\n",
      "맞춘갯수 :  2115\n",
      "f1-score(test) :  0.6676136363636364 accuracy :   0.6676136363636364 recall : 0.6676136363636364 precision : 0.6676136363636364\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 28 minibatches, 0 epoch,(7m 26s) is 0.403434\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.400603290181607\n",
      "Test Loss at  29  is  0.3806662\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6278409090909091\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 1 0 1]\n",
      "맞춘갯수 :  1989\n",
      "f1-score(test) :  0.6278409090909091 accuracy :   0.6278409090909091 recall : 0.6278409090909091 precision : 0.6278409090909091\n",
      "************************************************************************************************************\n",
      "Loss at 29 minibatches, 0 epoch,(7m 42s) is 0.400603\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.39584705846694607\n",
      "Test Loss at  30  is  0.36840588\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6313131313131313\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 0 1]\n",
      "맞춘갯수 :  2000\n",
      "f1-score(test) :  0.6313131313131313 accuracy :   0.6313131313131313 recall : 0.6313131313131313 precision : 0.6313131313131313\n",
      "************************************************************************************************************\n",
      "Loss at 30 minibatches, 0 epoch,(7m 58s) is 0.395847\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.395438554075857\n",
      "Test Loss at  31  is  0.37519774\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6139520202020202\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 0 1 ... 0 0 0]\n",
      "맞춘갯수 :  1945\n",
      "f1-score(test) :  0.6139520202020202 accuracy :   0.6139520202020202 recall : 0.6139520202020202 precision : 0.6139520202020202\n",
      "************************************************************************************************************\n",
      "Loss at 31 minibatches, 0 epoch,(8m 13s) is 0.395439\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.39475226115124923\n",
      "Test Loss at  32  is  0.3834931\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6306818181818182\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 1 1]\n",
      "맞춘갯수 :  1998\n",
      "f1-score(test) :  0.6306818181818182 accuracy :   0.6306818181818182 recall : 0.6306818181818182 precision : 0.6306818181818182\n",
      "************************************************************************************************************\n",
      "Loss at 32 minibatches, 0 epoch,(8m 29s) is 0.394752\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3945860507277151\n",
      "Test Loss at  33  is  0.36695617\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6095328282828283\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 1 1 0]\n",
      "맞춘갯수 :  1931\n",
      "f1-score(test) :  0.6095328282828283 accuracy :   0.6095328282828283 recall : 0.6095328282828283 precision : 0.6095328282828283\n",
      "************************************************************************************************************\n",
      "Loss at 33 minibatches, 0 epoch,(8m 45s) is 0.394586\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3947507097230603\n",
      "Test Loss at  34  is  0.37236506\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6139520202020202\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  1945\n",
      "f1-score(test) :  0.6139520202020202 accuracy :   0.6139520202020202 recall : 0.6139520202020202 precision : 0.6139520202020202\n",
      "************************************************************************************************************\n",
      "Loss at 34 minibatches, 0 epoch,(9m 1s) is 0.394751\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3900160831399262\n",
      "Test Loss at  35  is  0.37386304\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6272095959595959\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  1987\n",
      "f1-score(test) :  0.6272095959595959 accuracy :   0.6272095959595959 recall : 0.6272095959595959 precision : 0.6272095959595959\n",
      "************************************************************************************************************\n",
      "Loss at 35 minibatches, 0 epoch,(9m 17s) is 0.390016\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3879177577327937\n",
      "Test Loss at  36  is  0.37119746\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6272095959595959\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 0 0 ... 0 1 0]\n",
      "맞춘갯수 :  1987\n",
      "f1-score(test) :  0.6272095959595959 accuracy :   0.6272095959595959 recall : 0.6272095959595959 precision : 0.6272095959595959\n",
      "************************************************************************************************************\n",
      "Loss at 36 minibatches, 0 epoch,(9m 33s) is 0.387918\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3896902185709526\n",
      "Test Loss at  37  is  0.36503786\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6332070707070707\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 0 0]\n",
      "맞춘갯수 :  2006\n",
      "f1-score(test) :  0.6332070707070707 accuracy :   0.6332070707070707 recall : 0.6332070707070707 precision : 0.6332070707070707\n",
      "************************************************************************************************************\n",
      "Loss at 37 minibatches, 0 epoch,(9m 49s) is 0.389690\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3861000776135673\n",
      "Test Loss at  38  is  0.36646968\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6294191919191919\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 1 0 1]\n",
      "맞춘갯수 :  1994\n",
      "f1-score(test) :  0.6294191919191919 accuracy :   0.6294191919191919 recall : 0.6294191919191919 precision : 0.6294191919191919\n",
      "************************************************************************************************************\n",
      "Loss at 38 minibatches, 0 epoch,(10m 5s) is 0.386100\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.3846305439559122\n",
      "Test Loss at  39  is  0.3649147\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6174242424242424\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 1 0 1]\n",
      "맞춘갯수 :  1956\n",
      "f1-score(test) :  0.6174242424242424 accuracy :   0.6174242424242424 recall : 0.6174242424242424 precision : 0.6174242424242424\n",
      "************************************************************************************************************\n",
      "Loss at 39 minibatches, 0 epoch,(10m 20s) is 0.384631\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3884258839922647\n",
      "Test Loss at  40  is  0.36530262\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.646780303030303\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 1 0]\n",
      "맞춘갯수 :  2049\n",
      "f1-score(test) :  0.646780303030303 accuracy :   0.646780303030303 recall : 0.646780303030303 precision : 0.646780303030303\n",
      "************************************************************************************************************\n",
      "Loss at 40 minibatches, 0 epoch,(10m 36s) is 0.388426\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3856846737520148\n",
      "Test Loss at  41  is  0.373238\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6537247474747475\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  2071\n",
      "f1-score(test) :  0.6537247474747475 accuracy :   0.6537247474747475 recall : 0.6537247474747475 precision : 0.6537247474747475\n",
      "************************************************************************************************************\n",
      "Loss at 41 minibatches, 0 epoch,(10m 52s) is 0.385685\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.383675490738824\n",
      "Test Loss at  42  is  0.3606217\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.625\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  1980\n",
      "f1-score(test) :  0.625 accuracy :   0.625 recall : 0.625 precision : 0.625\n",
      "************************************************************************************************************\n",
      "Loss at 42 minibatches, 0 epoch,(11m 8s) is 0.383675\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.37664577132090926\n",
      "Test Loss at  43  is  0.38082913\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6654040404040404\n",
      "AUC :  0\n",
      "[0 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 0 1]\n",
      "맞춘갯수 :  2108\n",
      "f1-score(test) :  0.6654040404040404 accuracy :   0.6654040404040404 recall : 0.6654040404040404 precision : 0.6654040404040404\n",
      "************************************************************************************************************\n",
      "Loss at 43 minibatches, 0 epoch,(11m 24s) is 0.376646\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.38218738495682675\n",
      "Test Loss at  44  is  0.3602752\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6281565656565656\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 1 1]\n",
      "맞춘갯수 :  1990\n",
      "f1-score(test) :  0.6281565656565656 accuracy :   0.6281565656565656 recall : 0.6281565656565656 precision : 0.6281565656565656\n",
      "************************************************************************************************************\n",
      "Loss at 44 minibatches, 0 epoch,(11m 40s) is 0.382187\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.38293356425128877\n",
      "Test Loss at  45  is  0.36691707\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.608270202020202\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  1927\n",
      "f1-score(test) :  0.608270202020202 accuracy :   0.608270202020202 recall : 0.608270202020202 precision : 0.608270202020202\n",
      "************************************************************************************************************\n",
      "Loss at 45 minibatches, 0 epoch,(11m 56s) is 0.382934\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.37907091970555484\n",
      "Test Loss at  46  is  0.36760753\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6363636363636364\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  2016\n",
      "f1-score(test) :  0.6363636363636364 accuracy :   0.6363636363636364 recall : 0.6363636363636364 precision : 0.6363636363636364\n",
      "************************************************************************************************************\n",
      "Loss at 46 minibatches, 0 epoch,(12m 12s) is 0.379071\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3772660836111754\n",
      "Test Loss at  47  is  0.35814622\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.646780303030303\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 1 1]\n",
      "맞춘갯수 :  2049\n",
      "f1-score(test) :  0.646780303030303 accuracy :   0.646780303030303 recall : 0.646780303030303 precision : 0.646780303030303\n",
      "************************************************************************************************************\n",
      "Loss at 47 minibatches, 0 epoch,(12m 28s) is 0.377266\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3767113791157802\n",
      "Test Loss at  48  is  0.3500897\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6357323232323232\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  2014\n",
      "f1-score(test) :  0.6357323232323232 accuracy :   0.6357323232323232 recall : 0.6357323232323232 precision : 0.6357323232323232\n",
      "************************************************************************************************************\n",
      "Loss at 48 minibatches, 0 epoch,(12m 43s) is 0.376711\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3750478866665314\n",
      "Test Loss at  49  is  0.3504042\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6193181818181818\n",
      "AUC :  0\n",
      "[0 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 0 1 0]\n",
      "맞춘갯수 :  1962\n",
      "f1-score(test) :  0.6193181818181818 accuracy :   0.6193181818181818 recall : 0.6193181818181818 precision : 0.6193181818181818\n",
      "************************************************************************************************************\n",
      "Loss at 49 minibatches, 0 epoch,(12m 59s) is 0.375048\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3762092371471226\n",
      "Test Loss at  50  is  0.35622048\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6262626262626263\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 1 0]\n",
      "맞춘갯수 :  1984\n",
      "f1-score(test) :  0.6262626262626263 accuracy :   0.6262626262626263 recall : 0.6262626262626263 precision : 0.6262626262626263\n",
      "************************************************************************************************************\n",
      "Loss at 50 minibatches, 0 epoch,(13m 15s) is 0.376209\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3719034766157468\n",
      "Test Loss at  51  is  0.37742782\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6499368686868687\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 0]\n",
      "############\n",
      "[0 1 1 ... 1 1 1]\n",
      "맞춘갯수 :  2059\n",
      "f1-score(test) :  0.6499368686868687 accuracy :   0.6499368686868687 recall : 0.6499368686868687 precision : 0.6499368686868687\n",
      "************************************************************************************************************\n",
      "Loss at 51 minibatches, 0 epoch,(13m 31s) is 0.371903\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3831131882810344\n",
      "Test Loss at  52  is  0.35736927\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6120580808080808\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 0 1 0]\n",
      "맞춘갯수 :  1939\n",
      "f1-score(test) :  0.6120580808080808 accuracy :   0.6120580808080808 recall : 0.6120580808080808 precision : 0.6120580808080808\n",
      "************************************************************************************************************\n",
      "Loss at 52 minibatches, 0 epoch,(13m 47s) is 0.383113\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.3712630020454526\n",
      "Test Loss at  53  is  0.3604524\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6584595959595959\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 0 0]\n",
      "맞춘갯수 :  2086\n",
      "f1-score(test) :  0.6584595959595959 accuracy :   0.6584595959595959 recall : 0.6584595959595959 precision : 0.6584595959595959\n",
      "************************************************************************************************************\n",
      "Loss at 53 minibatches, 0 epoch,(14m 3s) is 0.371263\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3699516305544724\n",
      "Test Loss at  54  is  0.3607084\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.5946969696969697\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 0 0]\n",
      "맞춘갯수 :  1884\n",
      "f1-score(test) :  0.5946969696969697 accuracy :   0.5946969696969697 recall : 0.5946969696969697 precision : 0.5946969696969697\n",
      "************************************************************************************************************\n",
      "Loss at 54 minibatches, 0 epoch,(14m 19s) is 0.369952\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3707605487822245\n",
      "Test Loss at  55  is  0.3472283\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6429924242424242\n",
      "AUC :  0\n",
      "[1 1 0 ... 0 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2037\n",
      "f1-score(test) :  0.6429924242424242 accuracy :   0.6429924242424242 recall : 0.6429924242424242 precision : 0.6429924242424242\n",
      "************************************************************************************************************\n",
      "Loss at 55 minibatches, 0 epoch,(14m 35s) is 0.370761\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.36818564070078236\n",
      "Test Loss at  56  is  0.3471087\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6101641414141414\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 0 0 1]\n",
      "맞춘갯수 :  1933\n",
      "f1-score(test) :  0.6101641414141414 accuracy :   0.6101641414141414 recall : 0.6101641414141414 precision : 0.6101641414141414\n",
      "************************************************************************************************************\n",
      "Loss at 56 minibatches, 0 epoch,(14m 51s) is 0.368186\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.36745511220457655\n",
      "Test Loss at  57  is  0.36386004\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6246843434343434\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 0 0 1]\n",
      "맞춘갯수 :  1979\n",
      "f1-score(test) :  0.6246843434343434 accuracy :   0.6246843434343434 recall : 0.6246843434343434 precision : 0.6246843434343434\n",
      "************************************************************************************************************\n",
      "Loss at 57 minibatches, 0 epoch,(15m 6s) is 0.367455\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.36449190477530163\n",
      "Test Loss at  58  is  0.33752677\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6641414141414141\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 1 1]\n",
      "맞춘갯수 :  2104\n",
      "f1-score(test) :  0.6641414141414141 accuracy :   0.6641414141414141 recall : 0.6641414141414141 precision : 0.6641414141414141\n",
      "************************************************************************************************************\n",
      "Loss at 58 minibatches, 0 epoch,(15m 22s) is 0.364492\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.36398889605576795\n",
      "Test Loss at  59  is  0.36828426\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6022727272727273\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 0 0]\n",
      "맞춘갯수 :  1908\n",
      "f1-score(test) :  0.6022727272727273 accuracy :   0.6022727272727273 recall : 0.6022727272727273 precision : 0.6022727272727273\n",
      "************************************************************************************************************\n",
      "Loss at 59 minibatches, 0 epoch,(15m 38s) is 0.363989\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3676556235489746\n",
      "Test Loss at  60  is  0.35914168\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6619318181818182\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 1 1]\n",
      "맞춘갯수 :  2097\n",
      "f1-score(test) :  0.6619318181818182 accuracy :   0.6619318181818182 recall : 0.6619318181818182 precision : 0.6619318181818182\n",
      "************************************************************************************************************\n",
      "Loss at 60 minibatches, 0 epoch,(15m 54s) is 0.367656\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.36457567918114364\n",
      "Test Loss at  61  is  0.35190576\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6578282828282829\n",
      "AUC :  0\n",
      "[1 0 1 ... 0 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 0 1]\n",
      "맞춘갯수 :  2084\n",
      "f1-score(test) :  0.6578282828282829 accuracy :   0.6578282828282829 recall : 0.6578282828282829 precision : 0.6578282828282829\n",
      "************************************************************************************************************\n",
      "Loss at 61 minibatches, 0 epoch,(16m 10s) is 0.364576\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.35989624564535916\n",
      "Test Loss at  62  is  0.3580033\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6486742424242424\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2055\n",
      "f1-score(test) :  0.6486742424242424 accuracy :   0.6486742424242424 recall : 0.6486742424242424 precision : 0.6486742424242424\n",
      "************************************************************************************************************\n",
      "Loss at 62 minibatches, 0 epoch,(16m 26s) is 0.359896\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.35946893428141874\n",
      "Test Loss at  63  is  0.34897977\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7029671717171717\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  2227\n",
      "f1-score(test) :  0.7029671717171717 accuracy :   0.7029671717171717 recall : 0.7029671717171717 precision : 0.7029671717171717\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 63 minibatches, 0 epoch,(16m 42s) is 0.359469\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.35827205850121874\n",
      "Test Loss at  64  is  0.3546863\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7099116161616161\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 1]\n",
      "맞춘갯수 :  2249\n",
      "f1-score(test) :  0.7099116161616161 accuracy :   0.7099116161616161 recall : 0.7099116161616161 precision : 0.7099116161616161\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 64 minibatches, 0 epoch,(16m 58s) is 0.358272\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.35913581781399745\n",
      "Test Loss at  65  is  0.34798875\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6486742424242424\n",
      "AUC :  0\n",
      "[0 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 0 0 ... 0 1 1]\n",
      "맞춘갯수 :  2055\n",
      "f1-score(test) :  0.6486742424242424 accuracy :   0.6486742424242424 recall : 0.6486742424242424 precision : 0.6486742424242424\n",
      "************************************************************************************************************\n",
      "Loss at 65 minibatches, 0 epoch,(17m 14s) is 0.359136\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3589940161909908\n",
      "Test Loss at  66  is  0.3421646\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6606691919191919\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[1 1 1 ... 0 1 0]\n",
      "맞춘갯수 :  2093\n",
      "f1-score(test) :  0.6606691919191919 accuracy :   0.6606691919191919 recall : 0.6606691919191919 precision : 0.6606691919191919\n",
      "************************************************************************************************************\n",
      "Loss at 66 minibatches, 0 epoch,(17m 30s) is 0.358994\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.3556734094551454\n",
      "Test Loss at  67  is  0.329116\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6499368686868687\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 1 1]\n",
      "맞춘갯수 :  2059\n",
      "f1-score(test) :  0.6499368686868687 accuracy :   0.6499368686868687 recall : 0.6499368686868687 precision : 0.6499368686868687\n",
      "************************************************************************************************************\n",
      "Loss at 67 minibatches, 0 epoch,(17m 46s) is 0.355673\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3544229712182035\n",
      "Test Loss at  68  is  0.3523073\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6682449494949495\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 1 1]\n",
      "맞춘갯수 :  2117\n",
      "f1-score(test) :  0.6682449494949495 accuracy :   0.6682449494949495 recall : 0.6682449494949495 precision : 0.6682449494949495\n",
      "************************************************************************************************************\n",
      "Loss at 68 minibatches, 0 epoch,(18m 2s) is 0.354423\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3571415876504034\n",
      "Test Loss at  69  is  0.35201284\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6796085858585859\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 0]\n",
      "############\n",
      "[1 0 1 ... 1 1 1]\n",
      "맞춘갯수 :  2153\n",
      "f1-score(test) :  0.6796085858585859 accuracy :   0.6796085858585859 recall : 0.6796085858585859 precision : 0.6796085858585859\n",
      "************************************************************************************************************\n",
      "Loss at 69 minibatches, 0 epoch,(18m 18s) is 0.357142\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3505013034834216\n",
      "Test Loss at  70  is  0.33597466\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6852904040404041\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 1 0]\n",
      "맞춘갯수 :  2171\n",
      "f1-score(test) :  0.6852904040404041 accuracy :   0.6852904040404041 recall : 0.6852904040404041 precision : 0.6852904040404041\n",
      "************************************************************************************************************\n",
      "Loss at 70 minibatches, 0 epoch,(18m 34s) is 0.350501\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3501769045833498\n",
      "Test Loss at  71  is  0.33127186\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6429924242424242\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[0 1 0 ... 1 0 1]\n",
      "맞춘갯수 :  2037\n",
      "f1-score(test) :  0.6429924242424242 accuracy :   0.6429924242424242 recall : 0.6429924242424242 precision : 0.6429924242424242\n",
      "************************************************************************************************************\n",
      "Loss at 71 minibatches, 0 epoch,(18m 50s) is 0.350177\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3457294298956792\n",
      "Test Loss at  72  is  0.3273305\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6862373737373737\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 0]\n",
      "############\n",
      "[1 0 1 ... 1 0 0]\n",
      "맞춘갯수 :  2174\n",
      "f1-score(test) :  0.6862373737373737 accuracy :   0.6862373737373737 recall : 0.6862373737373737 precision : 0.6862373737373737\n",
      "************************************************************************************************************\n",
      "Loss at 72 minibatches, 0 epoch,(19m 6s) is 0.345729\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3461071220226586\n",
      "Test Loss at  73  is  0.33602256\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6865530303030303\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 1 1 1]\n",
      "맞춘갯수 :  2175\n",
      "f1-score(test) :  0.6865530303030303 accuracy :   0.6865530303030303 recall : 0.6865530303030303 precision : 0.6865530303030303\n",
      "************************************************************************************************************\n",
      "Loss at 73 minibatches, 0 epoch,(19m 22s) is 0.346107\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.34749696784031886\n",
      "Test Loss at  74  is  0.33291182\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6385732323232324\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 1 0]\n",
      "맞춘갯수 :  2023\n",
      "f1-score(test) :  0.6385732323232324 accuracy :   0.6385732323232324 recall : 0.6385732323232324 precision : 0.6385732323232324\n",
      "************************************************************************************************************\n",
      "Loss at 74 minibatches, 0 epoch,(19m 38s) is 0.347497\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.34300195099785924\n",
      "Test Loss at  75  is  0.32913423\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6818181818181818\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 0]\n",
      "맞춘갯수 :  2160\n",
      "f1-score(test) :  0.6818181818181818 accuracy :   0.6818181818181818 recall : 0.6818181818181818 precision : 0.6818181818181818\n",
      "************************************************************************************************************\n",
      "Loss at 75 minibatches, 0 epoch,(19m 54s) is 0.343002\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3466268108847241\n",
      "Test Loss at  76  is  0.33253825\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6906565656565656\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 0]\n",
      "맞춘갯수 :  2188\n",
      "f1-score(test) :  0.6906565656565656 accuracy :   0.6906565656565656 recall : 0.6906565656565656 precision : 0.6906565656565656\n",
      "************************************************************************************************************\n",
      "Loss at 76 minibatches, 0 epoch,(20m 10s) is 0.346627\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.34605037785756093\n",
      "Test Loss at  77  is  0.3309786\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6695075757575758\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 0]\n",
      "############\n",
      "[0 1 1 ... 1 0 0]\n",
      "맞춘갯수 :  2121\n",
      "f1-score(test) :  0.6695075757575758 accuracy :   0.6695075757575758 recall : 0.6695075757575758 precision : 0.6695075757575758\n",
      "************************************************************************************************************\n",
      "Loss at 77 minibatches, 0 epoch,(20m 26s) is 0.346050\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.343577300120766\n",
      "Test Loss at  78  is  0.3194325\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6786616161616161\n",
      "AUC :  0\n",
      "[0 0 1 ... 1 0 1]\n",
      "############\n",
      "[0 1 1 ... 0 0 1]\n",
      "맞춘갯수 :  2150\n",
      "f1-score(test) :  0.6786616161616161 accuracy :   0.6786616161616161 recall : 0.6786616161616161 precision : 0.6786616161616161\n",
      "************************************************************************************************************\n",
      "Loss at 78 minibatches, 0 epoch,(20m 42s) is 0.343577\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3386729479922603\n",
      "Test Loss at  79  is  0.32832724\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.67739898989899\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 1 1 1]\n",
      "맞춘갯수 :  2146\n",
      "f1-score(test) :  0.67739898989899 accuracy :   0.67739898989899 recall : 0.67739898989899 precision : 0.67739898989899\n",
      "************************************************************************************************************\n",
      "Loss at 79 minibatches, 0 epoch,(20m 58s) is 0.338673\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3440480060720195\n",
      "Test Loss at  80  is  0.3199869\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6685606060606061\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 1 1]\n",
      "맞춘갯수 :  2118\n",
      "f1-score(test) :  0.6685606060606061 accuracy :   0.6685606060606061 recall : 0.6685606060606061 precision : 0.6685606060606061\n",
      "************************************************************************************************************\n",
      "Loss at 80 minibatches, 0 epoch,(21m 14s) is 0.344048\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.3367417532329758\n",
      "Test Loss at  81  is  0.33168435\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6366792929292929\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 1 1 1]\n",
      "맞춘갯수 :  2017\n",
      "f1-score(test) :  0.6366792929292929 accuracy :   0.6366792929292929 recall : 0.6366792929292929 precision : 0.6366792929292929\n",
      "************************************************************************************************************\n",
      "Loss at 81 minibatches, 0 epoch,(21m 30s) is 0.336742\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.33647584659047425\n",
      "Test Loss at  82  is  0.3196302\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6448863636363636\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 1 0 1]\n",
      "맞춘갯수 :  2043\n",
      "f1-score(test) :  0.6448863636363636 accuracy :   0.6448863636363636 recall : 0.6448863636363636 precision : 0.6448863636363636\n",
      "************************************************************************************************************\n",
      "Loss at 82 minibatches, 0 epoch,(21m 46s) is 0.336476\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3336498065230747\n",
      "Test Loss at  83  is  0.3247289\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6521464646464646\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 1 0 1]\n",
      "맞춘갯수 :  2066\n",
      "f1-score(test) :  0.6521464646464646 accuracy :   0.6521464646464646 recall : 0.6521464646464646 precision : 0.6521464646464646\n",
      "************************************************************************************************************\n",
      "Loss at 83 minibatches, 0 epoch,(22m 2s) is 0.333650\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.33088102921222645\n",
      "Test Loss at  84  is  0.32247815\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6786616161616161\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 1 1]\n",
      "맞춘갯수 :  2150\n",
      "f1-score(test) :  0.6786616161616161 accuracy :   0.6786616161616161 recall : 0.6786616161616161 precision : 0.6786616161616161\n",
      "************************************************************************************************************\n",
      "Loss at 84 minibatches, 0 epoch,(22m 18s) is 0.330881\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3354270972777158\n",
      "Test Loss at  85  is  0.3151291\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6448863636363636\n",
      "AUC :  0\n",
      "[0 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 1 1]\n",
      "맞춘갯수 :  2043\n",
      "f1-score(test) :  0.6448863636363636 accuracy :   0.6448863636363636 recall : 0.6448863636363636 precision : 0.6448863636363636\n",
      "************************************************************************************************************\n",
      "Loss at 85 minibatches, 0 epoch,(22m 33s) is 0.335427\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.33464454890539247\n",
      "Test Loss at  86  is  0.3311441\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6404671717171717\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 0]\n",
      "맞춘갯수 :  2029\n",
      "f1-score(test) :  0.6404671717171717 accuracy :   0.6404671717171717 recall : 0.6404671717171717 precision : 0.6404671717171717\n",
      "************************************************************************************************************\n",
      "Loss at 86 minibatches, 0 epoch,(22m 49s) is 0.334645\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3322229801366727\n",
      "Test Loss at  87  is  0.32000777\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6960227272727273\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 1 1]\n",
      "맞춘갯수 :  2205\n",
      "f1-score(test) :  0.6960227272727273 accuracy :   0.6960227272727273 recall : 0.6960227272727273 precision : 0.6960227272727273\n",
      "************************************************************************************************************\n",
      "Loss at 87 minibatches, 0 epoch,(23m 5s) is 0.332223\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.32964149412388605\n",
      "Test Loss at  88  is  0.31711075\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.702020202020202\n",
      "AUC :  0\n",
      "[1 0 0 ... 0 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 0 1]\n",
      "맞춘갯수 :  2224\n",
      "f1-score(test) :  0.702020202020202 accuracy :   0.702020202020202 recall : 0.702020202020202 precision : 0.702020202020202\n",
      "************************************************************************************************************\n",
      "Loss at 88 minibatches, 0 epoch,(23m 21s) is 0.329641\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3276192265717934\n",
      "Test Loss at  89  is  0.3047336\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6912878787878788\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 1 1 0]\n",
      "맞춘갯수 :  2190\n",
      "f1-score(test) :  0.6912878787878788 accuracy :   0.6912878787878788 recall : 0.6912878787878788 precision : 0.6912878787878788\n",
      "************************************************************************************************************\n",
      "Loss at 89 minibatches, 0 epoch,(23m 37s) is 0.327619\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.324011622229591\n",
      "Test Loss at  90  is  0.3254927\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6922348484848485\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 1]\n",
      "맞춘갯수 :  2193\n",
      "f1-score(test) :  0.6922348484848485 accuracy :   0.6922348484848485 recall : 0.6922348484848485 precision : 0.6922348484848485\n",
      "************************************************************************************************************\n",
      "Loss at 90 minibatches, 0 epoch,(23m 53s) is 0.324012\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.32641856170569855\n",
      "Test Loss at  91  is  0.30920377\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6988636363636364\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  2214\n",
      "f1-score(test) :  0.6988636363636364 accuracy :   0.6988636363636364 recall : 0.6988636363636364 precision : 0.6988636363636364\n",
      "************************************************************************************************************\n",
      "Loss at 91 minibatches, 0 epoch,(24m 9s) is 0.326419\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.32061575446277857\n",
      "Test Loss at  92  is  0.32310247\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.715909090909091\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 1 0]\n",
      "맞춘갯수 :  2268\n",
      "f1-score(test) :  0.715909090909091 accuracy :   0.7159090909090909 recall : 0.7159090909090909 precision : 0.7159090909090909\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 92 minibatches, 0 epoch,(24m 25s) is 0.320616\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3206739977467805\n",
      "Test Loss at  93  is  0.30923766\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7193813131313131\n",
      "AUC :  0\n",
      "[0 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 1 0]\n",
      "맞춘갯수 :  2279\n",
      "f1-score(test) :  0.7193813131313131 accuracy :   0.7193813131313131 recall : 0.7193813131313131 precision : 0.7193813131313131\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 93 minibatches, 0 epoch,(24m 41s) is 0.320674\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3126940919707219\n",
      "Test Loss at  94  is  0.29377303\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7001262626262627\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  2218\n",
      "f1-score(test) :  0.7001262626262627 accuracy :   0.7001262626262627 recall : 0.7001262626262627 precision : 0.7001262626262627\n",
      "************************************************************************************************************\n",
      "Loss at 94 minibatches, 0 epoch,(24m 57s) is 0.312694\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.3181639045942575\n",
      "Test Loss at  95  is  0.3139461\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7222222222222222\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 0 1]\n",
      "############\n",
      "[1 1 0 ... 0 0 1]\n",
      "맞춘갯수 :  2288\n",
      "f1-score(test) :  0.7222222222222222 accuracy :   0.7222222222222222 recall : 0.7222222222222222 precision : 0.7222222222222222\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 95 minibatches, 0 epoch,(25m 12s) is 0.318164\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.31701331950413686\n",
      "Test Loss at  96  is  0.30241427\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6442550505050505\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 1 1 1]\n",
      "맞춘갯수 :  2041\n",
      "f1-score(test) :  0.6442550505050505 accuracy :   0.6442550505050505 recall : 0.6442550505050505 precision : 0.6442550505050505\n",
      "************************************************************************************************************\n",
      "Loss at 96 minibatches, 0 epoch,(25m 28s) is 0.317013\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.32066486480956274\n",
      "Test Loss at  97  is  0.29369187\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6811868686868687\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 1 1]\n",
      "맞춘갯수 :  2158\n",
      "f1-score(test) :  0.6811868686868687 accuracy :   0.6811868686868687 recall : 0.6811868686868687 precision : 0.6811868686868687\n",
      "************************************************************************************************************\n",
      "Loss at 97 minibatches, 0 epoch,(25m 44s) is 0.320665\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.31460635100180906\n",
      "Test Loss at  98  is  0.28923392\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7095959595959596\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 0]\n",
      "############\n",
      "[0 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  2248\n",
      "f1-score(test) :  0.7095959595959596 accuracy :   0.7095959595959596 recall : 0.7095959595959596 precision : 0.7095959595959596\n",
      "************************************************************************************************************\n",
      "Loss at 98 minibatches, 0 epoch,(26m 0s) is 0.314606\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3156149694696069\n",
      "Test Loss at  99  is  0.28915003\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6606691919191919\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 0 1 0]\n",
      "맞춘갯수 :  2093\n",
      "f1-score(test) :  0.6606691919191919 accuracy :   0.6606691919191919 recall : 0.6606691919191919 precision : 0.6606691919191919\n",
      "************************************************************************************************************\n",
      "Loss at 99 minibatches, 0 epoch,(26m 16s) is 0.315615\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.31209086867359775\n",
      "Test Loss at  100  is  0.28939664\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6833964646464646\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 1 1 0]\n",
      "맞춘갯수 :  2165\n",
      "f1-score(test) :  0.6833964646464646 accuracy :   0.6833964646464646 recall : 0.6833964646464646 precision : 0.6833964646464646\n",
      "************************************************************************************************************\n",
      "Loss at 100 minibatches, 0 epoch,(26m 32s) is 0.312091\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.30794110319887597\n",
      "Test Loss at  101  is  0.29481283\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7171717171717171\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2272\n",
      "f1-score(test) :  0.7171717171717171 accuracy :   0.7171717171717171 recall : 0.7171717171717171 precision : 0.7171717171717171\n",
      "************************************************************************************************************\n",
      "Loss at 101 minibatches, 0 epoch,(26m 48s) is 0.307941\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3126818034021805\n",
      "Test Loss at  102  is  0.28786168\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6679292929292929\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 0 1]\n",
      "맞춘갯수 :  2116\n",
      "f1-score(test) :  0.6679292929292929 accuracy :   0.6679292929292929 recall : 0.6679292929292929 precision : 0.6679292929292929\n",
      "************************************************************************************************************\n",
      "Loss at 102 minibatches, 0 epoch,(27m 4s) is 0.312682\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.30532232524516684\n",
      "Test Loss at  103  is  0.2931235\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6849747474747475\n",
      "AUC :  0\n",
      "[1 0 1 ... 0 1 1]\n",
      "############\n",
      "[0 0 0 ... 0 0 1]\n",
      "맞춘갯수 :  2170\n",
      "f1-score(test) :  0.6849747474747475 accuracy :   0.6849747474747475 recall : 0.6849747474747475 precision : 0.6849747474747475\n",
      "************************************************************************************************************\n",
      "Loss at 103 minibatches, 0 epoch,(27m 20s) is 0.305322\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.30663390705982846\n",
      "Test Loss at  104  is  0.2836815\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7326388888888888\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 1 0 1]\n",
      "맞춘갯수 :  2321\n",
      "f1-score(test) :  0.7326388888888888 accuracy :   0.7326388888888888 recall : 0.7326388888888888 precision : 0.7326388888888888\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 104 minibatches, 0 epoch,(27m 36s) is 0.306634\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3081235654341678\n",
      "Test Loss at  105  is  0.2899977\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7073863636363636\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[0 1 0 ... 1 1 0]\n",
      "맞춘갯수 :  2241\n",
      "f1-score(test) :  0.7073863636363636 accuracy :   0.7073863636363636 recall : 0.7073863636363636 precision : 0.7073863636363636\n",
      "************************************************************************************************************\n",
      "Loss at 105 minibatches, 0 epoch,(27m 52s) is 0.308124\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3050370111595839\n",
      "Test Loss at  106  is  0.28889906\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7114898989898989\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 0 1]\n",
      "############\n",
      "[0 0 1 ... 1 0 1]\n",
      "맞춘갯수 :  2254\n",
      "f1-score(test) :  0.7114898989898989 accuracy :   0.711489898989899 recall : 0.711489898989899 precision : 0.711489898989899\n",
      "************************************************************************************************************\n",
      "Loss at 106 minibatches, 0 epoch,(28m 7s) is 0.305037\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.3029645456311603\n",
      "Test Loss at  107  is  0.2729199\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7275883838383839\n",
      "AUC :  0\n",
      "[0 0 0 ... 1 0 1]\n",
      "############\n",
      "[0 0 0 ... 0 0 1]\n",
      "맞춘갯수 :  2305\n",
      "f1-score(test) :  0.7275883838383839 accuracy :   0.7275883838383839 recall : 0.7275883838383839 precision : 0.7275883838383839\n",
      "************************************************************************************************************\n",
      "Loss at 107 minibatches, 0 epoch,(28m 23s) is 0.302965\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2947750478827705\n",
      "Test Loss at  108  is  0.27875656\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6950757575757576\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 0]\n",
      "맞춘갯수 :  2202\n",
      "f1-score(test) :  0.6950757575757576 accuracy :   0.6950757575757576 recall : 0.6950757575757576 precision : 0.6950757575757576\n",
      "************************************************************************************************************\n",
      "Loss at 108 minibatches, 0 epoch,(28m 39s) is 0.294775\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.30030161204437417\n",
      "Test Loss at  109  is  0.27003494\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6559343434343434\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 1 1 1]\n",
      "맞춘갯수 :  2078\n",
      "f1-score(test) :  0.6559343434343434 accuracy :   0.6559343434343434 recall : 0.6559343434343434 precision : 0.6559343434343434\n",
      "************************************************************************************************************\n",
      "Loss at 109 minibatches, 0 epoch,(28m 55s) is 0.300302\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2953137850078444\n",
      "Test Loss at  110  is  0.26800755\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.665719696969697\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 1 1 0]\n",
      "맞춘갯수 :  2109\n",
      "f1-score(test) :  0.665719696969697 accuracy :   0.665719696969697 recall : 0.665719696969697 precision : 0.665719696969697\n",
      "************************************************************************************************************\n",
      "Loss at 110 minibatches, 0 epoch,(29m 11s) is 0.295314\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2976146151001255\n",
      "Test Loss at  111  is  0.28175434\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6893939393939394\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 1 0]\n",
      "맞춘갯수 :  2184\n",
      "f1-score(test) :  0.6893939393939394 accuracy :   0.6893939393939394 recall : 0.6893939393939394 precision : 0.6893939393939394\n",
      "************************************************************************************************************\n",
      "Loss at 111 minibatches, 0 epoch,(29m 27s) is 0.297615\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2998981807225694\n",
      "Test Loss at  112  is  0.2657989\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6751893939393939\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[0 1 1 ... 1 0 0]\n",
      "맞춘갯수 :  2139\n",
      "f1-score(test) :  0.6751893939393939 accuracy :   0.6751893939393939 recall : 0.6751893939393939 precision : 0.6751893939393939\n",
      "************************************************************************************************************\n",
      "Loss at 112 minibatches, 0 epoch,(29m 43s) is 0.299898\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2913843627708654\n",
      "Test Loss at  113  is  0.27946427\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.694760101010101\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[1 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2201\n",
      "f1-score(test) :  0.694760101010101 accuracy :   0.694760101010101 recall : 0.694760101010101 precision : 0.694760101010101\n",
      "************************************************************************************************************\n",
      "Loss at 113 minibatches, 0 epoch,(29m 58s) is 0.291384\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2952090495576461\n",
      "Test Loss at  114  is  0.2881092\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7256944444444444\n",
      "AUC :  0\n",
      "[0 1 0 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 0 1]\n",
      "맞춘갯수 :  2299\n",
      "f1-score(test) :  0.7256944444444444 accuracy :   0.7256944444444444 recall : 0.7256944444444444 precision : 0.7256944444444444\n",
      "************************************************************************************************************\n",
      "Loss at 114 minibatches, 0 epoch,(30m 14s) is 0.295209\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.29318779582778615\n",
      "Test Loss at  115  is  0.26590553\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6878156565656566\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 0 1]\n",
      "맞춘갯수 :  2179\n",
      "f1-score(test) :  0.6878156565656566 accuracy :   0.6878156565656566 recall : 0.6878156565656566 precision : 0.6878156565656566\n",
      "************************************************************************************************************\n",
      "Loss at 115 minibatches, 0 epoch,(30m 31s) is 0.293188\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.28291011570642394\n",
      "Test Loss at  116  is  0.2685762\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6878156565656566\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 0 1]\n",
      "############\n",
      "[1 0 1 ... 0 0 1]\n",
      "맞춘갯수 :  2179\n",
      "f1-score(test) :  0.6878156565656566 accuracy :   0.6878156565656566 recall : 0.6878156565656566 precision : 0.6878156565656566\n",
      "************************************************************************************************************\n",
      "Loss at 116 minibatches, 0 epoch,(30m 46s) is 0.282910\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.28534186996209127\n",
      "Test Loss at  117  is  0.30808952\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7411616161616161\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 1 1]\n",
      "맞춘갯수 :  2348\n",
      "f1-score(test) :  0.7411616161616161 accuracy :   0.7411616161616161 recall : 0.7411616161616161 precision : 0.7411616161616161\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 117 minibatches, 0 epoch,(31m 2s) is 0.285342\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2849170302118485\n",
      "Test Loss at  118  is  0.26184434\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7673611111111112\n",
      "AUC :  0\n",
      "[0 1 0 ... 0 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 1 0]\n",
      "맞춘갯수 :  2431\n",
      "f1-score(test) :  0.7673611111111112 accuracy :   0.7673611111111112 recall : 0.7673611111111112 precision : 0.7673611111111112\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 118 minibatches, 0 epoch,(31m 18s) is 0.284917\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.28138551325537264\n",
      "Test Loss at  119  is  0.26514727\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7067550505050505\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 1 1]\n",
      "맞춘갯수 :  2239\n",
      "f1-score(test) :  0.7067550505050505 accuracy :   0.7067550505050505 recall : 0.7067550505050505 precision : 0.7067550505050505\n",
      "************************************************************************************************************\n",
      "Loss at 119 minibatches, 0 epoch,(31m 34s) is 0.281386\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.278306594506527\n",
      "Test Loss at  120  is  0.25441682\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7269570707070707\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 1 1 0]\n",
      "맞춘갯수 :  2303\n",
      "f1-score(test) :  0.7269570707070707 accuracy :   0.7269570707070707 recall : 0.7269570707070707 precision : 0.7269570707070707\n",
      "************************************************************************************************************\n",
      "Loss at 120 minibatches, 0 epoch,(31m 50s) is 0.278307\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.27605086875458557\n",
      "Test Loss at  121  is  0.26312962\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6852904040404041\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  2171\n",
      "f1-score(test) :  0.6852904040404041 accuracy :   0.6852904040404041 recall : 0.6852904040404041 precision : 0.6852904040404041\n",
      "************************************************************************************************************\n",
      "Loss at 121 minibatches, 0 epoch,(32m 6s) is 0.276051\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.27558798405031365\n",
      "Test Loss at  122  is  0.2500834\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7007575757575758\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  2220\n",
      "f1-score(test) :  0.7007575757575758 accuracy :   0.7007575757575758 recall : 0.7007575757575758 precision : 0.7007575757575758\n",
      "************************************************************************************************************\n",
      "Loss at 122 minibatches, 0 epoch,(32m 22s) is 0.275588\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.27659950595504296\n",
      "Test Loss at  123  is  0.26111567\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.665719696969697\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 0 1]\n",
      "맞춘갯수 :  2109\n",
      "f1-score(test) :  0.665719696969697 accuracy :   0.665719696969697 recall : 0.665719696969697 precision : 0.665719696969697\n",
      "************************************************************************************************************\n",
      "Loss at 123 minibatches, 0 epoch,(32m 38s) is 0.276600\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2772595895609508\n",
      "Test Loss at  124  is  0.25566077\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7013888888888888\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 1 1 1]\n",
      "맞춘갯수 :  2222\n",
      "f1-score(test) :  0.7013888888888888 accuracy :   0.7013888888888888 recall : 0.7013888888888888 precision : 0.7013888888888888\n",
      "************************************************************************************************************\n",
      "Loss at 124 minibatches, 0 epoch,(32m 54s) is 0.277260\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.27606449846643955\n",
      "Test Loss at  125  is  0.23810612\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7127525252525253\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[1 1 0 ... 0 1 0]\n",
      "맞춘갯수 :  2258\n",
      "f1-score(test) :  0.7127525252525253 accuracy :   0.7127525252525253 recall : 0.7127525252525253 precision : 0.7127525252525253\n",
      "************************************************************************************************************\n",
      "Loss at 125 minibatches, 0 epoch,(33m 9s) is 0.276064\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2689797216250251\n",
      "Test Loss at  126  is  0.2509751\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.702020202020202\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 1 1]\n",
      "맞춘갯수 :  2224\n",
      "f1-score(test) :  0.702020202020202 accuracy :   0.702020202020202 recall : 0.702020202020202 precision : 0.702020202020202\n",
      "************************************************************************************************************\n",
      "Loss at 126 minibatches, 0 epoch,(33m 25s) is 0.268980\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.26932159702604014\n",
      "Test Loss at  127  is  0.23662949\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6979166666666666\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[0 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  2211\n",
      "f1-score(test) :  0.6979166666666666 accuracy :   0.6979166666666666 recall : 0.6979166666666666 precision : 0.6979166666666666\n",
      "************************************************************************************************************\n",
      "Loss at 127 minibatches, 0 epoch,(33m 41s) is 0.269322\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2691882513463497\n",
      "Test Loss at  128  is  0.26216722\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6972853535353535\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 0 1]\n",
      "맞춘갯수 :  2209\n",
      "f1-score(test) :  0.6972853535353535 accuracy :   0.6972853535353535 recall : 0.6972853535353535 precision : 0.6972853535353535\n",
      "************************************************************************************************************\n",
      "Loss at 128 minibatches, 0 epoch,(33m 57s) is 0.269188\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.26449974222729605\n",
      "Test Loss at  129  is  0.23810966\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7200126262626263\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 0 1]\n",
      "############\n",
      "[0 1 1 ... 0 1 0]\n",
      "맞춘갯수 :  2281\n",
      "f1-score(test) :  0.7200126262626263 accuracy :   0.7200126262626263 recall : 0.7200126262626263 precision : 0.7200126262626263\n",
      "************************************************************************************************************\n",
      "Loss at 129 minibatches, 0 epoch,(34m 13s) is 0.264500\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.26623384514823556\n",
      "Test Loss at  130  is  0.24230655\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.702020202020202\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 0 1 ... 0 1 0]\n",
      "맞춘갯수 :  2224\n",
      "f1-score(test) :  0.702020202020202 accuracy :   0.702020202020202 recall : 0.702020202020202 precision : 0.702020202020202\n",
      "************************************************************************************************************\n",
      "Loss at 130 minibatches, 0 epoch,(34m 29s) is 0.266234\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.26684999097293866\n",
      "Test Loss at  131  is  0.2591603\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.75\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[0 0 1 ... 1 0 1]\n",
      "맞춘갯수 :  2376\n",
      "f1-score(test) :  0.75 accuracy :   0.75 recall : 0.75 precision : 0.75\n",
      "************************************************************************************************************\n",
      "Loss at 131 minibatches, 0 epoch,(34m 45s) is 0.266850\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2595171839930117\n",
      "Test Loss at  132  is  0.26159894\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7272727272727273\n",
      "AUC :  0\n",
      "[0 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 0 0 ... 0 1 0]\n",
      "맞춘갯수 :  2304\n",
      "f1-score(test) :  0.7272727272727273 accuracy :   0.7272727272727273 recall : 0.7272727272727273 precision : 0.7272727272727273\n",
      "************************************************************************************************************\n",
      "Loss at 132 minibatches, 0 epoch,(35m 1s) is 0.259517\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2602018677086259\n",
      "Test Loss at  133  is  0.25895697\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6963383838383839\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 1 0 1]\n",
      "맞춘갯수 :  2206\n",
      "f1-score(test) :  0.6963383838383839 accuracy :   0.6963383838383839 recall : 0.6963383838383839 precision : 0.6963383838383839\n",
      "************************************************************************************************************\n",
      "Loss at 133 minibatches, 0 epoch,(35m 16s) is 0.260202\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.25043316480393213\n",
      "Test Loss at  134  is  0.27197632\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7563131313131313\n",
      "AUC :  0\n",
      "[1 0 0 ... 0 1 1]\n",
      "############\n",
      "[0 0 0 ... 0 1 1]\n",
      "맞춘갯수 :  2396\n",
      "f1-score(test) :  0.7563131313131313 accuracy :   0.7563131313131313 recall : 0.7563131313131313 precision : 0.7563131313131313\n",
      "************************************************************************************************************\n",
      "Loss at 134 minibatches, 0 epoch,(35m 32s) is 0.250433\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2571482287409405\n",
      "Test Loss at  135  is  0.24670678\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7417929292929293\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 0]\n",
      "############\n",
      "[0 0 1 ... 0 0 0]\n",
      "맞춘갯수 :  2350\n",
      "f1-score(test) :  0.7417929292929293 accuracy :   0.7417929292929293 recall : 0.7417929292929293 precision : 0.7417929292929293\n",
      "************************************************************************************************************\n",
      "Loss at 135 minibatches, 0 epoch,(35m 48s) is 0.257148\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2551239972623686\n",
      "Test Loss at  136  is  0.2542469\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7395833333333334\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  2343\n",
      "f1-score(test) :  0.7395833333333334 accuracy :   0.7395833333333334 recall : 0.7395833333333334 precision : 0.7395833333333334\n",
      "************************************************************************************************************\n",
      "Loss at 136 minibatches, 0 epoch,(36m 4s) is 0.255124\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.2551606588143234\n",
      "Test Loss at  137  is  0.24125272\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6695075757575758\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 0 1]\n",
      "맞춘갯수 :  2121\n",
      "f1-score(test) :  0.6695075757575758 accuracy :   0.6695075757575758 recall : 0.6695075757575758 precision : 0.6695075757575758\n",
      "************************************************************************************************************\n",
      "Loss at 137 minibatches, 0 epoch,(36m 20s) is 0.255161\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.25093012074163806\n",
      "Test Loss at  138  is  0.23772842\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6846590909090909\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 1 0 1]\n",
      "맞춘갯수 :  2169\n",
      "f1-score(test) :  0.6846590909090909 accuracy :   0.6846590909090909 recall : 0.6846590909090909 precision : 0.6846590909090909\n",
      "************************************************************************************************************\n",
      "Loss at 138 minibatches, 0 epoch,(36m 36s) is 0.250930\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.25459106305303675\n",
      "Test Loss at  139  is  0.23617797\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6808712121212122\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 1 1 1]\n",
      "맞춘갯수 :  2157\n",
      "f1-score(test) :  0.6808712121212122 accuracy :   0.6808712121212122 recall : 0.6808712121212122 precision : 0.6808712121212122\n",
      "************************************************************************************************************\n",
      "Loss at 139 minibatches, 0 epoch,(36m 52s) is 0.254591\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2515555811890711\n",
      "Test Loss at  140  is  0.25055954\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6628787878787878\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[0 1 1 ... 0 0 0]\n",
      "맞춘갯수 :  2100\n",
      "f1-score(test) :  0.6628787878787878 accuracy :   0.6628787878787878 recall : 0.6628787878787878 precision : 0.6628787878787878\n",
      "************************************************************************************************************\n",
      "Loss at 140 minibatches, 0 epoch,(37m 8s) is 0.251556\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2531257219767819\n",
      "Test Loss at  141  is  0.21704683\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7449494949494948\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 0]\n",
      "############\n",
      "[1 0 1 ... 0 1 0]\n",
      "맞춘갯수 :  2360\n",
      "f1-score(test) :  0.7449494949494948 accuracy :   0.7449494949494949 recall : 0.7449494949494949 precision : 0.7449494949494949\n",
      "************************************************************************************************************\n",
      "Loss at 141 minibatches, 0 epoch,(37m 24s) is 0.253126\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.24689244731174162\n",
      "Test Loss at  142  is  0.22920287\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7007575757575758\n",
      "AUC :  0\n",
      "[1 0 1 ... 0 1 0]\n",
      "############\n",
      "[1 0 0 ... 0 0 0]\n",
      "맞춘갯수 :  2220\n",
      "f1-score(test) :  0.7007575757575758 accuracy :   0.7007575757575758 recall : 0.7007575757575758 precision : 0.7007575757575758\n",
      "************************************************************************************************************\n",
      "Loss at 142 minibatches, 0 epoch,(37m 40s) is 0.246892\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.24442169353521118\n",
      "Test Loss at  143  is  0.22873849\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7130681818181818\n",
      "AUC :  0\n",
      "[0 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 1 0 0]\n",
      "맞춘갯수 :  2259\n",
      "f1-score(test) :  0.7130681818181818 accuracy :   0.7130681818181818 recall : 0.7130681818181818 precision : 0.7130681818181818\n",
      "************************************************************************************************************\n",
      "Loss at 143 minibatches, 0 epoch,(37m 56s) is 0.244422\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.24442965149258575\n",
      "Test Loss at  144  is  0.22269973\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6811868686868687\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 0]\n",
      "############\n",
      "[1 1 1 ... 0 0 1]\n",
      "맞춘갯수 :  2158\n",
      "f1-score(test) :  0.6811868686868687 accuracy :   0.6811868686868687 recall : 0.6811868686868687 precision : 0.6811868686868687\n",
      "************************************************************************************************************\n",
      "Loss at 144 minibatches, 0 epoch,(38m 12s) is 0.244430\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2406970738278081\n",
      "Test Loss at  145  is  0.22275838\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7297979797979797\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[1 1 1 ... 1 1 0]\n",
      "맞춘갯수 :  2312\n",
      "f1-score(test) :  0.7297979797979797 accuracy :   0.7297979797979798 recall : 0.7297979797979798 precision : 0.7297979797979798\n",
      "************************************************************************************************************\n",
      "Loss at 145 minibatches, 0 epoch,(38m 28s) is 0.240697\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.23860959518545619\n",
      "Test Loss at  146  is  0.22628021\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7544191919191919\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 1 0 0]\n",
      "맞춘갯수 :  2390\n",
      "f1-score(test) :  0.7544191919191919 accuracy :   0.7544191919191919 recall : 0.7544191919191919 precision : 0.7544191919191919\n",
      "************************************************************************************************************\n",
      "Loss at 146 minibatches, 0 epoch,(38m 44s) is 0.238610\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.23916503736594072\n",
      "Test Loss at  147  is  0.2200147\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6979166666666666\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 0]\n",
      "############\n",
      "[0 0 1 ... 0 0 0]\n",
      "맞춘갯수 :  2211\n",
      "f1-score(test) :  0.6979166666666666 accuracy :   0.6979166666666666 recall : 0.6979166666666666 precision : 0.6979166666666666\n",
      "************************************************************************************************************\n",
      "Loss at 147 minibatches, 0 epoch,(39m 0s) is 0.239165\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2398229109821841\n",
      "Test Loss at  148  is  0.22454709\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7503156565656566\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 0 0 0]\n",
      "맞춘갯수 :  2377\n",
      "f1-score(test) :  0.7503156565656566 accuracy :   0.7503156565656566 recall : 0.7503156565656566 precision : 0.7503156565656566\n",
      "************************************************************************************************************\n",
      "Loss at 148 minibatches, 0 epoch,(39m 16s) is 0.239823\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.23212073766626418\n",
      "Test Loss at  149  is  0.21270192\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7140151515151516\n",
      "AUC :  0\n",
      "[0 1 0 ... 1 1 0]\n",
      "############\n",
      "[0 1 0 ... 1 1 0]\n",
      "맞춘갯수 :  2262\n",
      "f1-score(test) :  0.7140151515151516 accuracy :   0.7140151515151515 recall : 0.7140151515151515 precision : 0.7140151515151515\n",
      "************************************************************************************************************\n",
      "Loss at 149 minibatches, 0 epoch,(39m 32s) is 0.232121\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2287865384714678\n",
      "Test Loss at  150  is  0.21740195\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7512626262626263\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[1 1 0 ... 1 0 1]\n",
      "맞춘갯수 :  2380\n",
      "f1-score(test) :  0.7512626262626263 accuracy :   0.7512626262626263 recall : 0.7512626262626263 precision : 0.7512626262626263\n",
      "************************************************************************************************************\n",
      "Loss at 150 minibatches, 0 epoch,(39m 47s) is 0.228787\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.2342710894299671\n",
      "Test Loss at  151  is  0.2063567\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7455808080808081\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 0 0 1]\n",
      "맞춘갯수 :  2362\n",
      "f1-score(test) :  0.7455808080808081 accuracy :   0.7455808080808081 recall : 0.7455808080808081 precision : 0.7455808080808081\n",
      "************************************************************************************************************\n",
      "Loss at 151 minibatches, 0 epoch,(40m 3s) is 0.234271\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.23515682911965996\n",
      "Test Loss at  152  is  0.22217776\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7436868686868687\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 0]\n",
      "############\n",
      "[0 1 1 ... 0 0 0]\n",
      "맞춘갯수 :  2356\n",
      "f1-score(test) :  0.7436868686868687 accuracy :   0.7436868686868687 recall : 0.7436868686868687 precision : 0.7436868686868687\n",
      "************************************************************************************************************\n",
      "Loss at 152 minibatches, 0 epoch,(40m 19s) is 0.235157\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.23744037929767123\n",
      "Test Loss at  153  is  0.20315976\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7152777777777778\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[1 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  2266\n",
      "f1-score(test) :  0.7152777777777778 accuracy :   0.7152777777777778 recall : 0.7152777777777778 precision : 0.7152777777777778\n",
      "************************************************************************************************************\n",
      "Loss at 153 minibatches, 0 epoch,(40m 35s) is 0.237440\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2278735846048221\n",
      "Test Loss at  154  is  0.19152112\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7193813131313131\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 1 1 1]\n",
      "맞춘갯수 :  2279\n",
      "f1-score(test) :  0.7193813131313131 accuracy :   0.7193813131313131 recall : 0.7193813131313131 precision : 0.7193813131313131\n",
      "************************************************************************************************************\n",
      "Loss at 154 minibatches, 0 epoch,(40m 51s) is 0.227874\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2320965271598349\n",
      "Test Loss at  155  is  0.21662404\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7758838383838383\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 0]\n",
      "############\n",
      "[1 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2458\n",
      "f1-score(test) :  0.7758838383838383 accuracy :   0.7758838383838383 recall : 0.7758838383838383 precision : 0.7758838383838383\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 155 minibatches, 0 epoch,(41m 8s) is 0.232097\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2275785127809892\n",
      "Test Loss at  156  is  0.20853429\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7064393939393939\n",
      "AUC :  0\n",
      "[1 0 1 ... 0 0 0]\n",
      "############\n",
      "[1 0 0 ... 0 0 0]\n",
      "맞춘갯수 :  2238\n",
      "f1-score(test) :  0.7064393939393939 accuracy :   0.7064393939393939 recall : 0.7064393939393939 precision : 0.7064393939393939\n",
      "************************************************************************************************************\n",
      "Loss at 156 minibatches, 0 epoch,(41m 24s) is 0.227579\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2243605030622954\n",
      "Test Loss at  157  is  0.21543519\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7323232323232324\n",
      "AUC :  0\n",
      "[0 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 1 1 1]\n",
      "맞춘갯수 :  2320\n",
      "f1-score(test) :  0.7323232323232324 accuracy :   0.7323232323232324 recall : 0.7323232323232324 precision : 0.7323232323232324\n",
      "************************************************************************************************************\n",
      "Loss at 157 minibatches, 0 epoch,(41m 39s) is 0.224361\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.22847392413920412\n",
      "Test Loss at  158  is  0.22968447\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7484217171717171\n",
      "AUC :  0\n",
      "[1 1 0 ... 0 0 1]\n",
      "############\n",
      "[0 0 0 ... 0 0 1]\n",
      "맞춘갯수 :  2371\n",
      "f1-score(test) :  0.7484217171717171 accuracy :   0.7484217171717171 recall : 0.7484217171717171 precision : 0.7484217171717171\n",
      "************************************************************************************************************\n",
      "Loss at 158 minibatches, 0 epoch,(41m 55s) is 0.228474\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.22583612458159527\n",
      "Test Loss at  159  is  0.21068919\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7525252525252525\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 1 1 1]\n",
      "맞춘갯수 :  2384\n",
      "f1-score(test) :  0.7525252525252525 accuracy :   0.7525252525252525 recall : 0.7525252525252525 precision : 0.7525252525252525\n",
      "************************************************************************************************************\n",
      "Loss at 159 minibatches, 0 epoch,(42m 11s) is 0.225836\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.21763687095760056\n",
      "Test Loss at  160  is  0.19568291\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7578914141414141\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 1 0 ... 0 1 0]\n",
      "맞춘갯수 :  2401\n",
      "f1-score(test) :  0.7578914141414141 accuracy :   0.7578914141414141 recall : 0.7578914141414141 precision : 0.7578914141414141\n",
      "************************************************************************************************************\n",
      "Loss at 160 minibatches, 0 epoch,(42m 27s) is 0.217637\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.220815016150785\n",
      "Test Loss at  161  is  0.18627542\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7010732323232324\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 1 0 1]\n",
      "맞춘갯수 :  2221\n",
      "f1-score(test) :  0.7010732323232324 accuracy :   0.7010732323232324 recall : 0.7010732323232324 precision : 0.7010732323232324\n",
      "************************************************************************************************************\n",
      "Loss at 161 minibatches, 0 epoch,(42m 43s) is 0.220815\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2183472279769679\n",
      "Test Loss at  162  is  0.18698585\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.735479797979798\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[1 1 1 ... 0 0 1]\n",
      "맞춘갯수 :  2330\n",
      "f1-score(test) :  0.735479797979798 accuracy :   0.735479797979798 recall : 0.735479797979798 precision : 0.735479797979798\n",
      "************************************************************************************************************\n",
      "Loss at 162 minibatches, 0 epoch,(42m 59s) is 0.218347\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.21317391085904092\n",
      "Test Loss at  163  is  0.19591486\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6963383838383839\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 1]\n",
      "맞춘갯수 :  2206\n",
      "f1-score(test) :  0.6963383838383839 accuracy :   0.6963383838383839 recall : 0.6963383838383839 precision : 0.6963383838383839\n",
      "************************************************************************************************************\n",
      "Loss at 163 minibatches, 0 epoch,(43m 15s) is 0.213174\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.20940573160381368\n",
      "Test Loss at  164  is  0.19346593\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7105429292929293\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 0]\n",
      "############\n",
      "[1 0 1 ... 0 0 0]\n",
      "맞춘갯수 :  2251\n",
      "f1-score(test) :  0.7105429292929293 accuracy :   0.7105429292929293 recall : 0.7105429292929293 precision : 0.7105429292929293\n",
      "************************************************************************************************************\n",
      "Loss at 164 minibatches, 0 epoch,(43m 31s) is 0.209406\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.206564612298583\n",
      "Test Loss at  165  is  0.17820168\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7626262626262628\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 0]\n",
      "############\n",
      "[0 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  2416\n",
      "f1-score(test) :  0.7626262626262628 accuracy :   0.7626262626262627 recall : 0.7626262626262627 precision : 0.7626262626262627\n",
      "************************************************************************************************************\n",
      "Loss at 165 minibatches, 0 epoch,(43m 47s) is 0.206565\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.21132841197929034\n",
      "Test Loss at  166  is  0.199707\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7761994949494948\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 1 0]\n",
      "맞춘갯수 :  2459\n",
      "f1-score(test) :  0.7761994949494948 accuracy :   0.7761994949494949 recall : 0.7761994949494949 precision : 0.7761994949494949\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 166 minibatches, 0 epoch,(44m 2s) is 0.211328\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.20895360658566156\n",
      "Test Loss at  167  is  0.1856837\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7683080808080808\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 1 ... 0 0 1]\n",
      "맞춘갯수 :  2434\n",
      "f1-score(test) :  0.7683080808080808 accuracy :   0.7683080808080808 recall : 0.7683080808080808 precision : 0.7683080808080808\n",
      "************************************************************************************************************\n",
      "Loss at 167 minibatches, 0 epoch,(44m 18s) is 0.208954\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.2104658647052323\n",
      "Test Loss at  168  is  0.18308814\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7623106060606061\n",
      "AUC :  0\n",
      "[1 0 1 ... 0 0 1]\n",
      "############\n",
      "[0 0 0 ... 0 0 1]\n",
      "맞춘갯수 :  2415\n",
      "f1-score(test) :  0.7623106060606061 accuracy :   0.7623106060606061 recall : 0.7623106060606061 precision : 0.7623106060606061\n",
      "************************************************************************************************************\n",
      "Loss at 168 minibatches, 0 epoch,(44m 34s) is 0.210466\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.20767897398521504\n",
      "Test Loss at  169  is  0.18415758\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7263257575757575\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 0]\n",
      "############\n",
      "[0 0 1 ... 1 0 0]\n",
      "맞춘갯수 :  2301\n",
      "f1-score(test) :  0.7263257575757575 accuracy :   0.7263257575757576 recall : 0.7263257575757576 precision : 0.7263257575757576\n",
      "************************************************************************************************************\n",
      "Loss at 169 minibatches, 0 epoch,(44m 50s) is 0.207679\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.20148585131391883\n",
      "Test Loss at  170  is  0.20283154\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7506313131313131\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 0]\n",
      "############\n",
      "[0 1 0 ... 0 1 0]\n",
      "맞춘갯수 :  2378\n",
      "f1-score(test) :  0.7506313131313131 accuracy :   0.7506313131313131 recall : 0.7506313131313131 precision : 0.7506313131313131\n",
      "************************************************************************************************************\n",
      "Loss at 170 minibatches, 0 epoch,(45m 6s) is 0.201486\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.20147742928626636\n",
      "Test Loss at  171  is  0.20069672\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7395833333333334\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 0 1 1]\n",
      "맞춘갯수 :  2343\n",
      "f1-score(test) :  0.7395833333333334 accuracy :   0.7395833333333334 recall : 0.7395833333333334 precision : 0.7395833333333334\n",
      "************************************************************************************************************\n",
      "Loss at 171 minibatches, 0 epoch,(45m 22s) is 0.201477\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.19744474157535782\n",
      "Test Loss at  172  is  0.16859792\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7793560606060606\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 1 1]\n",
      "맞춘갯수 :  2469\n",
      "f1-score(test) :  0.7793560606060606 accuracy :   0.7793560606060606 recall : 0.7793560606060606 precision : 0.7793560606060606\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 172 minibatches, 0 epoch,(45m 38s) is 0.197445\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.202036761213094\n",
      "Test Loss at  173  is  0.19078363\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7077020202020202\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2242\n",
      "f1-score(test) :  0.7077020202020202 accuracy :   0.7077020202020202 recall : 0.7077020202020202 precision : 0.7077020202020202\n",
      "************************************************************************************************************\n",
      "Loss at 173 minibatches, 0 epoch,(45m 54s) is 0.202037\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.19840198452584445\n",
      "Test Loss at  174  is  0.18559295\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7058080808080808\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[0 1 1 ... 1 1 0]\n",
      "맞춘갯수 :  2236\n",
      "f1-score(test) :  0.7058080808080808 accuracy :   0.7058080808080808 recall : 0.7058080808080808 precision : 0.7058080808080808\n",
      "************************************************************************************************************\n",
      "Loss at 174 minibatches, 0 epoch,(46m 9s) is 0.198402\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.19943762993595252\n",
      "Test Loss at  175  is  0.17012084\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7515782828282829\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[1 1 0 ... 1 1 0]\n",
      "맞춘갯수 :  2381\n",
      "f1-score(test) :  0.7515782828282829 accuracy :   0.7515782828282829 recall : 0.7515782828282829 precision : 0.7515782828282829\n",
      "************************************************************************************************************\n",
      "Loss at 175 minibatches, 0 epoch,(46m 25s) is 0.199438\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.19308849660834917\n",
      "Test Loss at  176  is  0.19635777\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7370580808080808\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 0 1]\n",
      "############\n",
      "[1 1 0 ... 1 0 1]\n",
      "맞춘갯수 :  2335\n",
      "f1-score(test) :  0.7370580808080808 accuracy :   0.7370580808080808 recall : 0.7370580808080808 precision : 0.7370580808080808\n",
      "************************************************************************************************************\n",
      "Loss at 176 minibatches, 0 epoch,(46m 41s) is 0.193088\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1944245522414955\n",
      "Test Loss at  177  is  0.16436042\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.779040404040404\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 0]\n",
      "############\n",
      "[1 1 1 ... 0 0 0]\n",
      "맞춘갯수 :  2468\n",
      "f1-score(test) :  0.779040404040404 accuracy :   0.7790404040404041 recall : 0.7790404040404041 precision : 0.7790404040404041\n",
      "************************************************************************************************************\n",
      "Loss at 177 minibatches, 0 epoch,(46m 57s) is 0.194425\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.19142360263504088\n",
      "Test Loss at  178  is  0.15951364\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7749368686868687\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 0 1]\n",
      "############\n",
      "[1 0 1 ... 0 0 0]\n",
      "맞춘갯수 :  2455\n",
      "f1-score(test) :  0.7749368686868687 accuracy :   0.7749368686868687 recall : 0.7749368686868687 precision : 0.7749368686868687\n",
      "************************************************************************************************************\n",
      "Loss at 178 minibatches, 0 epoch,(47m 13s) is 0.191424\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.18980908308488628\n",
      "Test Loss at  179  is  0.17353356\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.764520202020202\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 0 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 0]\n",
      "맞춘갯수 :  2422\n",
      "f1-score(test) :  0.764520202020202 accuracy :   0.764520202020202 recall : 0.764520202020202 precision : 0.764520202020202\n",
      "************************************************************************************************************\n",
      "Loss at 179 minibatches, 0 epoch,(47m 29s) is 0.189809\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.19423358674005917\n",
      "Test Loss at  180  is  0.16968247\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7509469696969697\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[0 1 1 ... 1 1 1]\n",
      "맞춘갯수 :  2379\n",
      "f1-score(test) :  0.7509469696969697 accuracy :   0.7509469696969697 recall : 0.7509469696969697 precision : 0.7509469696969697\n",
      "************************************************************************************************************\n",
      "Loss at 180 minibatches, 0 epoch,(47m 44s) is 0.194234\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1873914587389057\n",
      "Test Loss at  181  is  0.16044004\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7556818181818182\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 0 1]\n",
      "맞춘갯수 :  2394\n",
      "f1-score(test) :  0.7556818181818182 accuracy :   0.7556818181818182 recall : 0.7556818181818182 precision : 0.7556818181818182\n",
      "************************************************************************************************************\n",
      "Loss at 181 minibatches, 0 epoch,(48m 0s) is 0.187391\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.18688260313744345\n",
      "Test Loss at  182  is  0.16588569\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7711489898989898\n",
      "AUC :  0\n",
      "[1 0 1 ... 0 1 0]\n",
      "############\n",
      "[0 0 0 ... 0 1 0]\n",
      "맞춘갯수 :  2443\n",
      "f1-score(test) :  0.7711489898989898 accuracy :   0.77114898989899 recall : 0.77114898989899 precision : 0.77114898989899\n",
      "************************************************************************************************************\n",
      "Loss at 182 minibatches, 0 epoch,(48m 16s) is 0.186883\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.18663137239248803\n",
      "Test Loss at  183  is  0.15402815\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7566287878787878\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 0]\n",
      "############\n",
      "[0 0 1 ... 0 1 0]\n",
      "맞춘갯수 :  2397\n",
      "f1-score(test) :  0.7566287878787878 accuracy :   0.7566287878787878 recall : 0.7566287878787878 precision : 0.7566287878787878\n",
      "************************************************************************************************************\n",
      "Loss at 183 minibatches, 0 epoch,(48m 32s) is 0.186631\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.17996422950333604\n",
      "Test Loss at  184  is  0.15767974\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7648358585858586\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 0]\n",
      "############\n",
      "[0 0 0 ... 0 1 0]\n",
      "맞춘갯수 :  2423\n",
      "f1-score(test) :  0.7648358585858586 accuracy :   0.7648358585858586 recall : 0.7648358585858586 precision : 0.7648358585858586\n",
      "************************************************************************************************************\n",
      "Loss at 184 minibatches, 0 epoch,(48m 48s) is 0.179964\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.17955013669173545\n",
      "Test Loss at  185  is  0.17130257\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7291666666666665\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[1 1 1 ... 0 1 1]\n",
      "맞춘갯수 :  2310\n",
      "f1-score(test) :  0.7291666666666665 accuracy :   0.7291666666666666 recall : 0.7291666666666666 precision : 0.7291666666666666\n",
      "************************************************************************************************************\n",
      "Loss at 185 minibatches, 0 epoch,(49m 4s) is 0.179550\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.18363272685868046\n",
      "Test Loss at  186  is  0.15013675\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.742739898989899\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 1 0]\n",
      "맞춘갯수 :  2353\n",
      "f1-score(test) :  0.742739898989899 accuracy :   0.742739898989899 recall : 0.742739898989899 precision : 0.742739898989899\n",
      "************************************************************************************************************\n",
      "Loss at 186 minibatches, 0 epoch,(49m 19s) is 0.183633\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.18228984726980949\n",
      "Test Loss at  187  is  0.16833404\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7004419191919192\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 0 1]\n",
      "############\n",
      "[1 0 0 ... 0 1 1]\n",
      "맞춘갯수 :  2219\n",
      "f1-score(test) :  0.7004419191919192 accuracy :   0.7004419191919192 recall : 0.7004419191919192 precision : 0.7004419191919192\n",
      "************************************************************************************************************\n",
      "Loss at 187 minibatches, 0 epoch,(49m 35s) is 0.182290\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.17632472660625353\n",
      "Test Loss at  188  is  0.15825394\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.759469696969697\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[0 1 1 ... 1 0 1]\n",
      "맞춘갯수 :  2406\n",
      "f1-score(test) :  0.759469696969697 accuracy :   0.759469696969697 recall : 0.759469696969697 precision : 0.759469696969697\n",
      "************************************************************************************************************\n",
      "Loss at 188 minibatches, 0 epoch,(49m 51s) is 0.176325\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.16967494772203887\n",
      "Test Loss at  189  is  0.14766815\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7749368686868687\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  2455\n",
      "f1-score(test) :  0.7749368686868687 accuracy :   0.7749368686868687 recall : 0.7749368686868687 precision : 0.7749368686868687\n",
      "************************************************************************************************************\n",
      "Loss at 189 minibatches, 0 epoch,(50m 7s) is 0.169675\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.16786079027224332\n",
      "Test Loss at  190  is  0.15806\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7436868686868687\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 1 1 0]\n",
      "맞춘갯수 :  2356\n",
      "f1-score(test) :  0.7436868686868687 accuracy :   0.7436868686868687 recall : 0.7436868686868687 precision : 0.7436868686868687\n",
      "************************************************************************************************************\n",
      "Loss at 190 minibatches, 0 epoch,(50m 23s) is 0.167861\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.17491838875381896\n",
      "Test Loss at  191  is  0.15636496\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.757260101010101\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[1 1 1 ... 1 1 0]\n",
      "맞춘갯수 :  2399\n",
      "f1-score(test) :  0.757260101010101 accuracy :   0.757260101010101 recall : 0.757260101010101 precision : 0.757260101010101\n",
      "************************************************************************************************************\n",
      "Loss at 191 minibatches, 0 epoch,(50m 39s) is 0.174918\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.17137965882041803\n",
      "Test Loss at  192  is  0.1619832\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7585227272727274\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 0]\n",
      "맞춘갯수 :  2403\n",
      "f1-score(test) :  0.7585227272727274 accuracy :   0.7585227272727273 recall : 0.7585227272727273 precision : 0.7585227272727273\n",
      "************************************************************************************************************\n",
      "Loss at 192 minibatches, 0 epoch,(50m 55s) is 0.171380\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.17308824326998243\n",
      "Test Loss at  193  is  0.1676213\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7165404040404041\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 0]\n",
      "############\n",
      "[1 1 1 ... 0 0 0]\n",
      "맞춘갯수 :  2270\n",
      "f1-score(test) :  0.7165404040404041 accuracy :   0.7165404040404041 recall : 0.7165404040404041 precision : 0.7165404040404041\n",
      "************************************************************************************************************\n",
      "Loss at 193 minibatches, 0 epoch,(51m 11s) is 0.173088\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1779343238643681\n",
      "Test Loss at  194  is  0.17685089\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7556818181818182\n",
      "AUC :  0\n",
      "[0 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 1 1]\n",
      "맞춘갯수 :  2394\n",
      "f1-score(test) :  0.7556818181818182 accuracy :   0.7556818181818182 recall : 0.7556818181818182 precision : 0.7556818181818182\n",
      "************************************************************************************************************\n",
      "Loss at 194 minibatches, 0 epoch,(51m 27s) is 0.177934\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1674807311889405\n",
      "Test Loss at  195  is  0.1661218\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.6985479797979798\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 0 1]\n",
      "############\n",
      "[1 0 0 ... 1 1 0]\n",
      "맞춘갯수 :  2213\n",
      "f1-score(test) :  0.6985479797979798 accuracy :   0.6985479797979798 recall : 0.6985479797979798 precision : 0.6985479797979798\n",
      "************************************************************************************************************\n",
      "Loss at 195 minibatches, 0 epoch,(51m 43s) is 0.167481\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1609064892400056\n",
      "Test Loss at  196  is  0.16043527\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7285353535353534\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 1 1]\n",
      "맞춘갯수 :  2308\n",
      "f1-score(test) :  0.7285353535353534 accuracy :   0.7285353535353535 recall : 0.7285353535353535 precision : 0.7285353535353535\n",
      "************************************************************************************************************\n",
      "Loss at 196 minibatches, 0 epoch,(51m 59s) is 0.160906\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.16911873927650353\n",
      "Test Loss at  197  is  0.16444066\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7619949494949494\n",
      "AUC :  0\n",
      "[1 0 1 ... 0 1 1]\n",
      "############\n",
      "[1 0 1 ... 0 0 1]\n",
      "맞춘갯수 :  2414\n",
      "f1-score(test) :  0.7619949494949494 accuracy :   0.7619949494949495 recall : 0.7619949494949495 precision : 0.7619949494949495\n",
      "************************************************************************************************************\n",
      "Loss at 197 minibatches, 0 epoch,(52m 15s) is 0.169119\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.17282610970626897\n",
      "Test Loss at  198  is  0.13765924\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7730429292929293\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 0]\n",
      "############\n",
      "[0 1 0 ... 0 1 0]\n",
      "맞춘갯수 :  2449\n",
      "f1-score(test) :  0.7730429292929293 accuracy :   0.7730429292929293 recall : 0.7730429292929293 precision : 0.7730429292929293\n",
      "************************************************************************************************************\n",
      "Loss at 198 minibatches, 0 epoch,(52m 30s) is 0.172826\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.16764583739374453\n",
      "Test Loss at  199  is  0.16236137\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7440025252525253\n",
      "AUC :  0\n",
      "[0 1 0 ... 0 1 1]\n",
      "############\n",
      "[0 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2357\n",
      "f1-score(test) :  0.7440025252525253 accuracy :   0.7440025252525253 recall : 0.7440025252525253 precision : 0.7440025252525253\n",
      "************************************************************************************************************\n",
      "Loss at 199 minibatches, 0 epoch,(52m 46s) is 0.167646\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.16131909164444855\n",
      "Test Loss at  200  is  0.16559018\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7386363636363636\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 0]\n",
      "############\n",
      "[1 0 0 ... 1 0 0]\n",
      "맞춘갯수 :  2340\n",
      "f1-score(test) :  0.7386363636363636 accuracy :   0.7386363636363636 recall : 0.7386363636363636 precision : 0.7386363636363636\n",
      "************************************************************************************************************\n",
      "Loss at 200 minibatches, 0 epoch,(53m 2s) is 0.161319\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.16108035137100765\n",
      "Test Loss at  201  is  0.13825142\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7768308080808081\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[1 1 1 ... 1 1 0]\n",
      "맞춘갯수 :  2461\n",
      "f1-score(test) :  0.7768308080808081 accuracy :   0.7768308080808081 recall : 0.7768308080808081 precision : 0.7768308080808081\n",
      "************************************************************************************************************\n",
      "Loss at 201 minibatches, 0 epoch,(53m 18s) is 0.161080\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.16063856931092838\n",
      "Test Loss at  202  is  0.15687683\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7411616161616161\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2348\n",
      "f1-score(test) :  0.7411616161616161 accuracy :   0.7411616161616161 recall : 0.7411616161616161 precision : 0.7411616161616161\n",
      "************************************************************************************************************\n",
      "Loss at 202 minibatches, 0 epoch,(53m 34s) is 0.160639\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1563568161218427\n",
      "Test Loss at  203  is  0.12246635\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7976641414141414\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 0]\n",
      "############\n",
      "[1 1 0 ... 1 1 0]\n",
      "맞춘갯수 :  2527\n",
      "f1-score(test) :  0.7976641414141414 accuracy :   0.7976641414141414 recall : 0.7976641414141414 precision : 0.7976641414141414\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 203 minibatches, 0 epoch,(53m 50s) is 0.156357\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.16013446376503757\n",
      "Test Loss at  204  is  0.16343561\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7866161616161617\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  2492\n",
      "f1-score(test) :  0.7866161616161617 accuracy :   0.7866161616161617 recall : 0.7866161616161617 precision : 0.7866161616161617\n",
      "************************************************************************************************************\n",
      "Loss at 204 minibatches, 0 epoch,(54m 6s) is 0.160134\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.15157047540803129\n",
      "Test Loss at  205  is  0.18788812\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7215909090909091\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 1 0 1]\n",
      "맞춘갯수 :  2286\n",
      "f1-score(test) :  0.7215909090909091 accuracy :   0.7215909090909091 recall : 0.7215909090909091 precision : 0.7215909090909091\n",
      "************************************************************************************************************\n",
      "Loss at 205 minibatches, 0 epoch,(54m 22s) is 0.151570\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.16140755654002228\n",
      "Test Loss at  206  is  0.12796529\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7863005050505051\n",
      "AUC :  0\n",
      "[1 0 1 ... 0 1 1]\n",
      "############\n",
      "[1 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  2491\n",
      "f1-score(test) :  0.7863005050505051 accuracy :   0.7863005050505051 recall : 0.7863005050505051 precision : 0.7863005050505051\n",
      "************************************************************************************************************\n",
      "Loss at 206 minibatches, 0 epoch,(54m 38s) is 0.161408\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.1584384847956244\n",
      "Test Loss at  207  is  0.15713142\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.8068181818181818\n",
      "AUC :  0\n",
      "[1 1 0 ... 0 0 1]\n",
      "############\n",
      "[0 1 0 ... 0 0 0]\n",
      "맞춘갯수 :  2556\n",
      "f1-score(test) :  0.8068181818181818 accuracy :   0.8068181818181818 recall : 0.8068181818181818 precision : 0.8068181818181818\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 207 minibatches, 0 epoch,(54m 54s) is 0.158438\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.15985105256550014\n",
      "Test Loss at  208  is  0.13844134\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.8020833333333334\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 1 0 0]\n",
      "맞춘갯수 :  2541\n",
      "f1-score(test) :  0.8020833333333334 accuracy :   0.8020833333333334 recall : 0.8020833333333334 precision : 0.8020833333333334\n",
      "************************************************************************************************************\n",
      "Loss at 208 minibatches, 0 epoch,(55m 10s) is 0.159851\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.14834240690106526\n",
      "Test Loss at  209  is  0.12778194\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.8011363636363636\n",
      "AUC :  0\n",
      "[0 1 0 ... 1 1 0]\n",
      "############\n",
      "[0 1 0 ... 0 1 0]\n",
      "맞춘갯수 :  2538\n",
      "f1-score(test) :  0.8011363636363636 accuracy :   0.8011363636363636 recall : 0.8011363636363636 precision : 0.8011363636363636\n",
      "************************************************************************************************************\n",
      "Loss at 209 minibatches, 0 epoch,(55m 26s) is 0.148342\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1600523958525931\n",
      "Test Loss at  210  is  0.12379239\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7875631313131313\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 0]\n",
      "############\n",
      "[1 1 1 ... 0 0 0]\n",
      "맞춘갯수 :  2495\n",
      "f1-score(test) :  0.7875631313131313 accuracy :   0.7875631313131313 recall : 0.7875631313131313 precision : 0.7875631313131313\n",
      "************************************************************************************************************\n",
      "Loss at 210 minibatches, 0 epoch,(55m 42s) is 0.160052\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.14577761734835804\n",
      "Test Loss at  211  is  0.12743643\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7869318181818182\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 0]\n",
      "맞춘갯수 :  2493\n",
      "f1-score(test) :  0.7869318181818182 accuracy :   0.7869318181818182 recall : 0.7869318181818182 precision : 0.7869318181818182\n",
      "************************************************************************************************************\n",
      "Loss at 211 minibatches, 0 epoch,(55m 58s) is 0.145778\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1458600361753876\n",
      "Test Loss at  212  is  0.1290306\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7821969696969698\n",
      "AUC :  0\n",
      "[0 0 1 ... 0 1 0]\n",
      "############\n",
      "[0 0 0 ... 0 1 0]\n",
      "맞춘갯수 :  2478\n",
      "f1-score(test) :  0.7821969696969698 accuracy :   0.7821969696969697 recall : 0.7821969696969697 precision : 0.7821969696969697\n",
      "************************************************************************************************************\n",
      "Loss at 212 minibatches, 0 epoch,(56m 14s) is 0.145860\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.15110229977290146\n",
      "Test Loss at  213  is  0.12193316\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7784090909090909\n",
      "AUC :  0\n",
      "[1 0 1 ... 0 1 1]\n",
      "############\n",
      "[1 0 1 ... 1 1 1]\n",
      "맞춘갯수 :  2466\n",
      "f1-score(test) :  0.7784090909090909 accuracy :   0.7784090909090909 recall : 0.7784090909090909 precision : 0.7784090909090909\n",
      "************************************************************************************************************\n",
      "Loss at 213 minibatches, 0 epoch,(56m 30s) is 0.151102\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.14403839281294495\n",
      "Test Loss at  214  is  0.15290385\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7045454545454546\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 0]\n",
      "############\n",
      "[1 0 0 ... 1 1 0]\n",
      "맞춘갯수 :  2232\n",
      "f1-score(test) :  0.7045454545454546 accuracy :   0.7045454545454546 recall : 0.7045454545454546 precision : 0.7045454545454546\n",
      "************************************************************************************************************\n",
      "Loss at 214 minibatches, 0 epoch,(56m 46s) is 0.144038\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.14372902099664012\n",
      "Test Loss at  215  is  0.14086474\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7736742424242423\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 0 0 1]\n",
      "맞춘갯수 :  2451\n",
      "f1-score(test) :  0.7736742424242423 accuracy :   0.7736742424242424 recall : 0.7736742424242424 precision : 0.7736742424242424\n",
      "************************************************************************************************************\n",
      "Loss at 215 minibatches, 0 epoch,(57m 2s) is 0.143729\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.14574040742202973\n",
      "Test Loss at  216  is  0.12818407\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7891414141414141\n",
      "AUC :  0\n",
      "[1 1 0 ... 0 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2500\n",
      "f1-score(test) :  0.7891414141414141 accuracy :   0.7891414141414141 recall : 0.7891414141414141 precision : 0.7891414141414141\n",
      "************************************************************************************************************\n",
      "Loss at 216 minibatches, 0 epoch,(57m 18s) is 0.145740\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1433497632970102\n",
      "Test Loss at  217  is  0.1317578\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7926136363636364\n",
      "AUC :  0\n",
      "[1 1 0 ... 0 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2511\n",
      "f1-score(test) :  0.7926136363636364 accuracy :   0.7926136363636364 recall : 0.7926136363636364 precision : 0.7926136363636364\n",
      "************************************************************************************************************\n",
      "Loss at 217 minibatches, 0 epoch,(57m 34s) is 0.143350\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.13505062049565217\n",
      "Test Loss at  218  is  0.1242107\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7730429292929293\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 0 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 1]\n",
      "맞춘갯수 :  2449\n",
      "f1-score(test) :  0.7730429292929293 accuracy :   0.7730429292929293 recall : 0.7730429292929293 precision : 0.7730429292929293\n",
      "************************************************************************************************************\n",
      "Loss at 218 minibatches, 0 epoch,(57m 50s) is 0.135051\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1440119007990385\n",
      "Test Loss at  219  is  0.13287456\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7275883838383839\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[1 1 1 ... 1 1 1]\n",
      "맞춘갯수 :  2305\n",
      "f1-score(test) :  0.7275883838383839 accuracy :   0.7275883838383839 recall : 0.7275883838383839 precision : 0.7275883838383839\n",
      "************************************************************************************************************\n",
      "Loss at 219 minibatches, 0 epoch,(58m 5s) is 0.144012\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.14068425363317752\n",
      "Test Loss at  220  is  0.10704868\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7604166666666666\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 0 0]\n",
      "############\n",
      "[0 1 0 ... 0 0 1]\n",
      "맞춘갯수 :  2409\n",
      "f1-score(test) :  0.7604166666666666 accuracy :   0.7604166666666666 recall : 0.7604166666666666 precision : 0.7604166666666666\n",
      "************************************************************************************************************\n",
      "Loss at 220 minibatches, 0 epoch,(58m 21s) is 0.140684\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.1323787396249827\n",
      "Test Loss at  221  is  0.1342432\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7626262626262628\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[0 1 1 ... 0 0 0]\n",
      "맞춘갯수 :  2416\n",
      "f1-score(test) :  0.7626262626262628 accuracy :   0.7626262626262627 recall : 0.7626262626262627 precision : 0.7626262626262627\n",
      "************************************************************************************************************\n",
      "Loss at 221 minibatches, 0 epoch,(58m 37s) is 0.132379\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1426039090147242\n",
      "Test Loss at  222  is  0.12134808\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7736742424242423\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 0 1]\n",
      "############\n",
      "[0 0 0 ... 1 0 1]\n",
      "맞춘갯수 :  2451\n",
      "f1-score(test) :  0.7736742424242423 accuracy :   0.7736742424242424 recall : 0.7736742424242424 precision : 0.7736742424242424\n",
      "************************************************************************************************************\n",
      "Loss at 222 minibatches, 0 epoch,(58m 53s) is 0.142604\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.13233989983564243\n",
      "Test Loss at  223  is  0.10762385\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7837752525252525\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[1 0 1 ... 1 0 1]\n",
      "맞춘갯수 :  2483\n",
      "f1-score(test) :  0.7837752525252525 accuracy :   0.7837752525252525 recall : 0.7837752525252525 precision : 0.7837752525252525\n",
      "************************************************************************************************************\n",
      "Loss at 223 minibatches, 0 epoch,(59m 9s) is 0.132340\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.13113646273268387\n",
      "Test Loss at  224  is  0.11710354\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7787247474747475\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[0 1 1 ... 1 0 0]\n",
      "맞춘갯수 :  2467\n",
      "f1-score(test) :  0.7787247474747475 accuracy :   0.7787247474747475 recall : 0.7787247474747475 precision : 0.7787247474747475\n",
      "************************************************************************************************************\n",
      "Loss at 224 minibatches, 0 epoch,(59m 25s) is 0.131136\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.13594285683939233\n",
      "Test Loss at  225  is  0.1406143\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7919823232323232\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 0]\n",
      "############\n",
      "[1 1 0 ... 0 1 0]\n",
      "맞춘갯수 :  2509\n",
      "f1-score(test) :  0.7919823232323232 accuracy :   0.7919823232323232 recall : 0.7919823232323232 precision : 0.7919823232323232\n",
      "************************************************************************************************************\n",
      "Loss at 225 minibatches, 0 epoch,(59m 41s) is 0.135943\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.13610164014001688\n",
      "Test Loss at  226  is  0.099142335\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7746212121212122\n",
      "AUC :  0\n",
      "[0 0 1 ... 1 1 1]\n",
      "############\n",
      "[0 0 0 ... 0 1 1]\n",
      "맞춘갯수 :  2454\n",
      "f1-score(test) :  0.7746212121212122 accuracy :   0.7746212121212122 recall : 0.7746212121212122 precision : 0.7746212121212122\n",
      "************************************************************************************************************\n",
      "Loss at 226 minibatches, 0 epoch,(59m 57s) is 0.136102\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1292441972376158\n",
      "Test Loss at  227  is  0.13339418\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7512626262626263\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 1 1]\n",
      "맞춘갯수 :  2380\n",
      "f1-score(test) :  0.7512626262626263 accuracy :   0.7512626262626263 recall : 0.7512626262626263 precision : 0.7512626262626263\n",
      "************************************************************************************************************\n",
      "Loss at 227 minibatches, 0 epoch,(60m 13s) is 0.129244\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1269568707793951\n",
      "Test Loss at  228  is  0.11262776\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7897727272727273\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 1 ... 1 1 1]\n",
      "맞춘갯수 :  2502\n",
      "f1-score(test) :  0.7897727272727273 accuracy :   0.7897727272727273 recall : 0.7897727272727273 precision : 0.7897727272727273\n",
      "************************************************************************************************************\n",
      "Loss at 228 minibatches, 0 epoch,(60m 29s) is 0.126957\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.13132364811220518\n",
      "Test Loss at  229  is  0.1188012\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7881944444444445\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[1 0 1 ... 0 0 1]\n",
      "맞춘갯수 :  2497\n",
      "f1-score(test) :  0.7881944444444445 accuracy :   0.7881944444444444 recall : 0.7881944444444444 precision : 0.7881944444444444\n",
      "************************************************************************************************************\n",
      "Loss at 229 minibatches, 0 epoch,(60m 45s) is 0.131324\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1353945288574323\n",
      "Test Loss at  230  is  0.12017716\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7541035353535354\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[0 1 1 ... 1 1 0]\n",
      "맞춘갯수 :  2389\n",
      "f1-score(test) :  0.7541035353535354 accuracy :   0.7541035353535354 recall : 0.7541035353535354 precision : 0.7541035353535354\n",
      "************************************************************************************************************\n",
      "Loss at 230 minibatches, 0 epoch,(61m 1s) is 0.135395\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.12876559848276278\n",
      "Test Loss at  231  is  0.093184434\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7929292929292929\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 0 1]\n",
      "############\n",
      "[0 0 0 ... 0 0 0]\n",
      "맞춘갯수 :  2512\n",
      "f1-score(test) :  0.7929292929292929 accuracy :   0.7929292929292929 recall : 0.7929292929292929 precision : 0.7929292929292929\n",
      "************************************************************************************************************\n",
      "Loss at 231 minibatches, 0 epoch,(61m 17s) is 0.128766\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.12780306418426335\n",
      "Test Loss at  232  is  0.095302306\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.8042929292929293\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 1 1 0]\n",
      "맞춘갯수 :  2548\n",
      "f1-score(test) :  0.8042929292929293 accuracy :   0.8042929292929293 recall : 0.8042929292929293 precision : 0.8042929292929293\n",
      "************************************************************************************************************\n",
      "Loss at 232 minibatches, 0 epoch,(61m 33s) is 0.127803\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.11615941092410746\n",
      "Test Loss at  233  is  0.11908926\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7752525252525253\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 0 ... 1 1 1]\n",
      "맞춘갯수 :  2456\n",
      "f1-score(test) :  0.7752525252525253 accuracy :   0.7752525252525253 recall : 0.7752525252525253 precision : 0.7752525252525253\n",
      "************************************************************************************************************\n",
      "Loss at 233 minibatches, 0 epoch,(61m 49s) is 0.116159\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.127268523715126\n",
      "Test Loss at  234  is  0.104819365\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.8207070707070707\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[1 1 1 ... 0 0 0]\n",
      "맞춘갯수 :  2600\n",
      "f1-score(test) :  0.8207070707070707 accuracy :   0.8207070707070707 recall : 0.8207070707070707 precision : 0.8207070707070707\n",
      "saving...model\n",
      "************************************************************************************************************\n",
      "Loss at 234 minibatches, 0 epoch,(62m 5s) is 0.127269\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.11619504327730586\n",
      "Test Loss at  235  is  0.119609505\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7881944444444445\n",
      "AUC :  0\n",
      "[1 0 0 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  2497\n",
      "f1-score(test) :  0.7881944444444445 accuracy :   0.7881944444444444 recall : 0.7881944444444444 precision : 0.7881944444444444\n",
      "************************************************************************************************************\n",
      "Loss at 235 minibatches, 0 epoch,(62m 20s) is 0.116195\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.11587549117393792\n",
      "Test Loss at  236  is  0.119059816\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7727272727272727\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[1 1 1 ... 0 1 0]\n",
      "맞춘갯수 :  2448\n",
      "f1-score(test) :  0.7727272727272727 accuracy :   0.7727272727272727 recall : 0.7727272727272727 precision : 0.7727272727272727\n",
      "************************************************************************************************************\n",
      "Loss at 236 minibatches, 0 epoch,(62m 36s) is 0.115875\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.12086674101495494\n",
      "Test Loss at  237  is  0.116340026\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7837752525252525\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 1 1 1]\n",
      "맞춘갯수 :  2483\n",
      "f1-score(test) :  0.7837752525252525 accuracy :   0.7837752525252525 recall : 0.7837752525252525 precision : 0.7837752525252525\n",
      "************************************************************************************************************\n",
      "Loss at 237 minibatches, 0 epoch,(62m 52s) is 0.120867\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1286956555947351\n",
      "Test Loss at  238  is  0.10461393\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7806186868686869\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[0 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2473\n",
      "f1-score(test) :  0.7806186868686869 accuracy :   0.7806186868686869 recall : 0.7806186868686869 precision : 0.7806186868686869\n",
      "************************************************************************************************************\n",
      "Loss at 238 minibatches, 0 epoch,(63m 8s) is 0.128696\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1172498974580473\n",
      "Test Loss at  239  is  0.13164505\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7642045454545454\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 1 ... 0 1 0]\n",
      "맞춘갯수 :  2421\n",
      "f1-score(test) :  0.7642045454545454 accuracy :   0.7642045454545454 recall : 0.7642045454545454 precision : 0.7642045454545454\n",
      "************************************************************************************************************\n",
      "Loss at 239 minibatches, 0 epoch,(63m 24s) is 0.117250\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.11615194067902242\n",
      "Test Loss at  240  is  0.10972653\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7708333333333333\n",
      "AUC :  0\n",
      "[0 1 1 ... 1 1 0]\n",
      "############\n",
      "[0 1 1 ... 1 0 0]\n",
      "맞춘갯수 :  2442\n",
      "f1-score(test) :  0.7708333333333333 accuracy :   0.7708333333333334 recall : 0.7708333333333334 precision : 0.7708333333333334\n",
      "************************************************************************************************************\n",
      "Loss at 240 minibatches, 0 epoch,(63m 40s) is 0.116152\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.12340127024799585\n",
      "Test Loss at  241  is  0.1078491\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.788510101010101\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 0]\n",
      "############\n",
      "[1 1 1 ... 1 1 0]\n",
      "맞춘갯수 :  2498\n",
      "f1-score(test) :  0.788510101010101 accuracy :   0.788510101010101 recall : 0.788510101010101 precision : 0.788510101010101\n",
      "************************************************************************************************************\n",
      "Loss at 241 minibatches, 0 epoch,(63m 56s) is 0.123401\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.11253392294747755\n",
      "Test Loss at  242  is  0.09742132\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.79135101010101\n",
      "AUC :  0\n",
      "[1 1 1 ... 0 1 1]\n",
      "############\n",
      "[0 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  2507\n",
      "f1-score(test) :  0.79135101010101 accuracy :   0.79135101010101 recall : 0.79135101010101 precision : 0.79135101010101\n",
      "************************************************************************************************************\n",
      "Loss at 242 minibatches, 0 epoch,(64m 12s) is 0.112534\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.11788617591567647\n",
      "Test Loss at  243  is  0.11244365\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7834595959595959\n",
      "AUC :  0\n",
      "[1 1 0 ... 0 0 1]\n",
      "############\n",
      "[0 1 0 ... 0 0 1]\n",
      "맞춘갯수 :  2482\n",
      "f1-score(test) :  0.7834595959595959 accuracy :   0.7834595959595959 recall : 0.7834595959595959 precision : 0.7834595959595959\n",
      "************************************************************************************************************\n",
      "Loss at 243 minibatches, 0 epoch,(64m 28s) is 0.117886\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.11398553612525575\n",
      "Test Loss at  244  is  0.0843619\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.8112373737373737\n",
      "AUC :  0\n",
      "[0 0 0 ... 0 1 0]\n",
      "############\n",
      "[0 0 0 ... 0 1 0]\n",
      "맞춘갯수 :  2570\n",
      "f1-score(test) :  0.8112373737373737 accuracy :   0.8112373737373737 recall : 0.8112373737373737 precision : 0.8112373737373737\n",
      "************************************************************************************************************\n",
      "Loss at 244 minibatches, 0 epoch,(64m 43s) is 0.113986\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1185001553579544\n",
      "Test Loss at  245  is  0.11897884\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7986111111111112\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 1 1 0]\n",
      "맞춘갯수 :  2530\n",
      "f1-score(test) :  0.7986111111111112 accuracy :   0.7986111111111112 recall : 0.7986111111111112 precision : 0.7986111111111112\n",
      "************************************************************************************************************\n",
      "Loss at 245 minibatches, 0 epoch,(64m 59s) is 0.118500\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.10985706416734804\n",
      "Test Loss at  246  is  0.09600083\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7828282828282829\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 1 0 ... 0 0 1]\n",
      "맞춘갯수 :  2480\n",
      "f1-score(test) :  0.7828282828282829 accuracy :   0.7828282828282829 recall : 0.7828282828282829 precision : 0.7828282828282829\n",
      "************************************************************************************************************\n",
      "Loss at 246 minibatches, 0 epoch,(65m 15s) is 0.109857\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.11658429820090532\n",
      "Test Loss at  247  is  0.09694466\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7689393939393939\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 0 1]\n",
      "############\n",
      "[1 1 1 ... 1 0 1]\n",
      "맞춘갯수 :  2436\n",
      "f1-score(test) :  0.7689393939393939 accuracy :   0.7689393939393939 recall : 0.7689393939393939 precision : 0.7689393939393939\n",
      "************************************************************************************************************\n",
      "Loss at 247 minibatches, 0 epoch,(65m 31s) is 0.116584\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.10343788700993173\n",
      "Test Loss at  248  is  0.1017293\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7970328282828283\n",
      "AUC :  0\n",
      "[1 1 0 ... 1 1 1]\n",
      "############\n",
      "[0 1 0 ... 0 1 1]\n",
      "맞춘갯수 :  2525\n",
      "f1-score(test) :  0.7970328282828283 accuracy :   0.7970328282828283 recall : 0.7970328282828283 precision : 0.7970328282828283\n",
      "************************************************************************************************************\n",
      "Loss at 248 minibatches, 0 epoch,(65m 47s) is 0.103438\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at this epoch..minibatch  0.11847690859576687\n",
      "Test Loss at  249  is  0.1080461\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7856691919191919\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 1]\n",
      "############\n",
      "[1 0 1 ... 0 1 1]\n",
      "맞춘갯수 :  2489\n",
      "f1-score(test) :  0.7856691919191919 accuracy :   0.7856691919191919 recall : 0.7856691919191919 precision : 0.7856691919191919\n",
      "************************************************************************************************************\n",
      "Loss at 249 minibatches, 0 epoch,(66m 3s) is 0.118477\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.1031517924760313\n",
      "Test Loss at  250  is  0.08416758\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7979797979797979\n",
      "AUC :  0\n",
      "[1 0 1 ... 1 1 0]\n",
      "############\n",
      "[1 0 1 ... 1 1 1]\n",
      "맞춘갯수 :  2528\n",
      "f1-score(test) :  0.7979797979797979 accuracy :   0.797979797979798 recall : 0.797979797979798 precision : 0.797979797979798\n",
      "************************************************************************************************************\n",
      "Loss at 250 minibatches, 0 epoch,(66m 19s) is 0.103152\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.10486743584624492\n",
      "Test Loss at  251  is  0.08047503\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7904040404040404\n",
      "AUC :  0\n",
      "[1 0 0 ... 0 1 0]\n",
      "############\n",
      "[1 0 0 ... 0 0 0]\n",
      "맞춘갯수 :  2504\n",
      "f1-score(test) :  0.7904040404040404 accuracy :   0.7904040404040404 recall : 0.7904040404040404 precision : 0.7904040404040404\n",
      "************************************************************************************************************\n",
      "Loss at 251 minibatches, 0 epoch,(66m 35s) is 0.104867\n",
      "************************************************************************************************************\n",
      "Average training loss at this epoch..minibatch  0.10262395231984556\n",
      "Test Loss at  252  is  0.09008493\n",
      "test 갯수 : 3168\n",
      "F-1score :  0.7856691919191919\n",
      "AUC :  0\n",
      "[1 1 1 ... 1 1 0]\n",
      "############\n",
      "[0 1 1 ... 1 1 0]\n",
      "맞춘갯수 :  2489\n",
      "f1-score(test) :  0.7856691919191919 accuracy :   0.7856691919191919 recall : 0.7856691919191919 precision : 0.7856691919191919\n",
      "************************************************************************************************************\n",
      "Loss at 252 minibatches, 0 epoch,(66m 51s) is 0.102624\n",
      "************************************************************************************************************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-cdd00f3182fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         ac,b,c,d= train_early_stopping(64, X_train, y_train, X_dev,y_dev, X_test,y_test, entireContext_model, \n\u001b[0;32m---> 95\u001b[0;31m                                             entireContext_optimizer, criterion,  1000)\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mcur_a\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%%%%%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-180-a194173c7f25>\u001b[0m in \u001b[0;36mtrain_early_stopping\u001b[0;34m(mini_batch_size, X_train, y_train, X_dev, y_dev, X_test, y_test, sent_attn, sent_optimizer, loss_criterion, num_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m#print(\"!!! :\", tokens1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             loss = train_data(tokens1.cuda(),tokens2.cuda(), labels.cuda(), sent_attn, \n\u001b[0;32m---> 22\u001b[0;31m                               sent_optimizer, loss_criterion)\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mloss_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-b1b227c608b9>\u001b[0m in \u001b[0;36mtrain_data\u001b[0;34m(mini_batch, source, targets, sent_attn, sent_optimizer, criterion)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_attn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv-python3.6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv-python3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test1_f1 = []\n",
    "test1_acur = []\n",
    "test1_pre = []\n",
    "test1_recall =[]\n",
    "test1_roc=[]\n",
    "\n",
    "test1_f1_사전 = []\n",
    "test1_acur_사전 = []\n",
    "test1_pre_사전 = []\n",
    "test1_recall_사전 =[]\n",
    "test1_roc_사전=[]\n",
    "\n",
    "# import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "kfold = KFold(n_splits=9,random_state=0,shuffle=True)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "print(\"\\nKFold**************\")\n",
    "aurrrrr = []\n",
    "t=0\n",
    "cur_a=1\n",
    "c=0\n",
    "for train_index, validate_index in kfold.split(X_train):\n",
    "    c+=1\n",
    "    if(c==9):\n",
    "        print(\"train index:\", train_index.shape, \"validate index:\", validate_index.shape)\n",
    "        print(train_index)\n",
    "        \n",
    "        X_train1, X_dev = X_train[train_index], X_train[validate_index]\n",
    "        y_train1, y_dev = y_train[train_index], y_train[validate_index]\n",
    "\n",
    "\n",
    "        print(\"X_train1 index:\", X_train1.shape, \"X_dev index:\", X_dev.shape)\n",
    "        print(\"############################################################\")\n",
    "        print(X_dev)\n",
    "        train_2=0\n",
    "        train_1=0\n",
    "        train_0=0\n",
    "        test_2=0\n",
    "        test_1=0\n",
    "        test_0=0\n",
    "        for i in y_train:\n",
    "                #print(i)\n",
    "            if i==1:\n",
    "                train_1+=1\n",
    "            elif i==0:\n",
    "                train_0+=1\n",
    "            elif i==2:\n",
    "                train_2+=1\n",
    "        for i in y_dev:\n",
    "                #print(i)\n",
    "            if i==1:\n",
    "                test_1+=1\n",
    "            elif i==0:\n",
    "                test_0+=1\n",
    "            elif i==2:\n",
    "                test_2+=1\n",
    "\n",
    "\n",
    "        print_every = 100\n",
    "        vocab_size = 300000\n",
    "        output_size = 1 # binary class (1 or 0)\n",
    "        embedding_dim = 300\n",
    "        num_filters = 100\n",
    "        kernel_sizes = [3,4,5]\n",
    "        num_layer=1\n",
    "        num_classes =3\n",
    "\n",
    "        entireContext_model = entireContext( )\n",
    "\n",
    "\n",
    "\n",
    "        learning_rate = 0.001\n",
    "        momentum = 0.9\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        flag1=\"abusive_detection\"+str(cur_a)+\".pth\"\n",
    "\n",
    "\n",
    "            #final_attn_optimizer = torch.optim.SGD(final_attn.parameters(), lr=learning_rate, momentum= momentum)\n",
    "\n",
    "        #final_attn_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, final_attn.parameters()), lr=learning_rate)    \n",
    "\n",
    "        entireContext_optimizer = torch.optim.Adam(list(entireContext_model.parameters()), lr=learning_rate)\n",
    "        \n",
    "        entireContext_model.cuda()\n",
    "\n",
    "        print(cur_a)\n",
    "        print(\"#######################\")\n",
    "        print(X_train1)\n",
    "        ac,b,c,d= train_early_stopping(64, X_train, y_train, X_dev,y_dev, X_test,y_test, entireContext_model, \n",
    "                                            entireContext_optimizer, criterion,  1000)\n",
    "        cur_a+=1\n",
    "        print(\"%%%%%\")\n",
    "        print(ac)\n",
    "        print(b)\n",
    "        print(c)\n",
    "        print(d)\n",
    "\n",
    "        print(\"%%%\")\n",
    "        test1_acur.append(b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(weights, 'weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_lookup = torch.load('embed_lookup.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(val_tokens1, val_tokens2,  sent_attn):\n",
    "    max_sents, batch_size, max_tokens, embed_size = val_tokens1.size()\n",
    "    y_pred = sent_attn(val_tokens1.cuda(),val_tokens2.cuda(),  max_sents)\n",
    "    return y_pred\n",
    "\n",
    "# convert reviews to tokens\n",
    "def tokenize_all_reviews(reviews_split):\n",
    "    reviews_words = reviews_split.split(' ')\n",
    "    tokenized_reviews = []\n",
    "    for review in reviews_words:\n",
    "        ints = []\n",
    "        for word in review.split(' '):\n",
    "            if(word==''):\n",
    "                continue\n",
    "            if(word=='.'):\n",
    "                continue\n",
    "            try:\n",
    "                idx = embed_lookup.vocab[word].index\n",
    "            except: \n",
    "                idx = 0\n",
    "            tokenized_reviews.append(idx)\n",
    "    return tokenized_reviews\n",
    "\n",
    "\n",
    "\n",
    "def iterate_minibatches(inputs,  batchsize, shuffle=False):\n",
    "    if shuffle:\n",
    "        indices = np.arange(inputs.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, inputs.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt]\n",
    "\n",
    "def pad_batch(mini_batch):\n",
    "    mini_batch_size = len(mini_batch)\n",
    "    max_sent_len = int(np.max([len(x) for x in mini_batch]))\n",
    "    max_token_len = int(np.max([len(val) for sublist in mini_batch for val in sublist]))\n",
    "\n",
    "    if(max_sent_len==1):\n",
    "        max_sent_len=2\n",
    "        \n",
    "    if(max_sent_len >= 50):\n",
    "        max_sent_len = 20\n",
    "    if(max_token_len >= 300):\n",
    "        max_token_len = 100\n",
    "        \n",
    "    main_matrix = np.zeros((mini_batch_size, max_sent_len, max_token_len), dtype= np.int)\n",
    "    for i in range(main_matrix.shape[0]):\n",
    "        for j in range(main_matrix.shape[1]):\n",
    "            for k in range(main_matrix.shape[2]):\n",
    "                try:\n",
    "                    main_matrix[i,j,k] = mini_batch[i][j][k]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "    return Variable(torch.from_numpy(main_matrix).transpose(0,1))\n",
    "\n",
    "def pad_batch2(mini_batch):\n",
    "    mini_batch_size = len(mini_batch)\n",
    "    max_sent_len = int(np.max([len(mini_batch[x]) for x in range(0,len(mini_batch))]))\n",
    "    if(max_sent_len==1):\n",
    "        max_sent_len=2\n",
    "        \n",
    "    if(max_sent_len >=300):\n",
    "        max_sent_len = 100\n",
    "        \n",
    "    #print(\"max_sent_len:\", max_sent_len)\n",
    "    main_matrix = np.zeros((mini_batch_size, max_sent_len), dtype= np.int)\n",
    "    for i in range(main_matrix.shape[0]):\n",
    "         for k in range(main_matrix.shape[1]):\n",
    "            try:\n",
    "                main_matrix[i,k] = mini_batch[i][k]\n",
    "            except IndexError:\n",
    "                pass\n",
    "    return Variable(torch.from_numpy(main_matrix))\n",
    "\n",
    "\n",
    "def gen_minibatch2(tokens,  mini_batch_size, shuffle= True):\n",
    "    for token in iterate_minibatches(tokens,  mini_batch_size, shuffle= shuffle):\n",
    "        token1 = pad_batch(token)\n",
    "        token_x=[]\n",
    "        for i in token:\n",
    "            c = []\n",
    "            for j in i:\n",
    "                for k in j:\n",
    "                    c.append(k)\n",
    "            token_x.append(c)\n",
    "\n",
    "        token2 = pad_batch2(token_x)\n",
    "\n",
    "        yield token1, token2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_full_batch3(a, mini_batch_size,  sent_attn):\n",
    "    a_t=' '\n",
    "    c_t=' '\n",
    "    j=[]\n",
    "    g=0\n",
    "    tokens=list()\n",
    "    tok=[]\n",
    "\n",
    "    for e in a.split(' '):\n",
    "        a_t +=e+' '\n",
    "\n",
    "        c_t = list(tokenize_all_reviews(a_t))\n",
    "        g+=1\n",
    "        if(len(c_t) <=3):\n",
    "            continue\n",
    "        if('.' in e):\n",
    "            b_t = list(tokenize_all_reviews(a_t))\n",
    "            j.append(b_t)\n",
    "            a_t=' '\n",
    "        elif('?' in e):\n",
    "            b_t = list(tokenize_all_reviews(a_t))\n",
    "            j.append(b_t)\n",
    "            a_t=' '\n",
    "        elif('!' in e):\n",
    "            b_t = list(tokenize_all_reviews(a_t))\n",
    "            j.append(b_t)\n",
    "            a_t=' '\n",
    "\n",
    "    if(len(j) == 0 ):\n",
    "        b_t = list(tokenize_all_reviews(a))\n",
    "        j.append(b_t)\n",
    "    elif(len(j) > 0 and len(a_t)>=3):\n",
    "        b_t = list(tokenize_all_reviews(a_t))\n",
    "        j.append(b_t)\n",
    "\n",
    "    print(j)\n",
    "\n",
    "    tokens.append(j)\n",
    "    tokens.append(j)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    tokens = np.array(tokens)\n",
    "    print(\"22tokens# :\", tokens.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "    sent_attn.eval()\n",
    "\n",
    "    p = []\n",
    "    p2 = []\n",
    "    l = []\n",
    "   \n",
    "    probs=[]\n",
    "   \n",
    "    g = gen_minibatch2(tokens, mini_batch_size)\n",
    "\n",
    "    for token1,token2 in g:\n",
    "        \n",
    "        embedding = nn.Embedding.from_pretrained(weights)\n",
    "        tokens1 = embedding(token1.long())\n",
    "        tokens2 = embedding(token2.long())\n",
    "        print(\"tokens1#11#: \", tokens1.shape)\n",
    "        print(\"tokens2:\", tokens2.shape)\n",
    "        y_pred3 = get_predictions(tokens1,tokens2,  sent_attn)\n",
    "\n",
    "        y_pred1=F.softmax(y_pred3)\n",
    "        _, y_pred = y_pred1.max(1)\n",
    "        print(\"##y_pred3##:\", y_pred.shape)\n",
    "            \n",
    "        \n",
    "\n",
    "    return y_pred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_every = 100\n",
    "vocab_size = 300000\n",
    "output_size = 1 # binary class (1 or 0)\n",
    "embedding_dim = 300\n",
    "num_filters = 100\n",
    "kernel_sizes = [3,4,5]\n",
    "num_layer=1\n",
    "num_classes =3\n",
    "\n",
    "entireContext_model = entireContext( )\n",
    "entireContext_model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "entireContext_model.load_state_dict(torch.load(\"abusive_detection.pt\"))\n",
    "entireContext_model.eval()\n",
    "cur2, acur,pre2, recall2 =test_accuracy_full_batch(X_test, y_test, 32,entireContext_model)\n",
    "print(\"f1-score(test) : \", cur2 ,  \"accuracy :  \", acur, \"recall :\", recall2, \"precision :\", pre2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29958, 1282, 13225, 95009, 3959, 1857, 0], [500376, 571, 0, 507, 0], [192907, 9797, 189, 0, 507, 13480, 293189, 561957, 93985, 135, 0, 130142, 0, 11215, 0, 118, 230446, 3601, 10935, 1609, 43], [29958, 5379, 3847, 1218]]\n",
      "22tokens# : (2, 4)\n",
      "tokens1#11#:  torch.Size([4, 2, 21, 300])\n",
      "tokens2: torch.Size([2, 37, 300])\n",
      "##y_pred3##: torch.Size([2])\n",
      "0\n",
      "비윤리\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dlwngud3028/venv-python3.6/lib/python3.6/site-packages/ipykernel_launcher.py:69: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "a=\"안철수 부인 다운 계약서 작성 시인 매입. 실거래가 보다 4억 원 정도.. 낮춰서 신고 약 2000만 원 세금 탈루 탈세가 드러날 경우 일벌백계로 엄중하게 처벌해서 세금을 떼먹는 것은 엄두도 내지 못하도록 해야 한다 . 안철수 본인 저서 中\"\n",
    "prediction =test_accuracy_full_batch3(a, 2,entireContext_model)\n",
    "print(prediction[0].item())\n",
    "if(prediction[0].item()==0.0):\n",
    "    print(\"비윤리\")\n",
    "elif(prediction[0].item()==1.0):\n",
    "    print(\"윤리\")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
